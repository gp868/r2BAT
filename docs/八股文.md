# 🔥八股文

# 计算机网络

## 复习指南

**应用层** 

（1）另一个最最最常问的问题，在浏览器中输入 URL 地址到浏览器显示网页这个过程中计算机网络做了什么。

这个问题无论是考研还是找工作都是常见的，建议把 JavaGuide 中这个问题的总结熟读并全文背诵。

（2）HTTP 1.0 和 HTTP 1.1 的主要区别这个也要了解一下。

（3）HTTP 和 HTTPS 的区别这个也是面试常考问题，这个问题展开以后能问的就比较多了。

在回答这个问题时你首先分别介绍一下**HTTP 和 HTTPS 的原理以及区别**。大致就是 HTTP 是通过明文在网络上传输的，HTTPS 是加密的。有的面试官问到这也就可以了，有的面试官不讲武德，想搞偷袭，会继续让你讲 **HTTPS 建立连接的流程**、然后会继续追着你问**SSL 的工作流程**。建议把这里好好准备一下，面试官一问你就可以展开讲，你就能消耗很多面试时间，这样面试官问其它问题的时间就少了，嘿嘿。

（4）HTTP请求常见的状态码背几个常用的就好。

（5）DNS域名系统这里你要可以描述清楚工作原理，也是面试常问问题。

**传输层**

面试中计算机网络的问题最常出现在这一章中。

1. 记清楚 TCP 和 UDP 的区别。
2. TCP三次握手和UDP四次挥手。

这是面试计算机网络最最最常问的问题！！！你计算机网络就算其它的什么也不会，这个问题你必须要记清楚，如果面试官问出你这个问题你都答不上，面试官估计觉得你连敷衍都不想敷衍他了。

当面试官问你三次握手和四次挥手时，你要答出这三个点来：

（1）为什么要三次挥手和四次挥手，如果不这样做会有什么影响。

（2）三次握手四次挥手的整个流程。

（3）有的面试官只要你答出三次握手和四次挥手的大体流程就好了，但是有的面试官会要求你答出三次握手和四次挥手时发送端和接收端分别发了哪些标记。

3. TCP协议如何保证可靠传输

把 ARQ 协议、滑动窗口、流量控制、拥塞控制等回答清楚就算到位了。

**网络层**

网络层面试问的也相对较少，主要就是问IPV4，偶尔问一下ARP地址解析协议的的工作原理。

1. 首先要记清楚 IPV4 地址是怎么分类的、以及地址的格式。这里经常结合代码题一起问你，我和很多同学都在面试中被面试官要求写一个程序判断给定的字符串是否是 IPV4 地址。
2. IPV4 子网划分面试中不怎么问，笔试题时经常有这个问题。
3. 了解 IP 地址和 Mac 地址的区别，了解 ARP 地址解析协议并了解其工作原理。

**网络接口层**

把网卡、网桥、交换机的概念、用途简单了解下就好，一般面试官不会问。

## 键入网址到网页显示，期间发生了什么？

1. 浏览器解析`url`；
2. 生成一个`http`请求协议包，把协议包的发送委托给操作系统；
3. 操作系统在发送协议包之前先要获取服务器的IP地址。如果在本地的浏览器缓存、操作系统缓存或者hosts文件中存在对应的IP地址，就不需要再访问本地的DNS服务器了。如果不存在，访问本地的DNS服务器，由本地DNS服务器对进行递归访问，即按照层级向下访问，最后得到IP地址；
4. 得到ip地址后。进行TCP连接，三次握手；
5. 握手之后，把请求层层封装，通过网卡将数据发送到交换机。交换机会进行校验以及查找交换表转发，到达路由器。路由器把MAC层扒皮，查看目的ip，然后根据路由表选择下一跳，再进行MAC层封装。重复这个过程，最后到达服务器；
6. 到达服务器后，会对数据包进行扒皮并且校验。使用FCS校验码校验二进制序列的正确性。在MAC层看目的MAC是不是自己，在网络层看目的ip是不是自己，同时知道上层协议是TCP还是UDP协议。在TCP中知道这是一个什么保文，请求保文、响应报文还是结束连接的报文。通过端口号知道这是交给那么应用进程的；
7. 应用进程知道你访问的是什么资源，那么就给客户端返回一个Http响应协议包，把资源封装在其中。通过同样的流程把数据返回给客户端；
8. 浏览器拿到数据后，对数据进行渲染，解码，变成了一个页面显示在浏览器上。

## HTTP状态码

<div align=center><img src="https://cdn.jsdelivr.net/gh/CARLOSGP2021/myFigures/img/202205101656585.png" alt=" 五大类 HTTP 状态码 " style="zoom:50%;" /></div>

`1xx` 类状态码属于**提示信息**，是协议处理中的一种中间状态，实际用到的比较少。

`2xx` 类状态码表示服务器**成功**处理了客户端的请求，也是我们最愿意看到的状态。

- 「**200 OK**」是最常见的成功状态码，表示一切正常。如果是非 `HEAD` 请求，服务器返回的响应头都会有 body 数据。
- 「**204 No Content**」也是常见的成功状态码，与 200 OK 基本相同，但响应头没有 body 数据。
- 「**206 Partial Content**」是应用于 HTTP 分块下载或断点续传，表示响应返回的 body 数据并不是资源的全部，而是其中的一部分，也是服务器处理成功的状态。

`3xx` 类状态码表示客户端请求的资源发生了变动，需要客户端用新的 URL 重新发送请求获取资源，也就是**重定向**。

- 「**301 Moved Permanently**」表示永久重定向，说明请求的资源已经不存在了，需改用新的 URL 再次访问。
- 「**302 Found**」表示临时重定向，说明请求的资源还在，但暂时需要用另一个 URL 来访问。

301 和 302 都会在响应头里使用字段 `Location`，指明后续要跳转的 URL，浏览器会自动重定向新的 URL。

- 「**304 Not Modified**」不具有跳转的含义，表示资源未修改，重定向已存在的缓冲文件，也称缓存重定向，也就是告诉客户端可以继续使用缓存资源，用于缓存控制。

`4xx` 类状态码表示客户端发送的**报文有误**，服务器无法处理，也就是错误码的含义。

- 「**400 Bad Request**」表示客户端请求的报文有错误，但只是个笼统的错误。
- 「**403 Forbidden**」表示服务器禁止访问资源，并不是客户端的请求出错。
- 「**404 Not Found**」表示请求的资源在服务器上不存在或未找到，所以无法提供给客户端。

`5xx` 类状态码表示客户端请求报文正确，但是**服务器处理时内部发生了错误**，属于服务器端的错误码。

- 「**500 Internal Server Error**」与 400 类型，是个笼统通用的错误码，服务器发生了什么错误，我们并不知道。
- 「**501 Not Implemented**」表示客户端请求的功能还不支持，类似“即将开业，敬请期待”的意思。
- 「**502 Bad Gateway**」通常是服务器作为网关或代理时返回的错误码，表示服务器自身工作正常，访问后端服务器发生了错误。
- 「**503 Service Unavailable**」表示服务器当前很忙，暂时无法响应客户端，类似“网络服务正忙，请稍后重试”的意思。

## GET和POST的区别

GET和POST是HTTP协议中的两种发送请求的方法。GET和POST本质上就是TCP链接，并无差别。但是由于HTTP的规定和浏览器/服务器处理数据能力的限制，导致他们在应用过程中体现出一些不同。

首先，HTTP对GET和POST参数的传送渠道（url还是requrest body）提出了要求：GET把参数包含在**URL**中，POST通过**消息体**传递参数。GET主要是用来获取新的网页；POST用作向服务器传递用户的表单数据，如用户名、密码、留言等等。

其次，GET和POST参数大小的限制不同：GET请求在URL中传送的参数是有长度限制的，而POST通过**消息体**传递的参数没有长度限制。

此外，GET和POST还有一个**重大区别**：GET产生一个TCP数据包，而POST产生两个TCP数据包。

对于GET请求，浏览器会把请求头和消息体一并发送出去，服务器响应200 ok（返回数据）；而对于POST请求，浏览器先发送请求头，服务器响应100 continue后，浏览器再发送消息体，服务器响应200 ok（返回数据）。

其他的区别：GET请求参数会被完整保留在浏览器历史记录里，而POST中的参数不会被保留；对参数的数据类型，GET只接受ASCII字符，而POST没有限制。

------

POST需要两步，时间上消耗的要多一点，看起来GET比POST更有效，因此Yahoo团队有推荐用GET替换POST来优化网站性能。但这是一个坑！跳入需谨慎。为什么？

1. GET与POST都有自己的语义，不能随便混用。
2. 据研究，在网络环境好的情况下，发一次包的时间和发两次包的时间差别基本可以无视。而在网络环境差的情况下，两次包的TCP在验证数据包完整性上，有非常大的优点。
3. 并不是所有浏览器都会在POST中发送两次包，Firefox就只发送一次。

[GET和POST两种基本请求方法的区别 - 在途中# - 博客园 (cnblogs.com)](https://www.cnblogs.com/logsharing/p/8448446.html)

## HTTP（1.1）特性

### 优缺点

- **优点**

1. **简单**

HTTP 基本的报文格式就是 `header + body`，头部信息也是 `key-value` 简单文本的形式，很简单。

2. **灵活和易于扩展**

HTTP协议里的各类请求方法、状态码、头字段等都是可以自定义扩展的；同时 HTTP 工作在应用层，下层可以随意变化。

3. **应用广泛和跨平台**

- **缺点**

1. **无状态**

服务器不会去记忆 HTTP 的状态，所以不需要额外的资源来记录状态信息，但是会导致它在完成有关联性的操作时会非常麻烦。例如登录->添加购物车->下单->结算->支付，这系列操作都要知道用户的身份才行。 但服务器不知道这些请求是有关联的，每次都要问一遍身份信息。

无状态的问题解决方法有`cookie/session/token`，`Cookie` 通过在请求和响应报文中写入 Cookie 信息来控制客户端的状态。

2. **明文传输**

明文意味着在传输过程中的信息是可阅读的， 通过F12 控制台或 Wireshark 抓包都可以直接查看， 方便调试，但是也导致了信息泄露。明文传输的问题在`https`协议中得到了解决。

3. **不安全**

HTTP 比较严重的缺点就是不安全：通信使用明文传输，内容可能会被窃听；不验证通信方的身份，因此有可能遭遇伪装； 无法证明报文的完整性，所以有可能已遭篡改。

HTTP 的安全问题，可以用 `HTTPS`的方式解决，也就是通过引入 SSL/TLS 层，使得在安全上达到了极致。

### 性能

1. **长连接**

> `HTTP/1.0` 规定浏览器与服务器只保持短暂的连接，浏览器的每次请求都需要与服务器建立一个TCP连接，服务器完成请求处理后立即断开TCP连接，每个TCP连接只能发送一个请求。发送数据完毕，连接就关闭，如果还要请求其他资源，就必须再新建一个连接。 TCP连接的建立需要三次握手，通信开销比较大。所以，HTTP/1.0版本的性能比较差。

为了解决上述 TCP 连接问题，`HTTP/1.1`提出了**长连接**的通信方式，也叫持久连接。这种方式的好处在于减少了 TCP 连接的重复建立和断开所造成的额外开销，减轻了服务器的负载。

持久连接的特点是，只要任意一端没有明确提出断开连接，则保持 TCP 连接状态。当然，如果某个 HTTP 长连接超过一定时间没有任何数据交互，服务端就会主动断开这个连接。

- **管道网络传输**

HTTP/1.1 采用了长连接的方式，这使得**管道网络传输**成为了可能。即可在同一个 TCP 连接里面，客户端可以发起多个请求，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以**减少整体的响应时间**。

但是服务器必须按照接收请求的顺序发送对这些管道化请求的响应，如果服务端在处理 A 请求时耗时比较长，那么后续的请求的处理都会被阻塞，造成「**队头阻塞**」。所以，**HTTP/1.1 管道解决了请求的队头阻塞，但是没有解决响应的队头阻塞**。

- **队头阻塞**

当顺序发送的请求序列中的一个请求因为某种原因被阻塞时，在后面排队的所有请求也一同被阻塞了，会招致客户端一直请求不到数据，这也就是「**队头阻塞**」。

##  HTTPS特性

### HTTP 与 HTTPS 有哪些区别？

1. HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP 网络层之间加入了 `SSL/TLS` 安全协议，使得报文能够加密传输。
2. HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 `SSL/TLS` 的握手过程，才可进入加密报文传输。
3. HTTP 的端口号是 80，HTTPS 的端口号是 443。
4. HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。

### HTTPS 如何解决HHTP的三个安全风险？

1. **混合加密**的方式实现信息的**机密性**，解决了**窃听**的风险；
2. 将服务器公钥放入到**数字证书**中，解决了**冒充**的风险；
3. **摘要算法**的方式来实现**完整性**，它能够为数据生成独一无二的「**指纹**」，指纹用于校验数据的完整性，解决了**篡改**的风险。

HTTPS 采用的是**对称加密**和**非对称加密**结合的「混合加密」方式：

- 在通信建立前采用**非对称加密**的方式交换「会话秘钥」，后续就不再使用非对称加密。
- 在通信过程中全部使用**对称加密**的「会话秘钥」的方式加密明文数据。

采用「混合加密」的方式的原因：

- **对称加密**只使用一个密钥，运算速度快，密钥必须保密，无法做到安全的密钥交换。
- **非对称加密**使用两个密钥：公钥和私钥，公钥可以任意分发而私钥保密，解决了密钥交换问题但速度慢。

### HTTPS 的优缺点

- 优点

1. HTTPS传输数据过程中使用密钥进行加密，所以安全性更高；

2. HTTPS协议可以认证用户和服务器，确保数据发送到正确的用户和服务器。

- 缺点

1. HTTPS握手阶段延时较高：由于在进行HTTP会话之前还需要进行SSL握手，因此HTTPS协议握手阶段延时增加；

2. HTTPS部署成本高：一方面HTTPS协议需要使用证书来验证自身的安全性，所以需要购买CA证书；另一方面由于采用HTTPS协议需要进行加解密的计算，占用CPU资源较多，需要的服务器配置或数目高。

### HTTPS连接建立过程及SSL工作流程

SSL/TLS 协议基本流程：

- 客户端向服务器索要并验证服务器的公钥。
- 双方协商生产「会话秘钥」。
- 双方采用「会话秘钥」进行加密通信。

前两步也就是 SSL/TLS 的建立过程，也就是 TLS 握手阶段，SSL/TLS 的「握手阶段」涉及**四次**通信。SSL/TLS 协议建立的详细流程：

1. **ClientHello**

首先，由客户端向服务器发起加密通信请求，也就是 `ClientHello` 请求。

在这一步，客户端主要向服务器发送以下信息：

（1）客户端支持的 SSL/TLS 协议版本，如 TLS 1.2 版本。

（2）客户端生产的随机数（`Client Random`），后面用于生成「会话秘钥」条件之一。

（3）客户端支持的密码套件列表，如 RSA 加密算法。

2. **SeverHello**

服务器收到客户端请求后，向客户端发出响应，也就是 `SeverHello`。服务器回应的内容有如下内容：

（1）确认 SSL/ TLS 协议版本，如果浏览器不支持，则关闭加密通信。

（2）服务器生产的随机数（`Server Random`），也是后面用于生产「会话秘钥」条件之一。

（3）确认的密码套件列表，如 RSA 加密算法。

（4）服务器的数字证书。

3. **客户端回应**

客户端收到服务器的回应之后，首先通过浏览器或者操作系统中的 CA 公钥，确认服务器的数字证书的真实性。

如果证书没有问题，客户端会**从数字证书中取出服务器的公钥**，然后使用它加密报文，向服务器发送如下信息：

（1）一个随机数（`pre-master key`）。该随机数会被服务器公钥加密。

（2）加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。

（3）客户端握手结束通知，表示客户端的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供服务端校验。

上面第一项的随机数是整个握手阶段的第三个随机数，会发给服务端，所以这个随机数客户端和服务端都是一样的。

**服务器和客户端有了这三个随机数（Client Random、Server Random、pre-master key），接着就用双方协商的加密算法，各自生成本次通信的「会话秘钥」**。

4. **服务器的最后回应**

服务器收到客户端的第三个随机数（`pre-master key`）之后，通过协商的加密算法，计算出本次通信的「会话秘钥」。

然后，向客户端发送最后的信息：

（1）加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。

（2）服务器握手结束通知，表示服务器的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供客户端校验。

至此，整个 SSL/TLS 的握手阶段全部结束。接下来，客户端与服务器进入加密通信，就完全是使用普通的 HTTP 协议，只不过用「会话秘钥」加密内容。

## HTTP/1.1、HTTP/2、HTTP/3的演变

### HTTP/1.1 相比 HTTP/1.0 提高了什么性能？

- 使用 TCP 长连接的方式改善了 HTTP/1.0 短连接造成的性能开销。
- 支持管道（pipeline）网络传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。

### HTTP/2 做了什么优化？

HTTP/2 协议是基于 HTTPS 的，所以 HTTP/2 的安全性也是有保障的。

那 HTTP/2 相比 HTTP/1.1 性能上的改进：

1. **头部压缩**

HTTP/2 会**压缩头**，如果同时发出多个请求，如果请求头是一样的或是相似的，那么会消除重复的部分。

这就是所谓的 `HPACK` 算法：在客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就提高速度了。

2. **二进制格式**

HTTP/2 不再像 HTTP/1.1 里的纯文本形式的报文，而是采用了**二进制格式**，头信息和数据体都是二进制（统称为**帧**：头信息帧和数据帧）。收到报文后，无需再将明文的报文转成二进制，而是直接解析二进制报文，增加了数据传输的效率。

3. **数据流**

HTTP/2 的数据包不是按顺序发送的，同一个连接里面连续的数据包，可能属于不同的回应。因此，必须要对数据包做标记，指出它属于哪个回应。

在 HTTP/2 中每个请求或相应的所有数据包，称为一个数据流（`Stream`）。每个数据流都标记着一个独一无二的编号（Stream ID），**不同 Stream 的帧是可以乱序发送的（因此可以并发不同的 Stream ）**，因为每个帧的头部会携带 Stream ID 信息，所以接收端可以通过 Stream ID 有序组装成 HTTP 消息。

4. **多路复用**

HTTP/2 可以在一个连接中并发多个请求或回应，而不用按照顺序一一对应。移除了 HTTP/1.1 中的串行请求，不需要排队等待，也就不会再出现「**队头阻塞**」问题，降低了延迟，大幅度提高了连接的利用率。

5. **服务器推送**

HTTP/2 还在一定程度上改善了传统的「请求 - 应答」工作模式，服务不再是被动地响应，也可以**主动**向客户端发送消息。

### HTTP/2的缺陷

HTTP/2 还是存在**队头阻塞**的问题，只不过问题不是在 HTTP 这一层面，而是在 **TCP**这一层。

HTTP/2 是基于 TCP 协议来传输数据的，TCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且连续的，这样内核才会将缓冲区里的数据返回给 HTTP 应用。当前一个字节数据没有到达时，后收到的字节数据只能存放在内核缓冲区里，只有等到这一个字节数据到达时，HTTP/2 应用层才能从内核中拿到数据，这就是 **HTTP/2 队头阻塞**问题。

所以，一旦发生了丢包现象，就会触发 TCP 的**重传机制**，这样在一个 TCP 连接中的所有的 HTTP 请求都必须等待这个丢了的包被重传回来。

### HTTP/3 做了哪些优化？

 HTTP/1.1 和 HTTP/2 都有队头阻塞的问题：

- HTTP/1.1 中的管道虽然解决了请求的队头阻塞，但是**没有解决响应的队头阻塞**，因为服务端需要按顺序响应收到的请求，如果服务端处理某个请求消耗的时间比较长，那么只能等相应完这个请求后， 才能处理下一个请求，这属于 HTTP 层队头阻塞。
- HTTP/2 虽然通过多个请求复用一个 TCP 连接解决了 HTTP 的队头阻塞 ，但是**一旦发生丢包，就会阻塞住所有的 HTTP 请求**，这属于 TCP 层队头阻塞。

HTTP/2 队头阻塞的问题是因为 TCP，所以 **HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP**。

UDP的发生是不管顺序，也不管丢包的，所以不会出现像 HTTP/2 队头阻塞的问题。虽然 UDP 是不可靠传输的，但基于 UDP 的 **QUIC 协议** 可以实现类似 TCP 的可靠性传输。QUIC 有以下 3 个特点：

1. **无队头阻塞**

QUIC 连接上**当某个数据流发生丢包时，只会阻塞这个数据流，其他数据流不会受到影响，因此不存在队头阻塞问题**。这与 HTTP/2 不同，HTTP/2 只要某个数据流中的数据包丢失了，其他数据流也会因此受影响。

2. **更快的连接建立**

但是 HTTP/3 的 QUIC 协议并不是与 TLS 分层，而是QUIC 内部包含了 TLS，它在自己的帧会携带 TLS 里的“记录”，再加上 QUIC 使用的是 TLS/1.3，因此仅需 1 个 RTT 就可以「同时」完成建立连接与密钥协商。

3. **连接迁移**

基于 TCP 传输协议的 HTTP 协议，由于是通过四元组（源 IP、源端口、目的 IP、目的端口）确定一条 TCP 连接，那么**当移动设备的网络从 4G 切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建立连接**。而建立连接的过程包含 TCP 三次握手和 TLS 四次握手的时延，以及 TCP 慢启动的减速过程，给用户的感觉就是网络突然卡顿了一下，因此连接的迁移成本是很高的。

而 QUIC 协议没有用四元组的方式来“绑定”连接，而是通过**连接 ID**来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本，没有丝毫卡顿感，达到了**连接迁移**的功能。

所以， QUIC 是一个在 UDP 之上的**伪** TCP + TLS + HTTP/2 的多路复用的协议。

QUIC 是新协议，对于很多网络设备，根本不知道什么是 QUIC，只会当做 UDP，这样会出现新的问题，因为有的网络设备是会丢掉 UDP 包的，而 QUIC 是基于UDP 实现的，那么如果网络设备无法识别这个是 QUIC 包，那么就会当作 UDP包，然后被丢弃。

所以，HTTP/3 现在普及的进度非常的缓慢，不知道未来 UDP 是否能够逆袭 TCP。

## UDP 和 TCP 有什么区别呢？分别的应用场景是？

**TCP 和 UDP 区别：**

1. **连接**

- TCP 是面向连接的传输层协议，传输数据前先要建立连接。
- UDP 是不需要连接，即刻传输数据。

2. **服务对象**

- TCP 是一对一的两点服务，即一条连接只有两个端点。
- UDP 支持一对一、一对多、多对多的交互通信

3. **可靠性**

- TCP 是可靠交付数据的，数据可以无差错、不丢失、不重复、按需到达。
- UDP 是尽最大努力交付，不保证可靠交付数据。

4. **拥塞控制、流量控制**

- TCP 有拥塞控制和流量控制机制，保证数据传输的安全性。
- UDP 则没有，即使网络非常拥堵了，也不会影响 UDP 的发送速率。

5. **首部开销**

- TCP 首部长度较长，会有一定的开销，首部在没有使用「选项」字段时是 `20` 个字节，如果使用了「选项」字段则会变长的。
- UDP 首部只有 8 个字节，并且是固定不变的，开销较小。

6. **传输方式**

- TCP 是流式传输，没有边界，但保证顺序和可靠。
- UDP 是一个包一个包的发送，是有边界的，但可能会丢包和乱序。

7. **分片不同**

- TCP 的数据大小如果大于 MSS 大小，则会在传输层进行分片，目标主机收到后，也同样在传输层组装 TCP 数据包，如果中途丢失了一个分片，只需要传输丢失的这个分片。
- UDP 的数据大小如果大于 MTU 大小，则会在 IP 层进行分片，目标主机收到后，在 IP 层组装完数据，接着再传给传输层。

**TCP 和 UDP 应用场景：**

由于 TCP 是面向连接，能保证数据的可靠性交付，因此经常用于：

- `FTP` 文件传输；
- HTTP / HTTPS；

由于 UDP 面向无连接，它可以随时发送数据，再加上UDP本身的处理既简单又高效，因此经常用于：

- 包总量较少的通信，如 `DNS` 、`SNMP` 等；
- 视频、音频等多媒体通信；
- 广播通信；

## TCP三次握手

### TCP三次握手过程

- 一开始，客户端和服务端都处于 `CLOSED` 状态。先是服务端主动监听某个端口，处于 `LISTEN` 状态；
- 客户端会随机初始化序号为`x`，将此序号置于 TCP 首部的「序号」字段中，同时把 `SYN` 标志位置为 `1` ，表示 `SYN` 报文。接着把第一个 SYN 报文发送给服务端，表示向服务端发起连接，该报文不包含应用层数据，之后客户端处于 `SYN-SENT` 状态；
- 服务端收到客户端的 `SYN` 报文后，首先服务端也随机初始化自己的序号为`y`，将此序号填入 TCP 首部的「序号」字段中，其次把 TCP 首部的「确认应答号」字段填入 `x + 1`, 接着把 `SYN` 和 `ACK` 标志位置为 `1`。最后把该报文发给客户端，该报文也不包含应用层数据，之后服务端处于 `SYN-RCVD` 状态；
- 客户端收到服务端报文后，还要向服务端回应最后一个应答报文，首先将应答报文 TCP 首部 `ACK` 标志位置为 `1` ，其次「确认应答号」字段填入 `y + 1` ，最后把报文发送给服务端，这次报文可以携带客户到服务器的数据，之后客户端处于 `ESTABLISHED` 状态；
- 服务器收到客户端的应答报文后，也进入 `ESTABLISHED` 状态。

从上面的过程可以发现**第三次握手是可以携带数据的，前两次握手是不可以携带数据的**，这也是面试常问的题。

一旦完成三次握手，双方都处于 `ESTABLISHED` 状态，此时连接就已建立完成，客户端和服务端就可以相互发送数据了。

### 为什么是三次握手？不是两次、四次？

- **防止历史连接的建立**（主要原因）

客户端连续发送多次 SYN 建立连接的报文，在**网络拥堵**情况下：一个「旧 SYN 报文」比「最新的 SYN 」 报文早到达了服务端，那么此时服务端就会回一个 `SYN + ACK` 报文给客户端。客户端收到后可以根据自身的上下文，判断这是一个历史连接（序列号过期或超时），那么客户端就会发送 `RST` 报文给服务端，表示中止这一次连接。

**如果是两次握手连接，就无法阻止历史连接**，那为什么 TCP 两次握手为什么无法阻止历史连接呢？

主要是因为**在两次握手的情况下，服务端没有中间状态给客户端来阻止历史连接，导致服务端可能建立一个历史连接，造成资源浪费**。

两次握手的情况下，服务端在收到 SYN 报文后，就进入 ESTABLISHED 状态，意味着这时可以给对方发送数据，但是客户端此时还没有进入 ESTABLISHED 状态。假设这次是历史连接，客户端判断到此次连接为历史连接，那么就会回 RST 报文来断开连接，而服务端在第一次握手的时候就进入 ESTABLISHED 状态，所以它可以发送数据的，但是它并不知道这个是历史连接，它只有在收到 RST 报文后，才会断开连接。

可以看到，上面这种场景下，服务端在向客户端发送数据前，并没有阻止掉历史连接，导致服务端建立了一个历史连接，又白白发送了数据，妥妥地浪费了服务端的资源。

因此，**要解决这种现象，最好就是在服务端发送数据前，也就是建立连接之前，要阻止掉历史连接，这样就不会造成资源浪费，而要实现这个功能，就需要三次握手**。

- **同步双方的初始序列号**

TCP 协议的通信双方， 都必须维护一个「序列号」， 序列号是可靠传输的一个关键因素，它的作用：

1. 接收方可以去除重复的数据；

2. 接收方可以根据数据包的序列号按序接收；

3. 可以标识发送出去的数据包中， 哪些是已经被对方收到的（通过 ACK 报文中的序列号知道）；

可见，序列号在 TCP 连接中占据着非常重要的作用，所以当客户端发送携带「初始序列号」的 `SYN` 报文的时候，需要服务端回一个 `ACK` 应答报文，表示客户端的 SYN 报文已被服务端成功接收，那当服务端发送「初始序列号」给客户端的时候，依然也要得到客户端的应答回应，**这样一来一回，才能确保双方的初始序列号能被可靠的同步。**

四次握手其实也能够可靠的同步双方的初始化序号，但由于**第二步和第三步可以优化成一步**，所以就成了「三次握手」。

而两次握手只保证了一方的初始序列号能被对方成功接收，没办法保证双方的初始序列号都能被确认接收。

- **避免资源浪费**

如果只有「两次握手」，当客户端的 `SYN` 请求连接在网络中阻塞，客户端没有接收到 `ACK` 报文，就会重新发送 `SYN` ，由于没有第三次握手，服务器不清楚客户端是否收到了自己发送的建立连接的 `ACK` 确认信号，所以每收到一个 `SYN` 就只能先主动建立一个连接，这会造成什么情况呢？

如果客户端的 `SYN` 阻塞了，重复发送多次 `SYN` 报文，那么服务器在收到请求后就会**建立多个冗余的无效链接，造成不必要的资源浪费。**

即两次握手会造成消息滞留情况下，服务器重复接受无用的连接请求 `SYN` 报文，而造成重复分配资源。

**总结**：不使用「两次握手」和「四次握手」的原因：

- 「两次握手」：无法防止历史连接的建立，会造成双方资源的浪费，也无法可靠的同步双方序列号；
- 「四次握手」：三次握手就已经理论上最少可靠连接建立，所以不需要使用更多的通信次数。

### 第三次握手丢失会发生什么？

客户端收到服务端的 SYN-ACK 报文后，就会给服务端回一个 ACK 报文，也就是第三次握手，此时客户端状态进入到 `ESTABLISH` 状态。

因为这个第三次握手的 ACK 是对第二次握手的 SYN 的确认报文，所以当第三次握手丢失了，如果服务端那一方迟迟收不到这个确认报文，就会触发超时重传机制，重传 SYN-ACK 报文，直到收到第三次握手，或者达到最大重传次数。

注意，**ACK 报文是不会有重传的，当 ACK 丢失了，就由对方重传对应的报文**。

## TCP四次挥手

### TCP四次挥手过程

- 客户端打算关闭连接，此时会发送一个 TCP 首部 `FIN` 标志位被置为 `1` 的报文，也即 `FIN` 报文，之后客户端进入 `FIN_WAIT_1` 状态。
- 服务端收到该报文后，就向客户端发送 `ACK` 应答报文，接着服务端进入 `CLOSED_WAIT` 状态。
- 客户端收到服务端的 `ACK` 应答报文后，之后进入 `FIN_WAIT_2` 状态。
- 等待服务端处理完数据后，也向客户端发送 `FIN` 报文，之后服务端进入 `LAST_ACK` 状态。
- 客户端收到服务端的 `FIN` 报文后，回一个 `ACK` 应答报文，之后进入 `TIME_WAIT` 状态
- 服务器收到了 `ACK` 应答报文后，就进入了 `CLOSED` 状态，至此服务端已经完成连接的关闭。
- 客户端在经过 `2MSL` 一段时间后，自动进入 `CLOSED` 状态，至此客户端也完成连接的关闭。

每个方向都需要**一个 FIN 和一个 ACK**，因此通常被称为**四次挥手**。这里一点需要注意是：**主动关闭连接的，才有 TIME_WAIT 状态。**

### 为什么挥手需要四次？

再来回顾下四次挥手双方发 `FIN` 包的过程，就能理解为什么需要四次了。

- 关闭连接时，客户端向服务端发送 `FIN` 时，仅仅表示客户端不再发送数据了但是还能接收数据。
- 服务器收到客户端的 `FIN` 报文时，先回一个 `ACK` 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 `FIN` 报文给客户端来表示同意现在关闭连接。

从上面过程可知，服务端通常需要等待完成数据的发送和处理，所以服务端的 `ACK` 和 `FIN` 一般都会分开发送，从而比三次握手导致多了一次。

### 为什么需要 TIME_WAIT 状态？

主动发起关闭连接的一方，才会有 `TIME-WAIT` 状态。需要 TIME-WAIT 状态，主要是两个原因：

- 防止历史连接中的数据，被后面相同四元组的连接错误的接收；

为了防止历史连接中的数据，被后面相同四元组的连接错误的接收，因此 TCP 设计了 TIME_WAIT 状态，状态会持续 `2MSL` 时长，这个时间**足以让两个方向上的数据包都被丢弃，使得原来连接的数据包在网络中都自然消失，再出现的数据包一定都是新建立连接所产生的。**

- 保证「被动关闭连接」的一方，能被正确的关闭；

TIME-WAIT 作用是**等待足够的时间以确保最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭。**

## TCP如何保证可靠性

### 重传机制

TCP 实现可靠传输的方式之一，是通过序列号与确认应答。在 TCP 中，当发送端的数据到达接收主机时，接收端主机会返回一个确认应答消息，表示已收到消息。 TCP 针对数据包丢失的情况，会用**重传机制**解决，常见的有超时重传、快速重传、SACK方法、 Duplicate SACK。

- **超时重传**

超时重传就是在发送数据时，设定一个定时器，当超过指定的时间后，没有收到对方的 `ACK` 确认应答报文，就会重发该数据，超时重传时间 RTO 的值应该略大于报文往返 RTT 的值。

如果超时重发的数据，再次超时的时候，又需要重传的时候，TCP 的策略是**超时间隔加倍**，也就是每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍。两次超时，就说明网络环境差，不宜频繁反复发送。

超时触发重传存在的问题是，超时周期可能相对较长。那是不是可以有更快的方式呢？——快速重传

- **快速重传**

快速重传**不以时间为驱动，而是以数据驱动重传**。快速重传的工作方式是当收到三个相同的 ACK 报文时，会在定时器过期之前，重传丢失的报文段。

快速重传机制解决了超时时间的问题，但是它依然面临着另外一个问题：就是**重传的时候，是重传之前的一个，还是重传所有的问题。**为了解决不知道该重传哪些 TCP 报文的问题，于是就有 `SACK` 方法。

- **SACK方法**

`SACK`（ Selective Acknowledgment 选择性确认），这种方式需要在 TCP 头部「选项」字段里加一个 `SACK` 的东西，它**可以将缓存的地图发送给发送方**，这样发送方就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以**只重传丢失的数据**。

- **Duplicate SACK**

Duplicate SACK 又称 `D-SACK`，其主要**使用了 SACK 来告诉「发送方」有哪些数据被重复接收了。**

### 滑动窗口

TCP 会利用窗口控制来提高传输速度，在一个窗口大小内，不用等到应答返回就能发送下一段数据，窗口大小就是无需等待确认而可以继续发送数据的最大值。如果不使用窗口控制，每一个没收到确认应答的数据都要重发。

### 流量控制

流量控制就是让发送方的发送速率不要太快，防止接收方接受窗口溢出产生丢包，既要让接收方来得及接收，也不要使网络发生拥塞。利用滑动窗口机制可以很方便地在 TCP 连接上实现流量控制。

发送方维护一个发送窗口，发送窗口的大小表示在未收到接收方发来确认的情况下，最多还可以发送多少个帧。只有接收窗口向前滑动时（并且接收方发送了确认），发送窗口才有可能（只有发送方收到确认才是一定）向前滑动。

接收方维护一个接收窗口，只有当接收到的帧的序号落入接收窗口内才收下该帧，将接收窗口向前滑动一个位置，并给发送方发回确认。若接收到的顿的序号落在接收窗口之外，则一律将其丢弃。

### 拥塞控制

在网络出现拥堵时，如果继续发送大量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据，但是一重传就会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，这个情况就会进入恶性循环被不断地放大。于是，就有了**拥塞控制**，控制的目的就是**避免「发送方」的数据填满整个网络。**

发送方维护一个拥塞窗口，它的大小会随着网络的拥塞程度动态变化的。只要网络中没有出现拥塞，窗口大小就会增大；但网络中出现了拥塞，窗口大小就会减少。

拥塞控制主要是四个算法：**慢启动、拥塞避免、拥塞发生、快速恢复**。

**慢启动**算法的规则：当发送方每收到一个 ACK，拥塞窗口大小就会加 1，会导致发包个数呈**指数性**的增长。

拥塞窗口大小低于慢启动门限时采用慢启动算法，超过慢启动门限时采用拥塞避免算法。

**拥塞避免**算法的规则是：**每当收到一个 ACK 时，cwnd 增加 1/cwnd。**拥塞避免算法就是将原本慢启动算法的指数增长变成了**线性增长**，还是增长阶段，但是增长速度缓慢了一些。就这么一直增长着后，网络就会慢慢进入了拥塞的状况了，于是就会出现丢包现象，这时就需要对丢失的数据包进行重传。当触发了重传机制，也就进入了「拥塞发生算法」。

当网络出现拥塞，也就是会发生数据包重传，重传机制主要有两种：超时重传、快速重传。

这两种使用的拥塞发送算法是不同的，接下来分别来说说。

> 发生**超时重传**的拥塞发生算法

当发生了「超时重传」，则就会使用拥塞发生算法。这个时候，`ssthresh`和 `cwnd `的值会发生变化：

- `ssthresh` 设为 `cwnd/2`，
- `cwnd` 重置为 `1`

接着，就重新开始慢启动，慢启动是会突然减少数据流的。这真是一旦「超时重传」，马上回到解放前。但是这种方式太激进了，反应也很强烈，会造成网络卡顿。

> 发生**快速重传**的拥塞发生算法

还有更好的方式，前面我们讲过「快速重传算法」。当接收方发现丢了一个中间包的时候，发送三次前一个包的 ACK，于是发送端就会快速地重传，不必等待超时再重传。

TCP 认为这种情况不严重，因为大部分没丢，只丢了一小部分，则 `ssthresh` 和 `cwnd` 变化如下：

- `cwnd = cwnd/2` ，也就是设置为原来的一半;
- `ssthresh = cwnd`;
- 进入快速恢复算法，重新进入拥塞避免状态

## IP（网络层） 和 MAC （数据链路层）之间的区别和关系

MAC 的作用则是实现「直连」的两个设备之间通信，而 IP 则负责在「没有直连」的两个网络之间进行通信传输。

源IP地址和目标IP地址在传输过程中是不会变化的，只有源 MAC 地址和目标 MAC 一直在变化。









































