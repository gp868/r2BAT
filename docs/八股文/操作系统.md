# 操作系统

# 内存管理

虚拟内存的目的是为了让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存。为了在多进程环境下，使得进程之间的内存地址不受影响，相互隔离，于是操作系统就为每个进程独立分配一套**虚拟地址空间**，每个程序只关心自己的虚拟地址就可以，实际上大家的虚拟地址都是一样的，但分布到物理地址内存是不一样的。作为程序，也不用关心物理地址的事情。

每个进程都有自己的虚拟空间，而物理内存只有一个，所以当启用了大量的进程，物理内存必然会很紧张，于是操作系统会通过**内存交换**技术，把不常使用的内存暂时存放到硬盘（换出），在需要的时候再装载回物理内存（换入）。

那既然有了虚拟地址空间，那必然要把虚拟地址「映射」到物理地址，这个事情通常由操作系统来维护。那么对于虚拟地址与物理地址的映射关系，可以有**分段**和**分页**的方式，同时两者结合都是可以的。

**内存分段**是根据程序的逻辑角度，分成了栈段、堆段、数据段、代码段等，这样可以分离出不同属性的段，同时是一块连续的空间。但是每个段的大小都不是统一的，这就会导致内存碎片和内存交换效率低的问题。

于是，就出现了**内存分页**，把虚拟空间和物理空间分成大小固定的页，如在 Linux 系统中，每一页的大小为 `4KB`。由于分了页后，就不会产生细小的内存碎片。同时在内存交换的时候，写入硬盘也就一个页或几个页，这就大大提高了内存交换的效率。

再来，为了解决简单分页产生的页表过大的问题，就有了**多级页表**，它解决了空间上的问题，但这就会导致 CPU 在寻址的过程中，需要有很多层表参与，加大了时间上的开销。于是根据程序的**局部性原理**，在 CPU 芯片中加入了 **TLB**，负责缓存最近常被访问的页表项，大大提高了地址的转换速度。

**Linux 系统主要采用了分页管理，但是由于 Intel 处理器的发展史，Linux 系统无法避免分段管理**。于是 Linux 就把所有段的基地址设为 `0`，也就意味着所有程序的地址空间都是线性地址空间（虚拟地址），相当于屏蔽了 CPU 逻辑地址的概念，所以段只被用于访问控制和内存保护。

另外，Linux 系统中虚拟空间分布可分为**用户态**和**内核态**两部分，其中用户态的分布：代码段、全局变量、BSS、函数栈、堆内存、映射区。

## 内存分段

程序是由若干个逻辑分段组成的，如可由代码分段、数据分段、栈段、堆段组成。**不同的段是有不同的属性的，所以就用分段的形式把这些段分离出来。**

分段机制下的虚拟地址由两部分组成，**段选择因子**和**段内偏移量**。**段选择子**就保存在段寄存器里面。段选择子里面最重要的是**段号**，用作段表的索引。**段表**里面保存的是这个**段的基地址、段的界限和特权等级**等。虚拟地址中的**段内偏移量**应该位于 0 和段界限之间，如果段内偏移量是合法的，就将段基地址加上段内偏移量得到物理内存地址。

虚拟地址是通过**段表**与物理地址进行映射的，分段机制会把程序的虚拟地址分成 4 个段，每个段在段表中有一个项，在这一项找到段的基地址，再加上偏移量，于是就能找到物理内存中的地址。

分段的办法很好，解决了程序本身不需要关心具体的物理内存地址的问题，但它也有一些不足之处：第一个就是**内存碎片**的问题，第二个就是**内存交换的效率低**的问题。

这里的内存碎片的问题共有两处地方：

- 外部内存碎片，也就是产生了多个不连续的小物理内存，导致新的程序无法被装载，解决外部内存碎片问题的方法就是**内存交换**；
- 内部内存碎片，程序所有的内存都被装载到了物理内存，但是这个程序有部分的内存可能并不是很常使用，这也会导致内存的浪费；

这个内存交换空间，在 Linux 系统里，也就是我们常看到的 Swap 空间，这块空间是从硬盘划分出来的，用于内存与硬盘的空间交换。

对于多进程的系统来说，用分段的方式，内存碎片是很容易产生的，产生了内存碎片，那不得不重新 `Swap` 内存区域，这个过程会产生性能瓶颈。

因为硬盘的访问速度要比内存慢太多了，每一次内存交换，我们都需要把一大段连续的内存数据写到硬盘上。所以，**如果内存交换的时候，交换的是一个占内存空间很大的程序，这样整个机器都会显得卡顿。

## 内存分页

为了解决内存分段的内存碎片和内存交换效率低的问题，就出现了**内存分页**。分段的好处就是能产生连续的内存空间，但是会出现内存碎片和内存交换的空间太大的问题。

要解决这些问题，那么就要想出能少出现一些内存碎片的办法。另外，当需要进行内存交换的时候，让需要交换写入或者从磁盘装载的数据更少一点，这样就可以解决问题了。这个办法，也就是**内存分页**（*Paging*）。**分页是把整个虚拟和物理内存空间切成一段段固定尺寸的大小**。这样一个连续并且尺寸固定的内存空间，我们叫**页**（*Page*）。在 Linux 下，每一页的大小为 `4KB`。虚拟地址与物理地址之间通过**页表**来映射。页表存储在内存里的，**内存管理单元** （*MMU*）将虚拟内存地址转换成物理地址。而当进程访问的虚拟地址在页表中查不到时，系统会产生一个**缺页异常**，进入系统内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行。

由于内存空间都是预先划分好的，也就不会像分段会产生间隙非常小的内存，这正是分段会产生内存碎片的原因。而**采用了分页，那么释放的内存都是以页为单位释放的，也就不会产生无法给进程使用的小内存。**

如果内存空间不够，操作系统会把其他正在运行的进程中的「最近没被使用」的内存页面给释放掉，也就是暂时写在硬盘上，称为**换出**（*Swap Out*）。一旦需要的时候，再加载进来，称为**换入**（*Swap In*）。所以，一次性写入磁盘的也只有少数的一个页或者几个页，不会花太多时间，**内存交换的效率就相对比较高。**

更进一步地，分页的方式使得我们在加载程序的时候，不再需要一次性都把程序加载到物理内存中。我们完全可以在进行虚拟内存和物理内存的页之间的映射之后，并不真的把页加载到物理内存里，而是**只有在程序运行中，需要用到对应虚拟内存页里面的指令和数据时，再加载到物理内存里面去。**

在分页机制下，虚拟地址分为两部分，**页号**和**页内偏移**。页号作为页表的索引，**页表**包含物理页每页所在**物理内存的基地址**，这个基地址与页内偏移的组合就形成了物理内存地址，页表储存在内存。

总结一下，对于一个内存地址转换，其实就是这样三个步骤：

- 把虚拟内存地址，切分成页号和偏移量；
- 根据页号，从页表里面，查询对应的物理页号；
- 直接拿物理页号，加上前面的偏移量，就得到了物理内存地址。

但是有空间上的缺陷。因为操作系统是可以同时运行非常多的进程的，那这就意味着页表会非常的庞大。

**多级页表**

要解决上面的问题，就需要采用一种叫作**多级页表**的解决方案。

在前面我们知道了，对于单页表的实现方式，在 32 位和页大小 `4KB` 的环境下，一个进程的页表需要装下 100 多万个「页表项」，并且每个页表项是占用 4 字节大小的，于是相当于每个页表需占用 4MB 大小的空间。

我们把这个 100 多万个「页表项」的单级页表再分页，将页表（一级页表）分为 `1024` 个页表（二级页表），每个表（二级页表）中包含 `1024` 个「页表项」，形成**二级分页**。如果使用了二级分页，一级页表就可以覆盖整个 4GB 虚拟地址空间，但**如果某个一级页表的页表项没有被用到，也就不需要创建这个页表项对应的二级页表了，即可以在需要时才创建二级页表**。页表一定要覆盖全部虚拟地址空间，不分级的页表就需要有 100 多万个页表项来映射，而二级分页则只需要 1024 个页表项（此时一级页表覆盖到了全部虚拟地址空间，二级页表在需要时创建）。

多级页表虽然解决了空间上的问题，但是虚拟地址到物理地址的转换就多了几道转换的工序，这显然就降低了这俩地址转换的速度，也就是带来了时间上的开销。程序是有局部性的，即在一段时间内，整个程序的执行仅限于程序中的某一部分。相应地，执行所访问的存储空间也局限于某个内存区域。我们就可以利用这一特性，把最常访问的几个页表项存储到访问速度更快的硬件，在 CPU 芯片中加入一个专门存放程序最常访问的页表项的 Cache，这个 Cache 就是 **TLB**（*Translation Lookaside Buffer*） ，通常称为页表缓存、转址旁路缓存、快表等。

在 CPU 芯片里面，封装了内存管理单元（MMU）芯片，它用来完成地址转换和 TLB 的访问与交互。有了 TLB 后，那么 CPU 在寻址时，会先查 TLB，如果没找到，才会继续查常规的页表。TLB 的命中率其实是很高的，因为程序最常访问的页就那么几个。

## 段页式内存管理

内存分段和内存分页并不是对立的，它们是可以组合起来在同一个系统中使用的，那么组合起来后，通常称为**段页式内存管理**。

段页式内存管理实现的方式：

- 先将程序划分为多个有逻辑意义的段，也就是前面提到的分段机制；
- 接着再把每个段划分为多个页，也就是对分段划分出来的连续空间，再划分固定大小的页；

这样，地址结构就由**段号、段内页号和页内位移**三部分组成。

用于段页式地址变换的数据结构是每一个程序一张段表，每个段又建立一张页表，段表中的地址是页表的起始地址，而页表中的地址则为某页的物理页号。

段页式地址变换中要得到物理地址须经过三次内存访问：

- 第一次访问段表，得到页表起始地址；
- 第二次访问页表，得到物理页号；
- 第三次将物理页号与页内位移组合，得到物理地址。

可用软、硬件相结合的方法实现段页式地址变换，这样虽然增加了硬件成本和系统开销，但提高了内存的利用率。

## 内存页面置换算法

当发生缺页时，就是CPU所需访问的页面不在内存中，就需要将页面调入内存，如果内存已满，就需要执行相应的页面置换算法。常见的页面置换算法有如下几种：

- 最佳页面置换算法（*OPT*）
- 先进先出置换算法（*FIFO*）
- 最近最久未使用的置换算法（*LRU*）
- 时钟页面置换算法（*Lock*）

**最佳页面置换算法**

最佳页面置换算法基本思路是**置换在「未来」最长时间不访问的页面**。所以，该算法实现需要计算内存中每个逻辑页面的「下一次」访问时间，然后比较，选择未来最长时间不访问的页面。这很理想，但是实际系统中无法实现，因为程序访问页面时是动态的，我们是无法预知每个页面在「下一次」访问前的等待时间。所以，最佳页面置换算法作用是为了衡量其他算法的效率，算法效率越接近该算法的效率，那么说明你的算法是高效的。

**先进先出置换算法**

既然我们无法预知页面在下一次访问前所需的等待时间，那我们可以**选择在内存中驻留时间很长的页面进行置换**，也就是置换最早进入内存的页面，这个就是「先进先出置换」算法的思想。FIFO的性能较差，因为较早换入的页面往往是经常被访问的页面，这些页面在FIFO算法下被反复换入和换出。

**最近最久未使用置换算法**

最近最久未使用（*LRU*）置换算法的基本思路是发生缺页时，**选择过去最长时间没有被访问的页面进行置换**。这种算法近似最优置换算法，最优置换算法是通过「未来」的使用情况来推测要淘汰的页面，而 LRU 则是通过「历史」的使用情况来推测要淘汰的页面。

虽然 LRU 在理论上是可以实现的，但代价很高。为了完全实现 LRU，需要在内存中维护一个所有页面的链表，最近最多使用的页面在表头，最近最少使用的页面在表尾。困难的是，在每次访问内存时都必须要更新「整个链表」。在链表中找到一个页面，删除它，然后把它移动到表头是一个非常费时的操作。

所以，LRU 虽然看上去不错，但是由于开销比较大，实际应用中比较少使用。

**时钟页面置换算法**

时钟页面置换算法对前面进行了改进，该算法的思路是，把所有的页面都保存在一个类似钟面的「环形链表」中，一个表针指向最老的页面。当发生缺页中断时，算法首先检查表针指向的页面：如果它的访问位是 0 就置换该页面，并把新的页面插入这个位置，然后把表针前移一个位置；如果访问位是 1 就清除访问位，并把表针前移一个位置，重复这个过程直到找到了一个访问位为 0 的页面为止。

# 进程管理

## 对比

我们编写的代码只是一个存储在硬盘的静态文件，通过编译后就会生成二进制可执行文件，当我们运行这个可执行文件后，它会被装载到内存中，接着 CPU 会执行程序中的每一条指令，那么这个**运行中的程序，就被称为「进程」（Process）**。

在操作系统中，是用**进程控制块**（*process control block，PCB*）数据结构来描述进程的。**PCB 是进程存在的唯一标识**，这意味着一个进程的存在，必然会有一个 PCB，如果进程消失了，那么 PCB 也会随之消失。

一个进程切换到另一个进程运行，称为进程的上下文切换。进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。

**线程是进程当中的一条执行流程。**同一个进程内多个线程之间可以共享代码段、数据段、打开的文件等资源，但每个线程各自都有一套独立的寄存器和栈，这样可以确保线程的控制流是相对独立的。

**线程与进程的比较**如下：

- 进程是资源（包括内存、打开的文件等）分配的单位，线程是 CPU 调度的单位；
- 进程拥有一个完整的资源平台，而线程只独享必不可少的资源，如寄存器和栈；
- 线程同样具有就绪、阻塞、执行三种基本状态，同样具有状态之间的转换关系；
- 线程能减少并发执行的时间和空间开销；

最大的区别：**线程是调度的基本单位，而进程则是资源拥有的基本单位**。

线程相比进程能减少开销，体现在：

- 线程的创建时间比进程快，因为进程在创建的过程中，还需要资源管理信息，比如内存管理信息、文件管理信息，而线程在创建的过程中，不会涉及这些资源管理信息，而是共享它们；
- 线程的终止时间比进程快，因为线程释放的资源相比进程少很多；
- 同一个进程内的线程切换比进程切换快，因为线程具有相同的地址空间（虚拟内存共享），这意味着同一个进程的线程都具有同一个页表，那么在切换的时候不需要切换页表。而对于进程之间的切换，切换的时候要把页表给切换掉，而页表的切换过程开销是比较大的；
- 由于同一进程的各线程间共享内存和文件资源，那么在线程之间数据传递的时候，就不需要经过内核了，这就使得线程之间的数据交互效率更高了；

所以，不管是时间效率，还是空间效率线程比进程都要高。

那线程上下文切换的是什么？这还得看线程是不是属于同一个进程：

当两个线程不是属于同一个进程，则切换的过程就跟进程上下文切换一样。**当两个线程属于同一个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据**。所以，线程的上下文切换相比进程，开销要小很多。

## 进程调度算法

**先来先服务调度算法**

最简单的一个调度算法，就是非抢占式的先来先服务算法了。顾名思义，先来后到，每次从就绪队列选择最先进入队列的进程，然后一直运行，直到进程退出或被阻塞，才会继续从队列中选择第一个进程接着运行。

这似乎很公平，但是当一个长作业先运行了，那么后面的短作业等待的时间就会很长，不利于短作业。FCFS 对长作业有利，适用于 CPU 繁忙型作业的系统，而不适用于 I/O 繁忙型作业的系统。

**最短作业优先调度算法**

它会优先选择运行时间最短的进程来运行，这有助于提高系统的吞吐量。这显然对长作业不利，很容易造成一种极端现象。比如，一个长作业在就绪队列等待运行，而这个就绪队列有非常多的短作业，那么就会使得长作业不断的往后推，周转时间变长，致使长作业长期不会被运行。

**高响应比优先调度算法**

前面的「先来先服务调度算法」和「最短作业优先调度算法」都没有很好的权衡短作业和长作业。那么，高响应比优先调度算法主要是权衡了短作业和长作业。每次进行进程调度时，先计算「响应比优先级」，然后把「响应比优先级」最高的进程投入运行，「响应比优先级」的计算公式：

<img src="https://gcore.jsdelivr.net/gh/gp868/myFigures/img/202206142134909.jpeg" alt="img" style="zoom:70%;" />

从上面的公式，可以发现：

- 如果两个进程的「等待时间」相同时，「要求的服务时间」越短，「响应比」就越高，这样短作业的进程容易被选中运行；
- 如果两个进程「要求的服务时间」相同时，「等待时间」越长，「响应比」就越高，这就兼顾到了长作业进程，因为进程的响应比可以随时间等待的增加而提高，当其等待时间足够长时，其响应比便可以升到很高，从而获得运行的机会；

**时间片轮转调度算法**

最古老、最简单、最公平且使用最广的算法就是时间片轮转调度算法。

每个进程被分配一个时间段，称为时间片，即允许该进程在该时间段中运行。

- 如果时间片用完，进程还在运行，那么将会把此进程从 CPU 释放出来，并把 CPU 分配给另外一个进程；
- 如果该进程在时间片结束前阻塞或结束，则 CPU 立即进行切换；

另外，时间片的长度就是一个很关键的点：

- 如果时间片设得太短会导致过多的进程上下文切换，降低了 CPU 效率；
- 如果设得太长又可能引起对短作业进程的响应时间变长。将

一般来说，时间片设为 `20ms~50ms` 通常是一个比较合理的折中值。

**最高优先级调度算法**

前面的「时间片轮转算法」做了个假设，即让所有的进程同等重要，也不偏袒谁，大家的运行时间都一样。

但是，对于多用户计算机系统就有不同的看法了，它们希望调度是有优先级的，即希望调度程序能从就绪队列中选择最高优先级的进程进行运行，这称为最高优先级调度算法。

进程的优先级可以分为，静态优先级和动态优先级：

- 静态优先级：创建进程时候，就已经确定了优先级了，然后整个运行时间优先级都不会变化；
- 动态优先级：根据进程的动态变化调整优先级，比如如果进程运行时间增加，则降低其优先级，如果进程等待时间（就绪队列的等待时间）增加，则升高其优先级，也就是随着时间的推移增加等待进程的优先级。

该算法也有两种处理优先级高的方法，非抢占式和抢占式：

- 非抢占式：当就绪队列中出现优先级高的进程，运行完当前进程，再选择优先级高的进程。
- 抢占式：当就绪队列中出现优先级高的进程，当前进程挂起，调度优先级高的进程运行。

但是依然有缺点，可能会导致低优先级的进程永远不会运行。

**多级反馈队列调度算法**

多级反馈队列调度算法是「时间片轮转算法」和「最高优先级算法」的综合和发展。

顾名思义：

- 「多级」表示有多个队列，每个队列优先级从高到低，同时优先级越高时间片越短。
- 「反馈」表示如果有新的进程加入优先级高的队列时，立刻停止当前正在运行的进程，转而去运行优先级高的队列；

来看看，它是如何工作的：

- 设置了多个队列，赋予每个队列不同的优先级，每个**队列优先级从高到低**，同时**优先级越高时间片越短**；
- 新的进程会被放入到第一级队列的末尾，按先来先服务的原则排队等待被调度，如果在第一级队列规定的时间片没运行完成，则将其转入到第二级队列的末尾，以此类推，直至完成；
- 当较高优先级的队列为空，才调度较低优先级的队列中的进程运行。如果进程运行时，有新进程进入较高优先级的队列，则停止当前运行的进程并将其移入到原队列末尾，接着让较高优先级的进程运行；

可以发现，对于短作业可能可以在第一级队列很快被处理完。对于长作业，如果在第一级队列处理不完，可以移入下次队列等待被执行，虽然等待的时间变长了，但是运行时间也变更长了，所以该算法很好的**兼顾了长短作业，同时有较好的响应时间。**

## 进程间通信

**管道**

- 无名管道
  - 无名管道特点：
    - 无名管道是一种特殊的文件，这种文件只存在于内存中。
    - 无名管道只能用于父子进程或兄弟进程之间，必须用于具有亲缘关系的进程间的通信。
    - 无名管道只能由一端向另一端发送数据，是半双工方式，如果双方需要同时收发数据需要两个管道。
  - 相关接口：
    - int pipe(int fd[2]);
      - fd[2]：管道两端用fd[0]和fd[1]来描述，读的一端用fd[0]表示，写的一端用fd[1]表示。通信双方的进程中写数据的一方需要把fd[0]先close掉，读的一方需要先把fd[1]给close掉。
- 有名管道：
  - 有名管道特点：
    - 有名管道是FIFO文件，存在于文件系统中，可以通过文件路径名来指出。
    - 有名管道可以在不具有亲缘关系的进程间进行通信。
  - 相关接口：
    - int mkfifo(const char *pathname, mode_t mode);
      - pathname：即将创建的FIFO文件路径，如果文件存在需要先删除。
      - mode：和open()中的参数相同。

**消息队列**

**消息队列**克服了管道通信的数据是无格式的字节流的问题，消息队列实际上是保存在内核的「消息链表」，消息队列的消息体是可以用户自定义的数据类型，发送数据时，会被分成一个一个独立的消息体，当然接收数据时，也要与发送方发送的消息体的数据类型保持一致，这样才能保证读取的数据是正确的。消息队列通信的速度不是最及时的，毕竟**每次数据的写入和读取都需要经过用户态与内核态之间的拷贝过程。**

**共享内存**

**共享内存**可以解决消息队列通信中用户态与内核态之间数据拷贝过程带来的开销，**它直接分配一个共享空间，每个进程都可以直接访问**，就像访问进程自己的空间一样快捷方便，不需要陷入内核态或者系统调用，大大提高了通信的速度，享有**最快**的进程间通信方式之名。但是便捷高效的共享内存通信，**带来新的问题，多进程竞争同个共享资源会造成数据的错乱。**

创建共享内存后，进程结束，共享内存也不会消失。一旦创建后就由内核管理，若进程不对其主动释放，那么这些变量会一直存在，除非重启系统。

- 相关接口

  - 创建共享内存：int shmget(key_t key, int size, int flag);

    成功时返回一个和key相关的共享内存标识符，失败范湖范围-1。

    - key：为共享内存段命名，多个共享同一片内存的进程使用同一个key。
    - size：共享内存容量。
    - flag：权限标志位，和open的mode参数一样。

  - 连接到共享内存地址空间：void *shmat(int shmid, void *addr, int flag);

    返回值即共享内存实际地址。

    - shmid：shmget()返回的标识。
    - addr：决定以什么方式连接地址。
    - flag：访问模式。

  - 从共享内存分离：int shmdt(const void *shmaddr);

    调用成功返回0，失败返回-1。

    - shmaddr：是shmat()返回的地址指针。

  **信号量**

  那么，就需要**信号量**来保护共享资源，以确保任何时刻只能有一个进程访问共享资源，这种方式就是互斥访问。**信号量不仅可以实现访问的互斥性，还可以实现进程间的同步**，信号量其实是一个计数器，表示的是资源个数，其值可以通过两个原子操作来控制，分别是 **P 操作和 V 操作**。

  **信号**

  与信号量名字很相似的叫**信号**，它俩名字虽然相似，但功能一点儿都不一样。信号是**异步通信机制**，信号可以在应用进程和内核之间直接交互，内核也可以利用信号来通知用户空间的进程发生了哪些系统事件，信号事件的来源主要有硬件来源（如键盘 Cltr+C ）和软件来源（如 kill 命令），一旦有信号发生，**进程有三种方式响应信号 1. 执行默认操作、2. 捕捉信号、3. 忽略信号**。有两个信号是应用进程无法捕捉和忽略的，即 `SIGKILL` 和 `SIGSTOP`，这是为了方便我们能在任何时候结束或停止某个进程。`kill[参数][进程号]`

  ![image-20220706111137372](https://gcore.jsdelivr.net/gh/gp868/myFigures/img/202207061111967.png)

  ![image-20220706111227242](https://gcore.jsdelivr.net/gh/gp868/myFigures/img/202207061112913.png)
  
  ![image-20220706111257860](https://gcore.jsdelivr.net/gh/gp868/myFigures/img/202207061112816.png)
  
  ![image-20220706111314346](https://gcore.jsdelivr.net/gh/gp868/myFigures/img/202207061113310.png)
  
  **socket**
  
  前面说到的通信机制，都是工作于同一台主机，如果**要与不同主机的进程间通信，那么就需要 Socket 通信了**。Socket 实际上不仅用于不同的主机进程间通信，还可以用于本地主机进程间通信，可根据创建 Socket 的类型不同，分为三种常见的通信方式，一个是基于 TCP 协议的通信方式，一个是基于 UDP 协议的通信方式，一个是本地进程间通信方式。

## 特殊进程

- 守护进程

守护进程（Daemon Process）是Linux 中的后台服务进程。它是一个生存期较长的进程，通常独立于控制终端并且周期性地执行某种任务或等待处理某些发生的事件，一般采用以 d 结尾的名字。

守护进程具备下列特征：

1. 生命周期很长，守护进程会在系统启动的时候被创建并一直运行直至系统被关闭；
2. 它在后台运行并且不拥有控制终端，没有控制终端确保了内核永远不会为守护进程自动生成任何控制信号以及终端相关的信号（如 SIGINT、SIGQUIT）。

Linux 的大多数服务器就是用守护进程实现的。比如，Internet 服务器 inetd，Web 服务器 httpd 等。

守护进程的创建：

1. 执行一个 `fork()`，之后父进程退出，子进程继续执行。
2. 子进程调用 `setsid()` 开启一个新会话。
3. 清除进程的 `umask` 以确保当守护进程创建文件和目录时拥有所需的权限。
4. 修改进程的当前工作目录，通常会改为根目录（/）。
5. 关闭守护进程从其父进程继承而来的所有打开着的文件描述符。
6. 在关闭了文件描述符0、1、2之后，守护进程通常会打开/dev/null 并使用 `dup2()` 使所有这些描述符指向这个设备。
7. 核心业务逻辑

- 孤儿进程

父进程运行结束，但子进程还在运行（未运行结束），这样的子进程就称为**孤儿进程**。每当出现一个孤儿进程的时候，内核就把孤儿进程的父进程设置为 `init` ，而 init 进程会循环地 `wait()` 它的已经退出的子进程。这样，当一个孤儿进程结束了其生命周期的时候，init 进程就会处理它的一切善后工作。因此孤儿进程并不会有什么危害。

- 僵尸进程

每个进程结束之后, 都会释放自己地址空间中的用户区数据，内核区的 PCB 没有办法自己释放掉，需要父进程去释放。进程终止时，父进程尚未回收，子进程残留资源（PCB）存放于内核中，变成**僵尸进程**。

僵尸进程不能被 kill -9 杀死，这样就会导致一个问题，如果父进程不调用 `wait()` 或 `waitpid()` 的话，那么保留的那段信息就不会释放，其进程号就会一直被占用，但是系统所能使用的进程号是有限的，如果大量的产生僵尸进程，将因为没有可用的进程号而导致系统不能产生新的进程，此即为僵尸进程的危害，应当避免。

- SIGCHLD 信号

SIGCHLD 信号产生的3个条件：

1. 子进程终止时（最常见）
2. 子进程接收到 SIGSTOP 信号停止时
3. 子进程处在停止态，接受到 SIGCONT 后唤醒时

以上三种条件都会给父进程发送 SIGCHLD 信号，父进程默认会忽略该信号。使用 SIGCHLD 信号解决僵尸进程的问题：

```php
#include <stdio.h>
#include <unistd.h>
#include <sys/types.h>
#include <sys/stat.h>
#include <signal.h>
#include <sys/wait.h>

void myFun(int num) {
    printf("捕捉到的信号 ：%d\n", num);
    // 回收子进程PCB的资源
    // while(1) {
    // wait(NULL); 
    // }
    while(1) {
       int ret = waitpid(-1, NULL, WNOHANG);
       if(ret > 0) {
           printf("child die , pid = %d\n", ret);
       } else if(ret == 0) {
           // 说明还有子进程或者
           break;
       } else if(ret == -1) {
           // 没有子进程
           break;
       }
    }
}

int main() {
    // 提前设置好阻塞信号集，阻塞SIGCHLD，因为有可能子进程很快结束，父进程还没有注册完信号捕捉
    sigset_t set;
    sigemptyset(&set);
    sigaddset(&set, SIGCHLD);
    sigprocmask(SIG_BLOCK, &set, NULL);
    // 创建一些子进程
    pid_t pid;
    for(int i = 0; i < 20; i++) {
        pid = fork();
        if(pid == 0) {
            break;
        }
    }
    if(pid > 0) {
        // 父进程
        // 捕捉子进程死亡时发送的SIGCHLD信号
        struct sigaction act;
        act.sa_flags = 0;
        act.sa_handler = myFun;
        sigemptyset(&act.sa_mask);
        sigaction(SIGCHLD, &act, NULL);
        // 注册完信号捕捉以后，解除阻塞
        sigprocmask(SIG_UNBLOCK, &set, NULL);
        while(1) {
            printf("parent process pid : %d\n", getpid());
            sleep(2);
        }
    } else if( pid == 0) {
        // 子进程
        printf("child process pid : %d\n", getpid());
    }
    return 0;
}

```

## 多线程

- **互斥**：多个进程在同一时刻只有一个进程能进入临界区。
- **同步**：多个进程因为合作产生的直接制约关系，使得进程有一定的先后执行关系。并发进程/线程在一些关键点上可能需要互相等待与互通消息，这种相互制约的等待与互通信息称为进程/线程同步。

**互斥和同步的实现主要有两种方法：锁和信号量。**

### 锁

- **互斥锁**

一次只能一个线程拥有互斥锁，其他线程只有等待。

互斥锁是在抢锁失败的情况下主动放弃CPU进入睡眠状态，直到锁的状态改变时再唤醒。而操作系统负责线程调度，为了实现锁的状态发生改变时唤醒阻塞的线程或者进程，需要把锁交给操作系统管理，所以互斥锁在加锁操作时涉及上下文的切换。

互斥锁属于**无等待锁**。例如在一个双核的机器上有两个线程A和B，它们分别运行在core 0和core 1上。假设线程A想要通过pthread_mutex_lock操作去得到一个临界区的锁，而此时这个锁正被线程B所持有，那么线程A就会被阻塞，此时会通过上下文切换将线程A置于等待队列中，此时core 0就可以运行其他的任务（如线程C）。

- **自旋锁**

如果线程无法取得锁，线程不会立刻放弃CPU时间片，而是一直循环尝试获取锁，直到获取为止。如果别的线程长时间占有锁，那么自旋就是在浪费CPU做无用功，但是自旋锁一般应用于加锁时间很短的场景，这个时候效率比较高。

自旋锁属于**忙等待锁**，如果线程A是使用pthread_spin_lock操作去请求锁，如果自旋锁已经被线程B所持有，那么线程A就会一直在core 0上进行忙等待并不停的进行锁请求，检查该自旋锁是否已经被线程B释放，直到得到这个锁为止。因为自旋锁不会引起调用者睡眠，所以自旋锁的效率远高于互斥锁。

虽然它的效率比互斥锁高，但是它也有些不足之处：

- 自旋锁一直占用CPU，在未获得锁的情况下，一直进行自旋，所以占用着CPU，如果不能在很短的时间内获得锁，无疑会使CPU效率降低。
- 在用自旋锁时有可能造成死锁，当递归调用时有可能造成死锁。
- 自旋锁只有在内核可抢占式或SMP的情况下才真正需要，在单CPU且不可抢占式的内核下，自旋锁的操作为空操作。自旋锁适用于锁使用者保持锁时间比较短的情况下。

### **信号量**

信号量是操作系统提供的一种协调共享资源访问的方法。通常**信号量表示资源的数量**，对应的变量是一个整型（`sem`）变量。另外，还有**两个原子操作的系统调用函数来控制信号量的**，分别是：

- *P 操作*：将 `sem` 减 `1`，相减后，如果 `sem < 0`，则进程/线程进入阻塞等待，否则继续，表明 P 操作可能会阻塞；
- *V 操作*：将 `sem` 加 `1`，相加后，如果 `sem <= 0`，唤醒一个等待中的进程/线程，表明 V 操作不会阻塞；

P 操作是用在进入临界区之前，V 操作是用在离开临界区之后，这两个操作是必须成对出现的。

### 生产者消费者问题

问题描述：使用一个缓冲区来保存物品，只有缓冲区没有满，生产者才可以放入物品；只有缓冲区不为空，消费者才可以拿走物品。

因为缓冲区属于临界资源，因此需要使用一个互斥量 mutex 来控制对缓冲区的互斥访问。

为了同步生产者和消费者的行为，需要记录缓冲区中物品的数量。数量可以使用信号量来进行统计，这里需要使用两个信号量：empty 记录空缓冲区的数量，full 记录满缓冲区的数量。

其中，empty 信号量是在生产者进程中使用，当 empty 不为 0 时，生产者才可以放入物品；full 信号量是在消费者进程中使用，当 full 信号量不为 0 时，消费者才可以取走物品。

**注意**，不能先对缓冲区进行加锁，再测试信号量。也就是说，不能先执行 down(mutex) 再执行 down(empty)。如果这么做了，那么可能会出现这种情况：生产者对缓冲区加锁后，执行 down(empty) 操作，发现 empty = 0，此时生产者睡眠。

消费者不能进入临界区，因为生产者对缓冲区加锁了，消费者就无法执行 up(empty) 操作，empty 永远都为 0，导致生产者永远等待下，不会释放锁，消费者因此也会永远等待下去。

```php
#define N 100
typedef int semaphore;
semaphore mutex = 1;
semaphore empty = N;
semaphore full = 0;

void producer() {
    while(TRUE) {
        int item = produce_item();
        down(&empty);
        down(&mutex);
        insert_item(item);
        up(&mutex);
        up(&full);
    }
}

void consumer() {
    while(TRUE) {
        down(&full);
        down(&mutex);
        int item = remove_item();
        consume_item(item);
        up(&mutex);
        up(&empty);
    }
}
 
```

如果消费者线程一开始执行 `P(fullBuffers)`，由于信号量 `fullBuffers` 初始值为 0，则此时 `fullBuffers` 的值从 0 变为 -1，说明缓冲区里没有数据，消费者只能等待。

接着，轮到生产者执行 `P(emptyBuffers)`，表示减少 1 个空槽，如果当前没有其他生产者线程在临界区执行代码，那么该生产者线程就可以把数据放到缓冲区，放完后，执行 `V(fullBuffers)` ，信号量 `fullBuffers` 从 -1 变成 0，表明有「消费者」线程正在阻塞等待数据，于是阻塞等待的消费者线程会被唤醒。

消费者线程被唤醒后，如果此时没有其他消费者线程在读数据，那么就可以直接进入临界区，从缓冲区读取数据。最后，离开临界区后，把空槽的个数 + 1。

### 哲学家就餐问题

五个哲学家围着一张圆桌，每个哲学家面前放着食物。哲学家的生活有两种交替活动：吃饭以及思考。当一个哲学家吃饭时，需要先拿起自己左右两边的两根筷子，并且一次只能拿起一根筷子。

下面是一种错误的解法，如果所有哲学家同时拿起左手边的筷子，那么所有哲学家都在等待其它哲学家吃完并释放自己手中的筷子，导致死锁。

```php
#define N 5
void philosopher(int i) {
    while(TRUE) {
        think();
        take(i);       		// 拿起左边的筷子
        take((i + 1) % N); 	// 拿起右边的筷子
        eat();
        put(i);
        put((i + 1) % N);
    }
}    
```

为了防止死锁的发生，可以设置两个条件：

- 必须同时拿起左右两根筷子；
- 只有在两个邻居都没有进餐的情况下才允许进餐。

用一个数组 state 来记录每一位哲学家的三个状态，分别是在进餐状态、思考状态、饥饿状态（正在试图拿叉子）。使用了一个信号量数组 s[N]，每个信号量对应一位哲学家，这样在所需的叉子被占用时，想进餐的哲学家就被阻塞。

```php
#define N 5
#define LEFT (i + N - 1) % N // 左邻居
#define RIGHT (i + 1) % N    // 右邻居
#define THINKING 0
#define HUNGRY   1
#define EATING   2
typedef int semaphore;
int state[N];                // 跟踪每个哲学家的状态
semaphore mutex = 1;         // 临界区的互斥，临界区是 state 数组，对其修改需要互斥
semaphore s[N];              // 每个哲学家一个信号量，初始值为0

void philosopher(int i) {
    while(TRUE) {
        think(i);
        take_two(i);
        eat(i);
        put_two(i);
    }
}

void take_two(int i) {
    down(&mutex);
    state[i] = HUNGRY;
    check(i);
    up(&mutex);
    down(&s[i]); // 只有收到通知之后才可以开始吃，否则会一直等下去
}

void put_two(i) {
    down(&mutex);
    state[i] = THINKING;
    check(LEFT); // 尝试通知左右邻居，自己吃完了，你们可以开始吃了
    check(RIGHT);
    up(&mutex);
}

void eat(int i) {
    down(&mutex);
    state[i] = EATING;
    up(&mutex);
}

// 检查两个邻居是否都没有用餐，如果是的话，就 up(&s[i])，使得 down(&s[i]) 能够得到通知并继续执行
void check(i) {         
    if(state[i] == HUNGRY && state[LEFT] != EATING && state[RIGHT] !=EATING) {
        state[i] = EATING;
        up(&s[i]);
    }
}
 
```

### 读者写者问题

允许多个进程同时对数据进行读操作，但是不允许读和写以及写和写操作同时发生。

一个整型变量 `count `记录在对数据进行读操作的进程数量，一个互斥量 `count_mutex `用于对 `count `加锁，一个互斥量 `data_mutex `用于对读写的数据加锁。

```php
typedef int semaphore;
semaphore count_mutex = 1;
semaphore data_mutex = 1;
int count = 0;

void reader() {
    while(TRUE) {
        down(&count_mutex);
        count++;
        if(count == 1) down(&data_mutex); // 第一个读者需要对数据进行加锁，防止写进程访问
        up(&count_mutex);
        read();
        down(&count_mutex);
        count--;
        if(count == 0) up(&data_mutex);	//最后一个读者要对数据进行解锁，防止写进程无法访问
        up(&count_mutex);
    }
}

void writer() {
    while(TRUE) {
        down(&data_mutex);
        write();
        up(&data_mutex);
    }
}
```

## 死锁

死锁问题的产生是由两个或者以上线程并行执行的时候，争夺资源而互相等待造成的。死锁只有同时满足互斥、持有并等待、不可剥夺、环路等待这四个条件的时候才会发生。所以要避免死锁问题，就是要破坏其中一个条件即可，最常用的方法就是使用**资源有序分配法**来破坏环路等待条件。

死锁只有**同时满足**以下四个条件才会发生：

- **互斥条件**：进程对所需求的资源具有排他性，若有其他进程请求该资源，请求进程只能等待，多个线程不能同时使用同一个资源；
- **持有并等待条件**：进程当前所拥有的资源在进程请求其他新资源时，由该进程继续占有。例如：当线程 A 已经持有了资源 1，又想申请资源 2，而资源 2 已经被线程 C 持有了，所以线程 A 就会处于等待状态，但是线程 A 在等待资源 2 的同时并不会释放自己已经持有的资源 1；
- **不可剥夺条件**：当线程已经持有了资源 ，在自己使用完之前不能被其他线程获取，线程 B 如果也想使用此资源，则只能在线程 A 使用完并释放后才能获取；
- **环路等待条件**：存在一种进程资源循环等待链，链中每个进程已获得的资源同时被链中下一个进程所请求。在死锁发生的时候，两个线程获取资源的顺序构成了环形链。

通过代码的形式进行演示，需要两个线程和两个互斥量。

```php
pthread_mutex_t mutex_A = PTHREAD_MUTEX_INITIALIZER;
pthread_mutex_t mutex_B = PTHREAD_MUTEX_INITIALIZER;

int main()
{
    pthread_t tidA, tidB;
    
    //创建两个线程
    pthread_create(&tidA, NULL, threadA_proc, NULL);
    pthread_create(&tidB, NULL, threadB_proc, NULL);
    
    pthread_join(tidA, NULL);
    pthread_join(tidB, NULL);
    
    printf("exit\n");
    
    return 0;
}

//线程函数 A
void *threadA_proc(void *data)
{
    printf("thread A waiting get ResourceA \n");
    pthread_mutex_lock(&mutex_A);
    printf("thread A got ResourceA \n");
    
    sleep(1);
    
    printf("thread A waiting get ResourceB \n");
    pthread_mutex_lock(&mutex_B);
    printf("thread A got ResourceB \n");

    pthread_mutex_unlock(&mutex_B);
    pthread_mutex_unlock(&mutex_A);
    return (void *)0;
}

//线程函数 B
void *threadB_proc(void *data)
{
    printf("thread B waiting get ResourceB \n");
    pthread_mutex_lock(&mutex_B);
    printf("thread B got ResourceB \n");
    
    sleep(1);
    
    printf("thread B waiting  get ResourceA \n");
    pthread_mutex_lock(&mutex_A);
    printf("thread B got ResourceA \n");
    
    pthread_mutex_unlock(&mutex_A);
    pthread_mutex_unlock(&mutex_B);
    return (void *)0;
}

```

语句1和语句2表示线程A先锁资源1，再锁资源2，语句3和语句4表示线程B先锁资源2再锁资源1，具备死锁产生的条件。

**死锁避免**

前面我们提到，产生死锁的四个必要条件是：互斥条件、持有并等待条件、不可剥夺条件、环路等待条件。那么避免死锁问题就只需要破环其中一个条件就可以，最常见的并且可行的就是**使用资源有序分配法，来破环环路等待条件**。

那什么是资源有序分配法呢？线程 A 和 线程 B 获取资源的顺序要一样，当线程 A 是先尝试获取资源 A，然后尝试获取资源 B 的时候，线程 B 同样也是先尝试获取资源 A，然后尝试获取资源 B。也就是说，线程 A 和 线程 B 总是以相同的顺序申请自己想要的资源。

我们使用资源有序分配法的方式来修改前面发生死锁的代码，我们可以不改动线程 A 的代码。我们先要清楚线程 A 获取资源的顺序，它是先获取互斥锁 A，然后获取互斥锁 B。所以我们只需将线程 B 改成以相同顺序的获取资源，就可以打破死锁了。

```php
//线程 B 函数，同线程 A 一样，先获取互斥锁 A，然后获取互斥锁 B
void *threadB_proc(void *data)
{
    printf("thread B waiting get ResourceA \n");
    pthread_mutex_lock(&mutex_A);
    printf("thread B got ResourceA \n");
    
    sleep(1);
    
    printf("thread B waiting  get ResourceB \n");
    pthread_mutex_lock(&mutex_B);
    printf("thread B got ResourceB \n");
    
    pthread_mutex_unlock(&mutex_B);
    pthread_mutex_unlock(&mutex_A);
    return (void *)0;
}
```

# I/O操作

**阻塞 I/O**：当用户程序执行 `read` ，线程会被阻塞，一直等到内核数据准备好，并把数据从内核缓冲区拷贝到应用程序的缓冲区中，当拷贝过程完成，`read` 才会返回。

注意，**阻塞等待的是「内核数据准备好」和「数据从内核态拷贝到用户态」这两个过程**。

**非阻塞 I/O**：非阻塞的 read 请求在数据未准备好的情况下立即返回，可以继续往下执行，此时应用程序不断轮询内核，直到数据准备好，内核将数据拷贝到应用程序缓冲区，`read` 调用才可以获取到结果。

注意，**这里最后一次 read 调用，获取数据的过程，是一个同步的过程，是需要等待的过程。这里的同步指的是内核态的数据拷贝到用户程序的缓存区这个过程。**举个例子，访问管道或 socket 时，如果设置了 `O_NONBLOCK` 标志，那么就表示使用的是非阻塞 I/O 的方式访问，而不做任何设置的话，默认是阻塞 I/O。

应用程序每次轮询内核的 I/O 是否准备好，感觉有点傻乎乎，因为轮询的过程中，应用程序啥也做不了，只是在循环。为了解决这种傻乎乎轮询方式，于是 **I/O 多路复用**技术就出来了，如 select、poll，它是通过 I/O 事件分发，当内核数据准备好时，再以事件通知应用程序进行操作。这个做法大大改善了应用进程对 CPU 的利用率，在没有被通知的情况下，应用进程可以使用 CPU 做其他的事情。

注意，`read` 获取数据的过程（数据从内核态拷贝到用户态的过程），也是一个**同步的过程**，需要等待。

实际上，无论是阻塞 I/O、非阻塞 I/O，还是基于非阻塞 I/O 的多路复用都是**同步调用**。因为它们在 read 调用时，内核将数据从内核空间拷贝到应用程序空间，这个过程都是需要等待的，也就是说这个过程是同步的。如果内核实现的拷贝效率不高，read 调用就会在这个同步过程中等待比较长的时间。

而真正的**异步 I/O** 是「内核数据准备好」和「数据从内核态拷贝到用户态」这两个过程都不用等待。当我们发起 `aio_read` 之后，就立即返回，内核自动将数据从内核空间拷贝到应用程序空间，这个拷贝过程同样是异步的，内核自动完成的，和前面的同步操作不一样，应用程序并不需要主动发起拷贝动作。

# I/O 多路复用

`I/O多路复用`使得程序能同时监听多个文件描述符，能够提高程序的性能，Linux 下实现 I/O 多路复用的系统调用主要有 `select`、`poll` 和 `epoll`。

## select

select 实现多路复用的方式是，将已连接的 Socket 都放到一个**文件描述符集合**，然后调用 select 函数将文件描述符集合**拷贝**到内核里，让内核来检查是否有网络事件产生，检查的方式很粗暴，就是通过**遍历**文件描述符集合的方式，当检查到有事件产生后，将此 Socket 标记为可读或可写， 接着再把整个文件描述符集合**拷贝**回用户态里，然后用户态还需要再通过**遍历**的方法找到可读或可写的 Socket，然后再对其处理。

所以，对于 select 这种方式，需要进行 **2 次「遍历」文件描述符集合**，一次是在内核态里，一个次是在用户态里 ，而且还会发生 **2 次「拷贝」文件描述符集合**，先从用户空间传入内核空间，由内核修改后，再传出到用户空间中。

select 使用固定长度的 BitsMap，表示文件描述符集合，而且所支持的文件描述符的个数是有限制的，在 Linux 系统中，由内核中的 FD_SETSIZE 限制， 默认最大值为 `1024`，只能监听 0~1023 的文件描述符。

```php
// sizeof(fd_set) = 128   1024
#include <sys/time.h>
#include <sys/types.h>
#include <unistd.h>
#include <sys/select.h>
int select(int nfds, fd_set *readfds, fd_set *writefds,
     fd_set *exceptfds, struct timeval *timeout);
- 参数：
  - nfds : 委托内核检测的最大文件描述符的值 + 1
  - readfds : 要检测的文件描述符的读的集合，委托内核检测哪些文件描述符读的属性
      - 一般检测读操作
      - 对应的是对方发送过来的数据，因为读是被动的接收数据，检测的就是读缓冲区
      - 是一个传入传出参数
  - writefds : 要检测的文件描述符的写的集合，委托内核检测哪些文件描述符写的属性
        - 委托内核检测写缓冲区是不是还可以写数据（不满的就可以写）
  - exceptfds : 检测发生异常的文件描述符的集合
  - timeout : 设置的超时时间
   
     struct timeval {
       long   tv_sec;     /* seconds */
       long   tv_usec;     /* microseconds */
     };    
      - NULL : 永久阻塞，直到检测到了文件描述符有变化
      - tv_sec = 0 tv_usec = 0， 不阻塞
      - tv_sec > 0 tv_usec > 0， 阻塞对应的时间
         
   - 返回值 :
      - -1 : 失败
      - >0(n) : 检测的集合中有n个文件描述符发生了变化

// 将参数文件描述符fd对应的标志位设置为0
void FD_CLR(int fd, fd_set *set);

// 将参数文件描述符fd对应的标志位设置为1
void FD_SET(int fd, fd_set *set);

// 判断fd对应的标志位是0还是1，
// 返回值：fd 对应标志位的值
// 0，返回0， 1，返回1
int  FD_ISSET(int fd, fd_set *set);

// fd_set一共有1024 bit, 全部初始化为0
void FD_ZERO(fd_set *set);
```

- 缺点：
1. 每次调用 select，都需要把 fd 集合从用户态拷贝到内核态，这个开销在 fd 很多时会很大；
2. 同时每次调用 select 都需要在内核遍历传递进来的所有 fd，这个开销在 fd 很多时也很大；
3. select 支持的文件描述符数量太小了，默认是 1024；
4. fds 集合不能重用，每次都需要重置。

```php
#include <stdio.h>
#include <arpa/inet.h>
#include <unistd.h>
#include <stdlib.h>
#include <string.h>
#include <sys/select.h>

int main() {
    // 创建socket
    int lfd = socket(PF_INET, SOCK_STREAM, 0);
    struct sockaddr_in saddr;
    saddr.sin_port = htons(9999);
    saddr.sin_family = AF_INET;
    saddr.sin_addr.s_addr = INADDR_ANY;

    // 绑定
    bind(lfd, (struct sockaddr *)&saddr, sizeof(saddr));

    // 监听
    listen(lfd, 8);

    // 创建一个fd_set的集合，存放的是需要检测的文件描述符
    fd_set rdset, tmp;
    FD_ZERO(&rdset);
    FD_SET(lfd, &rdset);
    int maxfd = lfd;

    while(1) {
        tmp = rdset;
        // 调用select系统函数，让内核帮检测哪些文件描述符有数据
        int ret = select(maxfd + 1, &tmp, NULL, NULL, NULL);
        if(ret == -1) {
            perror("select");
            exit(-1);
        } else if(ret == 0) {
            continue;
        } else if(ret > 0) {
            // 说明检测到了有文件描述符的对应的缓冲区的数据发生了改变
            if(FD_ISSET(lfd, &tmp)) {
                // 表示有新的客户端连接进来了
                struct sockaddr_in cliaddr;
                int len = sizeof(cliaddr);
                int cfd = accept(lfd, (struct sockaddr *)&cliaddr, &len);

                // 将新的文件描述符加入到集合中
                FD_SET(cfd, &rdset);

                // 更新最大的文件描述符
                maxfd = maxfd > cfd ? maxfd : cfd;
            }

            for(int i = lfd + 1; i <= maxfd; i++) {
                if(FD_ISSET(i, &tmp)) {
                    // 说明这个文件描述符对应的客户端发来了数据
                    char buf[1024] = {0};
                    int len = read(i, buf, sizeof(buf));
                    if(len == -1) {
                        perror("read");
                        exit(-1);
                    } else if(len == 0) {
                        printf("client closed...\n");
                        close(i);
                        FD_CLR(i, &rdset);
                    } else if(len > 0) {
                        printf("read buf = %s\n", buf);
                        write(i, buf, strlen(buf) + 1);
                    }
                }
            }
        }
    }
    close(lfd);
    return 0;
}
```

## poll

poll 不再用 BitsMap 来存储所关注的文件描述符，取而代之用动态数组，以链表形式来组织，突破了 select 的文件描述符个数限制，当然还会受到系统文件描述符限制。

但是 poll 和 select 并没有太大的本质区别，**都是使用「线性结构」存储进程关注的 Socket 集合，因此都需要遍历文件描述符集合来找到可读或可写的 Socket，时间复杂度为 O(n)，而且也需要在用户态与内核态之间拷贝文件描述符集合**，这种方式随着并发数上来，性能的损耗会呈指数级增长。

```php
#include <poll.h>
struct pollfd {
    int  fd;     /* 委托内核检测的文件描述符 */
    short events;   /* 委托内核检测文件描述符的什么事件 */
    short revents;   /* 文件描述符实际发生的事件 */
};

//栗子
struct pollfd myfd;
myfd.fd = 5;
myfd.events = POLLIN | POLLOUT;

int poll(struct pollfd *fds, nfds_t nfds, int timeout);
- 参数：
    - fds : 是一个struct pollfd 结构体数组，这是一个需要检测的文件描述符的集合
        	传入传出参数
    - nfds : 这个是第一个参数数组中最后一个有效元素的下标 + 1
    - timeout : 阻塞时长
      0 : 不阻塞
      -1 : 阻塞，当检测到需要检测的文件描述符有变化，解除阻塞
      >0 : 阻塞的时长
  - 返回值：
    -1 : 失败
    >0（n） : 成功, n表示检测到集合中有n个文件描述符发生变化
```

例子：

```php
#include <stdio.h>
#include <arpa/inet.h>
#include <unistd.h>
#include <stdlib.h>
#include <string.h>
#include <poll.h>

int main() {
    // 创建socket
    int lfd = socket(PF_INET, SOCK_STREAM, 0);
    struct sockaddr_in saddr;
    saddr.sin_port = htons(9999);
    saddr.sin_family = AF_INET;
    saddr.sin_addr.s_addr = INADDR_ANY;

    // 绑定
    bind(lfd, (struct sockaddr *)&saddr, sizeof(saddr));

    // 监听
    listen(lfd, 8);

    // 初始化检测的文件描述符数组
    struct pollfd fds[1024];
    for(int i = 0; i < 1024; i++) {
        fds[i].fd = -1;
        fds[i].events = POLLIN;
    }
    fds[0].fd = lfd;
    int nfds = 0;

    while(1) {
        // 调用poll系统函数，让内核帮检测哪些文件描述符有数据
        int ret = poll(fds, nfds + 1, -1);
        if(ret == -1) {
            perror("poll");
            exit(-1);
        } else if(ret == 0) {
            continue;
        } else if(ret > 0) {
            // 说明检测到了有文件描述符的对应的缓冲区的数据发生了改变
            if(fds[0].revents & POLLIN) {
                // 表示有新的客户端连接进来了
                struct sockaddr_in cliaddr;
                int len = sizeof(cliaddr);
                int cfd = accept(lfd, (struct sockaddr *)&cliaddr, &len);
                // 将新的文件描述符加入到集合中
                for(int i = 1; i < 1024; i++) {
                    if(fds[i].fd == -1) {
                        fds[i].fd = cfd;
                        fds[i].events = POLLIN;
                        break;
                    }
                }
                // 更新最大的文件描述符的索引
                nfds = nfds > cfd ? nfds : cfd;
            }

            for(int i = 1; i <= nfds; i++) {
                if(fds[i].revents & POLLIN) {
                    // 说明这个文件描述符对应的客户端发来了数据
                    char buf[1024] = {0};
                    int len = read(fds[i].fd, buf, sizeof(buf));
                    if(len == -1) {
                        perror("read");
                        exit(-1);
                    } else if(len == 0) {
                        printf("client closed...\n");
                        close(fds[i].fd);
                        fds[i].fd = -1;
                    } else if(len > 0) {
                        printf("read buf = %s\n", buf);
                        write(fds[i].fd, buf, strlen(buf) + 1);
                    }
                }
            }
        }
    }
    close(lfd);
    return 0;
}
```

## epoll

用法：先用`epoll_create `创建一个 epoll 对象 epfd，再通过 `epoll_ctl `将需要监视的 socket 添加到epfd中，最后调用 `epoll_wait `等待数据。

```php
int s = socket(AF_INET, SOCK_STREAM, 0);
bind(s, ...);
listen(s, ...)

int epfd = epoll_create(...);
epoll_ctl(epfd, ...); //将所有需要监听的socket添加到epfd中

while(1) {
    int n = epoll_wait(...);
    for(接收到数据的socket){
        //处理
    }
}
```

```php
#include <sys/epoll.h>
// 创建一个新的epoll实例。在内核中创建了一个数据，这个数据中有两个比较重要的数据：
// 一个是需要检测的文件描述符的信息（红黑树）
// 还有一个是就绪列表，存放检测到数据发生改变的文件描述符信息（双向链表）

int epoll_create(int size);
- 参数：
    size : 目前没有意义了。随便写一个数，必须大于0
- 返回值：
    -1 : 失败
    > 0 : 文件描述符，操作epoll实例的
  
// 对epoll实例进行管理：添加文件描述符信息，删除信息，修改信息
int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);
- 参数：
  - epfd : epoll实例对应的文件描述符
  - op : 要进行什么操作
    EPOLL_CTL_ADD:  添加
    EPOLL_CTL_MOD: 修改
    EPOLL_CTL_DEL: 删除
  - fd : 要检测的文件描述符
  - event : 检测文件描述符对应的检测事件

    struct epoll_event {
    uint32_t   events;    /* Epoll events */
    epoll_data_t data;     /* User data variable */
    };

    常见的 Epoll 检测事件：
      - EPOLLIN
      - EPOLLOUT
      - EPOLLERR
      
    typedef union epoll_data {
    void     *ptr;
    int      fd;
    uint32_t   u32;
    uint64_t   u64;
    } epoll_data_t;

// 检测函数        
int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout);
- 参数：
  - epfd : epoll实例对应的文件描述符
  - events : 传出参数，保存发送变化的文件描述符的信息
  - maxevents : 第二个参数结构体数组的大小
  - timeout : 阻塞时间
    - 0 : 不阻塞
    - -1 : 阻塞，直到检测到fd数据发生变化，解除阻塞
    - > 0 : 阻塞的时长（毫秒）
       
- 返回值：
  - 成功，返回发送变化的文件描述符的个数 > 0
  - 失败 -1
```

epoll 通过两个方面，很好解决了 select/poll 的问题。

第一点，**epoll 在内核里使用红黑树来跟踪进程所有待检测的文件描述符**，把需要监控的 socket 通过 epoll_ctl() 函数加入内核中的红黑树里，红黑树是个高效的数据结构，增删改一般时间复杂度是 O(logn)。而 select/poll 内核里没有类似 epoll 红黑树这种保存所有待检测的 socket 的数据结构，所以 select/poll 每次操作时都传入整个 socket 集合给内核。而 epoll 因为在内核里维护了红黑树，可以保存所有待检测的 socket，应用程序直接把需要监控的 socket 对象添加到红黑树上，减少了内核和用户空间大量的数据拷贝和内存分配。

第二点， **epoll 在内核里维护了一个双向链表来记录就绪的文件描述符**，当某个 socket 有事件发生时，通过回调函数内核会将其加入到这个就绪事件列表中，当用户调用 epoll_wait() 函数时，只会返回有事件发生的文件描述符的个数，不需要像 select/poll 那样轮询扫描整个 socket 集合，大大提高了检测的效率。使用双向链表缓存就绪的 socket 数量较少，只需要拷贝这个双向链表到用户空间，再遍历就行，注意这里也需要拷贝，没有共享内存。


```php
#include <stdio.h>
#include <arpa/inet.h>
#include <unistd.h>
#include <stdlib.h>
#include <string.h>
#include <sys/epoll.h>

int main() {

    // 创建socket
    int lfd = socket(PF_INET, SOCK_STREAM, 0);
    struct sockaddr_in saddr;
    saddr.sin_port = htons(9999);
    saddr.sin_family = AF_INET;
    saddr.sin_addr.s_addr = INADDR_ANY;

    // 绑定
    bind(lfd, (struct sockaddr *)&saddr, sizeof(saddr));

    // 监听
    listen(lfd, 8);

    // 调用epoll_create()创建一个epoll实例
    int epfd = epoll_create(100);

    // 将监听的文件描述符相关的检测信息添加到epoll实例中
    struct epoll_event epev;
    epev.events = EPOLLIN;
    epev.data.fd = lfd;
    epoll_ctl(epfd, EPOLL_CTL_ADD, lfd, &epev);

    struct epoll_event epevs[1024];

    while(1) {
        int ret = epoll_wait(epfd, epevs, 1024, -1);
        if(ret == -1) {
            perror("epoll_wait");
            exit(-1);
        }

        printf("ret = %d\n", ret);

        for(int i = 0; i < ret; i++) {
            int curfd = epevs[i].data.fd;
            if(curfd == lfd) {
                // 监听的文件描述符有数据达到，有客户端连接
                struct sockaddr_in cliaddr;
                int len = sizeof(cliaddr);
                int cfd = accept(lfd, (struct sockaddr *)&cliaddr, &len);

                epev.events = EPOLLIN;
                epev.data.fd = cfd;
                epoll_ctl(epfd, EPOLL_CTL_ADD, cfd, &epev);
            } else {
                if(epevs[i].events & EPOLLOUT) {
                    continue;
                }   
                // 有数据到达，需要通信
                char buf[1024] = {0};
                int len = read(curfd, buf, sizeof(buf));
                if(len == -1) {
                    perror("read");
                    exit(-1);
                } else if(len == 0) {
                    printf("client closed...\n");
                    epoll_ctl(epfd, EPOLL_CTL_DEL, curfd, NULL);
                    close(curfd);
                } else if(len > 0) {
                    printf("read buf = %s\n", buf);
                    write(curfd, buf, strlen(buf) + 1);
                }
            }
        }
    }

    close(lfd);
    close(epfd);
    return 0;
}
```
- epoll为什么不用hash(O(1)的查找)，而用红黑树？

epoll 管理的文件描述符数量不确定，如果使用hash，不管是用拉链法，还是用开放寻址法，都需要提前创建一个数组，但由于无法确定epoll管理的文件描述符数量，所以不知道数组要创建多大，所以没办法使用hash。

- select，poll，epoll的时间复杂度

poll轮询的是所有的socket，而epoll只轮询就绪的socket。所有，poll和select的时间复杂度为O(n)，每个监听的文件描述符都遍历一遍。epoll的时间复杂度为O(1)，只遍历就绪的socket，在内核中断程序中添加就绪文件描述符到就绪列表。



## 触发方式

epoll 支持两种事件触发模式，分别是**边缘触发**（edge-triggered，ET）和**水平触发**（level-triggered，LT）。

使用边缘触发模式时，当被监控的 Socket 描述符上有可读事件发生时，**服务器端只会从 epoll_wait 中苏醒一次**，即使进程没有调用 read 函数从内核读取数据，也依然只苏醒一次，因此程序要保证一次性将内核缓冲区的数据读取完。

使用水平触发模式时，当被监控的 Socket 上有可读事件发生时，**服务器端不断地从 epoll_wait 中苏醒，直到内核缓冲区数据被 read 函数读完才结束**，目的是告诉我们有数据需要读取。

这就是两者的区别，水平触发是只要满足事件的条件，比如内核中有数据需要读，就一直不断地把这个事件传递给用户；而边缘触发是只有第一次满足条件的时候才触发，之后就不会再传递同样的事件了。

如果使用水平触发模式，当内核通知文件描述符可读写时，接下来还可以继续去检测它的状态，看它是否依然可读或可写。所以在收到通知后，没必要一次执行尽可能多的读写操作。

如果使用边缘触发模式，I/O 事件发生时只会通知一次，而且我们不知道到底能读写多少数据，所以在收到通知后应尽可能地读写数据，以免错失读写的机会。因此，我们会**循环**从文件描述符读写数据，那么如果文件描述符是阻塞的，没有数据可读写时，进程会阻塞在读写函数那里，程序就没办法继续往下执行。所以，**边缘触发模式一般和非阻塞 I/O 搭配使用**，程序会一直执行 I/O 操作，直到系统调用（如 `read` 和 `write`）返回错误，错误类型为 `EAGAIN` 或 `EWOULDBLOCK`。

一般来说，边缘触发的效率比水平触发的效率要高，因为边缘触发可以减少 epoll_wait 的系统调用次数，系统调用也是有一定的开销的的，毕竟也存在上下文的切换。select / poll 只有水平触发模式，epoll 默认的触发模式是水平触发，但是可以根据应用场景设置为边缘触发模式。

# Socket 通信

`socket`（套接字）可以实现网络中不同主机上的应用进程之间进行双向通信。与管道类似的，Linux 系统将其封装成文件的目的是为了统一接口，使得读写套接字和读写文件的操作一致，区别是管道主要应用于本地进程间通信，而套接字多应用于网络进程间通信。

## 字节序

字节序就是大于一个字节类型的数据在内存中的存放顺序。字节序分为大端字节序和小端字节序。

大端字节序是指一个整数的最高位字节（23 ~ 31 bit）存储在内存的低地址处，低位字节（0 ~ 7 bit）存储在内存的高地址处；小端字节序则是指整数的高位字节存储在内存的高地址处，而低位字节则存储在内存的低地址处。

- **字节序转换函数**

当格式化的数据在两台使用不同字节序的主机之间直接传递时，接收端必然错误的解释。解决问题的方法是：发送端总是把要发送的数据转换成大端字节序数据后再发送，而接收端知道对方传送过来的数据总是采用大端字节序，所以接收端可以根据自身采用的字节序决定是否对接收到的数据进行转换（小端机转换，大端机不转换）。

网络字节顺序是 TCP/IP 中规定好的一种数据表示格式，它与具体的 CPU 类型、操作系统等无关，从而可以保证数据在不同主机之间传输时能够被正确解释，**网络字节顺序采用大端排序方式**。

BSD Socket提供了封装好的转换接口，方便程序员使用。包括从主机字节序到网络字节序的转换函数：htons、htonl；从网络字节序到主机字节序的转换函数：ntohs、ntohl。

```php
h - host 主机，主机字节序
to - 转换成什么
n - network  网络字节序
s - short  unsigned short
l  - long  unsigned int
```
```php
#include <arpa/inet.h>
// 转换端口
uint16_t htons(uint16_t hostshort); // 主机字节序 - 网络字节序
uint16_t ntohs(uint16_t netshort); // 网络字节序 - 主机字节序
// 转IP
uint32_t htonl(uint32_t hostlong); // 主机字节序 - 网络字节序
uint32_t ntohl(uint32_t netlong); // 网络字节序 - 主机字节序
```
- 举例
```php
#include <stdio.h>
#include <arpa/inet.h>
int main() {
    // htons 转换端口
    unsigned short a = 0x0102;
    printf("a : %x\n", a);
    unsigned short b = htons(a);
    printf("b : %x\n", b);

    printf("=======================\n");

    // htonl  转换IP
    char buf[4] = {192, 168, 1, 100};
    int num = *(int *)buf;
    int sum = htonl(num);
    unsigned char *p = (char *)&sum;

    printf("%d %d %d %d\n", *p, *(p+1), *(p+2), *(p+3));

    printf("=======================\n");

    // ntohl
    unsigned char buf1[4] = {1, 1, 168, 192};
    int num1 = *(int *)buf1;
    int sum1 = ntohl(num1);
    unsigned char *p1 = (unsigned char *)&sum1;
    printf("%d %d %d %d\n", *p1, *(p1+1), *(p1+2), *(p1+3));
     // ntohs
    return 0;
}
```
## socket 地址

socket地址其实是一个结构体，封装端口号和IP等信息，后面的socket相关的api中需要使用到这个socket地址。

- **通用 socket 地址**

socket 网络编程接口中表示 socket 地址的是结构体 `sockaddr`，其定义如下：
```php
#include <bits/socket.h>
struct sockaddr {
    sa_family_t sa_family;
    char     sa_data[14];
};
typedef unsigned short int sa_family_t;
```
sa_family 成员是地址族类型（sa_family_t）的变量，地址族类型通常与协议族类型对应。常见的协议族（protocol family，也称 domain）和对应的地址族如下所示：

<img src="https://gcore.jsdelivr.net/gh/gp868/myFigures/img/202206272154303.png" alt="image-20220627215434240" style="zoom:70%;" />

宏 PF_* 和 AF_* 都定义在 bits/socket.h 头文件中，且后者与前者有完全相同的值，所以二者通常混用。

sa_data 成员用于存放 socket 地址值。但是，不同的协议族的地址值具有不同的含义和长度，如下所示：

<img src="https://gcore.jsdelivr.net/gh/gp868/myFigures/img/202206272154889.png" alt="image-20220627215454825" style="zoom:70%;" />

由上表可知，14 字节的 sa_data 根本无法容纳多数协议族的地址值。因此，Linux 定义了下面这个新的通用的 socket 地址结构体，这个结构体不仅提供了足够大的空间用于存放地址值，而且是内存对齐的。

```php
#include <bits/socket.h>
struct sockaddr_storage{
    sa_family_t sa_family;
    unsigned long int __ss_align;
    char __ss_padding[ 128 - sizeof(__ss_align) ];
};
typedef unsigned short int sa_family_t;
```
- **专用 socket 地址**

很多网络编程函数诞生早于 IPv4 协议，那时候都使用的是 `struct sockaddr` 结构体，为了向前兼容，现在sockaddr 退化成了（void *）的作用，传递一个地址给函数，至于这个函数是 `sockaddr_in `还是`sockaddr_in6`，由地址族确定，然后函数内部再强制类型转化为所需的地址类型。

<img src="https://gcore.jsdelivr.net/gh/gp868/myFigures/img/202206272155921.png" alt="image-20220627215554853" style="zoom:75%;" />

UNIX 本地域协议族使用如下专用的 socket 地址结构体：

```php
#include <sys/un.h>
struct sockaddr_un{
    sa_family_t sin_family;
    char sun_path[108];
};
```
TCP/IP 协议族有 `sockaddr_in` 和 `sockaddr_in6 `两个专用的 socket 地址结构体，它们分别用于 IPv4 和 IPv6：

```php
#include <netinet/in.h>
struct sockaddr_in{
  sa_family_t sin_family; /* __SOCKADDR_COMMON(sin_) */
  in_port_t sin_port;     /* Port number. */
  struct in_addr sin_addr;   /* Internet address. */
  /* Pad to size of `struct sockaddr'. */
  unsigned char sin_zero[sizeof (struct sockaddr) - __SOCKADDR_COMMON_SIZE -
       sizeof (in_port_t) - sizeof (struct in_addr)];
}; 

struct in_addr{
  in_addr_t s_addr;
};

struct sockaddr_in6{
  sa_family_t sin6_family;
  in_port_t sin6_port; /* Transport layer port # */
  uint32_t sin6_flowinfo; /* IPv6 flow information */
  struct in6_addr sin6_addr; /* IPv6 address */
  uint32_t sin6_scope_id; /* IPv6 scope-id */
};

typedef unsigned short  uint16_t;
typedef unsigned int   uint32_t;
typedef uint16_t in_port_t;
typedef uint32_t in_addr_t;
#define __SOCKADDR_COMMON_SIZE (sizeof (unsigned short int))
```
所有专用 socket 地址（以及 sockaddr_storage）类型的变量在实际使用时都需要转化为通用 socket 地址类型 sockaddr（强制转化即可），因为所有 socket 编程接口使用的地址参数类型都是 sockaddr。

## IP地址转换

通常，人们习惯用可读性好的字符串来表示 IP 地址，比如用点分十进制字符串表示 IPv4 地址，以及用十六进制字符串表示 IPv6 地址。但编程中我们需要先把它们转化为整数（二进制数）方能使用，而记录日志时则相反，我们要把整数表示的 IP 地址转化为可读的字符串。

下面 3 个函数可用于用点分十进制字符串表示的 IPv4 地址和用网络字节序整数表示的 IPv4 地址之间的转换：

```php
#include <arpa/inet.h>
in_addr_t inet_addr(const char *cp);
int inet_aton(const char *cp, struct in_addr *inp);
char *inet_ntoa(struct in_addr in);
```
下面更新的函数也能完成前面 3 个函数同样的功能，并且它们同时适用 IPv4 地址和 IPv6 地址，**推荐使用**：

```php
#include <arpa/inet.h>
// p:点分十进制的IP字符串，n:表示network，网络字节序的整数

int inet_pton(int af, const char *src, void *dst);
  af:地址族： AF_INET  AF_INET6
  src:需要转换的点分十进制的IP字符串
  dst:转换后的结果保存在这个里面，传出参数

// 将网络字节序的整数，转换成点分十进制的IP地址字符串
const char *inet_ntop(int af, const void *src, char *dst, socklen_t size);
  af:地址族： AF_INET  AF_INET6
  src: 要转换的ip的整数的地址
  dst: 转换成IP地址字符串保存的地方，传出参数
  size：第三个参数的大小（数组的大小）
返回值：返回转换后的数据的地址（字符串），和 dst 是一样的
```
- 栗子
```php
#include <stdio.h>
#include <arpa/inet.h>
int main() {
    // 创建一个ip字符串,点分十进制的IP地址字符串
    char buf[] = "192.168.1.4";
    unsigned int num = 0;

    // 将点分十进制的IP字符串转换成网络字节序的整数
    inet_pton(AF_INET, buf, &num);
    unsigned char * p = (unsigned char *)&num;
    printf("%d %d %d %d\n", *p, *(p+1), *(p+2), *(p+3));

    // 将网络字节序的IP整数转换成点分十进制的IP字符串
    char ip[16] = "";
    const char * str =  inet_ntop(AF_INET, &num, ip, 16);
    printf("str : %s\n", str);
    printf("ip : %s\n", str);
    printf("%d\n", ip == str);
    return 0;
}
```
## 通信流程

TCP通信流程要会口述并且熟悉其中的系统调用：

<img src="https://gcore.jsdelivr.net/gh/gp868/myFigures/img/202206272157464.png" alt="image-20220627215713346" style="zoom:50%;" />

```php
// 服务器端 （被动接受连接的角色）
1. 创建一个用于监听的套接字
  - 监听：监听有客户端的连接
  - 套接字：这个套接字其实就是一个文件描述符
2. 将这个监听文件描述符和本地的IP和端口绑定（IP和端口就是服务器的地址信息）
  - 客户端连接服务器的时候使用的就是这个IP和端口
3. 设置监听，监听的fd开始工作
4. 阻塞等待，当有客户端发起连接，解除阻塞，接受客户端的连接，
   会得到一个和客户端通信的套接字（fd）
5. 通信
 - 接收数据
 - 发送数据
6. 通信结束，断开连接

// 客户端
1. 创建一个用于通信的套接字（fd）
2. 连接服务器，需要指定连接的服务器的 IP 和 端口
3. 连接成功了，客户端可以直接和服务器通信
  - 接收数据
  - 发送数据
4. 通信结束，断开连接
```

## socket 函数

```php
#include <sys/types.h>   
#include <sys/socket.h>
#include <arpa/inet.h> // 包含了这个头文件，上面两个就可以省略
int socket(int domain, int type, int protocol);
- 功能：创建一个套接字
- 参数：
  - domain: 协议族
     AF_INET : ipv4
     AF_INET6 : ipv6
     AF_UNIX, AF_LOCAL : 本地套接字通信（进程间通信）
  - type: 通信过程中使用的协议类型
     SOCK_STREAM : 流式协议，适用TCP
     SOCK_DGRAM : 报式协议，适用UDP
  - protocol : 具体的一个协议。一般写0
    - SOCK_STREAM : 流式协议默认使用 TCP
    - SOCK_DGRAM : 报式协议默认使用 UDP
  - 返回值：
    - 成功：返回文件描述符，操作的就是内核缓冲区。
    - 失败：-1  
      
int bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen); // socket命名
- 功能：绑定，将fd 和本地的IP + 端口进行绑定
- 参数：
    - sockfd : 通过socket函数得到的文件描述符
    - addr : 需要绑定的socket地址，这个地址封装了ip和端口号的信息
    - addrlen : 第二个参数结构体占的内存大小
   - 返回值：
    - 成功：0
    - 失败：-1 

int listen(int sockfd, int backlog); // /proc/sys/net/core/somaxconn
- 功能：监听这个socket上的连接
- 参数：
    - sockfd : 通过socket()函数得到的文件描述符
    - backlog : 未连接的和已经连接的和的最大值， 5

int accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen);
- 功能：接收客户端连接，默认是一个阻塞的函数，阻塞等待客户端连接
- 参数：
   - sockfd : 用于监听的文件描述符
   - addr : 传出参数，记录了连接成功后客户端的地址信息（ip，port）
   - addrlen : 指定第二个参数的对应的内存大小
  - 返回值：
   - 成功 ：用于通信的文件描述符
   - -1 ： 失败
             
int connect(int sockfd, const struct sockaddr *addr, socklen_t addrlen);
- 功能： 客户端连接服务器
- 参数：
   - sockfd : 用于通信的文件描述符
   - addr : 客户端要连接的服务器的地址信息
   - addrlen : 第二个参数的内存大小
- 返回值：成功 0， 失败 -1

ssize_t write(int fd, const void *buf, size_t count); // 写数据
ssize_t read(int fd, void *buf, size_t count); // 读数据
```
例子：

```php
// TCP 通信的服务器端
#include <stdio.h>
#include <arpa/inet.h>
#include <unistd.h>
#include <string.h>
#include <stdlib.h>

int main() {

    // 1.创建socket(用于监听的套接字)
    int lfd = socket(AF_INET, SOCK_STREAM, 0);

    if(lfd == -1) {
        perror("socket");
        exit(-1);
    }

    // 2.绑定
    struct sockaddr_in saddr;
    saddr.sin_family = AF_INET;
    // inet_pton(AF_INET, "192.168.160.130", saddr.sin_addr.s_addr);
    saddr.sin_addr.s_addr = INADDR_ANY;  // 0.0.0.0
    saddr.sin_port = htons(9999);
    int ret = bind(lfd, (struct sockaddr *)&saddr, sizeof(saddr));

    if(ret == -1) {
        perror("bind");
        exit(-1);
    }

    // 3.监听
    ret = listen(lfd, 8);
    if(ret == -1) {
        perror("listen");
        exit(-1);
    }

    // 4.接收客户端连接
    struct sockaddr_in clientaddr;
    int len = sizeof(clientaddr);
    int cfd = accept(lfd, (struct sockaddr *)&clientaddr, &len);
    
    if(cfd == -1) {
        perror("accept");
        exit(-1);
    }

    // 输出客户端的信息
    char clientIP[16];
    inet_ntop(AF_INET, &clientaddr.sin_addr.s_addr, clientIP, sizeof(clientIP));
    unsigned short clientPort = ntohs(clientaddr.sin_port);
    printf("client ip is %s, port is %d\n", clientIP, clientPort);

    // 5.通信
    char recvBuf[1024] = {0};
    while(1) {
        
        // 获取客户端的数据
        int num = read(cfd, recvBuf, sizeof(recvBuf));
        if(num == -1) {
            perror("read");
            exit(-1);
        } else if(num > 0) {
            printf("recv client data : %s\n", recvBuf);
        } else if(num == 0) {
            // 表示客户端断开连接
            printf("clinet closed...");
            break;
        }

        char * data = "hello,i am server";
        // 给客户端发送数据
        write(cfd, data, strlen(data));
    }
   
    // 关闭文件描述符
    close(cfd);
    close(lfd);

    return 0;
}
```

```php
// TCP通信的客户端

#include <stdio.h>
#include <arpa/inet.h>
#include <unistd.h>
#include <string.h>
#include <stdlib.h>

int main() {

    // 1.创建套接字
    int fd = socket(AF_INET, SOCK_STREAM, 0);
    if(fd == -1) {
        perror("socket");
        exit(-1);
    }

    // 2.连接服务器端
    struct sockaddr_in serveraddr;
    serveraddr.sin_family = AF_INET;
    inet_pton(AF_INET, "192.168.193.128", &serveraddr.sin_addr.s_addr);
    serveraddr.sin_port = htons(9999);
    int ret = connect(fd, (struct sockaddr *)&serveraddr, sizeof(serveraddr));

    if(ret == -1) {
        perror("connect");
        exit(-1);
    }

    
    // 3. 通信
    char recvBuf[1024] = {0};
    while(1) {
        char * data = "hello,i am client";
        // 给客户端发送数据
        write(fd, data , strlen(data));

        sleep(1);
        
        int len = read(fd, recvBuf, sizeof(recvBuf));
        if(len == -1) {
            perror("read");
            exit(-1);
        } else if(len > 0) {
            printf("recv server data : %s\n", recvBuf);
        } else if(len == 0) {
            // 表示服务器端断开连接
            printf("server closed...");
            break;
        }
    }
    // 关闭连接
    close(fd);
    return 0;
}
```
## TCP 并发通信

**多进程通信**：

子进程不需要关心「监听 Socket」，只需要关心「已连接 Socket」；父进程则相反，将客户服务交给子进程来处理，因此父进程不需要关心「已连接 Socket」，只需要关心「监听 Socket」。

<img src="https://gcore.jsdelivr.net/gh/gp868/myFigures/img/202206272133442.png" alt="img" style="zoom:70%;" />

**多线程通信**：

当服务器与客户端 TCP 完成连接后，通过 `pthread_create()` 函数创建线程，然后将「已连接 Socket」的文件描述符传递给线程函数，接着在线程里和客户端进行通信，从而达到并发处理的目的。

使用**线程池**的方式来避免线程的频繁创建和销毁，提前创建若干个线程，当有新连接建立时，将这个已连接的 Socket 放入到一个队列里，然后线程池里的线程负责从队列中取出已连接 Socket 进程处理。

<img src="https://gcore.jsdelivr.net/gh/gp868/myFigures/img/202206272134707.png" alt="img" style="zoom:65%;" />

需要注意的是，这个队列是全局的，每个线程都会操作，为了避免多线程竞争，线程在操作这个队列前要加锁。

# 事件处理模式

服务器程序通常需要处理三类事件：I/O 事件、信号及定时事件。有两种高效的事件处理模式：Reactor 和 Proactor，同步 I/O 模型通常用于实现 Reactor 模式，异步 I/O 模型通常用于实现 Proactor 模式。

## Reactor模式
要求主线程（I/O处理单元）只负责监听文件描述符上是否有事件发生，有的话就立即将该事件通知工作线程（逻辑单元），将 socket 可读可写事件放入请求队列，交给工作线程处理。除此之外，主线程不做任何其他实质性的工作。读写数据，接受新的连接，以及处理客户请求均在工作线程中完成。

使用同步 I/O（以 epoll_wait 为例）实现的 Reactor 模式的工作流程是：
1. 主线程往 epoll 内核事件表中注册 socket 上的读就绪事件。
2. 主线程调用 epoll_wait 等待 socket 上有数据可读。
3. 当 socket 上有数据可读时， epoll_wait 通知主线程。主线程则将 socket 可读事件放入请求队列。
4. 睡眠在请求队列上的某个工作线程被唤醒，它从 socket 读取数据，并处理客户请求，然后往 epoll内核事件表中注册该 socket 上的写就绪事件。
5. 当主线程调用 epoll_wait 等待 socket 可写。
6. 当 socket 可写时，epoll_wait 通知主线程。主线程将 socket 可写事件放入请求队列。
7. 睡眠在请求队列上的某个工作线程被唤醒，它往 socket 上写入服务器处理客户请求的结果。

Reactor 模式的工作流程：

<img src="https://gcore.jsdelivr.net/gh/gp868/myFigures/img/202206281736564.png" style="zoom:80%;" />

## Proactor模式
Proactor 模式将所有 I/O 操作都交给主线程和内核来处理（进行读、写），工作线程仅仅负责业务逻辑。使用异步 I/O 模型（以 aio_read 和 aio_write 为例）实现的 Proactor 模式的工作流程是：
1. 主线程调用 aio_read 函数向内核注册 socket 上的读完成事件，并告诉内核用户读缓冲区的位置，以及读操作完成时如何通知应用程序（这里以信号为例）。
2. 主线程继续处理其他逻辑。
3. 当 socket 上的数据被读入用户缓冲区后，内核将向应用程序发送一个信号，以通知应用程序数据已经可用。
4. 应用程序预先定义好的信号处理函数选择一个工作线程来处理客户请求。工作线程处理完客户请求后，调用 aio_write 函数向内核注册 socket 上的写完成事件，并告诉内核用户写缓冲区的位置，以及写操作完成时如何通知应用程序。
5. 主线程继续处理其他逻辑。
6. 当用户缓冲区的数据被写入 socket 之后，内核将向应用程序发送一个信号，以通知应用程序数据已经发送完毕。
7. 应用程序预先定义好的信号处理函数选择一个工作线程来做善后处理，比如决定是否关闭 socket。

Proactor 模式的工作流程：

<img src="https://gcore.jsdelivr.net/gh/gp868/myFigures/img/202206281721001.png" style="zoom:80%;" />

可惜的是，在 Linux 下的异步 I/O 是不完善的， `aio` 系列函数是由 POSIX 定义的异步操作接口，不是真正的操作系统级别支持的，而是在用户空间模拟出来的异步，并且仅仅支持基于本地文件的 aio 异步操作，网络编程中的 socket 是不支持的，这也使得基于 Linux 的高性能网络程序都是使用 Reactor 方案。

而 Windows 里实现了一套完整的支持 socket 的异步编程接口，这套接口就是 `IOCP`，是由操作系统级别实现的异步 I/O，是真正意义上异步 I/O，因此在 Windows 里实现高性能网络程序可以使用效率更高的 Proactor 方案。

## 模拟 Proactor 模式

使用同步 I/O 方式模拟出 Proactor 模式。原理是：主线程执行数据读写操作，读写完成之后，主线程向工作线程通知这一 “完成事件”。那么从工作线程的角度来看，它们就直接获得了数据读写的结果，接下来要做的只是对读写的结果进行逻辑处理。

使用同步 I/O 模型（以 epoll_wait为例）模拟出的 Proactor 模式的工作流程如下：
1. 主线程往 epoll 内核事件表中注册 socket 上的读就绪事件。
2. 主线程调用 epoll_wait 等待 socket 上有数据可读。
3. 当 socket 上有数据可读时，epoll_wait 通知主线程。主线程从 socket 循环读取数据，直到没有更多数据可读，然后将读取到的数据封装成一个请求对象并插入请求队列。
4. 睡眠在请求队列上的某个工作线程被唤醒，它获得请求对象并处理客户请求，然后往 epoll 内核事件表中注册 socket 上的写就绪事件。
5. 主线程调用 epoll_wait 等待 socket 可写。
6. 当 socket 可写时，epoll_wait 通知主线程。主线程往 socket 上写入服务器处理客户请求的结果。

同步 I/O 模拟 Proactor 模式的工作流程：

<img src="https://gcore.jsdelivr.net/gh/gp868/myFigures/img/202206281721016.png" style="zoom:80%;" />

# 补充

- 为什么要区分内核态和用户态？

  区分内核态和用户态是为了保证操作系统的稳定性和安全性。

  在内核态下，操作系统可以直接访问硬件资源，执行特权指令，进行系统管理和维护任务，如进程调度、内存管理、设备驱动等。而在用户态下，应用程序只能通过系统调用接口向操作系统发起请求，操作系统会在内核态下完成相应的任务并返回结果给应用程序。

  通过区分内核态和用户态，可以有效地隔离应用程序和操作系统，防止应用程序的错误或恶意行为对操作系统的稳定性和安全性产生影响。同时，也可以提高操作系统的性能和效率，因为内核态下的操作系统可以直接访问硬件资源，而不需要经过系统调用的开销和限制。

* 内核态和用户态的区别
  1. 权限不同：内核态具有更高的权限，可以访问系统的所有资源，而用户态只能访问受限的资源。

  2. 运行环境不同：内核态运行在操作系统内部，用户态运行在操作系统外部。

  3. 调用方式不同：内核态通过系统调用方式调用操作系统提供的服务，而用户态通过库函数调用操作系统提供的服务。

  4. 响应速度不同：内核态响应速度更快，因为它可以直接访问硬件资源，而用户态需要通过操作系统提供的接口访问硬件资源。

  5. 安全性不同：内核态具有更高的安全性，因为它可以保护系统资源不被用户态非法访问。

  6. 内存管理不同：内核态可以直接访问所有内存，而用户态只能访问自己的内存空间。

  7. 中断处理不同：内核态可以处理所有中断，而用户态只能处理非关键性中断。

- 导致从用户态切换到内核态的操作

  - 系统调用

    很多程序开始时运行于用户态，但在执行的过程中，一些操作需要在内核权限下才能执行，这就涉及到一个从**用户态切换到内核态**的过程。比如C函数库中的内存分配函数 malloc()，它具体是使用 sbrk() 系统调用来分配内存，当malloc() 调用 sbrk() 的时候就涉及一次从用户态到内核态的切换，类似的函数还有 printf()，调用的是 wirte() 系统调用来输出字符串，等等。
  
  
    - 异常事件
  
      当 CPU 正在执行运行在用户态的程序时，突然发生某些预先不可知的异常事件，就会触发从当前用户态执行的进程转向内核态执行相关的异常事件，典型的如缺页异常。
  
  
    - 外围设备中断
  
      当外围设备完成用户的请求操作后，会向 CPU 发出中断信号，此时，CPU 就会暂停执行下一条即将要执行的指令，转而去执行中断信号对应的处理程序，如果先前执行的指令是在用户态下，则自然就发生从用户态到内核态的转换。


- 用户态的应用程序可以通过三种方式来访问内核态的资源：

  - 系统调用

  - 库函数

  - Shell 脚本


- 线程安全、线程安全函数、可重入函数、信号安全函数

  1. 线程安全

  线程安全是指多个线程同时访问同一份数据时，不会出现数据竞争和不一致的情况。线程安全的实现可以通过使用互斥量、信号量、读写锁等同步机制来保证。

  2. 线程安全函数

  线程安全函数是指在多线程环境下可以安全调用的函数。这些函数要么不使用全局变量，要么使用全局变量时使用同步机制来保证线程安全。例如，C标准库中的strtok_r函数就是线程安全函数。

  3. 可重入函数

  可重入函数是指在多线程环境下可以重复调用的函数。这些函数不使用全局变量，而是使用局部变量或者参数来保存状态信息。可重入函数的实现可以通过使用静态变量或者动态分配内存的方式来保存状态信息。

  4. 信号安全函数

  信号安全函数是指在信号处理函数中可以安全调用的函数。由于信号处理函数的执行是在中断上下文中进行的，因此不能使用会修改全局变量的函数，也不能使用会阻塞的函数。例如，C标准库中的malloc函数就不是信号安全函数。

- 浏览器中点击+号创建新的标签页，是开启了一个新线程还是新进程，以及原因

  在大多数浏览器中，点击+号创建新的标签页会开启一个新的进程。这是因为现代浏览器通常使用多进程架构，每个标签页都在单独的进程中运行，这样可以提高浏览器的稳定性和安全性，同时也可以更好地利用多核处理器的优势。每个进程都有自己的内存空间，这样即使一个标签页崩溃了，其他标签页也不会受到影响。当然，也有一些浏览器会在同一个进程中运行多个标签页，这取决于浏览器的具体实现。

- 产生缺页中断的几种情况：

  1. CPU所需访问的页面不在内存中，就需要将页面调入内存，如果内存已满，就需要执行相应的页面置换算法；
  2. 使用 mmap 函数在堆中创建一块虚拟内存，第一次访问时才会通过缺页中断机制映射到物理页中；
  3. fork() 创建子进程，读时共享，写时拷贝，缺页中断；


- GDB如何使用

  GDB是一种用于调试程序的工具，可以帮助程序员找出程序中的错误和问题。下面是使用GDB的基本步骤：

  1. 编译程序时加上-g选项，生成可调试的程序。

  2. 打开终端，输入gdb命令，进入GDB调试环境。

  3. 在GDB环境中，输入run命令，运行程序。

  4. 如果程序出现错误，GDB会停止程序的执行，并显示出错的位置。

  5. 可以使用backtrace命令查看函数调用栈，使用print命令查看变量的值，使用step命令逐行执行程序，使用break命令设置断点等。

  6. 如果需要退出GDB环境，可以使用quit命令。

  需要注意的是，GDB调试需要一定的技巧和经验，对于复杂的程序，可能需要花费较长的时间来找出问题。因此，建议在编写程序时尽可能避免出现错误，以减少调试的时间和精力。

  GDB是一款常用的调试工具，可以帮助程序员在开发过程中定位和解决程序中的错误。更详细的GDB使用方法：

  1. 编译程序时需要加上调试信息选项：-g

  例如：

  ```
  gcc -g -o myprogram myprogram.c
  ```

  2. 启动GDB

  在命令行中输入：

  ```
  gdb myprogram
  ```

  3. 设置断点

  在需要调试的代码行前加上断点：

  ```
  break main
  ```

  或者直接在GDB中输入：

  ```
  b main
  ```

  4. 运行程序

  在GDB中输入：

  ```
  run
  ```

  5. 调试程序

  程序运行到断点处时会停止，可以使用以下命令进行调试：

  - step：单步执行程序，进入函数内部
  - next：单步执行程序，不进入函数内部
  - print：打印变量的值
  - backtrace：查看函数调用栈
  - continue：继续执行程序直到下一个断点或程序结束

  6. 查看变量值

  在GDB中输入：

  ```
  print variable_name
  ```

  可以查看变量的值。

  7. 修改变量值

  在GDB中输入：

  ```
  set variable_name = new_value
  ```

  可以修改变量的值。

  8. 退出GDB

  在GDB中输入：

  ```
  quit
  ```

<img src="https://gcore.jsdelivr.net/gh/gp868/myFigures/img/202206301500801.png" alt="image-20220630145953705" style="zoom:80%;" />

<img src="https://gcore.jsdelivr.net/gh/gp868/myFigures/img/202206301500533.png" alt="image-20220630150022456" style="zoom:80%;" />

<img src="https://gcore.jsdelivr.net/gh/gp868/myFigures/img/202206301501962.png" alt="image-20220630150104907" style="zoom: 80%;" />

- 为什么ssh客户端关闭了会影响服务端的运行?

  当终端接口检测到网络连接断开，将挂断信号SIGHUP发送给控制进程(会话期首进程)。如果会话期首进程终止，则该信号发送到该会话期前台进程组。一个进程退出导致一个孤儿进程组产生时，如果任意一个孤儿进程组进程处于STOP状态，则会发送 SIGHUP 和 SIGCONT 信号到该进程组中所有进程。因此当网络断开或终端窗口关闭后，也就是SSH断开以后，控制进程收到 SIGHUP 信号退出，会导致该会话期内其他进程退出。也就是 ssh 打开以后，bash等都是他的子程序，一旦ssh关闭，系统将所有相关进程杀掉，导致一旦ssh关闭, 执行中的任务就取消了。

  那如何解决呢？

  在远端开启 tmux，在 tmux 里运行程序，此时运行的程序属于 tmux 的进程组，不属于 ssh 进程组；使用 `nohup `命令。

- 线程池里的线程数设置为多少最优？

  线程池里的线程数设置为多少最优，取决于以下因素：

  1. CPU核心数：线程池中的线程数应该小于等于CPU核心数，否则会导致CPU过度切换线程而降低性能。

  2. 任务类型：任务类型对线程池的大小也有影响。如果任务是I/O密集型，线程池中的线程数应该设置得更大，以便更好地利用I/O等待时间。如果任务是CPU密集型，线程池中的线程数应该设置得更小，以避免过度切换线程。

  3. 系统负载：系统负载也会影响线程池的大小。如果系统负载较高，线程池中的线程数应该设置得更小，以避免过度消耗系统资源。

  因此，线程池中的线程数应该根据以上因素进行适当调整，以达到最优的性能和资源利用率。


- 堆里面的机制？介绍下程序的内存释放？

  堆是一块动态分配的内存区域，程序可以在运行时向操作系统申请一定大小的堆内存，用于存储动态分配的数据结构，如链表、树、图等。堆内存的管理需要程序员手动进行，包括内存的分配和释放。

  堆的机制包括以下几个方面：

  1. 内存分配：程序通过调用malloc()或者new操作符来申请一定大小的堆内存，操作系统会在堆区域中为程序分配一块连续的内存空间，并返回内存的起始地址。

  2. 内存释放：程序通过调用free()或者delete操作符来释放先前申请的堆内存，操作系统会将这块内存标记为可用状态，等待下一次分配使用。

  3. 内存管理：程序需要手动管理堆内存的分配和释放，避免内存泄漏和内存溢出等问题。

  程序的内存释放是指程序在运行过程中释放不再使用的内存空间，以便操作系统可以重新利用这些内存空间。内存释放通常包括以下几个步骤：

  1. 标记不再使用的内存空间：程序通过一些方式标记不再使用的内存空间，如将指针置为NULL或者使用特定的标记位来标记内存块。

  2. 释放内存空间：程序通过调用free()或者delete操作符来释放不再使用的内存空间，操作系统会将这块内存标记为可用状态，等待下一次分配使用。

  3. 内存回收：操作系统会定期进行内存回收，将不再使用的内存空间回收并重新分配给其他程序使用。

  内存释放是程序设计中非常重要的一部分，如果程序没有正确释放内存，会导致内存泄漏和内存溢出等问题，严重影响程序的性能和稳定性。

- 共享内存存在于进程地址空间中哪个部分？未初始化数据段怎么存入数据？共享内存区增长方向？一般存啥？

  共享内存存在于进程地址空间中的堆区或者数据段中。未初始化数据段存入数据时，操作系统会在该段内存中分配一块空间，并将其清零。共享内存区的增长方向通常是向上增长，即地址值越来越大。一般来说，共享内存区存储的是需要在多个进程之间共享的数据，比如进程间通信的消息队列、共享缓存等。

- 内存映射工作机制，内存映射和共享内存区别？

  内存映射是一种将文件或设备映射到进程地址空间的机制。它允许进程像访问内存一样访问文件或设备，从而避免了繁琐的文件或设备I/O操作。内存映射是通过调用mmap()系统调用来实现的，它将文件或设备的数据映射到进程的虚拟地址空间中。内存映射工作机制如下：

  1. 调用mmap函数，将文件映射到进程的地址空间中。

  2. 操作系统将文件的内容读入内存中，并建立一个虚拟内存区域。

  3. 进程可以通过指针来访问这个虚拟内存区域，就像访问内存一样。

  4. 当进程对这个虚拟内存区域进行读写操作时，操作系统会自动将数据写回到文件中。

  内存映射和共享内存的区别在于，内存映射是将文件或设备映射到进程的地址空间中，而共享内存是将一块内存映射到多个进程的地址空间中，使得多个进程可以共享同一块内存。共享内存通常用于进程间通信，而内存映射则更多地用于文件和设备访问。

- TLB 是干嘛的？TLB 和磁盘缓存是一样的吗？

  TLB（Translation Lookaside Buffer）是一种硬件缓存，用于加速虚拟地址到物理地址的转换过程。TLB存储了最近使用过的虚拟地址与物理地址的映射关系，当CPU需要访问某个虚拟地址时，先在TLB中查找对应的物理地址，如果命中则可以直接访问物理地址，否则需要进行完整的地址转换流程。

  磁盘缓存是一种软件缓存，用于加速磁盘读写操作。磁盘缓存存储了最近读取过的磁盘数据，当需要再次读取时，可以直接从缓存中获取，避免了频繁的磁盘读取操作。

  因此，TLB和磁盘缓存的作用不同，TLB是用于加速虚拟地址到物理地址的转换，而磁盘缓存是用于加速磁盘读写操作。两者的实现方式也不同，TLB是硬件缓存，而磁盘缓存是软件缓存。

- 32和64位操作系统地址空间分别是多大？

  32位：2^32^ = 4 GB，64位：2^64^ 字节

- 构成一个计算机需要什么，各个组件做什么工作

  计算机由五大部件组成，包括运算器、控制器、存储器、输入设备和输出设备组成。

  1、控制器：计算机的控制系统，是计算机的神经中枢，指挥着计算机中各个部件自动协调工作。在控制器的控制下，计算机能够自动按照程序设定的步骤进行一系列操作，以完成特定任务。

  2、运算器：计算机的运算系统，计算机中执行各种算术和逻辑运算操作的部件。

  3、存储器：计算机存储系统，是一种利用半导体、磁性介质等技术制成的存储资料的电子设备。其电子电路中的资料以二进制方式存储。

  4、输入设备：向计算机输入数据和信息的设备，是计算机与用户或其他设备通信的桥梁。

  5、输出设备：是计算机硬件系统的终端设备，用于接收计算机数据的输出显示、打印、声音、控制外围设备等。

- 计算机的位数是由什么来决定的

  计算机的位数是由其处理器（CPU）的寄存器的位数决定的。寄存器是一种非常快速的存储器件，用于存储计算机正在处理的数据和指令。每个寄存器都有一个特定的位数，表示它可以存储的二进制位数。例如，一个32位的处理器具有32位的寄存器，可以处理32位的二进制数据。同样，64位的处理器具有64位的寄存器，可以处理64位的二进制数据。因此，计算机的位数决定了它可以处理的最大二进制数的位数，从而影响了其性能和处理能力。

- 线程创建 pthread_create 底层调用函数是啥

  pthread_create 底层调用的函数是 clone()。clone() 是 Linux 内核提供的系统调用，用于创建一个新的进程或线程。在 Linux 中，线程本质上也是一个进程，只是与创建它的进程共享了一部分资源。因此，pthread_create() 函数实际上是通过调用 clone() 创建一个新的线程，并将其加入到进程的线程池中。

- 段错误有什么原因

  段错误是一种常见的程序错误，通常是由于程序访问了不合法的内存地址或者内存越界引起的。具体来说，段错误可能由以下原因引起：

  1. 访问未分配内存：程序试图访问未分配的内存地址，比如使用空指针或者释放了已经被释放的内存。

  2. 内存越界：程序试图访问超出数组或者指针范围的内存地址，比如数组下标越界或者指针偏移量超出了指针指向的内存空间。

  3. 栈溢出：程序使用了过多的栈空间，导致栈溢出，比如递归调用过深或者在栈上分配过多的内存。

  为了避免段错误，可以采取以下措施：

  1. 避免使用空指针或者已经被释放的内存。

  2. 对于数组和指针，要确保访问的下标或者偏移量不越界。

  3. 在使用递归时，要注意控制递归深度，避免栈溢出。

  4. 使用工具进行内存检查，比如valgrind等工具可以检查程序中的内存错误。

  5. 编写高质量的代码，遵循良好的编程习惯，比如避免使用未初始化的变量等。

- Epoll是阻塞/非阻塞？异步/同步？

  Epoll是非阻塞/异步的。它使用事件通知机制，当有事件发生时，它会立即返回而不会阻塞线程，同时也不需要轮询来检查事件是否发生。这种异步的方式可以提高系统的并发性和响应性能。同时，Epoll也可以使用边缘触发模式，可以在数据可读/写时立即通知应用程序，从而实现异步处理。

- 服务器有一个连接进来，到应用程序读取到数据，需要经过几次内核态/用户态切换？需要几次缓冲区数据的拷贝？

  4次内核态/用户态切换：

  1. 用户应用进程调用read函数，向操作系统发起IO调用，上下文从用户态转为内核态（切换1）；
  2. DMA控制器把数据从磁盘中，读取到内核缓冲区；
  3. CPU把内核缓冲区数据，拷贝到用户应用缓冲区，上下文从内核态转为用户态（切换2），read函数返回；
  4. 用户应用进程通过write函数，发起IO调用，上下文从用户态转为内核态（切换3）；
  5. CPU将用户缓冲区中的数据，拷贝到socket缓冲区；
  6. DMA控制器把数据从socket缓冲区，拷贝到网卡设备，上下文从内核态切换回用户态（切换4），write函数返回；

  4次缓冲区数据的拷贝：

  1. 第一次拷贝：将磁盘中的数据拷贝到内核的缓冲区中；
  2. 第二次拷贝：内核将数据处理完，接着拷贝到用户缓冲区中；
  3. 第三次拷贝：此时需要通过socket将数据发送出去，将用户缓冲区中的数据拷贝至内核中socket的缓冲区中；
  4. 第四次拷贝：把内核中socket缓冲区的数据拷贝到网卡的缓冲区中，通过网卡将数据发送出去。

- 中断实现的原理

  中断是一种计算机硬件和软件协同工作的机制，它允许处理器在执行程序时，暂停当前任务，转而去处理其他任务，然后在完成这些任务后，再回到原来的任务继续执行。

  中断的实现原理主要包括以下几个方面：

  1. 中断请求的产生：中断请求可以来自于硬件设备，如键盘、鼠标、磁盘等，也可以来自于软件，如操作系统的系统调用、异常处理等。

  2. 中断向量表的建立：中断向量表是一个存储中断处理程序入口地址的数据结构，每个中断请求都有一个唯一的中断向量号，当中断请求产生时，处理器会根据中断向量号在中断向量表中查找对应的中断处理程序入口地址。

  3. 中断处理程序的执行：当处理器接收到中断请求后，会暂停当前任务，保存现场信息（如程序计数器、寄存器等）并跳转到中断向量表中对应的中断处理程序入口地址，执行中断处理程序。

  4. 中断处理程序的返回：中断处理程序执行完后，会恢复现场信息并返回到原来的任务继续执行。

  总之，中断机制的实现离不开中断请求的产生、中断向量表的建立、中断处理程序的执行和返回等关键步骤，这些步骤的协同工作使得处理器能够在多任务环境下有效地处理各种中断请求。

- 系统中断、中断向量、中断向量表

  - 系统中断是指由硬件或软件触发的一种机制，用于打断正在执行的程序，以便处理特定的事件或请求；
  - 中断向量是一个指向中断处理程序的地址，它由中断控制器提供，并用于确定应该执行哪个中断处理程序；
  - 中断向量表是一个包含所有中断向量的表格，通常存储在内存中，并由操作系统维护。当一个中断被触发时，处理器会查询中断向量表，找到相应的中断向量，并跳转到相应的中断处理程序中去执行。

- 软中断和硬中断区别

  软中断和硬中断是计算机系统中的两种中断类型，它们的区别在于中断的来源和处理方式。

  - 软中断

    软中断是由操作系统内核自身产生的中断，它们不是由硬件设备触发的。软中断通常用于处理计时器、网络数据包、文件系统等事件。软中断是通过调用操作系统内核中的函数来触发的，因此也被称为系统调用。

  - 硬中断

    硬中断是由硬件设备触发的中断，例如键盘、鼠标、网络卡等。硬中断通常由硬件设备发送一个中断请求信号（IRQ）给操作系统内核，内核会暂停正在执行的任务来处理这个中断请求。硬中断的处理需要较高的优先级，因为它们需要及时响应硬件设备的请求。

  软中断和硬中断是两种不同的中断类型，软中断是由操作系统内核自身产生的中断，硬中断是由硬件设备触发的中断。软中断通常用于处理计时器、网络数据包、文件系统等事件，而硬中断通常由键盘、鼠标、网络卡等设备触发。


- 异常和中断的区别

  异常和中断都是计算机系统中的两种不同的事件处理方式，它们的区别如下：

  1. 异常：是指在程序执行过程中由于出现了非法操作或者错误的数据等原因导致程序无法继续执行的情况。异常通常是由程序本身引起的，例如除零、空指针引用等。

  2. 中断：是指由外部设备或者程序发出的一种请求，要求处理器暂停当前的任务，转而去处理该请求。中断通常是由外部设备引起的，例如键盘输入、定时器等。

  因此，异常和中断的主要区别在于它们的来源不同，异常是由程序本身引起的，而中断是由外部设备引起的。另外，异常通常是在程序执行过程中发生的，而中断则可以在任何时候发生。

- 系统调用和中断的区别

  系统调用是一种机制，它允许用户程序请求内核执行某些特权操作，如文件读写、进程管理等。用户程序通过调用特定的系统调用接口来发起请求，内核根据请求参数执行相应的操作，并返回结果给用户程序。

  中断是一种事件，它可以被硬件或软件触发，用于打断当前程序的执行，转而执行中断处理程序。中断可以被用于处理硬件故障、时钟中断、网络数据包到达等事件。当中断发生时，CPU会保存当前程序的状态，然后跳转到中断处理程序执行相应的操作，处理完后再返回原程序继续执行。

  因此，系统调用和中断的区别在于：

  1. 作用不同：系统调用是用户程序请求内核执行特权操作的机制，而中断是打断当前程序执行的事件。

  2. 触发方式不同：系统调用是由用户程序主动发起的，而中断是由硬件或软件触发的。

  3. 实现方式不同：系统调用是用户态程序切换到内核态执行的过程，需要进行上下文切换和特权级切换；而中断是在当前程序执行过程中被打断，操作系统会保存当前程序的上下文并处理中断，然后再恢复被打断的程序继续执行。

  4. 返回方式不同：系统调用返回时，操作系统会将结果返回给用户程序；而中断处理完成后，控制权会返回到被打断的程序继续执行。

  总的来说，系统调用和中断都是操作系统中的重要机制，它们各自有着不同的作用和实现方式，但都为操作系统提供了强大的功能和灵活性。

- 系统调用和函数调用的区别

  系统调用和函数调用的区别如下：

  1. 调用方式不同：系统调用是通过操作系统提供的接口进行调用的，而函数调用是在程序内部进行调用的。

  2. 执行环境不同：系统调用是在内核态下执行的，而函数调用是在用户态下执行的。

  3. 功能不同：系统调用是提供给用户程序使用操作系统资源的接口，比如读写文件、创建进程等操作；而函数调用是程序内部实现某一特定功能的代码块。

  4. 开销不同：系统调用需要进行上下文切换，从用户态切换到内核态，需要进行堆栈切换等操作，开销比较大；而函数调用只需要进行简单的函数调用和返回操作，开销比较小。

  5. 安全性不同：系统调用会检查用户程序的权限，确保用户程序不能越权操作系统资源，保证系统的安全性；而函数调用不会进行权限检查，用户程序可以自由地调用函数，可能会对系统造成安全威胁。

  综上所述，系统调用和函数调用虽然都是程序中的调用方式，但是其执行环境、功能、开销、安全性等方面都有很大的区别。

- 系统调用进入内核态的过程

  当应用程序需要执行一些需要特权级别的操作时，比如读写文件、网络通信、内存管理等，就需要通过系统调用进入内核态。系统调用是用户程序与操作系统之间进行通信的接口，它可以让用户程序请求操作系统执行某些任务。

  以下是系统调用进入内核态的过程：

  1. 用户程序执行系统调用指令，将控制权转移到内核态。

  2. CPU从用户态切换到内核态，将程序计数器(PC)和堆栈指针(SP)压入内核栈中，保存用户程序的现场。

  3. 内核态的操作系统检查系统调用参数，验证权限，执行相应的操作。

  4. 操作系统将结果返回给用户程序，将控制权转移回用户态。

  5. CPU从内核态切换回用户态，将程序计数器(PC)和堆栈指针(SP)恢复，继续执行用户程序。

  需要注意的是，系统调用的执行过程中会涉及到内核态和用户态之间的切换，这个过程需要花费一定的时间和资源，因此在编写程序时应尽量减少系统调用的次数，提高程序的效率。

- 怎么用程序判断一个系统是大端字节序还是小端字节序

  - 大段字节序：数据的低位存储在高地址位，数据的高位存储在低地址位，大端字节序称为MSB；
  - 小段字节序：数据的低位存储在低地址位，数据的高位存储在高地址位，小端字节序称为LSB；

  ```cpp
  #include <stdio.h>
  
  int main()
  {
      int  a = 0x12345678;
      char *p = NULL;
      p = (char *)&a;
      if(*p == 0x78)
      {
          printf("小端字节序\n");
      }
      else if(*p == 0x12)
      {
           printf("大端字节序\n");
      }
      printf("%x\n",*p);   
      return 0;
  }
  ```

  指针将会指向整型数的首地址，而当我们调用 *p 往地址里取值时，系统会根据指针的类型的大小取对应大小的值。

  例如，char类型的指针就会从他指向的地址往后取char类型（1个字节）大小的值。所以，当我们使用char类型的指针指向一个int类型的数，再通过 *p 取值时，只会去取其低地址位的1个字节的内容。

  如果结果是 *p = 0x78，说明在地址中，低地址位存储了该数据的低位，就可以判断系统是小端字节序；如果 *p = 0x12，则说明低地址位存储了数据的高位，可判断系统是大端字节序。

- 什么时候用多线程，什么时候用多进程

  多线程和多进程都是并发编程的实现方式，但是它们适用的场景不同。

  多线程适用于以下情况：

  1. 程序需要同时处理多个任务，但是每个任务的执行时间比较短，且需要共享数据。

  2. 程序需要同时处理多个任务，但是每个任务的执行时间较长，且需要频繁地进行IO操作。

  3. 程序需要实现GUI界面，需要同时处理用户的输入和输出。

  4. 程序需要实现网络编程，需要同时处理多个客户端请求。

  多进程适用于以下情况：

  1. 程序需要处理大量的计算密集型任务，需要充分利用多核CPU的性能。

  2. 程序需要保证高可靠性和安全性，需要将不同的任务分配给不同的进程，避免一个任务的错误影响其他任务。

  3. 程序需要利用多台机器的计算资源，需要通过进程间通信来协调不同机器上的任务。

  总之，多线程适合处理IO密集型任务，而多进程适合处理计算密集型任务。在实际应用中，需要根据具体情况选择合适的并发编程方式。

- 什么是协程，什么情况下可以使用协程

  协程（Coroutine）是一种轻量级的线程，与线程相比，协程的切换不需要操作系统介入，因此可以实现更高效的并发编程。

  协程可以用于需要处理大量IO操作的场景，例如网络编程、文件读写等。在这些场景中，线程会因为等待IO操作完成而被阻塞，而协程可以在等待IO操作的同时切换到其他任务，从而提高CPU利用率。

  协程的优势包括：

  1. 更轻量级：协程的切换不需要操作系统介入，因此比线程更轻量级，可以创建更多的协程。

  2. 更高效：协程的切换比线程更快，因此可以实现更高效的并发编程。

  3. 更容易编写和维护：协程的代码结构更简单，可以避免线程的锁和同步问题，从而更容易编写和维护。

  4. 更容易调试：协程的调试比线程更容易，因为协程的调用栈比线程更清晰。

  总之，协程是一种高效、轻量级、易于编写和维护的并发编程模型，可以帮助开发者更好地处理并发编程问题。

- 如果读写锁占用很长时间，并且后续还有读者不断占用读锁，这就造成了写者饥饿的问题，怎么解决？

  一种解决方法是使用写优先锁，即当写锁等待队列中有写请求时，读锁请求将被阻塞，直到写锁被释放。这样可以确保写锁不会被长时间占用，从而避免写者饥饿的问题。

  另一种解决方法是使用公平锁，即按照请求的先后顺序来分配锁资源。这样可以确保所有请求都有公平的机会获取锁资源，从而避免某些请求长时间等待的情况。

  无论采用哪种方法，都需要根据具体的场景和需求来选择合适的锁机制，并进行适当的优化和调整。





