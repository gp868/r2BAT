

# 复习指南

**应用层** 

（1）另一个最最最常问的问题，在浏览器中输入 URL 地址到浏览器显示网页这个过程中计算机网络做了什么。

这个问题无论是考研还是找工作都是常见的，建议把 JavaGuide 中这个问题的总结熟读并全文背诵。

（2）HTTP 1.0 和 HTTP 1.1 的主要区别这个也要了解一下。

（3）HTTP 和 HTTPS 的区别这个也是面试常考问题，这个问题展开以后能问的就比较多了。

在回答这个问题时你首先分别介绍一下**HTTP 和 HTTPS 的原理以及区别**。大致就是 HTTP 是通过明文在网络上传输的，HTTPS 是加密的。有的面试官问到这也就可以了，有的面试官不讲武德，想搞偷袭，会继续让你讲 **HTTPS 建立连接的流程**、然后会继续追着你问**SSL 的工作流程**。建议把这里好好准备一下，面试官一问你就可以展开讲，你就能消耗很多面试时间，这样面试官问其它问题的时间就少了，嘿嘿。

（4）HTTP请求常见的状态码背几个常用的就好。

（5）DNS域名系统这里你要可以描述清楚工作原理，也是面试常问问题。

**传输层**

面试中计算机网络的问题最常出现在这一章中。

1. 记清楚 TCP 和 UDP 的区别。
2. TCP三次握手和UDP四次挥手。

这是面试计算机网络最最最常问的问题！！！你计算机网络就算其它的什么也不会，这个问题你必须要记清楚，如果面试官问出你这个问题你都答不上，面试官估计觉得你连敷衍都不想敷衍他了。

当面试官问你三次握手和四次挥手时，你要答出这三个点来：

（1）为什么要三次挥手和四次挥手，如果不这样做会有什么影响。

（2）三次握手四次挥手的整个流程。

（3）有的面试官只要你答出三次握手和四次挥手的大体流程就好了，但是有的面试官会要求你答出三次握手和四次挥手时发送端和接收端分别发了哪些标记。

3. TCP协议如何保证可靠传输

把 ARQ 协议、滑动窗口、流量控制、拥塞控制等回答清楚就算到位了。

**网络层**

网络层面试问的也相对较少，主要就是问IPV4，偶尔问一下ARP地址解析协议的的工作原理。

1. 首先要记清楚 IPV4 地址是怎么分类的、以及地址的格式。这里经常结合代码题一起问你，我和很多同学都在面试中被面试官要求写一个程序判断给定的字符串是否是 IPV4 地址。
2. IPV4 子网划分面试中不怎么问，笔试题时经常有这个问题。
3. 了解 IP 地址和 Mac 地址的区别，了解 ARP 地址解析协议并了解其工作原理。

**网络接口层**

把网卡、网桥、交换机的概念、用途简单了解下就好，一般面试官不会问。

# 键入网址到网页显示，期间发生了什么？

1. 浏览器解析`url`；
2. 生成一个`http`请求协议包，把协议包的发送委托给操作系统；
3. 操作系统在发送协议包之前先要获取服务器的IP地址。如果在本地的浏览器缓存、操作系统缓存或者hosts文件中存在对应的IP地址，就不需要再访问本地的DNS服务器了。如果不存在，访问本地的DNS服务器，由本地DNS服务器对进行递归访问，即按照层级向下访问，最后得到IP地址；
4. 得到ip地址后。进行TCP连接，三次握手；
5. 握手之后，把请求层层封装，通过网卡将数据发送到交换机。交换机会进行校验以及查找交换表转发，到达路由器。路由器把MAC层扒皮，查看目的ip，然后根据路由表选择下一跳，再进行MAC层封装。重复这个过程，最后到达服务器；
6. 到达服务器后，会对数据包进行扒皮并且校验。使用FCS校验码校验二进制序列的正确性。在MAC层看目的MAC是不是自己，在网络层看目的ip是不是自己，同时知道上层协议是TCP还是UDP协议。在TCP中知道这是一个什么保文，请求保文、响应报文还是结束连接的报文。通过端口号知道这是交给那么应用进程的；
7. 应用进程知道你访问的是什么资源，那么就给客户端返回一个Http响应协议包，把资源封装在其中。通过同样的流程把数据返回给客户端；
8. 浏览器拿到数据后，对数据进行渲染，解码，变成了一个页面显示在浏览器上。

# HTTP状态码

<img src="https://gcore.jsdelivr.net/gh/gp868/myFigures/img/202205101656585.png" alt=" 五大类 HTTP 状态码 " style="zoom:50%;" />

`1xx` 类状态码属于**提示信息**，是协议处理中的一种中间状态，实际用到的比较少。

`2xx` 类状态码表示服务器**成功**处理了客户端的请求，也是我们最愿意看到的状态。

- 「**200 OK**」是最常见的成功状态码，表示一切正常。如果是非 `HEAD` 请求，服务器返回的响应头都会有 body 数据。
- 「**204 No Content**」也是常见的成功状态码，与 200 OK 基本相同，但响应头没有 body 数据。
- 「**206 Partial Content**」是应用于 HTTP 分块下载或断点续传，表示响应返回的 body 数据并不是资源的全部，而是其中的一部分，也是服务器处理成功的状态。

`3xx` 类状态码表示客户端请求的资源发生了变动，需要客户端用新的 URL 重新发送请求获取资源，也就是**重定向**。

- 「**301 Moved Permanently**」表示永久重定向，说明请求的资源已经不存在了，需改用新的 URL 再次访问。
- 「**302 Found**」表示临时重定向，说明请求的资源还在，但暂时需要用另一个 URL 来访问。

301 和 302 都会在响应头里使用字段 `Location`，指明后续要跳转的 URL，浏览器会自动重定向新的 URL。

- 「**304 Not Modified**」不具有跳转的含义，表示资源未修改，重定向已存在的缓冲文件，也称缓存重定向，也就是告诉客户端可以继续使用缓存资源，用于缓存控制。

`4xx` 类状态码表示客户端发送的**报文有误**，服务器无法处理，也就是错误码的含义。

- 「**400 Bad Request**」表示客户端请求的报文有错误，但只是个笼统的错误。
- 「**403 Forbidden**」表示服务器禁止访问资源，并不是客户端的请求出错。
- 「**404 Not Found**」表示请求的资源在服务器上不存在或未找到，所以无法提供给客户端。

`5xx` 类状态码表示客户端请求报文正确，但是**服务器处理时内部发生了错误**，属于服务器端的错误码。

- 「**500 Internal Server Error**」与 400 类型，是个笼统通用的错误码，服务器发生了什么错误，我们并不知道。
- 「**501 Not Implemented**」表示客户端请求的功能还不支持，类似“即将开业，敬请期待”的意思。
- 「**502 Bad Gateway**」通常是服务器作为网关或代理时返回的错误码，表示服务器自身工作正常，访问后端服务器发生了错误。
- 「**503 Service Unavailable**」表示服务器当前很忙，暂时无法响应客户端，类似“网络服务正忙，请稍后重试”的意思。

# GET和POST的区别

GET和POST是HTTP协议中的两种发送请求的方法。GET和POST本质上就是TCP链接，并无差别。但是由于HTTP的规定和浏览器/服务器处理数据能力的限制，导致他们在应用过程中体现出一些不同。

- GET主要是用来获取新的网页；POST用作向服务器传递用户的表单数据，如用户名、密码、留言等等；

- GET把参数包含在**URL**中，POST通过**消息体**传递参数；

- GET请求在URL中传送的参数是有长度限制的，而POST通过**消息体**传递的参数没有长度限制。

- GET请求参数会被完整保留在浏览器历史记录里，而POST中的参数不会被保留；

- 对参数的数据类型，GET只接受ASCII字符，而POST没有限制；

- GET产生一个TCP数据包，而POST产生两个TCP数据包。

  对于GET请求，浏览器会把请求头和消息体一并发送出去，服务器响应200 ok（返回数据）；而对于POST请求，浏览器先发送请求头，服务器响应100 continue后，浏览器再发送消息体，服务器响应200 ok（返回数据）。在网络环境差的情况下，两次包的TCP在验证数据包完整性上，有非常大的优点。

# Cookie Session

## Cookie和Session的区别？

- **作用范围不同**，Cookie 保存在客户端，Session 保存在服务器端。
- **有效期不同**，Cookie 可设置为长时间保持，比如我们经常使用的默认登录功能，Session 一般失效时间较短，客户端关闭或者 Session 超时都会失效。
- **隐私策略不同**，Cookie 存储在客户端，容易被窃取；Session 存储在服务端，安全性相对 Cookie 要好一些。
- **存储大小不同**， 单个 Cookie 保存的数据不能超过 4K；对于 Session 来说存储没有上限，但出于对服务器的性能考虑，Session 内不要存放过多的数据，并且需要设置 Session 删除机制。

## 客户端和服务端能否更改cookie？

Cookie并不提供修改、删除操作。

如果要修改某个Cookie，只需要新建一个同名的Cookie，添加到response中覆盖原来的Cookie。

如果要删除某个Cookie，只需要新建一个同名的Cookie，并将maxAge设置为0，并添加到response中覆盖原来的Cookie。注意是0而不是负数。负数代表其他的意义。

注意：修改、删除Cookie时，新建的Cookie除value、maxAge之外的所有属性，例如name、path、domain等，都要与原Cookie完全一样。否则，浏览器将视为两个不同的Cookie不予覆盖，导致修改、删除失败。

> int maxAge：该Cookie失效的时间，单位秒。
>
> 如果为正数，则该Cookie在maxAge秒之后失效；
>
> 如果为负数，该Cookie为临时Cookie，关闭浏览器即失效，浏览器也不会以任何形式保存该Cookie；
>
> 如果为0，表示删除该Cookie；
>
> 默认为-1。

#  HTTPS特性

## HTTP 与 HTTPS 有哪些区别？

1. HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP 网络层之间加入了 `SSL/TLS` 安全协议，使得报文能够加密传输。
2. HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 `SSL/TLS` 的握手过程，才可进入加密报文传输。
3. HTTP 的端口号是 80，HTTPS 的端口号是 443。
4. HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。

## HTTPS 如何解决HHTP的三个安全风险？

1. **混合加密**的方式实现信息的**机密性**，解决了**窃听**的风险；
2. 将服务器公钥放入到**数字证书**中，解决了**冒充**的风险；
3. **摘要算法**的方式来实现**完整性**，它能够为数据生成独一无二的「**指纹**」，指纹用于校验数据的完整性，解决了**篡改**的风险。

HTTPS 采用的是**对称加密**和**非对称加密**结合的「混合加密」方式：

- 在通信建立前采用**非对称加密**的方式交换「会话秘钥」，保证传输过程的安全性。
- 在通信过程中全部使用**对称加密**的「会话秘钥」的方式加密明文数据，保证通信过程的效率。

采用「混合加密」的方式的原因：

- **对称加密**只使用一个密钥，运算速度快，密钥必须保密，无法做到安全的密钥交换。
- **非对称加密**使用两个密钥：公钥和私钥，公钥可以任意分发而私钥保密，解决了密钥交换问题但速度慢。

## HTTPS 的优缺点

- 优点

1. HTTPS传输数据过程中使用密钥进行加密，所以安全性更高；

2. HTTPS协议可以认证用户和服务器，确保数据发送到正确的用户和服务器。

- 缺点

1. HTTPS握手阶段延时较高：由于在进行HTTP会话之前还需要进行SSL握手，因此HTTPS协议握手阶段延时增加；

2. HTTPS部署成本高：一方面HTTPS协议需要使用证书来验证自身的安全性，所以需要购买CA证书；另一方面由于采用HTTPS协议需要进行加解密的计算，占用CPU资源较多，需要的服务器配置或数目高。

## HTTPS连接建立过程及SSL工作流程

SSL/TLS 协议基本流程（rsa原理）：

- 客户端向服务器索要并验证服务器的公钥。
- 双方协商生产「会话秘钥」。
- 双方采用「会话秘钥」进行加密通信。

前两步也就是 SSL/TLS 的建立过程，也就是 TLS 握手阶段，SSL/TLS 的「握手阶段」涉及**四次**通信。SSL/TLS 协议建立的详细流程：

1. 客户端给出协议版本号、一个客户端生成的随机数（Client random），以及客户端支持的加密方法。
2. 服务器确认双方使用的加密方法，并给出数字证书、以及一个服务器生成的随机数（Server random）。
3. 客户端确认数字证书有效，然后生成一个新的随机数（Premaster secret），并使用数字证书中的公钥，加密这个随机数，发给服务器。
4. 服务器使用自己的私钥，获取客户端发来的随机数（Premaster secret）。
5. 客户端和服务器根据约定的加密方法，使用前面的三个随机数，生成”对话密钥”（session key），用来加密接下来的整个对话过程。

# HTTP报文

## 请求报文

HTTP请求报文由请求行（request line）、请求头部（header）、空行和消息体四个部分组成。

请求报文分为两种，GET和POST：

- **GET**

```
GET /562f25980001b1b106000338.jpg HTTP/1.1
Host:img.mukewang.com
User-Agent:Mozilla/5.0 (Windows NT 10.0; WOW64)
AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.106 Safari/537.36
Accept:image/webp,image/*,*/*;q=0.8
Referer:http://www.imooc.com/
Accept-Encoding:gzip, deflate, sdch
Accept-Language:zh-CN,zh;q=0.8
空行
请求数据为空
```

- **POST**

```
POST / HTTP1.1
Host:www.wrox.com
User-Agent:Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; .NET CLR 2.0.50727; .NET CLR 3.0.04506.648; .NET CLR 3.5.21022)
Content-Type:application/x-www-form-urlencoded
Content-Length:40
Connection: Keep-Alive
空行
name=Professional%20Ajax&publisher=Wiley
```

**请求行**用来说明请求类型，要访问的资源以及所使用的HTTP版本。

GET说明请求类型为GET，/562f25980001b1b106000338.jpg(URL)为要访问的资源，该行的最后一部分说明使用的是HTTP1.1版本。

**请求头部**紧接着请求行（即第一行）之后的部分，用来说明服务器要使用的附加信息。

- HOST，给出请求资源所在服务器的域名。
- User-Agent，HTTP客户端程序的信息，该信息由你发出请求使用的浏览器来定义，并且在每个请求中自动发送等。
- Accept，说明用户代理可处理的媒体类型。
- Accept-Encoding，说明用户代理支持的内容编码。
- Accept-Language，说明用户代理能够处理的自然语言集。
- Content-Type，说明实现主体的媒体类型。
- Content-Length，说明实现主体的大小。
- Connection，连接管理，可以是Keep-Alive或close。

**空行**，请求头部后面的空行是必须的，即使第四部分的请求数据为空，也必须有空行。

**请求数据**也叫主体，可以添加任意的其他数据。

## 响应报文

HTTP响应也由四个部分组成，分别是：状态行、消息报头、空行和响应正文。

```
HTTP/1.1 200 OK
Date: Fri, 22 May 2009 06:07:21 GMT
Content-Type: text/html; charset=UTF-8
空行
<html>
      <head></head>
      <body>
            <!--body goes here-->
      </body>
</html>
```

状态行由HTTP协议版本号， 状态码， 状态消息三部分组成。第一行为状态行，（HTTP/1.1）表明HTTP版本为1.1版本，状态码为200，状态消息为OK。

消息报头，用来说明客户端要使用的一些附加信息。第二行和第三行为消息报头，Date：生成响应的日期和时间；Content-Type：指定了MIME类型的HTML(text/html)，编码类型是UTF-8。

空行，消息报头后面的空行是必须的。

响应正文，服务器返回给客户端的文本信息。空行后面的html部分为响应正文。

# HTTP/1.1、HTTP/2、HTTP/3的演变

## HTTP/1.1

- HTTP/1.1**优点**

1. **简单**

   HTTP 基本的报文格式就是 `header + body`，头部信息也是 `key-value` 简单文本的形式，很简单。

2. **灵活和易于扩展**

   HTTP协议里的各类请求方法、状态码、头字段等都是可以自定义扩展的；同时 HTTP 工作在应用层，下层可以随意变化。

3. **应用广泛和跨平台**

- HTTP/1.1**缺点**

1. **无状态**

   服务器不会去记忆 HTTP 的状态，所以不需要额外的资源来记录状态信息，但是会导致它在完成有关联性的操作时会非常麻烦。例如登录->添加购物车->下单->结算->支付，这系列操作都要知道用户的身份才行。 但服务器不知道这些请求是有关联的，每次都要问一遍身份信息。

   无状态的问题解决方法有`cookie/session/token`，`Cookie` 通过在请求和响应报文中写入 Cookie 信息来控制客户端的状态。

2. **明文传输**

   明文意味着在传输过程中的信息是可阅读的， 通过F12 控制台或 Wireshark 抓包都可以直接查看， 方便调试，但是也导致了信息泄露。明文传输的问题在`https`协议中得到了解决。

3. **不安全**

   HTTP 比较严重的缺点就是不安全：通信使用明文传输，内容可能会被窃听；不验证通信方的身份，因此有可能遭遇伪装； 无法证明报文的完整性，所以有可能已遭篡改。

HTTP 的安全问题，可以用 `HTTPS`的方式解决，也就是通过引入 SSL/TLS 层，使得在安全上达到了极致。

- HTTP/1.1的性能

1. **长连接**

> `HTTP/1.0` 规定浏览器与服务器只保持短暂的连接，浏览器的每次请求都需要与服务器建立一个TCP连接，服务器完成请求处理后立即断开TCP连接，每个TCP连接只能发送一个请求。发送数据完毕，连接就关闭，如果还要请求其他资源，就必须再新建一个连接。 TCP连接的建立需要三次握手，通信开销比较大。所以，HTTP/1.0版本的性能比较差。

为了解决上述 TCP 连接问题，`HTTP/1.1`提出了**长连接**的通信方式，也叫持久连接。这种方式的好处在于减少了 TCP 连接的重复建立和断开所造成的额外开销，减轻了服务器的负载。

持久连接的特点是，只要任意一端没有明确提出断开连接，则保持 TCP 连接状态。当然，如果某个 HTTP 长连接超过一定时间没有任何数据交互，服务端就会主动断开这个连接。

- **管道网络传输**

HTTP/1.1 采用了长连接的方式，这使得**管道网络传输**成为了可能。即可在同一个 TCP 连接里面，客户端可以发起多个请求，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以**减少整体的响应时间**。

但是服务器必须按照接收请求的顺序发送对这些管道化请求的响应，如果服务端在处理 A 请求时耗时比较长，那么后续的请求的处理都会被阻塞，造成「**队头阻塞**」。所以，**HTTP/1.1 管道解决了请求的队头阻塞，但是没有解决响应的队头阻塞**。

- **队头阻塞**

当顺序发送的请求序列中的一个请求因为某种原因被阻塞时，在后面排队的所有请求也一同被阻塞了，会招致客户端一直请求不到数据，这也就是「**队头阻塞**」。

## HTTP/1.1 相比 HTTP/1.0 提高了什么性能？

- 使用 TCP 长连接的方式改善了 HTTP/1.0 短连接造成的性能开销。
- 支持管道（pipeline）网络传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。

## HTTP/2 做了什么优化？

HTTP/2 协议是基于 HTTPS 的，所以 HTTP/2 的安全性也是有保障的。

那 HTTP/2 相比 HTTP/1.1 性能上的改进：

1. **头部压缩**

HTTP/2 会**压缩头**，如果同时发出多个请求，如果请求头是一样的或是相似的，那么会消除重复的部分。

这就是所谓的 `HPACK` 算法：在客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就提高速度了。

2. **二进制格式**

HTTP/2 不再像 HTTP/1.1 里的纯文本形式的报文，而是采用了**二进制格式**，头信息和数据体都是二进制（统称为**帧**：头信息帧和数据帧）。收到报文后，无需再将明文的报文转成二进制，而是直接解析二进制报文，增加了数据传输的效率。

3. **数据流**

HTTP/2 的数据包不是按顺序发送的，同一个连接里面连续的数据包，可能属于不同的回应。因此，必须要对数据包做标记，指出它属于哪个回应。

在 HTTP/2 中每个请求或相应的所有数据包，称为一个数据流（`Stream`）。每个数据流都标记着一个独一无二的编号（Stream ID），**不同 Stream 的帧是可以乱序发送的（因此可以并发不同的 Stream ）**，因为每个帧的头部会携带 Stream ID 信息，所以接收端可以通过 Stream ID 有序组装成 HTTP 消息。

4. **多路复用**

HTTP/2 可以在一个连接中并发多个请求或回应，而不用按照顺序一一对应。移除了 HTTP/1.1 中的串行请求，不需要排队等待，也就不会再出现「**队头阻塞**」问题，降低了延迟，大幅度提高了连接的利用率。

5. **服务器推送**

HTTP/2 还在一定程度上改善了传统的「请求 - 应答」工作模式，服务不再是被动地响应，也可以**主动**向客户端发送消息。

## HTTP/2的缺陷

HTTP/2 还是存在**队头阻塞**的问题，只不过问题不是在 HTTP 这一层面，而是在 **TCP**这一层。

HTTP/2 是基于 TCP 协议来传输数据的，TCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且连续的，这样内核才会将缓冲区里的数据返回给 HTTP 应用。当前一个字节数据没有到达时，后收到的字节数据只能存放在内核缓冲区里，只有等到这一个字节数据到达时，HTTP/2 应用层才能从内核中拿到数据，这就是 **HTTP/2 队头阻塞**问题。

所以，一旦发生了丢包现象，就会触发 TCP 的**重传机制**，这样在一个 TCP 连接中的所有的 HTTP 请求都必须等待这个丢了的包被重传回来。

## HTTP/3 做了哪些优化？

 HTTP/1.1 和 HTTP/2 都有队头阻塞的问题：

- HTTP/1.1 中的管道虽然解决了请求的队头阻塞，但是**没有解决响应的队头阻塞**，因为服务端需要按顺序响应收到的请求，如果服务端处理某个请求消耗的时间比较长，那么只能等相应完这个请求后， 才能处理下一个请求，这属于 HTTP 层队头阻塞。
- HTTP/2 虽然通过多个请求复用一个 TCP 连接解决了 HTTP 的队头阻塞 ，但是**一旦发生丢包，就会阻塞住所有的 HTTP 请求**，这属于 TCP 层队头阻塞。

HTTP/2 队头阻塞的问题是因为 TCP，所以 **HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP**。

UDP的发生是不管顺序，也不管丢包的，所以不会出现像 HTTP/2 队头阻塞的问题。虽然 UDP 是不可靠传输的，但基于 UDP 的 **QUIC 协议** 可以实现类似 TCP 的可靠性传输。QUIC 有以下 3 个特点：

1. **无队头阻塞**

QUIC 连接上**当某个数据流发生丢包时，只会阻塞这个数据流，其他数据流不会受到影响，因此不存在队头阻塞问题**。这与 HTTP/2 不同，HTTP/2 只要某个数据流中的数据包丢失了，其他数据流也会因此受影响。

2. **更快的连接建立**

但是 HTTP/3 的 QUIC 协议并不是与 TLS 分层，而是QUIC 内部包含了 TLS，它在自己的帧会携带 TLS 里的“记录”，再加上 QUIC 使用的是 TLS/1.3，因此仅需 1 个 RTT 就可以「同时」完成建立连接与密钥协商。

3. **连接迁移**

基于 TCP 传输协议的 HTTP 协议，由于是通过四元组（源 IP、源端口、目的 IP、目的端口）确定一条 TCP 连接，那么**当移动设备的网络从 4G 切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建立连接**。而建立连接的过程包含 TCP 三次握手和 TLS 四次握手的时延，以及 TCP 慢启动的减速过程，给用户的感觉就是网络突然卡顿了一下，因此连接的迁移成本是很高的。

而 QUIC 协议没有用四元组的方式来“绑定”连接，而是通过**连接 ID**来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本，没有丝毫卡顿感，达到了**连接迁移**的功能。

所以， QUIC 是一个在 UDP 之上的**伪** TCP + TLS + HTTP/2 的多路复用的协议。

QUIC 是新协议，对于很多网络设备，根本不知道什么是 QUIC，只会当做 UDP，这样会出现新的问题，因为有的网络设备是会丢掉 UDP 包的，而 QUIC 是基于UDP 实现的，那么如果网络设备无法识别这个是 QUIC 包，那么就会当作 UDP包，然后被丢弃。

所以，HTTP/3 现在普及的进度非常的缓慢，不知道未来 UDP 是否能够逆袭 TCP。

# UDP  TCP

**TCP 和 UDP 区别：**

1. **连接**

- TCP 是面向连接的传输层协议，传输数据前先要建立连接。
- UDP 是不需要连接，即刻传输数据。

2. **服务对象**

- TCP 是一对一的两点服务，即一条连接只有两个端点。
- UDP 支持一对一、一对多、多对多的交互通信

3. **可靠性**

- TCP 是可靠交付数据的，数据可以无差错、不丢失、不重复、按需到达。
- UDP 是尽最大努力交付，不保证可靠交付数据。

4. **拥塞控制、流量控制**

- TCP 有拥塞控制和流量控制机制，保证数据传输的安全性。
- UDP 则没有，即使网络非常拥堵了，也不会影响 UDP 的发送速率。

5. **首部开销**

- TCP 首部长度较长，会有一定的开销，首部在没有使用「选项」字段时是 `20` 个字节，如果使用了「选项」字段则会变长的。
- UDP 首部只有 8 个字节，并且是固定不变的，开销较小。

6. **传输方式**

- TCP 是流式传输，没有边界，但保证顺序和可靠。
- UDP 是一个包一个包的发送，是有边界的，但可能会丢包和乱序。

7. **分片不同**

- TCP 的数据大小如果大于 MSS 大小，则会在传输层进行分片，目标主机收到后，也同样在传输层组装 TCP 数据包，如果中途丢失了一个分片，只需要传输丢失的这个分片。
- UDP 的数据大小如果大于 MTU 大小，则会在 IP 层进行分片，目标主机收到后，在 IP 层组装完数据，接着再传给传输层。

**TCP 和 UDP 应用场景：**

由于 TCP 是面向连接，能保证数据的可靠性交付，因此经常用于：

- `FTP` 文件传输；
- HTTP / HTTPS；

由于 UDP 面向无连接，它可以随时发送数据，再加上UDP本身的处理既简单又高效，因此经常用于：

- 包总量较少的通信，如 `DNS` 、`SNMP` 等；
- 视频、音频等多媒体通信；
- 广播通信；

# TCP的头部



![aHR0cHM6Ly9jZG4uanNkZWxpdnIubmV0L2doL3hpYW9saW5jb2Rlci9JbWFnZUhvc3QyLyVFOCVBRSVBMSVFNyVBRSU5NyVFNiU5QyVCQSVFNyVCRCU5MSVFNyVCQiU5Qy9UQ1AtJUU0JUI4JTg5JUU2JUFDJUExJUU2JThGJUExJUU2JTg5JThCJUU1JTkyJThDJUU1JTlCJTlCJUU2JUFDJUExJUU2JThDJUE1JUU2JTg5JThCLzYuanBn (1053×828) (csdnimg.cn)](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jZG4uanNkZWxpdnIubmV0L2doL3hpYW9saW5jb2Rlci9JbWFnZUhvc3QyLyVFOCVBRSVBMSVFNyVBRSU5NyVFNiU5QyVCQSVFNyVCRCU5MSVFNyVCQiU5Qy9UQ1AtJUU0JUI4JTg5JUU2JUFDJUExJUU2JThGJUExJUU2JTg5JThCJUU1JTkyJThDJUU1JTlCJTlCJUU2JUFDJUExJUU2JThDJUE1JUU2JTg5JThCLzYuanBn?x-oss-process=image/format,png)

**序列号**：在建立连接时由计算机生成的随机数作为其初始值，通过 SYN 包传给接收端主机，每发送一次数据，就「累加」一次该「数据字节数」的大小。**用来解决网络包乱序问题。**

**确认应答号**：指下一次「期望」收到的数据的序列号，发送端收到这个确认应答以后可以认为在这个序号以前的数据都已经被正常接收。**用来解决丢包的问题。**

**控制位：**

- *ACK*：该位为 `1` 时，「确认应答」的字段变为有效，TCP 规定除了最初建立连接时的 `SYN` 包之外该位必须设置为 `1` 。
- *RST*：该位为 `1` 时，表示 TCP 连接中出现异常必须强制断开连接。
- *SYN*：该位为 `1` 时，表示希望建立连接，并在其「序列号」的字段进行序列号初始值的设定。
- *FIN*：该位为 `1` 时，表示今后不会再有数据发送，希望断开连接。当通信结束希望断开连接时，通信双方的主机之间就可以相互交换 `FIN` 位为 1 的 TCP 段。

# TCP三次握手

## TCP三次握手过程

- 一开始，客户端和服务端都处于 `CLOSED` 状态。先是服务端主动监听某个端口，处于 `LISTEN` 状态；
- 客户端会随机初始化序号为`x`，将此序号置于 TCP 首部的「序号」字段中，同时把 `SYN` 标志位置为 `1` ，表示 `SYN` 报文。接着把第一个 SYN 报文发送给服务端，表示向服务端发起连接，该报文不包含应用层数据，之后客户端处于 `SYN-SENT` 状态；
- 服务端收到客户端的 `SYN` 报文后，首先服务端也随机初始化自己的序号为`y`，将此序号填入 TCP 首部的「序号」字段中，其次把 TCP 首部的「确认应答号」字段填入 `x + 1`, 接着把 `SYN` 和 `ACK` 标志位置为 `1`。最后把该报文发给客户端，该报文也不包含应用层数据，之后服务端处于 `SYN-RCVD` 状态；
- 客户端收到服务端报文后，还要向服务端回应最后一个应答报文，首先将应答报文 TCP 首部 `ACK` 标志位置为 `1` ，其次「确认应答号」字段填入 `y + 1` ，最后把报文发送给服务端，这次报文可以携带客户到服务器的数据，之后客户端处于 `ESTABLISHED` 状态；
- 服务器收到客户端的应答报文后，也进入 `ESTABLISHED` 状态。

从上面的过程可以发现**第三次握手是可以携带数据的，前两次握手是不可以携带数据的**，这也是面试常问的题。

一旦完成三次握手，双方都处于 `ESTABLISHED` 状态，此时连接就已建立完成，客户端和服务端就可以相互发送数据了。

## 为什么是三次握手？不是两次、四次？

- **防止历史连接的建立**（主要原因）

客户端连续发送多次 SYN 建立连接的报文，在**网络拥堵**情况下：一个「旧 SYN 报文」比「最新的 SYN 」 报文早到达了服务端，那么此时服务端就会回一个 `SYN + ACK` 报文给客户端。客户端收到后可以根据自身的上下文，判断这是一个历史连接（序列号过期或超时），那么客户端就会发送 `RST` 报文给服务端，表示中止这一次连接。

**如果是两次握手连接，就无法阻止历史连接**，那为什么 TCP 两次握手为什么无法阻止历史连接呢？

主要是因为**在两次握手的情况下，服务端没有中间状态给客户端来阻止历史连接，导致服务端可能建立一个历史连接，造成资源浪费**。

两次握手的情况下，服务端在收到 SYN 报文后，就进入 ESTABLISHED 状态，意味着这时可以给对方发送数据，但是客户端此时还没有进入 ESTABLISHED 状态。假设这次是历史连接，客户端判断到此次连接为历史连接，那么就会回 RST 报文来断开连接，而服务端在第一次握手的时候就进入 ESTABLISHED 状态，所以它可以发送数据的，但是它并不知道这个是历史连接，它只有在收到 RST 报文后，才会断开连接。

可以看到，上面这种场景下，服务端在向客户端发送数据前，并没有阻止掉历史连接，导致服务端建立了一个历史连接，又白白发送了数据，妥妥地浪费了服务端的资源。

因此，**要解决这种现象，最好就是在服务端发送数据前，也就是建立连接之前，要阻止掉历史连接，这样就不会造成资源浪费，而要实现这个功能，就需要三次握手**。

- **同步双方的初始序列号**

TCP 协议的通信双方， 都必须维护一个「序列号」， 序列号是可靠传输的一个关键因素，它的作用：

1. 接收方可以去除重复的数据；

2. 接收方可以根据数据包的序列号按序接收；

3. 可以标识发送出去的数据包中， 哪些是已经被对方收到的（通过 ACK 报文中的序列号知道）；

可见，序列号在 TCP 连接中占据着非常重要的作用，所以当客户端发送携带「初始序列号」的 `SYN` 报文的时候，需要服务端回一个 `ACK` 应答报文，表示客户端的 SYN 报文已被服务端成功接收，那当服务端发送「初始序列号」给客户端的时候，依然也要得到客户端的应答回应，**这样一来一回，才能确保双方的初始序列号能被可靠的同步。**

四次握手其实也能够可靠的同步双方的初始化序号，但由于**第二步和第三步可以优化成一步**，所以就成了「三次握手」。

而两次握手只保证了一方的初始序列号能被对方成功接收，没办法保证双方的初始序列号都能被确认接收。

- **避免资源浪费**

如果只有「两次握手」，当客户端的 `SYN` 请求连接在网络中阻塞，客户端没有接收到 `ACK` 报文，就会重新发送 `SYN` ，由于没有第三次握手，服务器不清楚客户端是否收到了自己发送的建立连接的 `ACK` 确认信号，所以每收到一个 `SYN` 就只能先主动建立一个连接，这会造成什么情况呢？

如果客户端的 `SYN` 阻塞了，重复发送多次 `SYN` 报文，那么服务器在收到请求后就会**建立多个冗余的无效链接，造成不必要的资源浪费。**

即两次握手会造成消息滞留情况下，服务器重复接受无用的连接请求 `SYN` 报文，而造成重复分配资源。

**总结**：不使用「两次握手」和「四次握手」的原因：

- 「两次握手」：无法防止历史连接的建立，会造成双方资源的浪费，也无法可靠的同步双方序列号；
- 「四次握手」：三次握手就已经理论上最少可靠连接建立，所以不需要使用更多的通信次数。

## 第三次握手丢失会发生什么？

客户端收到服务端的 SYN-ACK 报文后，就会给服务端回一个 ACK 报文，也就是第三次握手，此时客户端状态进入到 `ESTABLISH` 状态。

因为这个第三次握手的 ACK 是对第二次握手的 SYN 的确认报文，所以当第三次握手丢失了，如果服务端那一方迟迟收不到这个确认报文，就会触发超时重传机制，重传 SYN-ACK 报文，直到收到第三次握手，或者达到最大重传次数。

注意，**ACK 报文是不会有重传的，当 ACK 丢失了，就由对方重传对应的报文**。

## TCP半连接队列和全连接队列、syn攻击

在TCP进行三次握手时，Liunx会为其维护两个队列：

- 半连接队列，也叫syn队列；
- 全连接队列，也叫accept队列；

在客户端发起第一次连接时，服务端会将其加入到syn队列中，并且响应客户端syn+ack报文，等到客户端发送ack应答报文时，服务端将该连接从半连接队列中取出，并新建一个新的连接，加入到accept队列当中。等待进程调用accept请求时，将该连接取出来。不管是半连接队列还是全连接队列，都有最大长度限制，超过限制时，内核会直接丢弃，或返回 RST 包。

- 如何查看半连接队列的长度

  半连接队列存放的是处于syn_recv状态的tcp连接。可以使用如下命令查看处于syn_recv状态的tcp连接：

  ```php
   netstat -natp | grep SYN_RECV | wc -l
  ```

* 如何模拟tcp半连接队列溢出场景

  一直对服务端发送syn包，但是不回ack包，这样就会使得服务端有大量请求处于syn_recv状态的连接，这就是所谓的syn洪泛，syn攻击，DDos攻击。

- 如何抵御syn攻击

  1. 增大半连接队列。

     不能只增大tcp_max_syn_backlog，还需要一同增大somaconn和backlog，也就是增大全连接队列。

  2. 开启tcp_syncookies功能。

     开启tcp_syncookies就可以在不使用syn半连接队列的情况下建立连接。syncookies在接收到客户端的syn报文时，计算出一个值，放到syn+ack报文中发出。当客户端返回ack报文时，取出该值验证，成功则建立连接。

# TCP四次挥手

## TCP四次挥手过程

- 客户端打算关闭连接，此时会发送一个 TCP 首部 `FIN` 标志位被置为 `1` 的报文，也即 `FIN` 报文，之后客户端进入 `FIN_WAIT_1` 状态。
- 服务端收到该报文后，就向客户端发送 `ACK` 应答报文，接着服务端进入 `CLOSED_WAIT` 状态。
- 客户端收到服务端的 `ACK` 应答报文后，之后进入 `FIN_WAIT_2` 状态。
- 等待服务端处理完数据后，也向客户端发送 `FIN` 报文，之后服务端进入 `LAST_ACK` 状态。
- 客户端收到服务端的 `FIN` 报文后，回一个 `ACK` 应答报文，之后进入 `TIME_WAIT` 状态
- 服务器收到了 `ACK` 应答报文后，就进入了 `CLOSED` 状态，至此服务端已经完成连接的关闭。
- 客户端在经过 `2MSL` 一段时间后，自动进入 `CLOSED` 状态，至此客户端也完成连接的关闭。

每个方向都需要**一个 FIN 和一个 ACK**，因此通常被称为**四次挥手**。这里一点需要注意是：**主动关闭连接的，才有 TIME_WAIT 状态。**

> MSL(Maximum Segment Lifetime)，即报文最大生存时间。

## 为什么挥手需要四次？

再来回顾下四次挥手双方发 `FIN` 包的过程，就能理解为什么需要四次了。

- 关闭连接时，客户端向服务端发送 `FIN` 时，仅仅表示客户端不再发送数据了但是还能接收数据。
- 服务器收到客户端的 `FIN` 报文时，先回一个 `ACK` 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 `FIN` 报文给客户端来表示同意现在关闭连接。

从上面过程可知，服务端通常需要等待完成数据的发送和处理，所以服务端的 `ACK` 和 `FIN` 一般都会分开发送，从而比三次握手导致多了一次。

## 为什么需要 TIME_WAIT 状态？

主动发起关闭连接的一方，才会有 `TIME-WAIT` 状态。需要 TIME-WAIT 状态，主要是两个原因：

- 防止历史连接中的数据，被后面相同四元组的连接错误的接收；

为了防止历史连接中的数据，被后面相同四元组的连接错误的接收，因此 TCP 设计了 TIME_WAIT 状态，状态会持续 `2MSL` 时长，这个时间**足以让两个方向上的数据包都被丢弃，使得原来连接的数据包在网络中都自然消失，再出现的数据包一定都是新建立连接所产生的。**

- 保证「被动关闭连接」的一方，能被正确的关闭；

TIME-WAIT 作用是**等待足够的时间以确保最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭。**

## time_wait大量出现？

- 如何查看TIME_WAIT连接

  查看状态为TIME_WAIT的TCP连接：`netstat -tan |grep TIME_WAIT`

  统计TCP各种状态的连接数：`netstat -n | awk '/^tcp/ {++S[$NF]} END {for(i in S) print i, S[i]}`

- 危害

  TIME_WAIT 状态下，TCP连接占用的本地端口将一直无法释放。大量的TIME_WAIT连接会占用系统本地端口，导致不能再创建新的TCP连接。

- 原因

  1. 大量的短连接存在：HTTP/1.0协议中默认使用短连接。也就是说，浏览器和服务器每进行一次HTTP操作，就会建立一次连接，任务结束后就会断开连接，而断开连接这个请求是由服务器去发起的，主动关闭连接的一方才会有TIME_WAIT状态。

  2. HTTP请求头里connection值被设置为close。

- 优化

  在客户端层面，可以在客户端将HTTP请求头里connection的值设置为keep-alive，将短连接改成长连接。长连接比短连接从根本上减少了服务器主动关闭连接的次数，减少了TIME_WAIT状态连接的产生。

  在服务器层面，我们可以通过修改服务器的系统内核参数来进行优化。

  1. 允许将TIME_WAIT状态的socket重新用于新的TCP连接。这样的好处就是如果出现大量TIME_WAIT状态的连接，也能够将这些连接占用的端口重新用于新的TCP连接。

     ```php
     $ vim /etc/sysctl.conf
     net.ipv4.tcp_tw_reuse = 1 #默认为0，表示关闭
     ```

  2. 快速回收TIME_WAIT状态的socket。

     ```php
     $ vim /etc/sysctl.conf
     net.ipv4.tcp_tw_recycle = 1  #默认为0，表示关闭
     ```

  3. 将MSL值缩减。linux中MSL的值默认为60s，可以通过缩减MSL值来使得主动关闭连接一端由TIME_WAIT状态到关闭状态的时间减少。但是这样做会导致延迟报文无法清除以及主动关闭连接一端不能收到重传来的FIN请求，也会影响很多基于TCP的应用的连接复用和调优。所以在实际生产环境中，需要谨慎操作。

     ```php
     #查看默认的MSL值
     $ cat /proc/sys/net/ipv4/tcp_fin_timeout
     #修改
     $echo 30 > /proc/sys/net/ipv4/tcp_fin_timeout
     或者$ vim /etc/sysctl.con
     fnet.ipv4.tcp_fin_timeout = 30
     ```

## close_wait大量出现？

close_wait状态是在TCP四次挥手的时候收到FIN，但是没有发送自己的FIN时出现的，服务器出现大量close_wait状态的原因：

服务器内部业务处理占用了过多时间，都没能处理完业务，或者还有数据需要发送，或者服务器的业务逻辑有问题，没有执行close()方法，服务端socket忙于读写；

处理方法：

1. 代码层面做到

   - 使用完socket就调用close方法；

   - socket读控制，当读取的长度为0时（读到结尾），立即close；

   - 如果read返回-1，出现错误，检查error返回码，有三种情况：INTR（被中断，可以继续读取），WOULDBLOCK（表示当前socket_fd文件描述符是非阻塞的，但是现在被阻塞了），AGAIN（表示现在没有数据稍后重新读取）。如果不是AGAIN，立即close；

2. 可以设置TCP的连接时长 keep_alive_time，还有TCP监控连接的频率以及连接没有活动多长时间被迫断开连接。

# TCP如何保证可靠性

## 重传机制

TCP 实现可靠传输的方式之一，是通过序列号与确认应答。在 TCP 中，当发送端的数据到达接收主机时，接收端主机会返回一个确认应答消息，表示已收到消息。 TCP 针对数据包丢失的情况，会用**重传机制**解决，常见的有超时重传、快速重传、SACK方法、 Duplicate SACK。

- **超时重传**

超时重传就是在发送数据时，设定一个定时器，当超过指定的时间后，没有收到对方的 `ACK` 确认应答报文，就会重发该数据，超时重传时间 RTO 的值应该略大于报文往返 RTT 的值。

如果超时重发的数据，再次超时的时候，又需要重传的时候，TCP 的策略是**超时间隔加倍**，也就是每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍。两次超时，就说明网络环境差，不宜频繁反复发送。

超时触发重传存在的问题是，超时周期可能相对较长。那是不是可以有更快的方式呢？——快速重传

- **快速重传**

快速重传**不以时间为驱动，而是以数据驱动重传**。快速重传的工作方式是当收到三个相同的 ACK 报文时，会在定时器过期之前，重传丢失的报文段。

快速重传机制解决了超时时间的问题，但是它依然面临着另外一个问题：就是**重传的时候，是重传之前的一个，还是重传所有的问题。**为了解决不知道该重传哪些 TCP 报文的问题，于是就有 `SACK` 方法。

- **SACK方法**

`SACK`（ Selective Acknowledgment 选择性确认），这种方式需要在 TCP 头部「选项」字段里加一个 `SACK` 的东西，它**可以将缓存的地图发送给发送方**，这样发送方就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以**只重传丢失的数据**。

- **Duplicate SACK**

Duplicate SACK 又称 `D-SACK`，其主要**使用了 SACK 来告诉「发送方」有哪些数据被重复接收了。**

## 滑动窗口

TCP 会利用窗口控制来提高传输速度，在一个窗口大小内，不用等到应答返回就能发送下一段数据，窗口大小就是无需等待确认而可以继续发送数据的最大值。如果不使用窗口控制，每一个没收到确认应答的数据都要重发。

## 流量控制

流量控制就是让发送方的发送速率不要太快，防止接收方接受窗口溢出产生丢包，既要让接收方来得及接收，也不要使网络发生拥塞。利用滑动窗口机制可以很方便地在 TCP 连接上实现流量控制。

发送方维护一个发送窗口，发送窗口的大小表示在未收到接收方发来确认的情况下，最多还可以发送多少个帧。只有接收窗口向前滑动时（并且接收方发送了确认），发送窗口才有可能（只有发送方收到确认才是一定）向前滑动。

接收方维护一个接收窗口，只有当接收到的帧的序号落入接收窗口内才收下该帧，将接收窗口向前滑动一个位置，并给发送方发回确认。若接收到的顿的序号落在接收窗口之外，则一律将其丢弃。

## 拥塞控制

![在这里插入图片描述](https://gcore.jsdelivr.net/gh/gp868/myFigures/img/20210517113954737.png)

在网络出现拥堵时，如果继续发送大量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据，但是一重传就会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，这个情况就会进入恶性循环被不断地放大。于是，就有了**拥塞控制**，控制的目的就是**避免「发送方」的数据填满整个网络。**

发送方维护一个拥塞窗口，它的大小会随着网络的拥塞程度动态变化的。只要网络中没有出现拥塞，窗口大小就会增大；但网络中出现了拥塞，窗口大小就会减少。

拥塞控制主要是四个算法：**慢启动、拥塞避免、拥塞发生、快速恢复**。

**慢启动**算法的规则：当发送方每收到一个 ACK，拥塞窗口大小就会加 1，会导致发包个数呈**指数性**的增长。

拥塞窗口大小低于慢启动门限时采用慢启动算法，超过慢启动门限时采用拥塞避免算法。

**拥塞避免**算法的规则是：**每当收到一个 ACK 时，cwnd 增加 1/cwnd。**拥塞避免算法就是将原本慢启动算法的指数增长变成了**线性增长**，还是增长阶段，但是增长速度缓慢了一些。就这么一直增长着后，网络就会慢慢进入了拥塞的状况了，于是就会出现丢包现象，这时就需要对丢失的数据包进行重传。当触发了重传机制，也就进入了「拥塞发生算法」。

当网络出现拥塞，也就是会发生数据包重传，重传机制主要有两种：超时重传、快速重传。这两种使用的拥塞发送算法是不同的，接下来分别来说说。

> 发生**超时重传**的拥塞发生算法

当发生了「超时重传」，则就会使用拥塞发生算法。这个时候，`ssthresh`和 `cwnd `的值会发生变化：

- `ssthresh` 设为 `cwnd/2`，
- `cwnd` 重置为 `1`

接着，就重新开始慢启动，慢启动是会突然减少数据流的。这真是一旦「超时重传」，马上回到解放前。但是这种方式太激进了，反应也很强烈，会造成网络卡顿。

> 发生**快速重传**的快速恢复算法

还有更好的方式，前面我们讲过「快速重传算法」。当接收方发现丢了一个中间包的时候，发送三次前一个包的 ACK，于是发送端就会快速地重传，不必等待超时再重传。

TCP 认为这种情况不严重，因为大部分没丢，只丢了一小部分，则 `ssthresh` 和 `cwnd` 变化如下：

- `cwnd = cwnd/2` ，也就是设置为原来的一半;
- `ssthresh = cwnd`;
- 进入快速恢复算法，重新进入拥塞避免状态


# TCP粘包和拆包

**为什么会产生粘包和拆包呢?**

- 要发送的数据⼩于TCP发送缓冲区的⼤⼩，TCP将多次写⼊缓冲区的数据⼀次发送出去，将会发⽣粘包；要发送的数据⼤于TCP发送缓冲区剩余空间⼤⼩，将会发⽣拆包；
- 接收数据端的应⽤层没有及时读取接收缓冲区中的数据，将发⽣粘包；
- 待发送数据⼤于MSS（最⼤报⽂⻓度），TCP在传输前将进⾏拆包。即TCP报⽂⻓度-TCP头部⻓度>MSS。

**解决⽅法**

- 发送端将每个数据包封装为固定⻓度；
- 在数据尾部增加特殊字符进⾏分割；
- 将数据分为两部分，⼀部分是头部，⼀部分是内容体；其中头部结构⼤⼩固定，且有⼀个字段声明内容体的⼤⼩。

# TCP其他

- 对于使用tcp通信的两端，如果client已经退出，此时服务端继续send会出现什么问题？

在linux下编写TCP socket程序时，如果客户端突然退出，导致连接中断，这个时候服务端如果继续调用send函数发送数据的话，会导致整个进程退出。当服务端尝试使用一个未连接的socket发送数据时，会抛出一个SIGPIPE信号，这个信号的缺省处理方法是退出进程。如果是服务端突然退出，客户端继续调用send发送，是不会导致进程退出的。

应对方法有以下两种：

1. 重新定义一个信号处理函数，覆盖系统默认的处理方法，这样进程就不会退出了。

2. 修改send函数最后一个参数，linux下send函数原型为：

```php
ssize_t send(int fd, const void* buf, size_t n, int flags);
```

其中，flags一般设置为0。当flags为0时，如果客户端断开，服务端继续send时，会引发一个信号SIGPIPE，使进程退出。所以只需要把flags设置为MSG_NOSIGNAL，就不会导致进程退出。MSG_NOSIGNAL的含义是：当对方断开连接导致错误时，不发送SIGPIPE信号，但还是会返回EPIPE错误。

这样，进程不退出，我们只需要判断send的返回值是否小于或等于0，就知道send函数是否调用成功。

# IP层相关技术

## DNS 的解析过程

1. 浏览器搜索**自己的DNS缓存**
2. 若没有，则搜索**操作系统中的DNS缓存和hosts文件**
3. 若没有，则操作系统将域名发送至**本地域名服务器**，本地域名服务器查询自己的DNS缓存，查找成功则返回结果，否则依次向**根域名服务器、顶级域名服务器、权限域名服务器**发起查询请求，最终返回IP地址给本地域名服务器
4. 本地域名服务器将得到的IP地址返回给**操作系统**，同时自己也**将IP地址缓存起来**
5. 操作系统将 IP 地址返回给浏览器，同时自己也将IP地址缓存起来
6. 浏览器得到域名对应的IP地址

## ARP和RARP

MAC 的作用则是实现「直连」的两个设备之间通信，而 IP 则负责在「没有直连」的两个网络之间进行通信传输。源IP地址和目标IP地址在传输过程中是不会变化的，只有源 MAC 地址和目标 MAC 一直在变化。

在传输一个 IP 数据报的时候，确定了源 IP 地址和目标 IP 地址后，就会通过主机「路由表」确定 IP 数据包下一跳。然而，网络层的下一层是数据链路层，所以我们还要知道「下一跳」的 MAC 地址。由于主机的路由表中可以找到下一跳的 IP 地址，所以可以通过 **ARP 协议**，求得下一跳的 MAC 地址。

ARP 是借助 **ARP 请求与 ARP 响应**两种类型的包确定 MAC 地址的。

主机会通过**广播发送 ARP 请求**，这个包中包含了想要知道的 MAC 地址的主机 IP 地址。当同个链路中的所有设备收到 ARP 请求时，会去拆开 ARP 请求包里的内容，如果 ARP 请求包中的目标 IP 地址与自己的 IP 地址一致，那么这个设备就将自己的 MAC 地址塞入 **ARP 响应包**返回给主机。

操作系统通常会把第一次通过 ARP 获取的 MAC 地址缓存起来，以便下次直接从缓存中找到对应 IP 地址的 MAC 地址。不过，MAC 地址的缓存是有一定期限的，超过这个期限，缓存的内容将被清除。

ARP 协议是已知 IP 地址求 MAC 地址，那 **RARP **协议正好相反，它是**已知 MAC 地址求 IP 地址**。例如将打印机服务器等小型嵌入式设备接入到网络时就经常会用得到。

通常这需要架设一台 `RARP` 服务器，在这个服务器上注册设备的 MAC 地址及其 IP 地址。然后再将这个设备接入到网络，接着：

- 该设备会发送一条「我的 MAC 地址是XXXX，请告诉我，我的IP地址应该是什么」的请求信息。
- RARP 服务器接到这个消息后返回「MAC地址为 XXXX 的设备，IP地址为 XXXX」的信息给这个设备。

最后，设备就根据从 RARP 服务器所收到的应答信息设置自己的 IP 地址。

# 补充

- osi 七层和五层，合并在哪

  七层模型：

  - 物理层：利用传输介质（双绞线、光纤、wifi-电磁波）为数据链路层提供物理连接，实现比特流的透明传输，可靠的物理型号：0和1—通过网卡（MAC地址）定位电脑

  - 数据链路层：将IP数据报组装成帧，控制信息在相邻两节点的链路上进行传输—局域网内部，提供了通讯过程中要用到的MAC地址（物理地址）

  - 网络层：IP — 通过IP找到网关（局域网内部负责人），再找到局域网

  - 传输层：TCP、UDP，不同端口对应不同的应用，控流校验

  - 会话层：建立两个app直接的会话

  - 表示层：对底层命令和数据进行解释

  - 应用层：应用层协议：DNS、HTTP、SMTP等，用户在这一层与网络进行交互

  五层模型：

  TCP/IP五层协议就是把OSI七层网络模型的会话层、表示层、应用层合并成了应用层。

  - 物理层：实现比特流的透明传输

  - 数据链路层：将IP数据报组装成帧，控制信息在相邻两节点的链路上进行传输

  - 网络层：IP，为不同主机分组交换信息服务

  - 传输层：TCP、UDP，为两台主机之间的通信提供通用的数据传输服务

  - 应用层：HTTP、SMTP、FTP、DNS等

- https 的 SSL 建立连接的过程会导致效率下降，如何优化

  HTTPS的SSL建立连接过程中确实会导致一定的性能损耗，主要是因为SSL握手过程需要进行非对称加密和数字签名等操作，而这些操作需要耗费CPU资源。

  以下是一些优化HTTPS性能的方法：

  1. 使用TLS 1.3协议：TLS 1.3协议在握手过程中使用了更快的加密算法，可以减少握手时间。

  2. 使用会话重用：在握手过程中，服务器可以生成一个会话ID或者会话密钥，客户端可以在下一次连接时重用这个会话ID或者会话密钥，从而避免重复进行SSL握手过程。

  3. 使用证书缓存：客户端可以缓存服务器的证书，避免每次连接都需要重新获取证书。

  4. 使用HTTP/2协议：HTTP/2协议使用了多路复用技术，可以在一个连接上同时传输多个请求和响应，从而减少握手次数。

  5. 使用CDN加速：将静态资源放在CDN上，可以减少HTTPS连接的数量，从而提高性能。

  6. 使用硬件加速：使用专门的硬件加速器可以加速SSL握手过程中的加密和解密操作，从而提高性能。

- https 整个握手交互的过程总共花了多少 rtt

  RTT(Round-Trip Time)为数据完全发送完（完成最后一个比特推送到数据链路上）到收到确认信号的时间。https的握手过程是在tcp三次握手之后额外添加2次RTT来完成。

  - TCP 握手（ 1 RTT）

    和服务器建立 TCP 连接，客户端向服务器发送 SYN 包，服务端返回确认的 ACK 包，这会花费一个往返（1 RTT）。

  - TLS 握手 （2 RTT）

    该部分客户端会和服务器交换密钥，同时设置加密链接，对于 TLS 1.2 或者更早的版本，这步需要 2 个 RTT。

  - 建立 HTTP 连接（1 RTT）

    一旦 TLS 连接建立，浏览器就会通过该连接发送加密过的 HTTP 请求。

  从开始到建立一个完整的 HTTPS 连接一共需要 4 个 RTT。如果是浏览刚刚已经访问过的站点的话，通过 TLS 的会话恢复机制，第三步 TLS 握手能够从 2 RTT 变为 1 RTT。

  **注意：**虽然握手过程有1.5个来回，但是最后客户端向服务器发送的第一条应用数据不需要等待服务器返回的信息，因此握手延时是1*RTT。

- 为什么DNS使用UDP而不是TCP？

  DNS（Domain Name System）使用UDP（User Datagram Protocol）而不是TCP（Transmission Control Protocol）是因为：

  1. UDP是无连接的，没有建立和维护连接的开销，可以更快地完成查询和响应，适合短消息的传输。而TCP是面向连接的，需要进行三次握手建立连接，然后再进行数据传输，会增加一定的延迟和开销。

  2. DNS是一个轻量级的协议，一般传输的数据包较小，可以通过UDP一次性传输完整的数据包，而TCP需要将数据包分成多个段进行传输，增加了数据包的大小和传输的开销。

  3. DNS使用UDP可以更好地处理网络拥塞的情况，因为UDP不会对网络拥塞作出反应，而TCP会根据网络拥塞情况调整数据传输的速率，可能会导致延迟和丢包。

  虽然UDP存在一定的缺陷，如可能丢包、重复、乱序等，但对于DNS这样的应用场景，这些问题并不会对查询和响应的准确性产生太大影响。而且，DNS还有一些机制可以处理UDP传输中的一些问题，如使用DNSSEC（DNS Security Extensions）保证数据的完整性和安全性，使用EDNS（Extension mechanisms for DNS）扩展DNS的功能。

- 端口复用和地址复用

  端口复用和地址复用是网络编程中的两个概念，它们的作用是优化网络资源的利用。

  1. 端口复用

  端口复用是指在同一个主机上，多个进程可以同时监听同一个端口。在传统的网络编程中，如果一个进程需要监听某个端口，那么其他进程就不能再监听这个端口了，这就造成了资源的浪费。而端口复用技术可以让多个进程同时监听同一个端口，从而提高了网络资源的利用率。

  在实现时，需要使用SO_REUSEPORT选项，让不同的进程可以绑定同一个端口。

  2. 地址复用

  地址复用是指在同一个主机上，多个进程可以同时绑定同一个IP地址和端口。在传统的网络编程中，如果一个进程需要绑定某个IP地址和端口，那么其他进程就不能再绑定这个IP地址和端口了，这就造成了资源的浪费。而地址复用技术可以让多个进程同时绑定同一个IP地址和端口，从而提高了网络资源的利用率。

  在实现时，需要使用SO_REUSEADDR选项，让不同的网络接口可以使用同一个IP地址。

  需要注意的是，端口复用和地址复用只能在同一个主机上使用，不能跨主机使用。而且，在使用端口复用和地址复用时，需要注意保证各个进程之间的通信不会出现冲突。

- TCP如何感知对方断开链接

  TCP使用一种称为“心跳检测”的机制来感知对方是否断开连接。通过发送称为“keep-alive”消息的特殊TCP数据包，TCP可以检测到对方是否还处于连接状态。如果TCP在一定时间内没有收到对方的响应，则会认为对方已经断开连接。这个时间通常被称为“keep-alive超时时间”，默认情况下为2小时。当然，这个时间可以根据需要进行调整。

- tcp 返回 EGIAN 是什么问题？

   当应用程序在socket中设置O_NONBLOCK属性后，如果发送缓存被占满，send就会返回EAGAIN或EWOULDBLOCK 的错误。

  当需要向socket发送数据时，现将数据压入发送缓存区，并且将socket加入可写事件监听。当socket触发可写事件（EPOLLOUT）时，调用 socket_send函数发送数据，所有数据发送完毕，再清除EPOLLOUT事件。

- close_wait 状态下可以收发数据吗？

  在 `CLOSE_WAIT` 状态下，应用程序已经调用了 `close()` 函数，但是仍然有可能收到对方发来的数据，因此可以继续接收数据。但是，应用程序不能再向对方发送数据，因为连接已经被对方关闭，发送数据会收到 `RST` 响应。在这个状态下，TCP 会等待应用程序处理完所有未读取的数据后，发送 `FIN` 报文给对方，然后进入 `LAST_ACK` 状态等待对方的确认。

- 接收端和发生端之间有个 TCP 长连接，接收端应用层一直不处理缓冲区数据，发送端一直发，最后发送端，接收端，TCP 一些属性，会有什么变化？

  在这种情况下，如果接收端一直不处理缓冲区数据，那么缓冲区会不断累积，直到达到一定的阈值，此时发送端的数据将会被阻塞，因为TCP的拥塞控制会认为网络出现了拥塞，从而触发拥塞避免算法，减少发送速率。同时，发送端和接收端的TCP会根据网络状况自动调整拥塞窗口大小，以达到更好的网络利用率和传输效率。

  在这种情况下，如果发送端一直发送数据，而接收端一直不读取数据，会导致接收端的TCP缓冲区被填满，从而触发TCP的流量控制机制，发送端的数据发送速率将被限制，从而保证接收端的TCP缓冲区不会溢出。同时，发送端和接收端的TCP会根据网络状况自动调整拥塞窗口大小，以达到更好的网络利用率和传输效率。

  如果这种情况持续较长时间，可能会导致发送端和接收端的TCP连接被超时关闭，从而需要重新建立TCP连接。

- UDP 包想一次性发送 2K 的数据，接收端 1K1K 的读，能成功么

  TCP可以，但是UDP不可以。

  TCP是以数据流来发送的，发送端可以是1K1K的发送数据，而接收端的应用程序可以是2K2K地提取数据，也可以一次性全部提走，或者一次只提取几个字节的数据。应用程序所看到的数据是一个整体，或者说是一个流(stream) ，一条消息有多少个字节对应用程序是不可见的，因此TCP协议是面向流的协议，这也是容易出现粘包问题的原因。

  而UDP协议是面向消息的协议，每个UDP字段都是一条消息，应用程序必须以消息为单位提取数据，不能一次性提取任意字节的数据，这和TCP很不相同。TCP协议下，一条消息的发送，无论底层如何分段分片，TCP协议层会把构成整条消息的数据段排序完成后才呈现在内核缓冲区。

- MSS和MTU

  MSS和MTU是TCP/IP协议栈中的两个重要参数，分别代表最大分段大小和最大传输单元。它们的含义和作用如下：

  - MSS（Maximum Segment Size）：指的是TCP数据包中的数据部分的最大长度，不包括TCP头部和IP头部。MSS的大小是由对端的TCP栈在建立连接时协商决定的，通常是MTU减去IP和TCP头部的长度。MSS的大小决定了TCP分段的大小，也就是说，如果TCP发送的数据包长度超过了MSS，那么就需要将数据分成多个MSS大小的分段进行传输。

  - MTU（Maximum Transmission Unit）：指的是网络能够传输的最大的TCP数据包的大小，不包括链路层头部和尾部的长度。MTU的大小是由网络设备决定的，不同的网络设备MTU大小可能不同。如果TCP要发送的数据包长度超过了MTU，那么就需要将数据分成多个MTU大小的分段进行传输。

  MSS和MTU之间的关系是：MSS = MTU - IP头部长度 - TCP头部长度。在TCP建立连接时，双方会协商MSS的大小，以保证TCP数据包不会超过MTU的大小，从而避免IP分片和重组的问题，提高网络传输效率。

- 服务端主动请求关闭连接，会发生什么？

  当服务器进程被终止时，会关闭其打开的所有文件描述符，此时就会向客户端发送一个FIN 的报文，客户端则响应一个ACK 报文，但是这样只完成了“四次挥手”的前两次挥手，也就是说这样只实现了半关闭，客户端仍然可以向服务器写入数据。

  但是当客户端向服务器写入数据时，由于服务器端的套接字进程已经终止，此时连接的状态已经异常了，所以服务端进程不会向客户端发送ACK 报文，而是发送了一个RST 报文请求将处于异常状态的连接复位。如果客户端此时还要向服务端发送数据，将诱发服务端TCP向服务端发送SIGPIPE信号，SIGPIPE信号的默认处理是终止程序，导致客户端进程退出。

- TCP的keep-alive和HTTP的keep-alive有什么区别？

  HTTP 的 Keep-Alive 也叫 HTTP 长连接，该功能是由「应用程序」实现的，可以使得用同一个 TCP 连接来发送和接收多个 HTTP 请求/应答，减少了 HTTP 短连接带来的多次 TCP 连接建立和释放的开销。

  TCP 的 Keepalive 也叫 TCP 保活机制，该功能是由「内核」实现的，当客户端和服务端长达一定时间没有进行数据交互时，内核为了确保该连接是否还有效，就会发送探测报文，来检测对方是否还在线，然后来决定是否要关闭该连接。

- 延时与吞吐率的区别

   延迟（Latency）是指从发送数据到接收数据所需的时间，也就是数据在网络中传输的时间。延迟一般是以毫秒（ms）为单位进行计算，是指网络传输速度的快慢，通常用于测量网络的响应速度。

   吞吐率（Throughput）是指在单位时间内通过网络的数据量，通常以比特每秒（bps）或字节每秒（Bps）为单位进行计算，是指网络的传输能力。吞吐率通常用于测量网络的容量大小，即网络传输速率的大小。
   
   延迟和吞吐率都是网络性能的重要指标，但它们的重点不同。延迟是关注网络的响应速度，而吞吐率则关注网络的传输能力。在实际应用中，延迟和吞吐率都是需要考虑的因素，不同的应用场景需要不同的重点。
   
- 服务端一下子涌入大量数据怎么办

   如果服务端一下子涌入大量数据，可能会导致服务端无法及时处理这些数据，甚至会导致服务端崩溃。为了避免这种情况的发生，可以采取以下几种方法：

   1. 增加服务端的处理能力：可以增加服务端的处理能力，例如增加服务器的硬件配置、优化代码等，以提高服务端的处理速度和稳定性。

   2. 限制客户端发送数据的速率：可以通过限制客户端发送数据的速率，以减少服务端处理数据的压力。可以通过限制客户端的带宽、设置发送数据的时间间隔等方式实现。

   3. 分批处理数据：可以将大量数据分批处理，每次处理一部分数据，以减少服务端的压力。可以通过设置缓存区、分段传输数据等方式实现。

   4. 采用异步处理方式：可以采用异步处理方式，将数据存储到队列中，由服务端异步处理，以提高服务端的处理效率和稳定性。可以通过使用线程池、消息队列等方式实现。

   5. 采用负载均衡技术：可以将请求分发到多个服务端上进行处理，以提高服务端的处理能力和稳定性。可以通过使用负载均衡器、集群等方式实现。

- TCP的拥塞控制和流量控制有什么区别？

   流量控制解决因发送方发送数据太快而导致接收方来不及接收使接收方缓存溢出的问题。流量控制的基本方法就接收方根据自己的接收能力控制发送方的发送速率，TCP采用接收方控制发送方发送窗口大小的方法来实现在TCP连接上的流量控制。

   流量控制利用滑动窗口协议控制发送端流量，是为了解决发送数据过快导致接收方来不及接收的问题。接收方会发送流量控制报文，通知发送方窗口大小，发送方发送的数据大小不能超过窗口大小。如果发送者发送数据过快，接收者来不及接收，那么就会有报文丢失。为了避免报文丢失，控制发送者的发送速度，使得接收者来得及接收，这就是流量控制。流量控制根本目的是防止报文丢失，它是构成TCP可靠性的一方面。

   拥塞控制就是防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不致过载。TCP的发送方维持一个叫做拥塞窗口的状态变量。拥塞窗口的大小取决于网络的拥塞程度，当网络拥塞时减小拥塞窗口的大小，控制TCP发送方的发送速率。TCP发送方的发送窗口大小取接收窗口和拥塞窗口的最小值。

   - 区别

   流量控制：流量控制是作用于接收者的，控制发送者的发送速度从而使接收者来得及接收，防止报文丢失。

   拥塞控制：拥塞控制是作用于网络的，防止过多的数据注入到网络中，避免出现网络负载过大的情况。常用的方法就是：慢启动、拥塞避免、拥塞发生、快速恢复。

- TCP是全双工的，HTTP是哪种？全双工半双工单工？

  1. 单工： 数据传输只允许在一个方向上的传输，只能一方来发送数据，另一方来接收数据并发送。例如：对讲机
  2. 半双工：数据传输允许两个方向上的传输，但是同一时间内，只可以有一方发送或接受消息。例如：打电话
  3. 全双工：同时可进行双向传输。例如：`websocket`

  HTTP需要分版本看待：

  1. `http1.0`：单工，因为是短连接，客户端发起请求之后，服务端处理完请求并收到客户端的响应后即断开连接。
  2. `http1.1`：半双工，默认开启长连接`keep-alive`，开启一个连接可发送多个请求。
  3. `http2.0`：全双工，允许服务端主动向客户端发送数据。

  TCP是全双工的。可以从TCP选择重传中看出来，在每一时刻是同时存在收发端发送的帧和ACK信号的。但是从三次握手看起来又像是半双工，每一时刻只有发送端发送的SYN信号或者是接收端发送的ACK确认信号，但是TCP三次握手不能代表平时的数据传输，三次握手的目的是为了确立连接建立，而在实际TCP传输过程中大多情况是收发端同时发送数据的。
  
  HTTP是半双工的。 
  
  在半双工通信中，通信双方都可以发送和接收数据，但不能同时进行。在HTTP中，客户端向服务器发送请求，服务器响应请求并返回数据，此时客户端不能再向服务器发送请求，直到服务器响应完毕。因此，HTTP是一种半双工通信协议。 
  
  相比之下，TCP是一种全双工通信协议，因为在TCP连接中，通信双方可以同时进行发送和接收数据。


- IP层如何找MAC地址？如果对应IP不在局域网呢

  在局域网内，IP地址和MAC地址之间的映射关系可以通过ARP协议来获取。当一台主机需要发送数据包给另一台主机时，它会首先检查目标IP地址是否在本地网络中。如果是，它会使用ARP广播来询问目标主机的MAC地址。目标主机收到ARP请求后，会回复一个ARP响应包，其中包含自己的MAC地址。

  如果目标IP地址不在本地网络中，发送主机会将数据包发送到默认网关。默认网关会根据路由表将数据包转发到下一个网络。在这种情况下，发送主机会使用ARP广播来获取默认网关的MAC地址，然后将数据包发送到默认网关。默认网关收到数据包后，会根据路由表将数据包转发到目标主机所在的网络。

  如果攻击者在局域网中进行ARP欺骗攻击，它会发送伪造的ARP响应包，欺骗其他主机将攻击者的MAC地址与目标IP地址关联起来。这样，攻击者就可以拦截、修改或重定向其他主机的数据流量，从而实现窃取信息或进行中间人攻击等恶意行为。

- ARP攻击/ARP欺骗

  ARP（Address Resolution Protocol）攻击，也叫ARP欺骗，是一种利用局域网上的ARP协议缺陷，欺骗目标主机的MAC地址，从而达到网络攻击的目的。

  攻击者通过伪造ARP响应包，将自己的MAC地址伪装成目标主机的MAC地址，然后发送给局域网上的其他主机，使得这些主机将攻击者的MAC地址缓存起来，从而将攻击者伪装成目标主机。这样，攻击者就可以通过ARP欺骗，窃取目标主机的数据包，或者劫持目标主机的网络连接，进行中间人攻击等恶意行为。

  ARP攻击可以分为主动式攻击和被动式攻击。主动式攻击是指攻击者主动伪造ARP响应包，欺骗目标主机；被动式攻击是指攻击者监听网络上的ARP请求和响应包，然后进行欺骗。

  为了防止ARP攻击，可以采取以下措施：

  1. 使用静态ARP表，手动维护IP地址和MAC地址的对应关系。

  2. 使用动态ARP缓存，设置ARP缓存的过期时间，定期清除缓存。

  3. 使用ARP防火墙，限制ARP请求和响应包的发送和接收。

  4. 使用虚拟局域网（VLAN）技术，将不同的主机分隔开来，减少攻击面。

  5. 使用加密技术，保护数据包的安全传输。

- 网际控制报文协议ICMP的过程

  网际控制报文协议（ICMP）是一种用于在IP网络上发送错误消息的协议。它的主要作用是在网络中传递控制信息和错误消息。以下是 ICMP 的过程：

  1. 发送方向目标主机发送 ICMP 报文。

  2. 目标主机接收到 ICMP 报文后，根据报文类型进行相应的处理。例如，如果是 Ping 请求报文，则目标主机会返回 Ping 应答报文。

  3. 如果目标主机无法处理 ICMP 报文，则会向发送方发送一个 ICMP 错误报文，告诉发送方发生了什么错误。

  4. 发送方接收到 ICMP 错误报文后，可以根据报文内容进行相应的处理。例如，如果是目标主机不可达的错误报文，则发送方可以尝试使用其他路径发送数据包。

  在 ICMP 过程中，主要使用了 IP 协议和 ICMP 协议。IP 协议用于将 ICMP 报文从发送方传输到目标主机，而 ICMP 协议则用于发送控制信息和错误消息。

- ping 的过程，分别用到了哪些协议

  Ping 的过程主要用到了两个协议：ICMP 和 IP。

  Ping 是一种用于测试网络连接的常用命令，其原理是向目标主机发送 ICMP 回显请求，然后等待目标主机返回 ICMP 回显应答。在这个过程中，Ping 命令首先使用 IP 协议将 ICMP 数据包发送到目标主机，然后目标主机收到 ICMP 数据包后，使用 ICMP 协议进行回应。具体来说，Ping 的过程如下：

  1. 发送端主机构建 ICMP 回显请求数据包，并使用 IP 协议将数据包发送到目标主机。

  2. 目标主机接收到 ICMP 数据包后，使用 ICMP 协议回应 ICMP 回显应答数据包。

  3. 发送端主机接收到 ICMP 回显应答数据包后，计算出往返时间（RTT），并显示在 Ping 命令的输出中。

  在这个过程中，Ping 命令使用了 ICMP 协议来发送和接收数据包，同时也使用了 IP 协议来进行数据包的路由和传输。

- 动态主机配置协议DHCP的过程

  DHCP（Dynamic Host Configuration Protocol，动态主机配置协议）是一种网络协议，它可以自动为计算机分配IP地址、子网掩码、默认网关、DNS服务器等网络配置信息，从而简化网络管理和配置。DHCP的过程如下：

  1. DHCP Discover：客户端在加入网络时发送一个广播消息，请求DHCP服务器提供IP地址和其他配置信息。

  2. DHCP Offer：DHCP服务器接收到客户端的广播消息后，向客户端发送一个包含IP地址和其他配置信息的DHCP Offer消息。

  3. DHCP Request：客户端收到DHCP Offer消息后，向DHCP服务器发送一个DHCP Request消息，确认接受所提供的配置信息。

  4. DHCP Acknowledge：DHCP服务器收到客户端的DHCP Request消息后，向客户端发送一个DHCP Acknowledge消息，确认分配IP地址和其他配置信息。

  5. DHCP Lease Renewal：客户端在租期到期前向DHCP服务器发送DHCP Request消息，请求续租IP地址和其他配置信息。

  6. DHCP Lease Expired：如果客户端在租期到期后没有向DHCP服务器发送DHCP Request消息，则DHCP服务器会释放该IP地址，以便其他客户端使用。

  通过DHCP，网络管理员可以轻松管理网络中的IP地址和其他配置信息，避免了手动配置的繁琐和错误，提高了网络管理的效率。
- NAT（Network Address Translation，网络地址转换）是一种网络协议，主要用于将内部网络的私有IP地址转换为合法的公网IP地址，以便实现内部网络与外部网络的通信。NAT的主要工作流程可以概括如下：

  1. 在内部网络中，客户端设备发送数据包到公网服务器时，数据包的源IP地址是客户端设备的私有IP地址，目标IP地址是公网服务器的公网IP地址。
  2. NAT设备接收到这个数据包后，会将源IP地址和源端口号进行修改，将其改为NAT设备的公网IP地址和一个随机的端口号，并记录这个映射关系。
  3. NAT设备将修改后的数据包发送到公网服务器。
  4. 公网服务器接收到数据包后，将响应数据包发送回NAT设备，并将目标IP地址和目标端口号设置为NAT设备的公网IP地址和之前记录的随机端口号。
  5. NAT设备接收到响应数据包后，根据记录的映射关系将目标IP地址和目标端口号还原成客户端设备的私有IP地址和端口号，并将响应数据包发送回客户端设备。

  NAT设备在转换IP地址时，会根据每个数据包的源IP地址、目标IP地址、源端口号和目标端口号等信息来进行映射。因此，在内网中，不同设备的私有IP地址和端口号不同，NAT设备可以根据这些信息来区分不同设备发送的数据包，并对其进行转换。

  当内网中的设备之间进行通信时，数据包的源IP地址和目标IP地址都是内网中的私有IP地址，NAT设备可以根据这些信息来确定数据包的目标设备，并将其传递到相应的设备。在这种情况下，NAT设备不需要对数据包进行IP地址转换。


- TCP 报文长度字段设置在哪里

  kind=2，最大报文段长度（MSS）选项。

  TCP连接初始化时，通信双方使用该选项来协商最大报文段长度。TCP模块通常将MSS设置为（MTU-40）字节（减掉的这40字节包括20字节的TCP头部和20字节的IP头部）。这样携带TCP报文段的IP数据报的长度就不会超过MTU（假设TCP头部和IP头部都不包含选项字段，并且这也是一般情况），从而避免本机发生IP分片。对以太网而言，MSS值是1460（1500-40）字节。

  TCP 报文长度字段被设置在TCP头部中的数据偏移字段中。它指定了TCP头部的长度（以32位字长为单位），因为TCP头部长度是可变的，所以数据偏移字段指定了TCP头部的字节数，这样接收端就可以正确地解析TCP报文。TCP头部的最小长度为20字节，最大长度为60字节。

- socket调用write返回值表示的意义

  1. 当read()或者write()函数返回值大于0时，表示实际从缓冲区读取或者写入的字节数目；
  2. 当read()函数返回值为0时，表示对端已经关闭了 socket，这时候也要关闭这个socket，否则会导致socket泄露。netstat命令查看下，如果有closewait状态的socket,就是socket泄露了。当write()函数返回0时，表示当前写缓冲区已满，是正常情况，下次再来写就行了；
  3. 当read()或者write()返回-1时，一般要判断errno。如果errno == EINTR,表示系统当前中断了，直接忽略。如果errno == EAGAIN或者EWOULDBLOCK，非阻塞socket直接忽略；如果是阻塞的socket,一般是读写操作超时了，还未返回。这个超时是指socket的SO_RCVTIMEO与SO_SNDTIMEO两个属性。所以在使用阻塞socket时，不要将超时时间设置的过小。不然返回了-1，你也不知道是socket连接是真的断开了，还是正常的网络抖动。一般情况下，阻塞的socket返回了-1，都需要关闭重新连接；
  4. 如果返回值为正数，表示成功发送了指定数量的字节；如果返回值为0，表示对方已经关闭了连接；如果返回值为-1，表示发送失败，此时可以通过errno来确定错误的具体原因。 在发送数据时，write函数会尽可能地将数据写入Socket的发送缓冲区，然后返回已经写入的字节数。如果写入的数据量超过了发送缓冲区的大小，write函数可能会阻塞，等待发送缓冲区有足够的空间。如果在一定时间内发送缓冲区还没有空间，write函数可能会返回-1，并设置errno为EAGAIN或EWOULDBLOCK，表示发送缓冲区已满，需要等待一段时间再尝试发送。

- 路由器和交换器的区别

  1. 工作层次不同 路由器工作在网络层，主要负责不同网络之间的数据转发和路由选择；而交换机工作在数据链路层，主要负责同一网络内部的数据交换。
  1. 转发方式不同 路由器使用IP地址进行转发，根据IP地址进行路由选择；而交换机使用MAC地址进行转发，根据MAC地址进行数据交换。
  1. 范围不同 路由器通常连接不同的网络，可以跨越不同的地域范围；而交换机通常连接同一网络内的设备，范围相对较小。
  1. 能力不同 路由器具备路由选择的功能，可以在不同网络之间进行数据转发；而交换机只能在同一网络内部进行数据交换。
  1. 安全性不同 由于路由器可以进行路由选择和网络隔离，因此具有更高的安全性；而交换机只能在同一网络内部进行数据交换，安全性相对较低。

- Accept函数与三次握手关系

  1. 当客户端调用connect时，触发了连接请求，向服务器发送了SYN J包，这时connect进入阻塞状态；
  2. 服务器监听到连接请求，即收到SYN J包，调用accept函数接收请求，向客户端发送SYN K ，ACK J+1，这时accept进入阻塞状态；
  3. 客户端收到服务器的SYN K ，ACK J+1之后，这时connect返回，并对SYN K进行确认；服务器收到ACK K+1时，accept返回，至此三次握手完毕，连接建立。

  


