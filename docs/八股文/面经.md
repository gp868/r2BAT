# 面经

# cpp

- i++和++i 的区别，哪个效率高？i++线程安全吗？

  1. 区别：

  - i++是先赋值，然后再自增；++i是先自增，后赋值；
  - i++ 不能作为左值，而++i可以；

  2. 效率：

  当考虑自定义类的时候，两者效率有区别。

  i++是先用临时对象保存原来的对象，然后对原对象自增，再返回临时对象，不能作为左值；++i是直接对原对象进行自增，然后返回原对象的引用，可以作为左值。

  由于要生成临时对象，i++需要调用两次拷贝构造函数与析构函数（将原对象赋给临时对象一次，临时对象以值传递方式返回一次）；++i由于不用生成临时变量，且以引用方式返回，故没有构造与析构的开销，效率更高。

  所以在使用类等自定义类型的时候，应尽量使用++i。

  3. 线程安全：

  - 如果i是局部变量（在方法里定义的），那么是线程安全的。因为局部变量是线程私有的，别的线程访问不到；

  - 如果i是全局变量（类的成员变量），那么是线程不安全的。因为如果是全局变量的话，同一进程中的不同线程都有可能访问到。

- 函数指针和指针函数的区别？

  - 函数指针：int (*f)(int x, int y);

  - 指针函数：int *f(int x, int y);

  函数指针本质是一个指针，其指向一个函数；指针函数本质是一个函数，其返回值为指针。

- 回调函数和普通函数的区别

  回调函数（Callback Function）是指在函数运行过程中，将函数指针作为参数传递给另一个函数，并在另一个函数中调用该函数指针，从而完成一定的操作。普通函数则是指没有回调机制，直接按照函数的定义和调用方式执行的函数。 回调函数和普通函数的主要区别如下：

  1. 使用方式不同：回调函数是将函数指针作为参数传递给另一个函数，并在另一个函数中调用该函数指针；而普通函数则是直接按照函数的定义和调用方式执行的函数。
  2. 调用时机不同：回调函数的调用时机是由另一个函数来确定，一般在某个事件发生时被回调；而普通函数的调用时机则是由函数的调用者来确定。
  3. 灵活性不同：由于回调函数是将函数指针作为参数传递，因此可以在运行时动态指定要调用的函数，从而使程序更加灵活；而普通函数则是在编译时确定的，不具备动态性。
  4. 作用不同：回调函数主要用于事件驱动型程序中，例如GUI程序、操作系统等；而普通函数则是用于完成特定的功能。

  需要注意的是，回调函数和普通函数并不是完全独立的概念，有些函数既可以作为普通函数使用，也可以作为回调函数使用。

- 静态变量的初始化时间

  - 静态初始化，用常量来对静态变量进行初始化

    在main()函数之前，程序加载时初始化；

  - 动态初始化，需要调用函数才能完成的初始化，比如类的构造函数

    全局静态变量或者类的静态成员变量，是在main()函数执行前，运行时初始化；局部静态变量在函数第一次执行到该初始化语句时初始化。

- C++空类会默认创建哪些函数

  缺省构造函数，拷贝构造函数，析构函数，赋值运算符，取址运算符，取址运算符 const。

  ```cpp
  class Empty{
    public:
        Empty(); // 缺省构造函数
        Empty( const Empty& ); // 拷贝构造函数
        ~Empty(); // 析构函数
         Empty& operator=( const Empty& ); // 赋值运算符
         Empty* operator&(); // 取址运算符
         const Empty* operator&() const; // 取址运算符 const
  };
  ```

- const int* a, int* const a, int const* a 的区别

  - const int* a：指针指向地址的内容不能被改变，但是指针指向的地址可以更改；
  - int const* a：和const int* a相同；
  - int* const a：指针指向的地址不能更改，但是指针指向地址的内容可以更改；

- 调用析构函数的时候类型是 void 类型，指向的是类对象，会正确调用析构函数吗？

  - void指向系统自建类型，可以使用delete void；
  - void*所指向的对象在析构函数里释放会丢失内存，因为它不执行析构函数。需要强制转换类型，然后delete；

- vfork 什么作用？fork和vfork的区别

  `vfork()` 是一种创建子进程的系统调用，与 `fork()` 类似，但是 `vfork()` 会与父进程共享地址空间，直到子进程调用 `execve()`、 `_exit()` 或发生错误时才会分离地址空间。`vfork()` 的主要作用是在创建子进程时避免复制父进程的地址空间，从而提高创建进程的效率。

  `fork()` 与 `vfork()` 的区别在于，`fork()` 会复制父进程的地址空间，而 `vfork()` 不会复制父进程的地址空间，直接在父进程的地址空间中运行子进程。因此，使用 `vfork()` 可以在创建子进程时避免复制大量的数据，提高创建进程的效率。但是，由于 `vfork()` 与父进程共享地址空间，因此必须保证子进程不会修改父进程的数据，否则可能会导致未定义的行为。 在使用 `vfork()` 时，需要注意以下几点：

  1. 子进程必须要调用 `execve()`、 `_exit()` 或发生错误时才能分离地址空间，否则可能会导致未定义的行为。
  2. 子进程不能修改父进程的数据，否则可能会破坏父进程的状态。
  3. 父进程在调用 `vfork()` 后应该立即调用 `wait()` 或 `waitpid()` 等待子进程结束，否则可能会导致子进程成为僵尸进程。 总的来说，`vfork()` 可以在创建进程时提高效率，但是需要注意子进程与父进程之间的共享问题，避免出现未定义的行为。

- 条件变量为什么需要加锁？

  条件变量是多线程编程中的一种同步机制，通常与互斥锁一起使用，在多线程中实现线程之间的同步和通信。条件变量的作用是当某个条件被满足时，唤醒正在等待该条件的线程。 条件变量需要加锁的原因如下：

  1. 确保线程安全：在使用条件变量时，需要先获取相关的互斥锁，然后再对条件变量进行操作。这是因为条件变量的操作通常需要访问共享资源，如果没有加锁，多个线程可能会同时访问共享资源，导致数据竞争和线程安全问题。
  2. 避免竞争条件：条件变量的等待和唤醒操作通常需要依赖互斥锁来保证其原子性和同步性。如果没有加锁，多个线程可能会同时调用条件变量的等待和唤醒操作，导致竞争条件和线程安全问题。
  3. 避免死锁：条件变量和互斥锁通常是成对使用的，如果在使用条件变量时没有获取相应的互斥锁，可能会导致死锁问题。 

  因此，为了保证线程安全、避免竞争条件和死锁问题，条件变量需要加锁。在使用条件变量时，通常需要先获取相关的互斥锁，然后再对条件变量进行操作。

- 虚函数可以内联吗

  虚函数可以是内联函数，但是当虚函数表现多态性的时候不能内联。内联发生在编译阶段，而虚函数的多态性在运行期，编译器无法知道运行期调用哪个代码，因此虚函数表现为多态性时（运行期）不可以内联。

  inline virtual 唯一可以内联的时候是：编译器知道所调用的对象是哪个类，这只有在编译器具有实际对象而不是对象的指针或引用时才会发生。

  ```cpp
  #include <iostream>  
  using namespace std;
  class Base{
  public:
  	inline virtual void who()
  	{
  		cout << "I am Base\n";
  	}
  	virtual ~Base() {}
  };
  class Derived : public Base{
  public:
  	inline void who()  // 不写inline时隐式内联
  	{
  		cout << "I am Derived\n";
  	}
  };
  
  int main(){
  	// 此处的虚函数 who()，是通过类（Base）的具体对象（b）来调用的，
      // 编译期间就能确定了，所以它可以是内联的，但最终是否内联取决于编译器。 
  	Base b;
  	b.who();
  
  	// 此处的虚函数是通过指针调用的，呈现多态性，需要在运行时期间才能确定，所以不能为内联。  
  	Base *ptr = new Derived();
  	ptr->who();
  
  	// 因为Base有虚析构函数（virtual ~Base() {}），所以 delete 时，
      // 会先调用派生类（Derived）析构函数，再调用基类（Base）析构函数，防止内存泄漏。
  	delete ptr;
  	ptr = nullptr;
  } 
  ```

- int a[10]; 这个数组的数组变量和数组内容都是存在哪里的？

  数组变量存储在栈内存中：在 C++ 中，数组变量是一个指向数组首元素的指针，它存储在栈内存中。对于 `int a[10];` 这个数组变量，它在内存中的存储位置是栈内存的某个位置，用于存储指向数组首元素的指针。

  数组内容存储在堆内存或栈内存中：数组内容存储在内存中的位置取决于数组的定义方式和存储位置。对于 `int a[10];` 这个数组，它是在函数栈内存中定义的，其内容也存储在栈内存中。而对于使用 new 运算符动态分配内存的数组，则其内容存储在堆内存中。

- 指针数组和数组指针的区别？

  数组指针本质是指针，是指向数组的指针；指针数组本质是数组，是保存指针的数组。

  ```cpp
  int (*p)[4]; // 数组指针
  // int类型的指针p指向int[4]数组首地址，数组的每一个元素是一个int类型的变量，数组大小为4
  int *p[4];  // 指针数组
  // 数组长度为4，所有元素均为int类型的指针
  ```

- 求一个表达式的值：

  ```cpp
  int a = (int)(((int*)0)+4);  
  ```

  a =16，相当于把`(int*)`，这个整形指针加4，即移动`4*sizeof（int）`个字节，即16个字节，然后把这个指针转为int就是16，`(int*)0`地址0，加上16字节后，为0x00000010。

- 下面这段代码最终打印什么

  ```cpp
  int main () {
    fork();
    fork();
    fork();
    printf("hello world\n");
    exit(0);
  }
  // 打印2的3次方即8行hello world
  int main()
  {
  	fork();
  	printf("hello\n");
  	fork();	
  	printf("hello\n");
  }
  // 打印6行hello world
  ```

- const int func(const char *const p) const 四个 const 的作用

  1. const修饰函数返回值，可以防止函数返回值被修改；
  2. 指针指向地址的内容不可更改；
  3. 指针指向的地址不可以更改；
  4. const修饰类成员函数，可以防止成员函数修改对象的内容；

- assert 函数说一下？abort 函数调用后程序会咋样？

  `assert` 是宏，而不是函数。它的原型定义在头文件 assert中：

  ```cpp
  void assert( int expression );
  ```

  宏 assert 经常用于在函数开始处检验传入参数的合法性，可以将其看作是异常处理的一种高级形式。assert 的作用是先计算表达式expression，然后判断：

  - 如果表达式值为假，那么它先向 stderr 打印错误信息，然后通过调用 abort 来终止程序运行；
  - 如果表达式值为真，继续运行后面的程序；

  注意：`assert` 只在 `DEBUG` 下生效，在调试结束后，可以通过在 `#include <assert.h>` 语句之前插入 `#define NDEBUG` 来禁用 assert 调用。频繁的调用assert函数会极大的影响程序的性能，增加额外的开销。

  ```cpp
  #define NDEBUG
  #include <assert.h>
  ```

  abort()函数的原型位于头文件cstdlib（或stdlib.h）中，作用是异常终止一个进程，意味着abort后面的代码将不再执行。调用abort()时，不进行任何清理工作，直接终止程序。abort()函数通过发出一个SIGABRT信号终止程序的执行。

- 二维数组的按行和按列获取元素顺序有什么异同，哪个效果好，为什么

  按行获取时，同一行的元素在内存中是连续存储的；而按列获取时，同一列的元素在内存中不是连续存储的。

  - 对于连续遍历所有元素的情况，按行获取效果更好。因为按行获取的元素在内存中是连续存储的，这样可以充分利用 CPU 缓存，提高程序的运行效率。
  - 对于查找某一行或某一列的所有元素的情况，按列获取效果更好。按列获取元素的优点是可以利用程序的局部性原理，因为二维数组在内存中是连续存储的，所以在按列获取元素时，CPU可以预先将该列的所有元素加载到缓存中，这样可以减少CPU的缓存失效率，提高程序的效率。

  综上所述，如果需要遍历所有元素，建议按行获取；如果需要查找某一行或某一列的所有元素，建议按列获取。

- 运算符重载和函数重载的区别

  函数重载是指在同一作用域内的若干个参数特征不同的函数可以使用相同的函数名字；运算符重载是指同一个运算符可以施加于不同类型的操作数上面。就是对已有的运算符重新进行定义，赋予其另一种功能，以适应不同的数据类型。

  1. 定义方式不同：运算符重载是通过在函数名前加上运算符关键字和符号来定义的，例如重载加法运算符可以使用`operator+`来定义；而函数重载是在函数名相同的情况下，通过参数列表的不同来定义的。
  2. 使用方式不同：运算符重载可以像使用内置运算符一样来使用，例如 `a+b`，其中 `+` 运算符被重载了；而函数重载需要在调用时根据传递的参数列表来确定具体调用哪个函数。
  3. 限制不同：运算符重载只能重载 C++ 中现有的运算符，而函数重载可以重载任何函数名。
  4. 返回值类型不同：运算符重载的返回值通常是运算结果，而函数重载的返回值可以是任何类型。
  5. 参数个数不同：运算符重载通常只有一个参数，即运算符左侧的操作数，但有些运算符重载可能有两个参数，例如重载赋值运算符 `operator=`；而函数重载可以有任意数量的参数。

- 栈的时间复杂度、空间复杂度

  时间复杂度：栈的基本操作包括入栈和出栈，它们的时间复杂度都是 O(1)，即常数级别的时间复杂度。因为栈只允许在栈顶进行插入和删除操作，所以不需要遍历整个栈来查找元素，从而使得栈的操作非常高效。

  空间复杂度：栈的空间复杂度取决于栈的使用情况和实现方式。对于静态数组实现的栈，它的空间复杂度是固定的，即 O(n)，其中 n 表示数组的长度。而对于动态数组或链表实现的栈，它的空间复杂度会根据实际情况进行动态调整，最坏情况下为 O(n)，其中 n 表示栈中元素的个数。

- 一个类有多个基类，内存中怎么虚函数表是怎么分布的？

  在派生类对象的内存中，虚表指针放在最前面，和对象的地址相同。然后是成员变量，基类的成员变量在派生类的成员变量前面，基类和派生类的成员变量分别按类中的声明顺序排列。

  对于多继承的情况，假如派生类有n个直接基类，那么派生类对象中就有n个虚表指针。派生类对象的内存可以划分为n+1块，首先存放第1个基类的虚表指针和成员变量，然后存放第2个基类的虚表指针和成员变量，以此类推。派生类自己的成员变量放在最后1块。

  虚表中虚函数的顺序是按声明顺序排列的，基类虚函数的声明先于派生类。派生类的虚函数和第一个直接基类共用一张虚表，并且在这张虚表中，基类的虚函数在前，派生类的虚函数在后。如果派生类覆盖了基类的一个虚函数，那么虚表中本来存放这个基类虚函数地址的位置改为存放派生类版本的虚函数地址。

- 内存对齐有什么用？

  内存对齐是指在分配内存时，按照一定的规则和字节对齐方式分配，使得数据存储在内存中的地址能够被 CPU 高效地访问，从而提高程序的执行效率和性能。 内存对齐的主要作用有以下几个方面：

  1. 提高访问效率：CPU 访问对齐的数据的速度是非对齐数据的速度的两倍。这是因为对于对齐的数据，CPU 可以通过一次内存读取操作就能够读取到所需的数据，而对于非对齐的数据，CPU 需要进行两次内存读取操作，从而造成额外的开销。
  2. 保证数据结构的正确性：内存对齐可以保证数据结构中的每个元素都被正确地存放在其应该存放的地址上，从而避免了数据被错误地访问或修改的情况。
  3. 与硬件的兼容性：一些硬件设备要求数据必须按照一定的规则和字节对齐方式存储，否则可能会引起硬件异常或错误。
  4. 提高缓存效率：CPU 的缓存系统通常也需要对数据进行对齐。如果数据没有按照对齐的方式存储，可能会造成缓存失效，从而降低程序的执行效率。 

  总之，内存对齐是一种优化技术，可以提高程序的执行效率和性能。在编写程序时，应该尽可能地遵循内存对齐的规则，从而使程序更加高效、稳定和可靠。

  先来看下内存对齐的规则：

  1. 对于结构的各个成员，第一个成员位于偏移为0的位置，以后每个数据成员的偏移量必须是min(#pragma pack()指定的数，这个数据成员的自身长度) 的倍数。#pragma pack(n) 表示设置为n字节对齐，VC6默认8字节对齐；

  2. 在数据成员完成各自对齐之后，结构(或联合)本身也要进行对齐，对齐将按照#pragma pack指定的数值和结构(或联合)最大数据成员长度中，比较小的那个进行。

   ```cpp
  // 环境：vc6 + windows sp2
  #include <iostream>
  using namespace std;
  struct st1 {
      char a ;
      int  b ;
      short c ;
  };
  struct st2{
      short c ;
      char  a ;
      int   b ;
  };
  // sizeof(st1) is 12
  // sizeof(st2) is 8
   ```

  St1 ：char占一个字节，起始偏移为0 ，int 占4个字节，min(#pragma pack()指定的数，这个数据成员的自身长度) = 4（VC6默认8字节对齐），所以int按4字节对齐，起始偏移必须为4的倍数，所以起始偏移为4，在char后编译器会添加3个字节的额外字节，不存放任意数据。short占2个字节，按2字节对齐，起始偏移为8，正好是2的倍数，无须添加额外字节。到此规则1的数据成员对齐结束，此时的内存状态为：

  ```cpp
  oxxx|oooo|oo
  0123 4567 89 （地址）
  （x表示额外添加的字节）
  ```

  共占10个字节，还要继续进行结构本身的对齐。对齐将按照#pragma pack指定的数值和结构(或联合)最大数据成员长度中，比较小的那个进行，st1结构中最大数据成员长度为int，占4字节，而默认的#pragma pack 指定的值为8，所以结果本身按照4字节对齐，结构总大小必须为4的倍数，需添加2个额外字节使结构的总大小为12 。此时的内存状态为：

  ```cpp
  oxxx|oooo|ooxx
  0123 4567 89ab  （地址）
  ```

  到此内存对齐结束，St1占用了12个字节而非7个字节。St2 的对齐方法和st1相同，st2结构体总大小为8。


- 拷贝构造函数为什么传引用

  因为调用拷贝构造函数是实参向形参传值，如果传进来的不是引用，那么就是值传递，那么就会在函数里又重新创建一个对象，而重新创建又是通过调用拷贝构造函数，所以如果不是引用的话，就会无穷递归地调用拷贝构造函数。另外调用拷贝构造函数时不需要消耗另外的内存空间。

- 如何在 main 函数之前执行一些操作

  在 C++ 中，可以使用静态变量（static variable）和全局变量（global variable）来在 `main` 函数之前执行一些操作。因为静态变量和全局变量的初始化顺序是在 `main` 函数之前的。 

  具体来说，可以定义一个全局变量或静态变量，将其初始化为一个函数指针，在其构造函数中执行需要在 `main` 函数之前执行的操作。当程序启动时，全局变量和静态变量的构造函数会自动执行，从而实现在 `main` 函数之前执行一些操作。 

  下面是一个示例代码，演示了如何在 `main` 函数之前执行一些操作：

  ```c++
  #include <iostream>
  using namespace std;
  class Init {
  public:
      Init() {
          cout << "Before main." << endl;
      }
  };
  Init init;
  int main() {
      cout << "In main." << endl;
      return 0;
  }
  ```

  在这个示例代码中，我们定义了一个 `Init` 类，将其实例化为一个全局变量 `init`，在其构造函数中输出一条消息。然后，我们定义了 `main` 函数，输出另一条消息。运行这个程序，输出结果如下：

  ```cpp
  Before main.
  In main.
  ```

  从输出结果可以看出，在 `main` 函数之前，全局变量 `init` 的构造函数已经执行了，输出了一条消息。这说明我们成功地在 `main` 函数之前执行了一些操作。

- STL中仿函数有什么用，和函数指针有什么不同，哪个效率高

  STL 中的仿函数（Functor）是一种重载了函数调用运算符 () 的类，它可以像函数一样被调用。仿函数可以作为函数对象传递给 STL 算法或容器，用于自定义排序、查找、统计等操作的比较规则或操作规则。与函数指针相比，仿函数具有更高的灵活性和可定制性，可以通过类的成员变量来保存状态，也可以通过模板参数来实现更加通用的操作。 与函数指针相比，仿函数有以下优点：

  1. 仿函数可以保存状态，因为仿函数是一个类，可以将需要保存的状态保存在类的成员变量中，这样就可以在连续调用中保留状态，而函数指针不能保存状态；
  2. 仿函数可以通过模板参数来实现更加通用的操作，因为仿函数可以定义多个重载的 operator() 函数，可以根据需要进行不同的操作，而函数指针只能指向一个函数；
  3. 仿函数可以使用函数对象适配器来适应不同的算法或容器，例如，可以使用 std::bind 和 std::function 来适配不同的参数列表或返回类型。 

  相比之下，仿函数的效率可能稍低于函数指针，因为仿函数是一个类，需要实例化对象，而函数指针只需要保存一个指针。但是，由于仿函数可以保存状态，因此在一些需要保存状态的场合，例如排序算法，仿函数比函数指针更加有效。此外，现代编译器对于使用仿函数进行的优化，可能会使其效率更高。

- 使用 map 不是基础数据类型需要重载什么运算符

  使用 `map` 存储自定义类型时，需要重载 `<` 运算符，以便 `map` 能够正确地进行排序和查找。因为 `map` 是一种关联容器，它的内部实现依赖于对元素的排序，而排序依赖于元素之间的比较。如果没有重载 `<` 运算符，编译器不知道如何比较两个元素的大小，也就无法对 `map` 进行正确的排序和查找。 

  下面是一个示例代码，演示了如何重载 `<` 运算符来实现 `map` 的自定义类型：

  ```c++
  #include <iostream>
  #include <map>
  using namespace std;
  class Person {
  public:
      Person(string name, int age) : m_name(name), m_age(age) {}
      string GetName() const { return m_name; }
      int GetAge() const { return m_age; }
  private:
      string m_name;
      int m_age;
  };
  bool operator<(const Person& lhs, const Person& rhs) {
      if (lhs.GetAge() < rhs.GetAge()) {
          return true;
      } else if (lhs.GetAge() == rhs.GetAge()) {
          return lhs.GetName() < rhs.GetName();
      } else {
          return false;
      }
  }
  int main() {
      map<Person, int> people;
      people[Person("Tom", 25)] = 1;
      people[Person("John", 30)] = 2;
      people[Person("Alice", 20)] = 3;
      for (const auto& p : people) {
          cout << p.first.GetName() << " " << p.first.GetAge() << " " << p.second << endl;
      }
      return 0;
  }
  ```

  在这个示例代码中，我们定义了一个 `Person` 类，包含了姓名和年龄两个成员变量。接着，我们重载了 `<` 运算符，按照年龄从小到大排序，如果年龄相等，则按照姓名从小到大排序。然后，我们定义了一个 `map` 对象 `people`，用于存储 `Person` 对象和一个整数。最后，我们遍历 `people` 对象，并输出每个 `Person` 对象的姓名、年龄和对应的整数。运行这个程序，输出结果如下：

  ```cpp
  Alice 20 3
  Tom 25 1
  John 30 2
  ```

  从输出结果可以看出，`map` 按照年龄从小到大排序，如果年龄相等，则按照姓名从小到大排序，这是由于我们重载了 `<` 运算符的缘故。

- 硬链接和软链接的区别

  硬链接（Hard Link）： 硬链接是指多个文件名指向同一个物理数据块，不同文件名的文件在文件系统中的 inode 号是相同的，它们占用的硬盘空间也是相同的。当其中一个文件被删除时，由于其它文件还指向同一个物理数据块，因此文件的数据不会被删除，只是将文件的链接数减 1，当链接数为 0 时才会真正删除文件数据。

  软链接（Symbolic Link）： 软链接是指类似于 Windows 中的快捷方式，它是一个特殊的文件，其中包含的是链接文件的路径。软链接与原文件是两个独立的文件，它们的 inode 号是不同的，占用的硬盘空间也不同。当原文件被删除时，软链接失效，因为它指向的文件已经不存在了。但是软链接本身不会被删除，如果需要删除软链接，需要使用 `rm` 命令。

  综上所述，硬链接和软链接的最大区别在于：硬链接是多个文件名指向同一份数据，它们之间是互相独立的，而软链接则是一个文件指向另一个文件，软链接本身是一个特殊的文件，它指向的文件删除后就失效了。

- explicit 的作用

  `explicit` 是 C++ 中的一个关键字，用于修饰单参构造函数或者转换函数，其作用是防止隐式转换，只能显式调用。

  举个例子，当我们在定义一个只有一个参数的构造函数时，有时候我们不希望这个构造函数被自动调用进行隐式转换，而是需要在使用的时候显式地调用它。这时候就可以使用 `explicit` 关键字进行修饰。 下面是一个示例代码，演示了 `explicit` 关键字的使用：

  ```c++
  class A {
  public:
      A(int i) : m_i(i) {}
  private:
      int m_i;
  };
  void fun(A a) {
      // do something
  }
  int main() {
      A a1 = 10; // ok，隐式转换
      A a2(10); // ok，显式构造
      fun(10); // error，不能隐式转换为 A 类型
      fun(A(10)); // ok，显式构造
      return 0;
  }
  ```

  在上面的示例中，我们定义了一个类 `A`，它有一个带有 `int` 类型参数的构造函数。如果我们没有在构造函数前面加上 `explicit` 关键字，那么在 `main` 函数中，我们可以用整型常量值 `10` 隐式地创建一个 `A` 类型的对象 `a1`。但是，如果我们在构造函数前面加上 `explicit` 关键字，则不能用整型常量值隐式地创建 `A` 类型的对象，必须显式地调用构造函数。

  同时，如果我们定义了一个函数 `fun`，它的参数是 `A` 类型的对象，如果我们没有在构造函数前面加上 `explicit` 关键字，则函数 `fun` 的参数可以隐式地将整型常量值 `10` 转换为 `A` 类型的对象，但是如果我们在构造函数前面加上 `explicit` 关键字，则不能进行隐式转换，必须显式地调用构造函数。

- sizeof 和 strlen的区别

  1. strlen是一个库函数，使用时需要引用#include<string.h>这个头文件，而sizeof是一个运算符号；
  2. strlen计算的是'\0'之前的字符个数，sizeof计算的是所占空间内存的大小，单位是字节；
  3. strlen计算时不包含'\0'，而sizeof包含'\0'，strlen遇到'\0'才结束；
  4. strlen计算字符串的具体长度 (只能是字符串)，不包括字符串结束符，返回的是字符个数。
  5. strlen的参数是指针类型，所以传过来的参数为指针才对。

- 一个函数的形参是数组，在函数内部调用 sizeof 和 strlen 分别得到什么答案

  ```cpp
  #include <stdio.h>
  int main() {
  	int a[] = { 1,2,3,4 };
  	printf("%d\n", sizeof(a));		// 计算整个数组的大小，结果是sizeof（int）*4 = 16
  	printf("%d\n", sizeof(a + 0));	// 代表首元素地址，地址分为32位和64位，32位占4个字节，64位占8个字节
  	printf("%d\n", sizeof(a + 1));	// +1代表指向第二个元素地址，也就是2的地址，结果是4或8
      printf("%d\n", sizeof(a[1]));	// a[1]代表第二个元素2，所以结果为4
  	printf("%d\n", sizeof(*a));		// a表示首元素地址，进行解引用以后就代表了第一个元素也就是1，所以结果是4
  	printf("%d\n", sizeof(&a));		// &a就是取出a整个数组的地址，但是它还是一个地址，结果为4或8
  	printf("%d\n", sizeof(*&a));	// &a取出了整个数组的地址，解引用以后代表的是整个数组，所以结果是16
  	printf("%d\n", sizeof(&a + 1));	// &a代表取出整个数组地址，再+1代表直接跨过这个数组到达2的地址位置。结果为4或8
  	printf("%d\n", sizeof(&a[0]));	// 表示取a[0]的地址，结果是4或8
  	printf("%d\n", sizeof(&a[0] + 1));	// 取出a[0]的地址再向后跨过一个整形到达第二个元素的地址，结果是4或8。
  	return 0;
  }
  ```

  ```cpp
  #include <stdio.h>
  int main() {
  	char arr[] = { "abcdef" };
  	printf("%d\n", sizeof(arr));	// 这里的arr数组里最后是有\0的，sizeof()会算上最后的\0，也就是6 + 1 = 7
  	return 0;
  }
  ```

  ```cpp
  #include <stdio.h>
  int main() {
  	char arr[] = { "abcdef" };
  	printf("%d\n", strlen(arr));	// arr表示数组首元素地址，而数组后面有字符串结束符‘\0’，而strlen计算本身并不包括'\0'，所以结果为6。
  	printf("%d\n", strlen(arr + 0));// arr+0表示首元素地址，结果为6
  	printf("%d\n", strlen(*arr));	// *arr表示首元素，但是strlen得接受地址，所以此条代码错误
  	printf("%d\n", strlen(arr[1]));	// arr[1]代表数组第二个元素，理由如上条，此条代码错误
  	printf("%d\n", strlen(&arr));	// &arr表示取出整个数组地址，但是传过去的值是首元素地址，所以结果为6。
  	printf("%d\n", strlen(&arr + 1));// &arr + 1表示越过arr数组到arr后面的地址空间，所以是随机值。
  	printf("%d\n", strlen(&arr[0] + 1)); // &arr[0]，表示区第一个元素的地址，+1代表往后走一个字节（因为是char类型），取到了第二个元素的地址，所以结果为5。
  	return 0;
  }
  ```

- 在主函数中对一个指向字符串的指针分别调用sizeof 和 strlen分别得到什么答案

  ```cpp
  #include <stdio.h>
  int main() {
  	char* p = "abcedf";
  	printf("%d\n", sizeof(p));		// p是指针，结果是4或8。
  	printf("%d\n", sizeof(p+1));	// p+1还是一个地址，结果为4或8
  	printf("%d\n", sizeof(*p));		// p是指向数组首元素的指针，*p指的就是‘a’，结果为1
  	printf("%d\n", sizeof(p[0]));	// p[0]相当于arr[0]，相当于*（p+0），指的还是‘a’，结果为1
  	printf("%d\n", sizeof(&p));		// p本身为指针，&p也还是一个地址，结果为4或8
  	printf("%d\n", sizeof(&p + 1));	// &p为地址，+1取出的是p后面那块内存空间的地址，结果为4或8
  	printf("%d\n", sizeof(&p[0] + 1));	// &p[0]取出的是首元素的地址，+1代表第二个元素的地址，结果为4或8
  	return 0;
  }
  ```

  ```cpp
  #include <stdio.h>
  int main() {
  	char* p = "abcdef";
  	printf("%d\n", strlen(p));		// p是一个指向'a'地址的指针，strlen（p）就相当于把'a'的地址作为参数，结果为6
  	printf("%d\n", strlen(p + 1));	// p + 1就是跳过一个char型指向'b'的地址，结果是5
  	printf("%d\n", strlen(*p));		// p是指向'a'地址的指针，*p获取的就是'a'，但是strlen的参数是指针，所以此条语句错误
  	printf("%d\n", strlen(p[0]));	// p[0] 相当于*（p + 0），取出来的就是'a'，词条语句错误
  	printf("%d\n", strlen(&p));		// 已知p是指向'a'地址的指针，此数组里有\0可以让strlen停下来。&p取出来的是p这个指针的地址，可是p里面存放了什么我们并不知道，所以是随机值
  	printf("%d\n", strlen(&p + 1));	// &p + 1指的是取到了p后面的地址空间，结果为随机值
  	printf("%d\n", strlen(&p[0] + 1));	// &p[0]取到的是'a'这个元素的地址，+1就跳过一个char型，取到'b'的地址，结果是5
  	return 0;
  }
  ```

- strcpy 与 memcpy 的区别

  1. 复制的内容不同。strcpy只能复制字符串，而memcpy可以复制任意内容，例如字符数组、整型、结构体、类等；
  2. 复制的方法不同。strcpy不需要指定长度，它遇到被复制字符的串结束符"\0"才结束，如果空间不够，就会引起内存溢出。memcpy则是根据其第3个参数决定复制的长度；
  3. 用途不同。通常在复制字符串时用strcpy，而需要复制其他类型数据时则一般用memcpy，由于字符串是以“\0”结尾的，所以对于在数据中包含“\0”的数据只能用memcpy；
  4. 从s1复制字符串到s2。strncpy和memcpy很相似，只不过它在一个终止的空字符处停止。当n>strlen(s1)时，给s2不够数的空间里填充“\0”（n为s2的空间大小）；当n<=strlen(s1)时，s2是没有结束符“\0”的，所以使用strncpy时，确保s2的最后一个字符是“\0”。

- 构造函数里面可以调用成员函数吗

  1. 构造函数调用成员函数的顺序应该在初始化列表中指定。因为初始化列表是在进入构造函数的主体之前执行的，所以成员函数调用必须放在初始化列表中。
  2. 在构造函数中调用成员函数时，需要注意成员变量的值是否已经初始化。如果成员变量的值还没有初始化，可能会导致成员函数调用出错。
  3. 如果成员函数是虚函数，那么在构造函数中调用虚函数是有风险的，因为在构造函数中，对象还没有完全构造完成，此时调用虚函数可能会导致不可预测的行为。 下面是一个示例代码，演示了如何在构造函数中调用成员函数：

  ```cpp
  class MyClass {
  public:
      MyClass(int value) : m_value(value) {
          m_data = new int[m_value];
          InitData();
      }
      ~MyClass() {
          delete[] m_data;
          m_data = nullptr;
      }
  private:
      int m_value;
      int* m_data;
      void InitData() {
          for (int i = 0; i < m_value; i++) {
              m_data[i] = i;
          }
      }
  };
  ```

  在这个示例代码中，我们定义了一个 MyClass 类，包含了一个构造函数和一个 InitData 成员函数。

  在构造函数中，我们首先使用初始化列表将 m_value 成员变量初始化，然后在构造函数主体中调用 new 操作符动态分配了一个数组，并将其赋值给 m_data 成员变量。接着，我们调用了 InitData 成员函数，用于初始化 m_data 数组中的值。

  在析构函数中，我们使用 delete[] 操作符释放了 m_data 数组所占用的内存。 需要注意的是，在构造函数中调用成员函数时，需要特别小心，确保成员变量的值已经被正确初始化。此外，在构造函数中调用虚函数是有风险的，请尽量避免这种情况的发生。

- 空指针和野指针的区别

  - 指向的地址为空的指针是空指针；
  - 指向的地址是不可知的、随机的、没有明确限制的指针是野指针；

  1. 指针未初始化；2. 指针越界访问；3. 指针指向的空间释放。

- 移动语义和移动构造函数

  引入右值引用的目的之一是实现移动语义。移动语义的引入是为了解决在进行大数据复制的时候，将动态申请的内存空间的所有权直接转让出去，不用进行大量的数据移动，既节省空间又提高效率。移动语义可能修改右值的值，所以，右值引用参数不能是const。

  通过复制构造函数来实现复制语义，通过移动构造函数来实现移动语义。复制构造使用const &引用，而移动构造函数使用非const && 引用，需要传入右值引用。

  被移动语义的数据交出了所有权，为了不出现析构两次同一数据区，要将交出所有权的数据的指向动态申请内存区的指针赋值为nullptr，即空指针，对空指针执行delete[]是合法的。

  移动构造函数：右值主要用来实现移动构造函数，资源给了新的移动构造函数的对象，移动构造函数只交换资源的所有权。也就是说，移动构造函数事实上做了一个浅拷贝，将右值的地址给调用了移动构造函数的对象，并将原来的指针置空。

  ```cpp
  class MyString {
  public:
      // 普通构造函数
      MyString(const char* str = nullptr) {
          if (str == nullptr) {
              m_data = new char[1];
              *m_data = '\0';
          } else {
              int len = strlen(str);
              m_data = new char[len+1];
              strcpy(m_data, str);
          }
      }
      // 移动构造函数
      MyString(MyString&& other) {
          m_data = other.m_data;
          other.m_data = nullptr;
      }
      // 析构函数
      ~MyString() {
          if (m_data != nullptr) {
              delete[] m_data;
              m_data = nullptr;
          }
      }
  private:
      char* m_data;
  };
  ```

  在这个示例代码中，我们定义了一个 MyString 类，包含了一个普通构造函数和一个移动构造函数。在移动构造函数中，我们将 other 对象的内部资源移动到了新对象中，并将 other.m_data 置为 nullptr，以避免析构函数重复释放内存。

  使用移动构造函数可以减少不必要的内存复制操作，提高程序的性能和效率。需要注意的是，在定义移动构造函数时，需要将源对象的指针置为 nullptr，以避免重复释放内存。

- STL容器的线程安全性

  线程安全的情况：

  - 多个读取者是安全的。多线程可能同时读取一个容器的内容，这将正确地执行。当然，在读取时不能有任何写入者操作这个容器；

  - 对不同容器的多个写入者是安全的，多线程可以同时写不同的容器；

  线程不安全的情况：

  - 在对同一个容器进行多线程的读写、写操作时；

  - 在每次调用容器的成员函数期间都要锁定该容器；

  - 在每个容器返回的迭代器（例如通过调用begin或end）的生存期之内都要锁定该容器；

  - 在每个在容器上调用的算法执行期间锁定该容器；

- 什么情况用栈什么情况用队列

  栈的应用：非常广泛，在CPU内部就有提供栈这个机制。主要用途：函数调用和返回，数字转字符，表达式求值，走迷宫等等。在CPU内部栈主要是用来进行子程序调用和返回，中断时数据保存和返回。在编程语言中：主要用来进行函数的调用和返回。可以说在计算机中，只要数据的保存满足先进后出的原理，都优先考虑使用栈，所以栈是计算机中不可缺的机制。

  队列的应用：队列主要用在和时间有关的地方，特别是操作系统中，队列是实现多任务的重要机制。windows中的消息机制就是通过队列来实现的。进程调度也是使用队列来实现，所以队列也是一个重要的机制，只要满足数据的先进先出原理就可以使用队列。

- 函数重载，变量前有无const是否可以重载

  fun(int i) 和 fun(const int i)，不能重载。二者是一样的，是因为函数调用中存在实参和形参的结合。假如我们用的实参是 int a，那么这两个函数都不会改变 a 的值，这两个函数对于 a 来说是没有任何区别的，所以不能通过编译，提示重定义。

  fun(char *a) 和 fun(const char *a)，可以重载。因为 char *a 中 a 指向的是一个字符串变量，而 const char *a 指向的是一个字符串常量，所以当参数为字符串常量时，调用第二个函数，而当函数是字符串变量时，调用第一个函数。

  fun(char *a) 和fun(char * const a) ，不能重载。这两个都是指向字符串变量，不同的是 char *a 是指针变量 而 char const *a 是指针常量，这就和 int i 和 const int i 的关系一样了，所以也会提示重定义。

  int &i 和const int & i 也是可以重载的。对于引用，比如 int &i 和 const int & i 也是可以重载的，原因是第一个 i 引用的是一个变量，而第二个i引用的是一个常量，两者是不一样的，类似于上面指向变量的指针和指向常量的指针。

- 一个类对象数据的初始化顺序

  一个类对象的数据初始化顺序是先调用基类的构造函数，然后按照派生类中非静态成员变量的定义顺序依次初始化这些成员变量，最后调用派生类的构造函数。需要注意的是，静态成员变量的初始化是在程序启动时进行的，不属于类对象的初始化顺序。

  总之，一个类对象的数据初始化顺序遵循基类构造函数先于派生类构造函数，派生类中非静态成员变量按照定义顺序初始化的规则。

- volatile 能保证线程安全吗，不能的话怎么解决

  volatile 关键字是 C/C++ 中的一个类型修饰符，用于告诉编译器一个变量是易变的，需要在每次访问时重新读取。但是，volatile 关键字不能保证线程安全，因为它只能保证变量在多线程或多进程环境下的可见性，而不能保证原子性和有序性，因此在并发环境下使用 volatile 关键字仍然存在数据竞争和死锁等问题。

  为了解决线程安全问题，可以使用互斥锁、条件变量、原子操作等方法来保证数据的原子性和有序性，避免数据竞争和死锁问题。互斥锁是一种常用的线程同步机制，可以保证在同一时刻只有一个线程可以访问共享资源，从而避免数据竞争问题。条件变量可以用来等待共享资源的状态改变，原子操作可以保证对共享变量的操作是不可分割的，从而避免数据竞争和死锁问题。

  总之，volatile 关键字不能保证线程安全，需要采用其他的线程同步机制来保证数据的原子性和有序性，避免数据竞争和死锁问题。

- struct 和 union 区别

  struct 和 union 都是 C/C++ 中的数据类型，它们的主要区别在于存储方式和内存使用方式：

  struct 是一种自定义的数据类型，可以包含多个不同类型的成员变量，每个成员变量占用独立的内存空间，结构体的大小等于所有成员变量的大小之和，不同成员变量之间没有关联。

  union：union 也是一种自定义的数据类型，可以包含多个不同类型的成员变量，但只有一个成员变量可以被赋值和访问，不同成员变量共享同一块内存空间，共用一个内存地址，结构体的大小等于最大的成员变量的大小。因此，union 可以节省内存空间，但存在数据安全问题，因为不同的成员变量共用同一块内存空间，修改一个成员变量的值可能会影响其他成员变量的值，而 struct 没有这个问题。 

- 头文件中 #ifdef，#endif 有什么作用

  避免头文件被重复引用。在一个大型软件工程编写code，可能会有多个文件同时包含一个头文件，当这些文件编译链接成一个可执行文件时，就会出现大量重定义的错误。在头文件中实用#ifndef #define #endif能避免头文件的重定义。

  如编写头文件ArrayList.h，在头文件开头写上两行：

  ```cpp
  #ifndef _Array_List_h
  #define ArrayList.h //一般是文件名的大写
  ```

  头文件结尾写上一行：#endif，这样一个工程文件里同时包含两个ArrayList.h时，就不会出现重定义的错误了。

  分析：当第一次包含ArrayList.h时，由于没有定义_Array_List_h，条件为真，这样就会包含（执行）#ifndef _Array_List_h和#endif之间的代码，当第二次包含test.h时前面一次已经定义了_Array_List_h，条件为假，#ifndef _Array_List_h和#endif之间的代码也就不会再次被包含，这样就避免了重定义了。主要用于防止重复定义宏和重复包含头文件。

- 模板的编译过程，模板是什么时候实例化的

  模板是 C++ 中的一种特殊的类型，它的编译过程和普通的函数或类的编译过程有所不同。模板的编译分为两个阶段：声明和实例化。

  声明阶段：在源代码中定义模板时，编译器只会对模板进行语法和类型检查，不会生成任何代码。在编译器遇到使用模板的语句时，只会对模板进行简单的语法检查，然后将其标记为待实例化。

  实例化阶段：当编译器需要生成实际的代码时，会根据使用模板的具体情况实例化模板。也就是说，模板是在使用时才进行实例化。实例化的过程包括将模板中的类型参数替换为具体的类型，生成对应的代码，并进行编译和链接，生成可执行文件。

   总之，模板的编译过程分为声明阶段和实例化阶段。模板只有在使用时才会进行实例化，根据具体的类型参数生成对应的代码。

- #include<> 和 #include"" 的区别

  1. 引用的头文件不同。#include< >引用的是编译器的类库路径里面的头文件；#include“ ”引用的是你程序目录的相对路径中的头文件。
  2. 用法不同。#include< >用来包含标准头文件(例如stdio.h或stdlib.h)；#include“ ”用来包含非标准头文件。
  3. 调用文件的顺序不同。#include< >编译程序会先到标准函数库中调用文件；#include“ ”编译程序会先从当前目录中调用文件。
  4. 预处理程序的指示不同。#include< >指示预处理程序到预定义的缺省路径下寻找文件；#include“ ”指示预处理程序先到当前目录下寻找文件，再到预定义的缺省路径下寻找文件。



- unique_ptr如何实现独占对象

  unique_ptr实现独占对象的关键在于禁止复制和移动操作，只允许通过move函数进行所有权的转移。

  具体实现方式如下：

  1. 禁止复制构造函数和复制赋值运算符

  在类的定义中声明为私有，并不提供实现。这样可以防止其他代码通过复制操作来获取对象的所有权，确保对象只能被一个unique_ptr实例所拥有。

  2. 实现移动构造函数和移动赋值运算符

  移动构造函数和移动赋值运算符可以通过std::move函数将对象的所有权转移给另一个unique_ptr实例。在转移所有权后，原来的unique_ptr实例将不再拥有对象的所有权，避免了资源的重复释放。

  3. 在析构函数中释放资源

  unique_ptr的析构函数会自动调用对象的析构函数，并释放资源。由于unique_ptr只能拥有一个对象的所有权，因此在析构函数中只需要释放一次资源，避免了资源的重复释放。

  总之，unique_ptr通过禁止复制和移动操作，以及在析构函数中释放资源的方式，实现了独占对象的功能。

- memove和memcpy有什么区别

  memmove和memcpy是C++中的两个函数，它们的作用都是复制内存区块，但是它们有以下区别：

  1. 目标内存区域与源内存区域重叠时，memmove可以正确处理，而memcpy则不能。

  2. memmove的复制过程是从前往后进行，即使目标内存区域在源内存区域的后面，也是先将前面的数据复制过去，再将后面的数据复制过去。而memcpy则没有这个限制，可以从前往后复制，也可以从后往前复制。

  3. memmove的复制速度通常比memcpy慢，因为它要判断内存区域是否重叠，而memcpy则没有这个开销。

  总的来说，如果目标内存区域与源内存区域可能会重叠，应该使用memmove，否则使用memcpy。

- free 和 delete 的区别

  `free`和`delete`都可以用于释放动态分配的内存，但它们之间有几个重要的区别：

  1. 动态分配方式不同：`new`和`malloc`是不同的内存分配方式，对应的释放操作也不同。`delete`用于释放使用`new`分配的内存，`free`用于释放使用`malloc`分配的内存。

  2. 对象销毁方式不同：`delete`操作除了释放内存以外，还会自动调用对象的析构函数，从而保证对象被正确销毁；而`free`只会释放内存，不会调用任何对象的析构函数。

  3. 参数类型不同：`free`仅接受`void*`类型的指针作为参数，而`delete`需要传入指向动态分配的对象的指针。

  4. 风险不同：使用`delete`可避免出现忘记释放内存的情况，因为`delete`的语义已经包含了释放内存的操作。而`free`则需要程序员显式地调用才能释放内存，容易出现遗漏的情况，从而引发内存泄漏等问题。

  因此，在C++中，应该优先使用`new/delete`，而不是使用`malloc/free`。不过，对于C语言开发者来说，由于`new/delete`是C++特有的操作符，因此在C项目中还是需要使用`malloc/free`来分配和释放内存。

- char*p和char p[]的区别，用sizeof去计算上述指针和数组的区别

  `char* p`和`char p[]`都是指向字符型数据的指针，但它们定义的方式不同。`char* p`是一个指针变量，用于存储一个字符型数据的地址；而`char p[]`是一个数组变量，用于存储一段连续的字符型数据。

  在C/C++中，使用`sizeof`操作符可以返回一个类型或变量占用的字节数。对于指针变量`char* p`，`sizeof(p)`返回的是该指针本身所占用的字节大小，通常为4或8字节（取决于平台），而不是它所指向的字符串的长度。而对于字符数组`char p[]`，`sizeof(p)`返回的是该数组占用的字节大小，等于数组元素数量乘以每个元素所占的字节数，即`sizeof(char) = 1`，因此`sizeof(p)`等于数组长度乘以1。

  具体来说，`sizeof(char*)`返回的值（通常为4或8）是指针变量所占用的字节数，而不是其指向的字符串的长度；而`sizeof(char[])`返回的值是数组所占用的字节数，等于数组长度乘以每个元素的字节数。例如：

  ```cpp
  char* p = "hello";
  char str[] = "world";
  cout << sizeof(p) << endl;   // 输出8
  cout << sizeof(str) << endl; // 输出6
  ```

  这里，`sizeof(p)`返回了指针变量`p`所占用的字节数，而`sizeof(str)`返回了数组变量`str`所占用的字节数，由于`str`是一个长度为5的字符数组，因此`sizeof(str)`返回6。

  总之，`char* p`和`char p[]`虽然都可以指向字符型数据，但它们的定义方式和sizeof返回值是不同的。因此，我们在使用时需要注意到它们之间的区别。

- 如何让类不能被继承

  在C++中，可以通过声明一个类为`final`来防止其被继承。使用`final`关键字修饰的类称为最终类（或密封类），这些类不能再被其他类所继承。

  例如，下面的代码定义了一个最终类`MyClass`：

  ```c++
  class MyClass final {
    // 类定义
  };
  ```

  在这个例子中，`final`关键字用于修饰类`MyClass`，表示该类不能再被其他类所继承。

  需要注意的是，`final`只能用于类的声明中，而不能用于类的定义中。同时，如果一个类被声明为最终类，那么它的成员函数也都将自动成为最终函数，不能被派生类覆盖。

  除了使用`final`关键字，还可以通过将类的构造函数声明为`private`来实现类无法被继承。由于不能在派生类中访问基类的私有成员，因此这样定义的类无法被继承。例如：

  ```c++
  class MyClass {
  private:
    MyClass() {}  // 将构造函数声明为私有，防止类被继承
    friend class SomeFriend; // 友元类可以调用私有构造函数
  };
  
  // 不能继承MyClass，因为其构造函数是私有的
  class MyDerived : public MyClass {
    // 类定义
  };
  ```

  在这个例子中，`MyClass`的构造函数被声明为私有，在`MyDerived`中无法访问到该构造函数，因此`MyDerived`无法继承`MyClass`。

  总之，可以通过将类声明为`final`、将构造函数声明为`private`等方式来实现类不能被继承。选择哪种方式取决于具体的要求和场景。

- 如何禁止构造函数的使用

  有两种方法可以禁止构造函数的使用：

  1. 将构造函数声明为私有（private）或受保护（protected），这样就无法从外部访问和调用构造函数。例如：

  ```cpp
  class MyClass {
  private:
      MyClass() {}
  };
  ```

  在这个例子中，将`MyClass`的构造函数声明为`private`，这样在类的外部就无法调用构造函数来创建对象。

  2. 继承一个不可复制（uncopyable）的基类。不可复制的基类中包含了私有的构造函数和赋值运算符，并将它们声明为`delete`，以防止任何尝试复制该类的操作。例如：

  ```cpp
  class Uncopyable {
  protected:
      Uncopyable() {}
      ~Uncopyable() {}
  
  private:
      Uncopyable(const Uncopyable&) = delete;
      Uncopyable& operator=(const Uncopyable&) = delete;
  };
  
  class MyClass : private Uncopyable {
  public:
      // ...
  };
  ```

  在这个例子中，`MyClass`继承了`Uncopyable`类，因此在编译期间会检测到任何尝试复制或移动`MyClass`对象的操作，并报告编译错误。

  总之，以上两种方法都可以禁止构造函数的使用，具体取决于需要实现的场景。

- 什么是野指针，怎么检测

  野指针是指指向无效内存地址的指针。这通常发生在指针被释放或初始化之前，或者指针指向的对象已经被销毁或移动了。当程序访问野指针时，可能会导致程序崩溃、数据损坏、安全漏洞等问题。

  检测野指针可以通过以下方法：

  1. 编译器选项：现代编译器通常提供一些开关来检测野指针，如gcc的"-Wuninitialized"选项可以检测未初始化的变量和指针。

  2. 静态分析工具：静态分析工具可以扫描代码并检测潜在的野指针问题。例如，Clang Static Analyzer、Coverity等工具都提供了野指针的检测功能。

  3. 动态调试工具：动态调试工具可以在程序运行时检测野指针。例如，Valgrind是一款常用的动态调试工具，可以检测内存泄漏、野指针等问题。

  总之，尽可能避免野指针的出现是最好的方法，可以通过合理的内存管理、指针初始化等方式来减少野指针问题的发生。

- 如果多重继承，只有一个虚表指针吗

  在多重继承情况下，一个子类会继承来自多个父类的成员和方法，这些父类中可能都有虚函数。因此，在这种情况下，每个父类都有自己的虚函数表，而一个子类也会有对应数量的虚函数表指针。具体来说，如果一个子类中继承了n个父类，则存在n个指向虚函数表的指针。

  虚函数表指针的数量等于子类的直接父类的数量加上1，其中这1个指针指向子类自己的虚函数表。还需要注意的是，虚函数表指针的顺序与直接父类在声明时的顺序相同，即先声明的父类的虚函数表指针排在前面。

  请注意，在一些操作系统或编译器的实现中，虚函数表和虚函数表指针的布局有所不同，但通常都会遵循上述原则。

- 在一台内存为 2G 的机器上，使用 malloc 分配 20G 会发生什么，new 20G 呢

  在一台内存为2G的机器上，使用malloc分配20GB内存会导致分配失败，因为需要的内存空间已经超出了可用的物理内存大小，malloc会返回NULL指针，表明分配失败。

  而对于new操作符，如果使用的是标准的C++库，那么在同样的情况下也无法成功分配20GB内存，它会抛出std::bad_alloc异常。但是，某些实现可能会尝试通过申请虚拟内存来满足请求，这可能会导致系统变得非常慢，甚至崩溃。

  需要注意的是，即使内存分配成功了，也要确保能够在程序中正确和及时地释放这些内存，否则可能导致内存泄漏等问题。通常情况下，应该在动态分配内存后，及时释放不再需要的内存，以便其他程序可以使用这些内存空间。

  总之，为了避免这种情况的发生，应该在编写程序时仔细估计所需的内存量，并尽可能地避免过多地申请内存空间。另外，在分配内存之前，还可以通过查询可用内存或进行内存回收等操作来提高系统可用内存的效率。

- 一台只有 2G 物理内存的电脑，能否 new 一个 4G 大小的数组

  在一台只有2GB物理内存的电脑上，不能直接使用new操作符分配4GB大小的数组。因为，可用的物理内存不足以支持这个请求。

  无论在操作系统还是在程序设计中，都有一些额外的开销和内存占用，如堆栈、堆空间等。安全起见，操作系统通常会保留一部分可用内存而不供分配，这被称为“保留空间”。在C++的标准库和操作系统中，都会对new操作符的使用进行限制，以避免内存泄漏等问题。

  因此，在申请内存时，需要确保所需内存空间不超过系统可用的最大值。如果所需内存空间超出了系统的最大限制，则应该将内存需求重新定义为可行的范围内，或者考虑使用其他解决方案，如文件映射。

  综上所述，如果想要在只有2G物理内存的电脑上使用4G大小的数组，可以考虑使用文件映射或增加系统的物理内存。

- 1G 的物理内存可以读取 2G 的数据吗

  在一台只有1G的物理内存的计算机上，尝试读取2G的数据是不可行的。

  在计算机中，数据需要被加载到内存中才能被处理。如果要处理的数据量超过了系统可用的内存大小，CPU就无法将这些数据全部装入内存，因此无法处理。

  当需要读取较大的文件或处理大型数据集时，可以考虑使用基于磁盘或云存储的流式处理方式，将文件或数据集分成较小的块，逐个块地读入并处理，以避免需要一次性读取整个数据集的情况。

  另外，在程序设计中，也可以对数据进行压缩等操作，以减少所需内存空间和读取数据的时间和开销。

- 一般程序中栈大小多少

  栈大小在不同的操作系统和编译器下可能有所不同。在大多数操作系统中，每个线程都有自己的栈，操作系统会为每个线程分配一定大小的栈空间。在Windows系统下，默认的栈大小为1MB，而在Linux系统下，栈大小通常为8MB。在编写程序时，如果使用了递归、大量的局部变量或者过多的函数嵌套等操作，可能会导致栈溢出。因此，在编写程序时需要注意控制栈的大小，避免出现栈溢出的情况。

- 全局变量定义在头文件中有什么问题

  在头文件中定义全局变量可能会导致重复定义错误。因为当多个C++源文件包含同一个头文件时，其中的全局变量会在每个源文件中都被定义一次。

  例如，在头文件`globals.h`中定义了一个全局变量`int x = 0;`，并在C++源文件`file1.cpp`和`file2.cpp`中分别包含`globals.h`头文件进行编译。则在编译时，由于`globals.h`被包含了两次，全局变量`x`也被定义了两次，这将导致重复定义错误。

  为避免这种错误，通常建议在头文件中使用`extern`关键字声明全局变量，并在一个C++源文件中定义它。例如，在`globals.h`头文件中可以声明`extern int x;`，而在`globals.cpp`源文件中定义`int x = 0;`。这样，任何需要使用全局变量`x`的源文件只需要包含`globals.h`头文件即可。

  总之，尽管在C++中允许在头文件中定义全局变量，但为了避免重复定义错误，通常应该在头文件中使用`extern`关键字声明全局变量，并在一个源文件中定义它。

- 如果禁止类实例化时候的动态分配方式

  如果要禁止类实例化时的动态分配方式，可以将类的构造函数声明为私有，并提供一个静态成员函数来创建类的对象。由于构造函数是私有的，类的对象只能通过该静态成员函数来创建，从而限制了动态分配方式。

  下面是一个示例代码：

  ```cpp
  class MyClass {
  private:
      MyClass() {}  // 将构造函数声明为私有
  
  public:
      static MyClass createInstance() {
          return MyClass();  // 静态成员函数来创建对象
      }
  };
  
  int main() {
      //MyClass* ptr = new MyClass();  // 错误：无法动态分配对象
      MyClass obj = MyClass::createInstance();  // 用静态成员函数创建对象
      return 0;
  }
  ```

  在这个例子中，将`MyClass`的构造函数声明为`private`，这样就无法在类的外部通过`new`运算符来动态分配内存以创建对象。但是通过提供一个公共的静态成员函数`createInstance()`，可以在类的外部调用该函数来创建对象，从而避免了动态分配对象的问题。

  需要注意的一点是，尽管这种方法可以禁止动态分配对象，但仍然可以使用栈空间和全局变量等方式来创建对象。因此，如果需要确保对象不被任何方式所创建，可以考虑将类的构造函数声明为`private`并删除该类的拷贝构造函数和赋值运算符重载函数。

- define 和 typedef 区别

  1. 定义方式不同：`define`使用预处理指令，`typedef`使用类型定义关键字。
  2. 定义对象不同：`define`用于定义常量，`typedef`用于定义类型别名。
  3. 使用方式不同：`define`是在编译前进行替换，`typedef`是在编译时进行类型定义。
  4. 作用范围不同：`define`作用于整个文件，`typedef`作用于当前作用域。
  5. 可读性不同：`typedef`定义的类型别名更加直观易懂。

- sizeof(1==1) 在 C 和 C++ 中分别是什么结果

  在 C 和 C++ 中，`sizeof(1==1)` 的结果分别是1和4。

  在C语言中，表达式`1==1`的值为真，即1，所以`sizeof(1==1)`等同于`sizeof(1)`。因为1是int型字面量，占用4个字节，所以`sizeof(1==1)`的结果是4。

  而在C++语言中，`1==1` 是一个bool 类型的表达式，因此 `sizeof(1==1)` 等价于 `sizeof(bool)`，即布尔类型所占用的字节数，通常是1。

  需要注意的是，C++11之后可以使用`sizeof...(parameter_pack)`获取可变参数模板中可变参数的数量。例如`sizeof...(args)`表示参数包`args`中元素的数量。但是，请注意这种用法不同于上面的问题。

- c++ 有哪些创建线程的方法？

  C++创建线程的方法有：

  1. 使用标准库的thread类，通过创建对象来创建线程。

  2. 使用POSIX线程库，通过pthread_create()函数来创建线程。

  3. 使用Windows API，通过CreateThread()函数来创建线程。

  4. 使用Boost库，通过boost::thread类来创建线程。

  5. 使用Qt框架，通过QThread类来创建线程。

  6. 使用OpenMP并行编程，通过#pragma omp parallel指令来创建线程。

  7. 使用CUDA并行编程，通过kernel函数启动线程。

  8. 使用OpenCL并行编程，通过clEnqueueNDRangeKernel()函数启动线程。

  以上是常见的创建线程的方法，具体选择哪种方法，可以根据实际情况和需要来选择。

- const int i=1024 char *str =”"hello" 在全局范围和局部范围声明时在内存的分布情况

  在全局范围中声明`const int i=1024`和`const char *str ="hello"`时，它们会被分配在静态存储区，通常是可执行文件的数据段或者BSS段。具体分布情况取决于编译器的实现和链接器的策略。

  其中`const int i=1024`会被编译器视为常量，也就是只读数据，存储在数据段中，它的初始值为1024，且不能被修改。

  而`const char *str ="hello"`声明了一个指向字符串常量的指针。在全局范围中，该指针将存储在数据段中，而字符串常量"hello"将存储在只读数据段中。

  在局部范围中声明`const int i=1024`和`const char *str ="hello"`时，它们会进入栈空间。`i`被存储在栈帧中，并初始化为1024。因为它是一个常量，所以无法修改。而`str`是一个指向字符串常量的指针，它也被存储在栈帧中。但是，其指向的字符串常量"hello"所在的内存区域在栈帧之外。

  总结来说，不论是全局还是局部范围，常量`i`的内存分布都与变量类型有关，在可执行文件的数据段或BSS段，或栈空间中存储其初始值。指针`str`的值表示其指向的内存地址，因此在局部范围中时，指向的字符串常量存储在只读数据段中，而在全局范围中时，指向的字符串常量和指针本身都存储在数据段中。

- int i=1024 static int i=1024 在全局声明使用的区别和局部声明的区别

  全局声明时，`int i=1024`将会被存储在全局数据区中，而且是可读可写的。在程序运行期间，该变量一直存在，知道程序结束才被销毁。可以通过其他文件中的 `extern int i;` 引用该变量。

  而`static int i=1024`将会被存储在全局数据区中，并且只能在声明它的源文件中访问到。其他文件无法使用`extern int i;`来引用该变量。使用`static`修饰全局变量的主要目的是为了隐藏其实现细节，防止外部代码修改其值。

  在局部声明时，`int i=1024`将会被分配在栈空间中，而且是可读可写的。在程序运行期间，该变量所占用的栈空间会随着函数执行完毕而被释放。

  而`static int i=1024`将会被分配在数据段(或者BSS段)中，而且只会在第一次调用该函数时被赋值，并且该值在函数执行期间保持不变。如果下次再调用该函数，该变量将保留上一次执行后的值，而不是重新初始化。因此，在多次调用同一个函数时，静态变量的值会一直存在。还需要注意的是，由于静态变量的生命周期跨越函数调用，因此必须确保其初始值为常量或可行的动态计算值（例如使用常量表达式来初始化）。

  总体而言，`static`关键字用于声明具有静态存储期的实体，可以通过修改链接属性和作用域来影响变量的可见性和访问方法。

- 函数模板和类模板的区别？

  函数模板和类模板的区别主要有以下几点：

  1. 定义方式不同：函数模板以关键字“template”开头，后跟模板参数列表和函数定义；类模板以关键字“template”开头，后跟模板参数列表和类定义。

  2. 使用方式不同：函数模板可以根据实参的类型自动推导模板参数类型，也可以手动指定模板参数类型；类模板必须显式指定模板参数类型。

  3. 模板参数列表的位置不同：函数模板的模板参数列表位于函数定义的前面，类模板的模板参数列表位于类定义的前面。

  4. 模板参数的作用域不同：函数模板的模板参数作用域仅限于函数体内，类模板的模板参数作用域覆盖整个类的作用域。

- c++ 下的可执行文件和 linux 下的可执行文件是什么后缀？

  在C++中，可执行文件的后缀名通常为`.exe`或者`.out`，具体使用哪种后缀名视情况而定。在Windows系统中，`.exe`是最常见的可执行文件后缀名；而在Linux系统中，由于历史原因，`.out`是最常见的可执行文件后缀名。

  需要注意的是，C++编译器生成的可执行文件不仅仅包含了程序的代码，还包括了解释程序如何运行所需的元数据（如入口地址、依赖库等）。因此，在将可执行文件从一个操作系统迁移到另一个操作系统时，很可能需要重新编译程序，以生成针对目标操作系统的可执行文件。

  另外，由于可执行文件的后缀名并不是固定的，因此无法通过后缀名来确定文件是否是可执行文件。Linux系统下一般会使用`file`命令来检查文件类型，例如：

  ```cpp
  $ file myprogram.out
  myprogram.out: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, for GNU/Linux 3.2.0, not stripped
  ```

  上述命令检查了`myprogram.out`文件的类型，输出结果显示该文件是一个ELF格式的可执行文件，针对x86-64架构，可以在Linux系统上运行。

- c++11 中可以用什么特性替换单例模式中的 static 写法？

  在C++11标准中，可以使用局部静态变量（local static variable）来替代单例模式中的静态变量写法。这种实现方法也被称为"Meyers Singleton"，它具有如下特点：

  1. 只有在第一次访问单例对象时才会创建该对象，避免了懒汉式单例中可能存在的线程安全问题；
  2. 局部静态变量在多线程环境下自动初始化，并且保证了初始化过程的线程安全性。

  下面是一个使用局部静态变量实现的单例类的示例代码：

  ```c++
  class Singleton {
  public:
      static Singleton& getInstance() {
          static Singleton instance; // 局部静态变量，只在首次调用时初始化
          return instance;
      }
  
      void doSomething() {
          // ...
      }
  
  private:
      Singleton() = default;
      ~Singleton() = default;
      Singleton(const Singleton&) = delete;
      Singleton& operator=(const Singleton&) = delete;
  };
  ```

  在上述代码中，`getInstance()`函数返回一个引用类型的`Singleton`对象，其中`instance`是一个局部静态变量，只在第一次调用时初始化。由于局部静态变量的初始化过程是线程安全的，因此这种实现方式避免了懒汉式单例中可能存在的线程安全问题。同时，该实现方式也避免了饿汉式单例中可能存在的静态初始化顺序问题。

  需要注意的是，为了防止单例被复制或移动，上述代码将拷贝构造函数和赋值运算符声明为删除函数。此外，为了防止单例在程序结束前被销毁，通常将析构函数声明为`default`以使用默认行为。

- sizeof(vector)多大

  在C++中，`vector`是一个模板类，包含两个模板参数：元素类型和分配器类型。因此，在求取`sizeof(vector)`的值时需要先确定`vector`的模板参数。

  假设我们定义了一个`vector<int>`类型的对象`vec`，则`sizeof(vec)`的大小等于该`vector`对象的存储空间大小，包括其所有成员变量和分配内存所占据的空间。具体而言，`sizeof(vec)`的值等于:

  ```cpp
  sizeof(vector<int>) * n
  ```

  其中，`n`为`vec`中元素的个数。对于`vector<int>`来说，它包含了一个指针（指向分配的动态内存）、一个表示已使用的元素个数的计数器以及几个其他控制数据。在一些实现中，还可能包含分配器对象和其它成员函数指针等数据。通常而言，`vector`对象的总大小至少为3个指针大小。

  举个例子，如果我们创建了一个包含3个`int`类型的元素的`vector`对象，则`sizeof(vec)`的大小应该为`3*sizeof(int) + 3*sizeof(void*)`，其中`sizeof(int)`为`4`字节（假设`int`类型占据4个字节）。

  需要注意的是，`vector`对象本身的大小与其所包含的元素个数无关，而是由其成员变量和分配内存所占据的空间决定的。例如，即使一个空的`vector`对象也会占用一定的存储空间（通常为3个指针大小），因为它需要存储指向分配内存的指针以及表示已使用元素数量的计数器等数据。

- dynamic_cast的作用，编译器如何打开这个功能（RTII），如果编译器关闭了运行期类型识别，自己如何实现dynamic_cast

  `dynamic_cast`运算符的主要作用是将基类指针或引用安全地转换为派生类指针或引用，以便调用派生类的非虚函数，或者在基类指针或引用调用派生类的虚函数时获得正确的行为。它可以检查类型是否兼容，并在不合适的情况下返回空指针或引发`std::bad_cast`异常。

  在默认情况下，大多数编译器都会启用运行期类型识别（RTTI），这使得`dynamic_cast`可以正常工作。如果编译器关闭了RTTI功能，则`dynamic_cast`将无法使用。要打开RTTI功能，可以使用不同的编译器选项。例如，在gcc编译器中，可以通过设置`-frtti`选项来启用RTTI。

  如果编译器没有启用RTTI，我们可以尝试手动实现`dynamic_cast`的功能。一种可行的方法是使用`static_cast`操作符进行类型转换，并在转换后进行类型检查。例如，假设我们有以下代码：

  ```cpp
  class Base {
     // ...
  };
  
  class Derived : public Base {
     // ...
  };
  
  Base* basePtr = new Derived;
  Derived* derivedPtr = static_cast<Derived*>(basePtr);
  
  if (derivedPtr) {
     // 操作Derived指针
  }
  else {
     // 转换失败，basePtr不是指向Derived类型的对象
  }
  ```

  在上面的代码中，我们首先将`Base*`指针`basePtr`强制转换为`Derived*`类型的指针，并将结果存储在`derivedPtr`中。然后，我们检查`derivedPtr`是否为空，以确定转换是否成功。如果转换成功，我们就可以使用`derivedPtr`指向的`Derived`对象进行操作。否则，如果转换失败，我们就需要处理错误。

  需要注意的是，使用`static_cast`进行类型转换并不总是安全的，因为它无法检查类型是否匹配。因此，在进行转换之前，必须明确知道转换后的类型，并且确保该类型是由传递给`static_cast`的指针或引用实际继承而来的。如果存在任何不确定性，最好使用`dynamic_cast`运算符进行类型转换，以确保类型安全。

- g++如何链接动态库，如何生成动态库，库和二进制文件分别在哪些目录

  1. 链接动态库：

  在编译时使用`-l`选项指定动态库的名称，同时使用`-L`选项指定动态库所在的目录。例如，链接名为`libexample.so`的动态库，可以使用以下命令：

  ```
  g++ main.cpp -o main -l example -L /path/to/lib/
  ```

  2. 生成动态库：

  使用`-shared`选项生成动态库，例如：

  ```
  g++ -shared -o libexample.so example.cpp
  ```

  3. 库和二进制文件分别在哪些目录：

  一般情况下，库文件会被安装到`/usr/lib`或`/usr/local/lib`目录下，而二进制文件则被安装到`/usr/bin`或`/usr/local/bin`目录下。但是在开发过程中，库和二进制文件可以放在任何目录下，只需要在编译时使用`-L`选项指定库所在的目录即可。

- 如果我 new 了一个内存，然后在 delete 之前这个进程被系统杀死了，那这样是内存泄露吗？

  是的，如果程序在使用 `new` 动态分配内存后，未使用 `delete` 释放该内存，并且进程在释放该内存之前被系统杀死，那么这就是一种内存泄漏现象。因为当进程被杀死时，它占用的所有内存都被操作系统回收，但由于该内存未被释放，因此操作系统无法回收这部分内存，导致内存泄漏。

  内存泄漏是一种非常严重的问题，可能导致内存资源的耗尽和程序运行效率的降低。为了避免内存泄漏，我们需要在程序中养成良好的内存管理习惯，及时释放不再使用的内存空间，从而提高程序的稳定性和可靠性。

- vector的push_back操作的时间复杂度

  vector的push_back操作的时间复杂度为O(1)（摊还时间复杂度）。这是因为vector采用的是连续的内存空间，当向vector的末尾添加元素时，只需要在已分配的内存空间最后一个位置插入元素即可，时间复杂度为常数级别。但是，当vector的内存空间不足时，需要重新分配更大的内存空间并将原有元素复制到新的内存空间中，此时的时间复杂度为O(n)。但是，由于这种情况出现的概率很小，因此可以将其视为摊还时间复杂度为O(1)。



# 计网

- osi 七层和五层，合并在哪

  七层模型：

  - 物理层：利用传输介质（双绞线、光纤、wifi-电磁波）为数据链路层提供物理连接，实现比特流的透明传输，可靠的物理型号：0和1—通过网卡（MAC地址）定位电脑

  - 数据链路层：将IP数据报组装成帧，控制信息在相邻两节点的链路上进行传输—局域网内部，提供了通讯过程中要用到的MAC地址（物理地址）

  - 网络层：IP — 通过IP找到网关（局域网内部负责人），再找到局域网

  - 传输层：TCP、UDP，不同端口对应不同的应用，控流校验

  - 会话层：建立两个app直接的会话

  - 表示层：对底层命令和数据进行解释

  - 应用层：应用层协议：DNS、HTTP、SMTP等，用户在这一层与网络进行交互

  五层模型：

  TCP/IP五层协议就是把OSI七层网络模型的会话层、表示层、应用层合并成了应用层。

  - 应用层：负责应用程序之间的数据传输和通信。这个层级包括所有的应用程序，如电子邮件、FTP、HTTP、SSH等。

  - 传输层：提供端到端的数据传输服务，确保数据在源和目标之间可靠传输。这个层级包括TCP和UDP协议。
  - 网络层：负责数据包的传输，将数据包从源主机传到目标主机。这个层级包括IP协议。
  - 数据链路层：负责将数据包转换成物理层可以传输的信号。这个层级包括以太网协议。
  - 物理层：负责在物理媒介上传输数据，如光纤、电缆等。

- 网络层有哪些作用？

  网络层是OSI七层模型或TCP/IP五层模型中的第三层，位于传输层和数据链路层之间。其作用是为分组交换网上的不同主机之间提供端到端的通信服务，促进了网络内部和网络之间的数据传输。

  网络层有以下主要作用：

  1. 路由选择：通过路由选择协议，选择合适的路径将数据包从源地址传输到目的地址。

  2. 数据转发：将接收到的数据包移动到正确的出口端口，并发送到下一跳设备。

  3. 网络拥塞控制：使用一定策略来避免在网络中发生大量数据包同时传输导致的网络拥塞问题。

  4. 数据包分片和重组：将大数据包分割成小的数据包进行传输，并在接收端重组为原始的数据包。

  5. 网际互连：使得不同的网络之间可以互相通信，实现了互联网的主要功能。

  总之，网络层是整个互联网体系结构的重要组成部分，对于保证数据在网络中的流动、实现网络互联等方面具有不可替代的作用。

- 数据链路层有哪些协议？物理层使用到了些什么？

  数据链路层主要有以下协议：

  1. 以太网协议（Ethernet）：以太网是最常用的局域网协议，使用CSMA/CD（载波监听多路访问/碰撞检测）协议来解决数据冲突问题。

  2. 无线局域网协议（Wi-Fi）：Wi-Fi是一种无线局域网协议，采用CSMA/CA（载波监听多路访问/碰撞避免）协议来解决数据冲突问题。

  3. PPP协议（Point-to-Point Protocol）：PPP协议是一种点对点协议，常用于拨号上网和虚拟专用网（VPN）等场景。

  4. HDLC协议（High-level Data Link Control）：HDLC协议是一种数据链路层协议，常用于广域网（WAN）和数据通信等场景。

  5. SLIP协议（Serial Line Internet Protocol）：SLIP协议是一种串行线路协议，常用于串行线路上的IP数据传输。

  物理层使用到的技术主要有以下几种：

  1. 传输介质：物理层使用传输介质来传输数据，包括双绞线、同轴电缆、光纤等。

  2. 编码技术：物理层使用编码技术将数字信号转换为模拟信号，包括非归零编码、曼彻斯特编码等。

  3. 调制技术：物理层使用调制技术将数字信号转换为模拟信号，包括调幅、调频、调相等。

  4. 传输速率：物理层定义了不同的传输速率标准，包括10Mbps、100Mbps、1Gbps等。

  需要注意的是，数据链路层和物理层是OSI模型中最底层的两层，主要负责数据的传输和物理信号的转换。

- https 的 SSL 建立连接的过程会导致效率下降，如何优化

  HTTPS的SSL建立连接过程中确实会导致一定的性能损耗，主要是因为SSL握手过程需要进行非对称加密和数字签名等操作，而这些操作需要耗费CPU资源。

  以下是一些优化HTTPS性能的方法：

  1. 使用TLS 1.3协议：TLS 1.3协议在握手过程中使用了更快的加密算法，可以减少握手时间。

  2. 使用会话重用：在握手过程中，服务器可以生成一个会话ID或者会话密钥，客户端可以在下一次连接时重用这个会话ID或者会话密钥，从而避免重复进行SSL握手过程。

  3. 使用证书缓存：客户端可以缓存服务器的证书，避免每次连接都需要重新获取证书。

  4. 使用HTTP/2协议：HTTP/2协议使用了多路复用技术，可以在一个连接上同时传输多个请求和响应，从而减少握手次数。

  5. 使用CDN加速：将静态资源放在CDN上，可以减少HTTPS连接的数量，从而提高性能。

  6. 使用硬件加速：使用专门的硬件加速器可以加速SSL握手过程中的加密和解密操作，从而提高性能。

- https 整个握手交互的过程总共花了多少 rtt

  RTT(Round-Trip Time)为数据完全发送完（完成最后一个比特推送到数据链路上）到收到确认信号的时间。https的握手过程是在tcp三次握手之后额外添加2次RTT来完成。

  - TCP 握手（ 1 RTT）

    和服务器建立 TCP 连接，客户端向服务器发送 SYN 包，服务端返回确认的 ACK 包，这会花费一个往返（1 RTT）。

  - TLS 握手 （2 RTT）

    该部分客户端会和服务器交换密钥，同时设置加密链接，对于 TLS 1.2 或者更早的版本，这步需要 2 个 RTT。

  - 建立 HTTP 连接（1 RTT）

    一旦 TLS 连接建立，浏览器就会通过该连接发送加密过的 HTTP 请求。

  从开始到建立一个完整的 HTTPS 连接一共需要 4 个 RTT。如果是浏览刚刚已经访问过的站点的话，通过 TLS 的会话恢复机制，第三步 TLS 握手能够从 2 RTT 变为 1 RTT。

  **注意：**虽然握手过程有1.5个来回，但是最后客户端向服务器发送的第一条应用数据不需要等待服务器返回的信息，因此握手延时是1*RTT。

- 端口复用和地址复用

  端口复用和地址复用是网络编程中的两个概念，它们的作用是优化网络资源的利用。

  1. 端口复用

  端口复用是指在同一个主机上，多个进程可以同时监听同一个端口。在传统的网络编程中，如果一个进程需要监听某个端口，那么其他进程就不能再监听这个端口了，这就造成了资源的浪费。而端口复用技术可以让多个进程同时监听同一个端口，从而提高了网络资源的利用率。

  在实现时，需要使用SO_REUSEPORT选项，让不同的进程可以绑定同一个端口。

  2. 地址复用

  地址复用是指在同一个主机上，多个进程可以同时绑定同一个IP地址和端口。在传统的网络编程中，如果一个进程需要绑定某个IP地址和端口，那么其他进程就不能再绑定这个IP地址和端口了，这就造成了资源的浪费。而地址复用技术可以让多个进程同时绑定同一个IP地址和端口，从而提高了网络资源的利用率。

  在实现时，需要使用SO_REUSEADDR选项，让不同的网络接口可以使用同一个IP地址。

  需要注意的是，端口复用和地址复用只能在同一个主机上使用，不能跨主机使用。而且，在使用端口复用和地址复用时，需要注意保证各个进程之间的通信不会出现冲突。

- TCP如何感知对方断开链接

  TCP使用一种称为“心跳检测”的机制来感知对方是否断开连接。通过发送称为“keep-alive”消息的特殊TCP数据包，TCP可以检测到对方是否还处于连接状态。如果TCP在一定时间内没有收到对方的响应，则会认为对方已经断开连接。这个时间通常被称为“keep-alive超时时间”，默认情况下为2小时。当然，这个时间可以根据需要进行调整。

- tcp 返回 EGIAN 是什么问题？

  当应用程序在socket中设置O_NONBLOCK属性后，如果发送缓存被占满，send就会返回EAGAIN或EWOULDBLOCK 的错误。

  当需要向socket发送数据时，现将数据压入发送缓存区，并且将socket加入可写事件监听。当socket触发可写事件（EPOLLOUT）时，调用 socket_send函数发送数据，所有数据发送完毕，再清除EPOLLOUT事件。

- close_wait 状态下可以收发数据吗？

  在 `CLOSE_WAIT` 状态下，应用程序已经调用了 `close()` 函数，但是仍然有可能收到对方发来的数据，因此可以继续接收数据。但是，应用程序不能再向对方发送数据，因为连接已经被对方关闭，发送数据会收到 `RST` 响应。在这个状态下，TCP 会等待应用程序处理完所有未读取的数据后，发送 `FIN` 报文给对方，然后进入 `LAST_ACK` 状态等待对方的确认。

- 接收端和发生端之间有个 TCP 长连接，接收端应用层一直不处理缓冲区数据，发送端一直发，最后发送端，接收端，TCP 一些属性，会有什么变化？

  在这种情况下，如果接收端一直不处理缓冲区数据，那么缓冲区会不断累积，直到达到一定的阈值，此时发送端的数据将会被阻塞，因为TCP的拥塞控制会认为网络出现了拥塞，从而触发拥塞避免算法，减少发送速率。同时，发送端和接收端的TCP会根据网络状况自动调整拥塞窗口大小，以达到更好的网络利用率和传输效率。

  在这种情况下，如果发送端一直发送数据，而接收端一直不读取数据，会导致接收端的TCP缓冲区被填满，从而触发TCP的流量控制机制，发送端的数据发送速率将被限制，从而保证接收端的TCP缓冲区不会溢出。同时，发送端和接收端的TCP会根据网络状况自动调整拥塞窗口大小，以达到更好的网络利用率和传输效率。

  如果这种情况持续较长时间，可能会导致发送端和接收端的TCP连接被超时关闭，从而需要重新建立TCP连接。

- UDP 包想一次性发送 2K 的数据，接收端 1K1K 的读，能成功么

  TCP可以，但是UDP不可以。

  TCP是以数据流来发送的，发送端可以是1K1K的发送数据，而接收端的应用程序可以是2K2K地提取数据，也可以一次性全部提走，或者一次只提取几个字节的数据。应用程序所看到的数据是一个整体，或者说是一个流(stream) ，一条消息有多少个字节对应用程序是不可见的，因此TCP协议是面向流的协议，这也是容易出现粘包问题的原因。

  而UDP协议是面向消息的协议，每个UDP字段都是一条消息，应用程序必须以消息为单位提取数据，不能一次性提取任意字节的数据，这和TCP很不相同。TCP协议下，一条消息的发送，无论底层如何分段分片，TCP协议层会把构成整条消息的数据段排序完成后才呈现在内核缓冲区。

- MSS和MTU

  MSS和MTU是TCP/IP协议栈中的两个重要参数，分别代表最大分段大小和最大传输单元。它们的含义和作用如下：

  - MSS（Maximum Segment Size）：指的是TCP数据包中的数据部分的最大长度，不包括TCP头部和IP头部。MSS的大小是由对端的TCP栈在建立连接时协商决定的，通常是MTU减去IP和TCP头部的长度。MSS的大小决定了TCP分段的大小，也就是说，如果TCP发送的数据包长度超过了MSS，那么就需要将数据分成多个MSS大小的分段进行传输。

  - MTU（Maximum Transmission Unit）：指的是网络能够传输的最大的TCP数据包的大小，不包括链路层头部和尾部的长度。MTU的大小是由网络设备决定的，不同的网络设备MTU大小可能不同。如果TCP要发送的数据包长度超过了MTU，那么就需要将数据分成多个MTU大小的分段进行传输。

  MSS和MTU之间的关系是：MSS = MTU - IP头部长度 - TCP头部长度。在TCP建立连接时，双方会协商MSS的大小，以保证TCP数据包不会超过MTU的大小，从而避免IP分片和重组的问题，提高网络传输效率。

- 服务端主动请求关闭连接，会发生什么？

  当服务器进程被终止时，会关闭其打开的所有文件描述符，此时就会向客户端发送一个FIN 的报文，客户端则响应一个ACK 报文，但是这样只完成了“四次挥手”的前两次挥手，也就是说这样只实现了半关闭，客户端仍然可以向服务器写入数据。

  但是当客户端向服务器写入数据时，由于服务器端的套接字进程已经终止，此时连接的状态已经异常了，所以服务端进程不会向客户端发送ACK 报文，而是发送了一个RST 报文请求将处于异常状态的连接复位。如果客户端此时还要向服务端发送数据，将诱发服务端TCP向服务端发送SIGPIPE信号，SIGPIPE信号的默认处理是终止程序，导致客户端进程退出。

- TCP的keep-alive和HTTP的keep-alive有什么区别？

  HTTP 的 Keep-Alive 也叫 HTTP 长连接，该功能是由「应用程序」实现的，可以使得用同一个 TCP 连接来发送和接收多个 HTTP 请求/应答，减少了 HTTP 短连接带来的多次 TCP 连接建立和释放的开销。

  TCP 的 Keepalive 也叫 TCP 保活机制，该功能是由「内核」实现的，当客户端和服务端长达一定时间没有进行数据交互时，内核为了确保该连接是否还有效，就会发送探测报文，来检测对方是否还在线，然后来决定是否要关闭该连接。

- 延时与吞吐率的区别

  延迟（Latency）是指从发送数据到接收数据所需的时间，也就是数据在网络中传输的时间。延迟一般是以毫秒（ms）为单位进行计算，是指网络传输速度的快慢，通常用于测量网络的响应速度。

  吞吐率（Throughput）是指在单位时间内通过网络的数据量，通常以比特每秒（bps）或字节每秒（Bps）为单位进行计算，是指网络的传输能力。吞吐率通常用于测量网络的容量大小，即网络传输速率的大小。

  延迟和吞吐率都是网络性能的重要指标，但它们的重点不同。延迟是关注网络的响应速度，而吞吐率则关注网络的传输能力。在实际应用中，延迟和吞吐率都是需要考虑的因素，不同的应用场景需要不同的重点。

- 服务端一下子涌入大量数据怎么办

  如果服务端一下子涌入大量数据，可能会导致服务端无法及时处理这些数据，甚至会导致服务端崩溃。为了避免这种情况的发生，可以采取以下几种方法：

  1. 增加服务端的处理能力：可以增加服务端的处理能力，例如增加服务器的硬件配置、优化代码等，以提高服务端的处理速度和稳定性。

  2. 限制客户端发送数据的速率：可以通过限制客户端发送数据的速率，以减少服务端处理数据的压力。可以通过限制客户端的带宽、设置发送数据的时间间隔等方式实现。

  3. 分批处理数据：可以将大量数据分批处理，每次处理一部分数据，以减少服务端的压力。可以通过设置缓存区、分段传输数据等方式实现。

  4. 采用异步处理方式：可以采用异步处理方式，将数据存储到队列中，由服务端异步处理，以提高服务端的处理效率和稳定性。可以通过使用线程池、消息队列等方式实现。

  5. 采用负载均衡技术：可以将请求分发到多个服务端上进行处理，以提高服务端的处理能力和稳定性。可以通过使用负载均衡器、集群等方式实现。

- TCP的拥塞控制和流量控制有什么区别？

  流量控制解决因发送方发送数据太快而导致接收方来不及接收使接收方缓存溢出的问题。流量控制的基本方法就接收方根据自己的接收能力控制发送方的发送速率，TCP采用接收方控制发送方发送窗口大小的方法来实现在TCP连接上的流量控制。

  流量控制利用滑动窗口协议控制发送端流量，是为了解决发送数据过快导致接收方来不及接收的问题。接收方会发送流量控制报文，通知发送方窗口大小，发送方发送的数据大小不能超过窗口大小。如果发送者发送数据过快，接收者来不及接收，那么就会有报文丢失。为了避免报文丢失，控制发送者的发送速度，使得接收者来得及接收，这就是流量控制。流量控制根本目的是防止报文丢失，它是构成TCP可靠性的一方面。

  拥塞控制就是防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不致过载。TCP的发送方维持一个叫做拥塞窗口的状态变量。拥塞窗口的大小取决于网络的拥塞程度，当网络拥塞时减小拥塞窗口的大小，控制TCP发送方的发送速率。TCP发送方的发送窗口大小取接收窗口和拥塞窗口的最小值。

  - 区别

  流量控制：流量控制是作用于接收者的，控制发送者的发送速度从而使接收者来得及接收，防止报文丢失。

  拥塞控制：拥塞控制是作用于网络的，防止过多的数据注入到网络中，避免出现网络负载过大的情况。常用的方法就是：慢启动、拥塞避免、拥塞发生、快速恢复。

- TCP是全双工的，HTTP是哪种？全双工半双工单工？

  1. 单工： 数据传输只允许在一个方向上的传输，只能一方来发送数据，另一方来接收数据并发送。例如：对讲机
  2. 半双工：数据传输允许两个方向上的传输，但是同一时间内，只可以有一方发送或接受消息。例如：打电话
  3. 全双工：同时可进行双向传输。例如：`websocket`

  HTTP是半双工的。 

  在半双工通信中，通信双方都可以发送和接收数据，但不能同时进行。在HTTP中，客户端向服务器发送请求，服务器响应请求并返回数据，此时客户端不能再向服务器发送请求，直到服务器响应完毕。因此，HTTP是一种半双工通信协议。 
  
  相比之下，TCP是一种全双工通信协议，因为在TCP连接中，通信双方可以同时进行发送和接收数据。

- TCP 报文长度字段设置在哪里

  kind=2，最大报文段长度（MSS）选项。

  TCP连接初始化时，通信双方使用该选项来协商最大报文段长度。TCP模块通常将MSS设置为（MTU-40）字节（减掉的这40字节包括20字节的TCP头部和20字节的IP头部）。这样携带TCP报文段的IP数据报的长度就不会超过MTU（假设TCP头部和IP头部都不包含选项字段，并且这也是一般情况），从而避免本机发生IP分片。对以太网而言，MSS值是1460（1500-40）字节。

  TCP 报文长度字段被设置在TCP头部中的数据偏移字段中。它指定了TCP头部的长度（以32位字长为单位），因为TCP头部长度是可变的，所以数据偏移字段指定了TCP头部的字节数，这样接收端就可以正确地解析TCP报文。TCP头部的最小长度为20字节，最大长度为60字节。

- socket调用write返回值表示的意义

  1. 当read()或者write()函数返回值大于0时，表示实际从缓冲区读取或者写入的字节数目；
  2. 当read()函数返回值为0时，表示对端已经关闭了 socket，这时候也要关闭这个socket，否则会导致socket泄露。netstat命令查看下，如果有closewait状态的socket,就是socket泄露了。当write()函数返回0时，表示当前写缓冲区已满，是正常情况，下次再来写就行了；
  3. 当read()或者write()返回-1时，一般要判断errno。如果errno == EINTR,表示系统当前中断了，直接忽略。如果errno == EAGAIN或者EWOULDBLOCK，非阻塞socket直接忽略；如果是阻塞的socket,一般是读写操作超时了，还未返回。这个超时是指socket的SO_RCVTIMEO与SO_SNDTIMEO两个属性。所以在使用阻塞socket时，不要将超时时间设置的过小。不然返回了-1，你也不知道是socket连接是真的断开了，还是正常的网络抖动。一般情况下，阻塞的socket返回了-1，都需要关闭重新连接；
  4. 如果返回值为正数，表示成功发送了指定数量的字节；如果返回值为0，表示对方已经关闭了连接；如果返回值为-1，表示发送失败，此时可以通过errno来确定错误的具体原因。 在发送数据时，write函数会尽可能地将数据写入Socket的发送缓冲区，然后返回已经写入的字节数。如果写入的数据量超过了发送缓冲区的大小，write函数可能会阻塞，等待发送缓冲区有足够的空间。如果在一定时间内发送缓冲区还没有空间，write函数可能会返回-1，并设置errno为EAGAIN或EWOULDBLOCK，表示发送缓冲区已满，需要等待一段时间再尝试发送。
- 路由器和交换器的区别

  1. 工作层次不同 路由器工作在网络层，主要负责不同网络之间的数据转发和路由选择；而交换机工作在数据链路层，主要负责同一网络内部的数据交换。
  1. 转发方式不同 路由器使用IP地址进行转发，根据IP地址进行路由选择；而交换机使用MAC地址进行转发，根据MAC地址进行数据交换。
  1. 范围不同 路由器通常连接不同的网络，可以跨越不同的地域范围；而交换机通常连接同一网络内的设备，范围相对较小。
  1. 能力不同 路由器具备路由选择的功能，可以在不同网络之间进行数据转发；而交换机只能在同一网络内部进行数据交换。
  1. 安全性不同 由于路由器可以进行路由选择和网络隔离，因此具有更高的安全性；而交换机只能在同一网络内部进行数据交换，安全性相对较低。

- Accept函数与三次握手关系

  1. 当客户端调用connect时，触发了连接请求，向服务器发送了SYN J包，这时connect进入阻塞状态；
  2. 服务器监听到连接请求，即收到SYN J包，调用accept函数接收请求，向客户端发送SYN K ，ACK J+1，这时accept进入阻塞状态；
  3. 客户端收到服务器的SYN K ，ACK J+1之后，这时connect返回，并对SYN K进行确认；服务器收到ACK K+1时，accept返回，至此三次握手完毕，连接建立。


- IP层如何找MAC地址？如果对应IP不在局域网呢

  在局域网内，IP地址和MAC地址之间的映射关系可以通过ARP协议来获取。当一台主机需要发送数据包给另一台主机时，它会首先检查目标IP地址是否在本地网络中。如果是，它会使用ARP广播来询问目标主机的MAC地址。目标主机收到ARP请求后，会回复一个ARP响应包，其中包含自己的MAC地址。

  如果目标IP地址不在本地网络中，发送主机会将数据包发送到默认网关。默认网关会根据路由表将数据包转发到下一个网络。在这种情况下，发送主机会使用ARP广播来获取默认网关的MAC地址，然后将数据包发送到默认网关。默认网关收到数据包后，会根据路由表将数据包转发到目标主机所在的网络。

  如果攻击者在局域网中进行ARP欺骗攻击，它会发送伪造的ARP响应包，欺骗其他主机将攻击者的MAC地址与目标IP地址关联起来。这样，攻击者就可以拦截、修改或重定向其他主机的数据流量，从而实现窃取信息或进行中间人攻击等恶意行为。

- 为什么DNS使用UDP而不是TCP？

  DNS（Domain Name System）使用UDP（User Datagram Protocol）而不是TCP（Transmission Control Protocol）是因为：

  1. UDP是无连接的，没有建立和维护连接的开销，可以更快地完成查询和响应，适合短消息的传输。而TCP是面向连接的，需要进行三次握手建立连接，然后再进行数据传输，会增加一定的延迟和开销。

  2. DNS是一个轻量级的协议，一般传输的数据包较小，可以通过UDP一次性传输完整的数据包，而TCP需要将数据包分成多个段进行传输，增加了数据包的大小和传输的开销。

  3. DNS使用UDP可以更好地处理网络拥塞的情况，因为UDP不会对网络拥塞作出反应，而TCP会根据网络拥塞情况调整数据传输的速率，可能会导致延迟和丢包。

  虽然UDP存在一定的缺陷，如可能丢包、重复、乱序等，但对于DNS这样的应用场景，这些问题并不会对查询和响应的准确性产生太大影响。而且，DNS还有一些机制可以处理UDP传输中的一些问题，如使用DNSSEC（DNS Security Extensions）保证数据的完整性和安全性，使用EDNS（Extension mechanisms for DNS）扩展DNS的功能。


- 当有两个近远的IP地址，怎么做出调整让DNS选择近的？

  要让DNS选择近的IP地址，可以通过以下步骤进行调整：

  1. 确定哪个IP地址更近：使用ping命令或traceroute命令测试两个IP地址的延迟和路由跳数，确定哪个IP地址更近。

  2. 在DNS服务器上设置优先级：在DNS服务器上设置优先级，将近的IP地址优先级设置为高，远的IP地址优先级设置为低。

  3. 使用DNS负载均衡器：使用DNS负载均衡器可以根据用户的位置和网络状况自动选择最近的IP地址，提高网站的访问速度和稳定性。

  4. 使用CDN服务：使用CDN服务可以将网站的内容分发到全球各地的服务器上，根据用户的位置自动选择最近的服务器，提高访问速度和稳定性。

  综上所述，通过以上步骤可以让DNS选择近的IP地址，提高网站的访问速度和稳定性。


- ARP攻击/ARP欺骗

  ARP（Address Resolution Protocol）攻击，也叫ARP欺骗，是一种利用局域网上的ARP协议缺陷，欺骗目标主机的MAC地址，从而达到网络攻击的目的。

  攻击者通过伪造ARP响应包，将自己的MAC地址伪装成目标主机的MAC地址，然后发送给局域网上的其他主机，使得这些主机将攻击者的MAC地址缓存起来，从而将攻击者伪装成目标主机。这样，攻击者就可以通过ARP欺骗，窃取目标主机的数据包，或者劫持目标主机的网络连接，进行中间人攻击等恶意行为。

  ARP攻击可以分为主动式攻击和被动式攻击。主动式攻击是指攻击者主动伪造ARP响应包，欺骗目标主机；被动式攻击是指攻击者监听网络上的ARP请求和响应包，然后进行欺骗。

  为了防止ARP攻击，可以采取以下措施：

  1. 使用静态ARP表，手动维护IP地址和MAC地址的对应关系。

  2. 使用动态ARP缓存，设置ARP缓存的过期时间，定期清除缓存。

  3. 使用ARP防火墙，限制ARP请求和响应包的发送和接收。

  4. 使用虚拟局域网（VLAN）技术，将不同的主机分隔开来，减少攻击面。

  5. 使用加密技术，保护数据包的安全传输。

- 网际控制报文协议ICMP的过程

  网际控制报文协议（ICMP）是一种用于在IP网络上发送错误消息的协议。它的主要作用是在网络中传递控制信息和错误消息。以下是 ICMP 的过程：

  1. 发送方向目标主机发送 ICMP 报文。

  2. 目标主机接收到 ICMP 报文后，根据报文类型进行相应的处理。例如，如果是 Ping 请求报文，则目标主机会返回 Ping 应答报文。

  3. 如果目标主机无法处理 ICMP 报文，则会向发送方发送一个 ICMP 错误报文，告诉发送方发生了什么错误。

  4. 发送方接收到 ICMP 错误报文后，可以根据报文内容进行相应的处理。例如，如果是目标主机不可达的错误报文，则发送方可以尝试使用其他路径发送数据包。

  在 ICMP 过程中，主要使用了 IP 协议和 ICMP 协议。IP 协议用于将 ICMP 报文从发送方传输到目标主机，而 ICMP 协议则用于发送控制信息和错误消息。

- ping 的过程，分别用到了哪些协议

  Ping 的过程主要用到了两个协议：ICMP 和 IP。

  Ping 是一种用于测试网络连接的常用命令，其原理是向目标主机发送 ICMP 回显请求，然后等待目标主机返回 ICMP 回显应答。在这个过程中，Ping 命令首先使用 IP 协议将 ICMP 数据包发送到目标主机，然后目标主机收到 ICMP 数据包后，使用 ICMP 协议进行回应。具体来说，Ping 的过程如下：

  1. 发送端主机构建 ICMP 回显请求数据包，并使用 IP 协议将数据包发送到目标主机。

  2. 目标主机接收到 ICMP 数据包后，使用 ICMP 协议回应 ICMP 回显应答数据包。

  3. 发送端主机接收到 ICMP 回显应答数据包后，计算出往返时间（RTT），并显示在 Ping 命令的输出中。

  在这个过程中，Ping 命令使用了 ICMP 协议来发送和接收数据包，同时也使用了 IP 协议来进行数据包的路由和传输。

- 动态主机配置协议DHCP的过程

  DHCP（Dynamic Host Configuration Protocol，动态主机配置协议）是一种网络协议，它可以自动为计算机分配IP地址、子网掩码、默认网关、DNS服务器等网络配置信息，从而简化网络管理和配置。DHCP的过程如下：

  1. DHCP Discover：客户端在加入网络时发送一个广播消息，请求DHCP服务器提供IP地址和其他配置信息。

  2. DHCP Offer：DHCP服务器接收到客户端的广播消息后，向客户端发送一个包含IP地址和其他配置信息的DHCP Offer消息。

  3. DHCP Request：客户端收到DHCP Offer消息后，向DHCP服务器发送一个DHCP Request消息，确认接受所提供的配置信息。

  4. DHCP Acknowledge：DHCP服务器收到客户端的DHCP Request消息后，向客户端发送一个DHCP Acknowledge消息，确认分配IP地址和其他配置信息。

  5. DHCP Lease Renewal：客户端在租期到期前向DHCP服务器发送DHCP Request消息，请求续租IP地址和其他配置信息。

  6. DHCP Lease Expired：如果客户端在租期到期后没有向DHCP服务器发送DHCP Request消息，则DHCP服务器会释放该IP地址，以便其他客户端使用。

  通过DHCP，网络管理员可以轻松管理网络中的IP地址和其他配置信息，避免了手动配置的繁琐和错误，提高了网络管理的效率。

- NAT（Network Address Translation，网络地址转换）是一种网络协议，主要用于将内部网络的私有IP地址转换为合法的公网IP地址，以便实现内部网络与外部网络的通信。NAT的主要工作流程可以概括如下：

  1. 在内部网络中，客户端设备发送数据包到公网服务器时，数据包的源IP地址是客户端设备的私有IP地址，目标IP地址是公网服务器的公网IP地址。
  2. NAT设备接收到这个数据包后，会将源IP地址和源端口号进行修改，将其改为NAT设备的公网IP地址和一个随机的端口号，并记录这个映射关系。
  3. NAT设备将修改后的数据包发送到公网服务器。
  4. 公网服务器接收到数据包后，将响应数据包发送回NAT设备，并将目标IP地址和目标端口号设置为NAT设备的公网IP地址和之前记录的随机端口号。
  5. NAT设备接收到响应数据包后，根据记录的映射关系将目标IP地址和目标端口号还原成客户端设备的私有IP地址和端口号，并将响应数据包发送回客户端设备。

  NAT设备在转换IP地址时，会根据每个数据包的源IP地址、目标IP地址、源端口号和目标端口号等信息来进行映射。因此，在内网中，不同设备的私有IP地址和端口号不同，NAT设备可以根据这些信息来区分不同设备发送的数据包，并对其进行转换。

  当内网中的设备之间进行通信时，数据包的源IP地址和目标IP地址都是内网中的私有IP地址，NAT设备可以根据这些信息来确定数据包的目标设备，并将其传递到相应的设备。在这种情况下，NAT设备不需要对数据包进行IP地址转换。


- UDP协议的最大长度，超过最大长度会怎么样

  UDP（User Datagram Protocol，用户数据报协议）是一个无连接的、不可靠的、面向数据报的传输层协议。

  UDP报文的最大长度由其16位长度字段决定。该字段指定了整个报文（包括报头和数据）的长度。因此，UDP报文的最大长度是 2^16 - 1 字节，即65,535字节。需要注意的是，这里的长度包括了8字节的UDP报头，所以最大的有效载荷长度是 65,527 字节。

  如果试图发送长度超过最大长度的UDP报文，以下情况可能会发生：

  1. **应用程序错误**：操作系统或编程语言的socket库可能会报告错误，提示报文长度过长。在这种情况下，数据可能无法发送。

  2. **分片**：如果操作系统或网络设备支持IP分片，那么超过最大长度的UDP报文可能会被分成多个较小的IP分片。接收端将尝试重新组合这些分片以重建原始UDP报文。但是，这会增加网络负载，同时由于UDP的不可靠性，任何丢失的分片都可能导致整个报文无法正确接收。

  3. **数据截断**：如果UDP报文被发送，但超过了最大长度，某些数据可能会被截断。接收端收到的报文将不完整，可能导致处理错误或数据丢失。

  为了避免这些问题，可以考虑将大数据分成多个较小的UDP报文发送，或者使用具备可靠性和流量控制的传输协议（如TCP）替代UDP。

- udp大量传输应该注意什么

  udp大量传输应该注意以下几点:

  1. 控制报文大小。udp没有拥塞控制,过大的报文容易导致网络拥塞,影响传输效率。一般控制在MTU(最大传输单元)范围内。

  2. 快速重传机制。udp本身不 guaranteetransmission,需要应用层实现重传机制,来应对报文丢失的情况。通常使用定时器以及序列号来实现。

  3. 拥塞控制。虽然udp本身没有拥塞控制,但应用层可以实现拥塞控制算法,比如slow start,拥塞避免等,来在一定程度上控制网络拥塞。

  4. 误差校验。udp不提供任何错误校验能力,应用层需要实现CRC或其它检验码来检测传输错误。

  5. 负载分片。如果应用数据过大,可以在应用层进行分片,然后通过多个udp数据报传输。接收端需要进行重组。

  6. 重传次数上限。对于无响应的包,应用层需要重传,但重传次数不应该无限,需要设置一个上限,超过上限判定对端不可达。

  7. 心跳包。当长时间没有数据报文传输时,可以定期发送心跳包来维持端到端的连接,防止NAT / 防火墙将端口映射删除。

  8. 过载保护。发送端需要控制发送速率,防止接收端处理能力被过载,导致大量报文丢失。可以通过接收端反馈的丢包率来调整发送速率。

  9. 时间同步。在某些应用场景下,发送端和接收端需要保持较为精确的时间同步,这需要应用层自己实现时间同步机制。

- udp 为什么是不可靠的？bind 和 connect 对于 udp 的作用是什么

  UDP协议是不可靠的，主要有以下两个方面的原因：

  1. UDP协议没有提供数据确认和重传机制，因此无法保证数据的可靠性。如果一个数据包在传输过程中丢失或损坏，UDP协议没有任何手段来检测并重传这个数据包，接收方也没有办法知道是否漏掉了数据包。

  2. UDP协议没有提供流量控制和拥塞控制机制，因此在网络拥塞或数据量大的情况下，UDP协议可能会导致数据丢失或延迟。

  bind和connect对于UDP的作用如下：

  1. bind函数用于将一个UDP套接字绑定到一个特定的IP地址和端口号，以便监听指定的IP地址和端口号上的数据报文。在UDP协议中，bind操作是可选的，如果不进行bind操作，系统会随机分配一个端口号。

  2. connect函数用于将一个UDP套接字连接到一个特定的目的IP地址和端口号。在UDP协议中，connect操作是可选的，如果不进行connect操作，则在发送数据时需要在sendto函数中指定目的IP地址和端口号。

  通过bind和connect操作，UDP应用程序可以指定发送和接收数据的IP地址和端口号，以便在网络中正确地路由数据报文。同时，connect操作还可以将UDP套接字关联到一个特定的目的地址，从而使应用程序不必在每次发送数据时都指定目的地址，提高了应用程序的效率。但是需要注意的是，UDP协议仍然是不可靠的，因此在应用程序中需要进行一些额外的处理来确保数据的可靠性和完整性。

- TCP连接中，服务端网线拔掉会怎么样

  如果服务端的网线被拔掉，TCP连接会遇到以下情况：

  1. 客户端发送数据包时无响应：当客户端发送一个数据包到服务端时，如果服务端的网线被拔掉，服务端将无法接收到该数据包，也就不会给客户端发送ACK确认包，因此客户端会重试发送数据包。

  2. 客户端会进入TIME_WAIT状态：当服务端的网线被拔掉后，如果服务端主动关闭连接（通过发送FIN包），客户端在接收到FIN包后会给出ACK确认包，并进入TIME_WAIT状态。在这个状态下，客户端会等待一段时间（通常是2倍MSL，即最长报文段寿命），确保服务端收到了ACK确认包，然后才会关闭连接。

  3. 服务端会重传FIN包：如果服务端网线被拔掉，那么它发送的FIN包可能无法到达客户端。在这种情况下，服务端会重传FIN包，直到客户端收到为止。如果重传次数达到阈值（通常是10次），服务端会认为连接已经断开，关闭连接。

  4. 服务端会继续等待：如果服务端的网线被拔掉，它会继续等待客户端发送数据包。如果客户端在服务端重新连接之前就关闭了连接，服务端将一直等待，直到超时或者客户端重新连接为止。

  总之，如果服务端的网线被拔掉，TCP连接会受到影响，客户端需要重试发送数据包，同时服务端需要重传FIN包来关闭连接。为了确保连接正确地关闭，客户端还需要进入TIME_WAIT状态等待一定时间。

- TCP 怎么保证发送数据顺序性（数据包乱序问题）？

  在TCP协议中，为了保证发送数据的顺序性，使用了以下几种机制：

  1. 序列号：TCP协议在发送数据时，会给每个数据包分配一个唯一的序列号，用于区分每个数据包。接收方会通过序列号来确定数据包的顺序，以及是否有丢失的数据包。

  2. 确认应答：接收方在收到数据包后，会向发送方发送一个确认应答（ACK），用于告诉发送方已经接收到数据包。发送方在收到ACK后，会认为该数据包已经成功发送，并将下一个数据包发送出去。

  3. 滑动窗口：TCP协议使用滑动窗口机制来控制发送方发送数据的速度。滑动窗口的大小是动态调节的，接收方可以通过发送窗口（Receiver Window）来告诉发送方可以接收多少数据，发送方将根据发送窗口的大小来控制发送数据的速度。

  通过上述机制，TCP协议可以保证发送数据的顺序性。发送方会按照数据的顺序发送数据包，并等待接收方的确认应答。如果接收方没有收到某个数据包，则会通知发送方重新发送该数据包。同时，滑动窗口机制可以帮助发送方控制发送数据的速度，避免发送过快导致数据包丢失或错误。

- TCP的序列号为什么是随机的？能不能固定从1开始？为什么？

  TCP序列号是为了保证数据传输的可靠性而设计的，它的随机性可以提高数据传输的安全性和可靠性。具体原因如下：

  1. 防止数据包重复：TCP序列号可以防止数据包在传输过程中重复发送或被重复接收，从而保证数据传输的可靠性。

  2. 防止数据包被篡改：TCP序列号可以防止数据包被篡改或冒充，从而保证数据传输的安全性。

  3. 防止攻击者利用序列号进行攻击：如果TCP序列号是固定的，攻击者可以通过猜测序列号来执行攻击，例如TCP SYN Flood攻击。

  因此，TCP序列号通常是随机生成的，以提高数据传输的安全性和可靠性。如果TCP序列号从1开始，攻击者可以轻易地猜测下一个序列号，并进行攻击。此外，TCP序列号的随机性可以保证TCP连接的唯一性，避免不同的连接使用相同的序列号，从而导致数据混乱或错误。

- TCP滑动窗口最大值

  TCP滑动窗口的最大值取决于接收方和发送方的实现以及网络状况。TCP滑动窗口的大小是动态调整的，发送方和接收方会根据网络状况和对方的处理能力来动态调整滑动窗口的大小。

  在TCP协议中，发送方和接收方都有一个窗口大小的参数，分别称为发送窗口和接收窗口。发送方的发送窗口表示可以发送的数据量，而接收方的接收窗口表示可以接收的数据量。发送方和接收方会通过TCP报文段中的窗口字段来告知对方它们的窗口大小。

  发送方会根据接收方的接收窗口来调整自己的发送窗口大小，以控制发送数据的速率。如果接收方的接收窗口变小，发送方就会减小自己的发送窗口，以避免发送过多的数据导致数据包丢失。如果接收方的接收窗口变大，发送方就会增大自己的发送窗口，以提高发送数据的速率。

  因此，TCP滑动窗口的最大值取决于网络状况、对方的处理能力以及实现的具体细节。在实际应用中，TCP滑动窗口的最大值一般会根据具体情况进行调整，以达到最优的网络性能。

- socket 本地通信需要通过 TCP/IP 协议栈吗

  在一些操作系统（如Linux和Windows）中，socket本地通信是通过本地协议栈来实现的，而不需要经过TCP/IP协议栈。本地协议栈是操作系统提供的一种机制，用于在同一台计算机的不同进程之间进行通信。

  本地协议栈通常使用Unix域套接字（Unix domain socket）来进行通信，它是一种专门用于进程间通信的套接字类型。与TCP/IP套接字不同，Unix域套接字不需要经过网络协议栈，而是直接在内核中进行数据传输，因此具有更高的性能和更低的延迟。

  在Unix-like系统中，本地协议栈通常是通过Unix域套接字来实现的。在Windows系统中，本地协议栈使用命名管道（Named Pipes）来实现进程间通信。

  因此，对于本地通信，如果使用本地协议栈（如Unix域套接字或命名管道），就不需要经过TCP/IP协议栈。但如果使用TCP/IP协议栈来进行本地通信，就需要经过TCP/IP协议栈的处理，会增加额外的网络开销和延迟。

- 怎么知道 http 的报文长度

  在HTTP协议中，有多种方法可以确定HTTP报文的长度，其中常用的包括：

  1. Content-Length首部字段：当HTTP报文中包含消息体时，可以使用Content-Length首部字段来指定消息体的长度。例如，Content-Length: 123表示消息体的长度为123个字节。

  2. Transfer-Encoding首部字段：如果HTTP报文采用分块传输编码（chunked transfer encoding）方式进行传输，就可以使用Transfer-Encoding首部字段来指定每个分块的长度。例如，Transfer-Encoding: chunked表示采用分块传输编码方式进行传输。

  3. Connection首部字段：如果HTTP报文采用持久连接（persistent connection）方式进行传输，就可以使用Connection首部字段来指定消息体的长度。例如，Connection: Keep-Alive，表示使用持久连接方式进行传输。

  在实际应用中，通常会根据具体情况选择合适的方法来确定HTTP报文的长度。如果HTTP报文中包含消息体，建议使用Content-Length首部字段来指定消息体的长度。如果采用分块传输编码方式进行传输，就可以使用Transfer-Encoding首部字段来指定每个分块的长度。如果采用持久连接方式进行传输，就可以使用Connection首部字段来指定消息体的长度。

- 如果你访问一个网站很慢，怎么排查和解决

  如果访问一个网站很慢，可以按照以下步骤进行排查和解决：

  1. 检查网络连接：首先需要检查自己的网络连接是否正常。可以通过打开其他网站或者使用ping或traceroute命令测试网络是否正常。

  2. 清除浏览器缓存：浏览器缓存可能会导致网站访问变慢，可以尝试清除浏览器缓存并重新访问网站。

  3. 检查DNS解析：DNS解析也可能是导致网站访问变慢的原因之一。可以使用nslookup或dig命令检查DNS解析是否正常，如果不正常，可以尝试切换到其他DNS服务器。

  4. 检查网站服务器：网站服务器可能出现宕机或者负载过高等问题，可以使用ping或traceroute命令检查网站服务器是否正常，如果不正常，可以联系网站管理员。

  5. 检查网络延迟：网络延迟也可能导致网站访问变慢，可以使用网络诊断工具（如ping或traceroute）检查网络延迟是否过高，如果过高，可以尝试使用VPN或者更换网络环境。

  6. 检查网站内容：网站内容过大或者包含大量的媒体文件可能会导致网站访问变慢，可以使用浏览器的开发者工具检查网站的加载时间和资源大小，如果过大，可以尝试优化网站内容或者使用CDN加速服务。

  7. 使用其他浏览器或设备：如果以上方法都没有解决问题，可以尝试使用其他浏览器或设备访问网站，以确定问题是否与浏览器或设备有关。

  总之，排查和解决网站访问变慢的问题需要综合考虑多方面因素，并且需要有耐心和细心地进行排查和测试。

- TIME_WAIT状态会导致什么问题，怎么解决

  TIME_WAIT状态是指TCP连接关闭后，等待一段时间（通常为2倍MSL，即两倍的最长报文段生存时间）才会释放连接。TIME_WAIT状态可以避免网络中残留的数据包影响下一次连接，但同时也会导致以下问题：

  1. 资源浪费：在高并发场景下，TIME_WAIT状态会占用大量的系统资源，导致资源浪费。

  2. 端口耗尽：在短时间内频繁创建和销毁TCP连接时，TIME_WAIT状态会占用大量的端口资源，导致端口耗尽问题。

  为了解决TIME_WAIT状态带来的问题，可以采取以下措施：

  1. 调整TCP参数：可以通过修改操作系统的TCP参数来缩短TIME_WAIT状态的时间，例如修改tcp_fin_timeout参数等。

  2. 优化应用程序：在应用程序中，可以采用连接池等技术来复用TCP连接，减少TCP连接的创建和销毁，从而避免TIME_WAIT状态的产生。

  3. 使用SO_REUSEADDR选项：在TCP连接关闭时，可以使用SO_REUSEADDR选项来重用端口，避免端口耗尽问题。

  4. 使用负载均衡器：在高并发场景下，可以使用负载均衡器来分发请求，从而减少单个服务器上的TCP连接数量，缓解TIME_WAIT状态带来的负面影响。

  需要注意的是，对TCP参数的调整需要根据具体的应用场景和操作系统而定，同时也需要谨慎进行调整，避免引入其他问题。

- 半连接、半打开、半关闭

  半连接、半打开和半关闭都是TCP协议中的概念，具体含义如下：

  1. 半连接（SYN_SENT状态）：指TCP客户端向服务器发出连接请求，但是服务器还没有进行确认的状态。在这种状态下，TCP客户端等待服务器的响应，如果服务器不响应或响应超时，客户端会重试连接请求。

  2. 半打开（SYN_RCVD状态）：指TCP服务器收到客户端的连接请求后，向客户端发送确认消息，但是还没有完成连接的状态。在这种状态下，TCP服务器等待客户端的确认消息，如果客户端没有响应或响应超时，服务器会重新发送确认消息。

  3. 半关闭（FIN_WAIT_1、FIN_WAIT_2状态）：指TCP连接中的一端主动关闭连接，但是另一端还没有进行确认的状态。在这种状态下，主动关闭的一端等待对方的确认消息，如果对方没有响应或响应超时，主动关闭的一端会重新发送关闭请求。

  需要注意的是，半连接、半打开和半关闭都属于TCP协议中的状态，用于描述TCP连接的建立、维护和关闭过程。在实际应用中，这些状态会对TCP连接的性能和可靠性产生一定的影响，因此需要进行合理的配置和优化。

  




# OS

- 为什么要区分内核态和用户态？

  区分内核态和用户态是为了保证操作系统的稳定性和安全性。

  在内核态下，操作系统可以直接访问硬件资源，执行特权指令，进行系统管理和维护任务，如进程调度、内存管理、设备驱动等。而在用户态下，应用程序只能通过系统调用接口向操作系统发起请求，操作系统会在内核态下完成相应的任务并返回结果给应用程序。

  通过区分内核态和用户态，可以有效地隔离应用程序和操作系统，防止应用程序的错误或恶意行为对操作系统的稳定性和安全性产生影响。同时，也可以提高操作系统的性能和效率，因为内核态下的操作系统可以直接访问硬件资源，而不需要经过系统调用的开销和限制。

* 内核态和用户态的区别
  1. 权限不同：内核态具有更高的权限，可以访问系统的所有资源，而用户态只能访问受限的资源。

  2. 运行环境不同：内核态运行在操作系统内部，用户态运行在操作系统外部。

  3. 调用方式不同：内核态通过系统调用方式调用操作系统提供的服务，而用户态通过库函数调用操作系统提供的服务。

  4. 响应速度不同：内核态响应速度更快，因为它可以直接访问硬件资源，而用户态需要通过操作系统提供的接口访问硬件资源。

  5. 安全性不同：内核态具有更高的安全性，因为它可以保护系统资源不被用户态非法访问。

  6. 内存管理不同：内核态可以直接访问所有内存，而用户态只能访问自己的内存空间。

  7. 中断处理不同：内核态可以处理所有中断，而用户态只能处理非关键性中断。

- 导致从用户态切换到内核态的操作

  - 系统调用

    很多程序开始时运行于用户态，但在执行的过程中，一些操作需要在内核权限下才能执行，这就涉及到一个从**用户态切换到内核态**的过程。比如C函数库中的内存分配函数 malloc()，它具体是使用 sbrk() 系统调用来分配内存，当malloc() 调用 sbrk() 的时候就涉及一次从用户态到内核态的切换，类似的函数还有 printf()，调用的是 wirte() 系统调用来输出字符串，等等。
  
  
    - 异常事件
      
        当 CPU 正在执行运行在用户态的程序时，突然发生某些预先不可知的异常事件，就会触发从当前用户态执行的进程转向内核态执行相关的异常事件，典型的如缺页异常。
  
  
    - 外围设备中断
      
        当外围设备完成用户的请求操作后，会向 CPU 发出中断信号，此时，CPU 就会暂停执行下一条即将要执行的指令，转而去执行中断信号对应的处理程序，如果先前执行的指令是在用户态下，则自然就发生从用户态到内核态的转换。
  


- 用户态的应用程序可以通过三种方式来访问内核态的资源：

  - 系统调用

  - 库函数

  - Shell 脚本


- 中断实现的原理

  中断是一种计算机硬件和软件协同工作的机制，它允许处理器在执行程序时，暂停当前任务，转而去处理其他任务，然后在完成这些任务后，再回到原来的任务继续执行。

  中断的实现原理主要包括以下几个方面：

  1. 中断请求的产生：中断请求可以来自于硬件设备，如键盘、鼠标、磁盘等，也可以来自于软件，如操作系统的系统调用、异常处理等。

  2. 中断向量表的建立：中断向量表是一个存储中断处理程序入口地址的数据结构，每个中断请求都有一个唯一的中断向量号，当中断请求产生时，处理器会根据中断向量号在中断向量表中查找对应的中断处理程序入口地址。

  3. 中断处理程序的执行：当处理器接收到中断请求后，会暂停当前任务，保存现场信息（如程序计数器、寄存器等）并跳转到中断向量表中对应的中断处理程序入口地址，执行中断处理程序。

  4. 中断处理程序的返回：中断处理程序执行完后，会恢复现场信息并返回到原来的任务继续执行。

  总之，中断机制的实现离不开中断请求的产生、中断向量表的建立、中断处理程序的执行和返回等关键步骤，这些步骤的协同工作使得处理器能够在多任务环境下有效地处理各种中断请求。

- 系统中断、中断向量、中断向量表

  - 系统中断是指由硬件或软件触发的一种机制，用于打断正在执行的程序，以便处理特定的事件或请求；
  - 中断向量是一个指向中断处理程序的地址，它由中断控制器提供，并用于确定应该执行哪个中断处理程序；
  - 中断向量表是一个包含所有中断向量的表格，通常存储在内存中，并由操作系统维护。当一个中断被触发时，处理器会查询中断向量表，找到相应的中断向量，并跳转到相应的中断处理程序中去执行。

- 软中断和硬中断区别

  软中断和硬中断是计算机系统中的两种中断类型，它们的区别在于中断的来源和处理方式。

  - 软中断

    软中断是由操作系统内核自身产生的中断，它们不是由硬件设备触发的。软中断通常用于处理计时器、网络数据包、文件系统等事件。软中断是通过调用操作系统内核中的函数来触发的，因此也被称为系统调用。

  - 硬中断

    硬中断是由硬件设备触发的中断，例如键盘、鼠标、网络卡等。硬中断通常由硬件设备发送一个中断请求信号（IRQ）给操作系统内核，内核会暂停正在执行的任务来处理这个中断请求。硬中断的处理需要较高的优先级，因为它们需要及时响应硬件设备的请求。

  软中断和硬中断是两种不同的中断类型，软中断是由操作系统内核自身产生的中断，硬中断是由硬件设备触发的中断。软中断通常用于处理计时器、网络数据包、文件系统等事件，而硬中断通常由键盘、鼠标、网络卡等设备触发。

- 异常和中断的区别

  异常和中断都是计算机系统中的两种不同的事件处理方式，它们的区别如下：

  1. 异常：是指在程序执行过程中由于出现了非法操作或者错误的数据等原因导致程序无法继续执行的情况。异常通常是由程序本身引起的，例如除零、空指针引用等。

  2. 中断：是指由外部设备或者程序发出的一种请求，要求处理器暂停当前的任务，转而去处理该请求。中断通常是由外部设备引起的，例如键盘输入、定时器等。

  因此，异常和中断的主要区别在于它们的来源不同，异常是由程序本身引起的，而中断是由外部设备引起的。另外，异常通常是在程序执行过程中发生的，而中断则可以在任何时候发生。

- 系统调用和中断的区别

  系统调用是一种机制，它允许用户程序请求内核执行某些特权操作，如文件读写、进程管理等。用户程序通过调用特定的系统调用接口来发起请求，内核根据请求参数执行相应的操作，并返回结果给用户程序。

  中断是一种事件，它可以被硬件或软件触发，用于打断当前程序的执行，转而执行中断处理程序。中断可以被用于处理硬件故障、时钟中断、网络数据包到达等事件。当中断发生时，CPU会保存当前程序的状态，然后跳转到中断处理程序执行相应的操作，处理完后再返回原程序继续执行。

  因此，系统调用和中断的区别在于：

  1. 作用不同：系统调用是用户程序请求内核执行特权操作的机制，而中断是打断当前程序执行的事件。

  2. 触发方式不同：系统调用是由用户程序主动发起的，而中断是由硬件或软件触发的。

  3. 实现方式不同：系统调用是用户态程序切换到内核态执行的过程，需要进行上下文切换和特权级切换；而中断是在当前程序执行过程中被打断，操作系统会保存当前程序的上下文并处理中断，然后再恢复被打断的程序继续执行。

  4. 返回方式不同：系统调用返回时，操作系统会将结果返回给用户程序；而中断处理完成后，控制权会返回到被打断的程序继续执行。

  总的来说，系统调用和中断都是操作系统中的重要机制，它们各自有着不同的作用和实现方式，但都为操作系统提供了强大的功能和灵活性。

- 系统调用和函数调用的区别

  系统调用和函数调用的区别如下：

  1. 调用方式不同：系统调用是通过操作系统提供的接口进行调用的，而函数调用是在程序内部进行调用的。

  2. 执行环境不同：系统调用是在内核态下执行的，而函数调用是在用户态下执行的。

  3. 功能不同：系统调用是提供给用户程序使用操作系统资源的接口，比如读写文件、创建进程等操作；而函数调用是程序内部实现某一特定功能的代码块。

  4. 开销不同：系统调用需要进行上下文切换，从用户态切换到内核态，需要进行堆栈切换等操作，开销比较大；而函数调用只需要进行简单的函数调用和返回操作，开销比较小。

  5. 安全性不同：系统调用会检查用户程序的权限，确保用户程序不能越权操作系统资源，保证系统的安全性；而函数调用不会进行权限检查，用户程序可以自由地调用函数，可能会对系统造成安全威胁。

  综上所述，系统调用和函数调用虽然都是程序中的调用方式，但是其执行环境、功能、开销、安全性等方面都有很大的区别。

- 系统调用进入内核态的过程

  当应用程序需要执行一些需要特权级别的操作时，比如读写文件、网络通信、内存管理等，就需要通过系统调用进入内核态。系统调用是用户程序与操作系统之间进行通信的接口，它可以让用户程序请求操作系统执行某些任务。

  以下是系统调用进入内核态的过程：

  1. 用户程序执行系统调用指令，将控制权转移到内核态。

  2. CPU从用户态切换到内核态，将程序计数器(PC)和堆栈指针(SP)压入内核栈中，保存用户程序的现场。

  3. 内核态的操作系统检查系统调用参数，验证权限，执行相应的操作。

  4. 操作系统将结果返回给用户程序，将控制权转移回用户态。

  5. CPU从内核态切换回用户态，将程序计数器(PC)和堆栈指针(SP)恢复，继续执行用户程序。

  需要注意的是，系统调用的执行过程中会涉及到内核态和用户态之间的切换，这个过程需要花费一定的时间和资源，因此在编写程序时应尽量减少系统调用的次数，提高程序的效率。

- 内存映射工作机制，内存映射和共享内存区别？

  内存映射是一种将文件或设备映射到进程地址空间的机制。它允许进程像访问内存一样访问文件或设备，从而避免了繁琐的文件或设备I/O操作。内存映射是通过调用mmap()系统调用来实现的，它将文件或设备的数据映射到进程的虚拟地址空间中。内存映射工作机制如下：

  1. 调用mmap函数，将文件映射到进程的地址空间中。

  2. 操作系统将文件的内容读入内存中，并建立一个虚拟内存区域。

  3. 进程可以通过指针来访问这个虚拟内存区域，就像访问内存一样。

  4. 当进程对这个虚拟内存区域进行读写操作时，操作系统会自动将数据写回到文件中。

  内存映射和共享内存的区别在于，内存映射是将文件或设备映射到进程的地址空间中，而共享内存是将一块内存映射到多个进程的地址空间中，使得多个进程可以共享同一块内存。共享内存通常用于进程间通信，而内存映射则更多地用于文件和设备访问。

- 共享内存存在于进程地址空间中哪个部分？未初始化数据段怎么存入数据？共享内存区增长方向？一般存啥？

  共享内存存在于进程地址空间中的堆区或者数据段中。未初始化数据段存入数据时，操作系统会在该段内存中分配一块空间，并将其清零。共享内存区的增长方向通常是向上增长，即地址值越来越大。一般来说，共享内存区存储的是需要在多个进程之间共享的数据，比如进程间通信的消息队列、共享缓存等。

- TLB 是干嘛的？TLB 和磁盘缓存是一样的吗？

  TLB（Translation Lookaside Buffer）是一种硬件缓存，用于加速虚拟地址到物理地址的转换过程。TLB存储了最近使用过的虚拟地址与物理地址的映射关系，当CPU需要访问某个虚拟地址时，先在TLB中查找对应的物理地址，如果命中则可以直接访问物理地址，否则需要进行完整的地址转换流程。

  磁盘缓存是一种软件缓存，用于加速磁盘读写操作。磁盘缓存存储了最近读取过的磁盘数据，当需要再次读取时，可以直接从缓存中获取，避免了频繁的磁盘读取操作。

  因此，TLB和磁盘缓存的作用不同，TLB是用于加速虚拟地址到物理地址的转换，而磁盘缓存是用于加速磁盘读写操作。两者的实现方式也不同，TLB是硬件缓存，而磁盘缓存是软件缓存。

- 线程安全、线程安全函数、可重入函数、信号安全函数

  1. 线程安全

  线程安全是指多个线程同时访问同一份数据时，不会出现数据竞争和不一致的情况。线程安全的实现可以通过使用互斥量、信号量、读写锁等同步机制来保证。

  2. 线程安全函数

  线程安全函数是指在多线程环境下可以安全调用的函数。这些函数要么不使用全局变量，要么使用全局变量时使用同步机制来保证线程安全。例如，C标准库中的strtok_r函数就是线程安全函数。

  3. 可重入函数

  可重入函数是指在多线程环境下可以重复调用的函数。这些函数不使用全局变量，而是使用局部变量或者参数来保存状态信息。可重入函数的实现可以通过使用静态变量或者动态分配内存的方式来保存状态信息。

  4. 信号安全函数

  信号安全函数是指在信号处理函数中可以安全调用的函数。由于信号处理函数的执行是在中断上下文中进行的，因此不能使用会修改全局变量的函数，也不能使用会阻塞的函数。例如，C标准库中的malloc函数就不是信号安全函数。

- 浏览器中点击+号创建新的标签页，是开启了一个新线程还是新进程，以及原因

  在大多数浏览器中，点击+号创建新的标签页会开启一个新的进程。这是因为现代浏览器通常使用多进程架构，每个标签页都在单独的进程中运行，这样可以提高浏览器的稳定性和安全性，同时也可以更好地利用多核处理器的优势。每个进程都有自己的内存空间，这样即使一个标签页崩溃了，其他标签页也不会受到影响。当然，也有一些浏览器会在同一个进程中运行多个标签页，这取决于浏览器的具体实现。

- 产生缺页中断的几种情况：

  1. CPU所需访问的页面不在内存中，就需要将页面调入内存，如果内存已满，就需要执行相应的页面置换算法；
  2. 使用 mmap 函数在堆中创建一块虚拟内存，第一次访问时才会通过缺页中断机制映射到物理页中；
  3. fork() 创建子进程，读时共享，写时拷贝，缺页中断；


- 什么是缺页异常，什么情况下会缺页异常

  缺页异常（Page Fault）是指当程序访问一个尚未在内存中的页面时，操作系统会将其从磁盘或其他存储设备中读入内存，此过程就是缺页异常。当程序试图访问某个虚拟地址时，如果对应的物理页不在内存中，就会发生缺页异常。

  缺页异常通常发生在以下情况下：

  1. 程序第一次访问某个页面，该页面尚未被加载到内存中。

  2. 程序访问的页面已经被换出到磁盘或其他存储设备中，需要重新加载到内存中。

  3. 程序访问的页面已经被修改，需要将其写回到磁盘或其他存储设备中，并且加载新的页面到内存中。

  缺页异常是操作系统中常见的机制之一，它可以有效地利用内存资源，提高系统的性能和效率。

- GDB如何使用

  GDB是一种用于调试程序的工具，可以帮助程序员找出程序中的错误和问题。下面是使用GDB的基本步骤：

  1. 编译程序时加上-g选项，生成可调试的程序。

  2. 打开终端，输入gdb命令，进入GDB调试环境。

  3. 在GDB环境中，输入run命令，运行程序。

  4. 如果程序出现错误，GDB会停止程序的执行，并显示出错的位置。

  5. 可以使用backtrace命令查看函数调用栈，使用print命令查看变量的值，使用step命令逐行执行程序，使用break命令设置断点等。

  6. 如果需要退出GDB环境，可以使用quit命令。

  需要注意的是，GDB调试需要一定的技巧和经验，对于复杂的程序，可能需要花费较长的时间来找出问题。因此，建议在编写程序时尽可能避免出现错误，以减少调试的时间和精力。

  GDB是一款常用的调试工具，可以帮助程序员在开发过程中定位和解决程序中的错误。更详细的GDB使用方法：

  1. 编译程序时需要加上调试信息选项：-g

  例如：

  ```
  gcc -g -o myprogram myprogram.c
  ```

  2. 启动GDB

  在命令行中输入：

  ```
  gdb myprogram
  ```

  3. 设置断点

  在需要调试的代码行前加上断点：

  ```
  break main
  ```

  或者直接在GDB中输入：

  ```
  b main
  ```

  4. 运行程序

  在GDB中输入：

  ```
  run
  ```

  5. 调试程序

  程序运行到断点处时会停止，可以使用以下命令进行调试：

  - step：单步执行程序，进入函数内部
  - next：单步执行程序，不进入函数内部
  - print：打印变量的值
  - backtrace：查看函数调用栈
  - continue：继续执行程序直到下一个断点或程序结束

  6. 查看变量值

  在GDB中输入：

  ```
  print variable_name
  ```

  可以查看变量的值。

  7. 修改变量值

  在GDB中输入：

  ```
  set variable_name = new_value
  ```

  可以修改变量的值。

  8. 退出GDB

  在GDB中输入：

  ```
  quit
  ```

<img src="https://gcore.jsdelivr.net/gh/gp868/myFigures/img/202206301500801.png" alt="image-20220630145953705" style="zoom:80%;" />

<img src="https://gcore.jsdelivr.net/gh/gp868/myFigures/img/202206301500533.png" alt="image-20220630150022456" style="zoom:80%;" />

<img src="https://gcore.jsdelivr.net/gh/gp868/myFigures/img/202206301501962.png" alt="image-20220630150104907" style="zoom: 80%;" />

- 为什么ssh客户端关闭了会影响服务端的运行?

  当终端接口检测到网络连接断开，将挂断信号SIGHUP发送给控制进程(会话期首进程)。如果会话期首进程终止，则该信号发送到该会话期前台进程组。一个进程退出导致一个孤儿进程组产生时，如果任意一个孤儿进程组进程处于STOP状态，则会发送 SIGHUP 和 SIGCONT 信号到该进程组中所有进程。因此当网络断开或终端窗口关闭后，也就是SSH断开以后，控制进程收到 SIGHUP 信号退出，会导致该会话期内其他进程退出。也就是 ssh 打开以后，bash等都是他的子程序，一旦ssh关闭，系统将所有相关进程杀掉，导致一旦ssh关闭, 执行中的任务就取消了。

  那如何解决呢？

  在远端开启 tmux，在 tmux 里运行程序，此时运行的程序属于 tmux 的进程组，不属于 ssh 进程组；使用 `nohup `命令。

- 线程池里的线程数设置为多少最优？

  线程池里的线程数设置为多少最优，取决于以下因素：

  1. CPU核心数：线程池中的线程数应该小于等于CPU核心数，否则会导致CPU过度切换线程而降低性能。

  2. 任务类型：任务类型对线程池的大小也有影响。如果任务是I/O密集型，线程池中的线程数应该设置得更大，以便更好地利用I/O等待时间。如果任务是CPU密集型，线程池中的线程数应该设置得更小，以避免过度切换线程。

  3. 系统负载：系统负载也会影响线程池的大小。如果系统负载较高，线程池中的线程数应该设置得更小，以避免过度消耗系统资源。

  因此，线程池中的线程数应该根据以上因素进行适当调整，以达到最优的性能和资源利用率。


- 堆里面的机制？介绍下程序的内存释放？

  堆是一块动态分配的内存区域，程序可以在运行时向操作系统申请一定大小的堆内存，用于存储动态分配的数据结构，如链表、树、图等。堆内存的管理需要程序员手动进行，包括内存的分配和释放。

  堆的机制包括以下几个方面：

  1. 内存分配：程序通过调用malloc()或者new操作符来申请一定大小的堆内存，操作系统会在堆区域中为程序分配一块连续的内存空间，并返回内存的起始地址。

  2. 内存释放：程序通过调用free()或者delete操作符来释放先前申请的堆内存，操作系统会将这块内存标记为可用状态，等待下一次分配使用。

  3. 内存管理：程序需要手动管理堆内存的分配和释放，避免内存泄漏和内存溢出等问题。

  程序的内存释放是指程序在运行过程中释放不再使用的内存空间，以便操作系统可以重新利用这些内存空间。内存释放通常包括以下几个步骤：

  1. 标记不再使用的内存空间：程序通过一些方式标记不再使用的内存空间，如将指针置为NULL或者使用特定的标记位来标记内存块。

  2. 释放内存空间：程序通过调用free()或者delete操作符来释放不再使用的内存空间，操作系统会将这块内存标记为可用状态，等待下一次分配使用。

  3. 内存回收：操作系统会定期进行内存回收，将不再使用的内存空间回收并重新分配给其他程序使用。

  内存释放是程序设计中非常重要的一部分，如果程序没有正确释放内存，会导致内存泄漏和内存溢出等问题，严重影响程序的性能和稳定性。

- 32和64位操作系统地址空间分别是多大？

  32位：2^32^ = 4 GB，64位：2^64^ 字节

- 构成一个计算机需要什么，各个组件做什么工作

  计算机由五大部件组成，包括运算器、控制器、存储器、输入设备和输出设备组成。

  1、控制器：计算机的控制系统，是计算机的神经中枢，指挥着计算机中各个部件自动协调工作。在控制器的控制下，计算机能够自动按照程序设定的步骤进行一系列操作，以完成特定任务。

  2、运算器：计算机的运算系统，计算机中执行各种算术和逻辑运算操作的部件。

  3、存储器：计算机存储系统，是一种利用半导体、磁性介质等技术制成的存储资料的电子设备。其电子电路中的资料以二进制方式存储。

  4、输入设备：向计算机输入数据和信息的设备，是计算机与用户或其他设备通信的桥梁。

  5、输出设备：是计算机硬件系统的终端设备，用于接收计算机数据的输出显示、打印、声音、控制外围设备等。

- 计算机的位数是由什么来决定的

  计算机的位数是由其处理器（CPU）的寄存器的位数决定的。寄存器是一种非常快速的存储器件，用于存储计算机正在处理的数据和指令。每个寄存器都有一个特定的位数，表示它可以存储的二进制位数。例如，一个32位的处理器具有32位的寄存器，可以处理32位的二进制数据。同样，64位的处理器具有64位的寄存器，可以处理64位的二进制数据。因此，计算机的位数决定了它可以处理的最大二进制数的位数，从而影响了其性能和处理能力。

- 线程创建 pthread_create 底层调用函数是啥

  pthread_create 底层调用的函数是 clone()。clone() 是 Linux 内核提供的系统调用，用于创建一个新的进程或线程。在 Linux 中，线程本质上也是一个进程，只是与创建它的进程共享了一部分资源。因此，pthread_create() 函数实际上是通过调用 clone() 创建一个新的线程，并将其加入到进程的线程池中。

- 段错误有什么原因

  段错误是一种常见的程序错误，通常是由于程序访问了不合法的内存地址或者内存越界引起的。具体来说，段错误可能由以下原因引起：

  1. 访问未分配内存：程序试图访问未分配的内存地址，比如使用空指针或者释放了已经被释放的内存。

  2. 内存越界：程序试图访问超出数组或者指针范围的内存地址，比如数组下标越界或者指针偏移量超出了指针指向的内存空间。

  3. 栈溢出：程序使用了过多的栈空间，导致栈溢出，比如递归调用过深或者在栈上分配过多的内存。

  为了避免段错误，可以采取以下措施：

  1. 避免使用空指针或者已经被释放的内存。

  2. 对于数组和指针，要确保访问的下标或者偏移量不越界。

  3. 在使用递归时，要注意控制递归深度，避免栈溢出。

  4. 使用工具进行内存检查，比如valgrind等工具可以检查程序中的内存错误。

  5. 编写高质量的代码，遵循良好的编程习惯，比如避免使用未初始化的变量等。

- Epoll是阻塞/非阻塞？异步/同步？

  Epoll是非阻塞/异步的。它使用事件通知机制，当有事件发生时，它会立即返回而不会阻塞线程，同时也不需要轮询来检查事件是否发生。这种异步的方式可以提高系统的并发性和响应性能。同时，Epoll也可以使用边缘触发模式，可以在数据可读/写时立即通知应用程序，从而实现异步处理。

- 服务器有一个连接进来，到应用程序读取到数据，需要经过几次内核态/用户态切换？需要几次缓冲区数据的拷贝？

  4次内核态/用户态切换：

  1. 用户应用进程调用read函数，向操作系统发起IO调用，上下文从用户态转为内核态（切换1）；
  2. DMA控制器把数据从磁盘中，读取到内核缓冲区；
  3. CPU把内核缓冲区数据，拷贝到用户应用缓冲区，上下文从内核态转为用户态（切换2），read函数返回；
  4. 用户应用进程通过write函数，发起IO调用，上下文从用户态转为内核态（切换3）；
  5. CPU将用户缓冲区中的数据，拷贝到socket缓冲区；
  6. DMA控制器把数据从socket缓冲区，拷贝到网卡设备，上下文从内核态切换回用户态（切换4），write函数返回；

  4次缓冲区数据的拷贝：

  1. 第一次拷贝：将磁盘中的数据拷贝到内核的缓冲区中；
  2. 第二次拷贝：内核将数据处理完，接着拷贝到用户缓冲区中；
  3. 第三次拷贝：此时需要通过socket将数据发送出去，将用户缓冲区中的数据拷贝至内核中socket的缓冲区中；
  4. 第四次拷贝：把内核中socket缓冲区的数据拷贝到网卡的缓冲区中，通过网卡将数据发送出去。


- 多线程和多进程区别

  多线程和多进程是并发编程中的两种常见方式，它们的主要区别在于：

  1. 资源占用：多进程需要独立的内存空间和系统资源，因此它的资源占用比多线程更大。而多线程共享进程的资源，因此资源占用较少。

  2. 通信方式：多进程之间的通信需要使用IPC（进程间通信）方式，如管道、消息队列、共享内存等。而多线程之间的通信可以直接使用共享变量、锁等线程同步机制。

  3. CPU利用率：多进程因为需要切换进程，因此CPU利用率较低。而多线程因为共享进程的资源，因此切换线程的开销较小，CPU利用率较高。

  4. 稳定性：多线程的稳定性较差，因为一个线程的崩溃可能会导致整个进程的崩溃。而多进程的稳定性较好，因为一个进程的崩溃不会影响其他进程的运行。

  5. 编程复杂度：多线程的编程复杂度较低，因为它不需要考虑进程间通信的问题。而多进程的编程复杂度较高，因为需要考虑进程间通信的问题。

  综上所述，多线程适用于需要共享资源、处理并发请求的场景，而多进程适用于需要处理大量计算密集型任务、需要提高系统稳定性的场景。

- 多进程和多线程的使用场景

  多线程和多进程都是并发编程的实现方式，但是它们适用的场景不同。

  多线程适用于以下情况：

  1. 程序需要同时处理多个任务，但是每个任务的执行时间比较短，且需要共享数据。

  2. 程序需要同时处理多个任务，但是每个任务的执行时间较长，且需要频繁地进行IO操作。

  3. 程序需要实现GUI界面，需要同时处理用户的输入和输出。

  4. 程序需要实现网络编程，需要同时处理多个客户端请求。

  多进程适用于以下情况：

  1. 程序需要处理大量的计算密集型任务，需要充分利用多核CPU的性能。

  2. 程序需要保证高可靠性和安全性，需要将不同的任务分配给不同的进程，避免一个任务的错误影响其他任务。

  3. 程序需要利用多台机器的计算资源，需要通过进程间通信来协调不同机器上的任务。

  总之，多线程适合处理IO密集型任务，而多进程适合处理计算密集型任务。在实际应用中，需要根据具体情况选择合适的并发编程方式。

- 什么是协程，什么情况下可以使用协程

  协程（Coroutine）是一种轻量级的线程，与线程相比，协程的切换不需要操作系统介入，因此可以实现更高效的并发编程。

  协程可以用于需要处理大量IO操作的场景，例如网络编程、文件读写等。在这些场景中，线程会因为等待IO操作完成而被阻塞，而协程可以在等待IO操作的同时切换到其他任务，从而提高CPU利用率。

  协程的优势包括：

  1. 更轻量级：协程的切换不需要操作系统介入，因此比线程更轻量级，可以创建更多的协程。

  2. 更高效：协程的切换比线程更快，因此可以实现更高效的并发编程。

  3. 更容易编写和维护：协程的代码结构更简单，可以避免线程的锁和同步问题，从而更容易编写和维护。

  4. 更容易调试：协程的调试比线程更容易，因为协程的调用栈比线程更清晰。

  总之，协程是一种高效、轻量级、易于编写和维护的并发编程模型，可以帮助开发者更好地处理并发编程问题。

- 协程的切换在什么时候？

  协程的切换在以下几种情况下会发生：

  1. 当当前协程遇到阻塞操作，比如等待 I/O 操作完成或者等待其他协程的消息时，协程的控制权就会被剥夺并被切换出去，其他可执行的协程就会被调度到运行状态。

  2. 当一个协程主动放弃 CPU 运行权，比如调用 `runtime.Gosched()` 函数或者 `yield` 等操作时，协程也会被切换出去，让其他可执行的协程获得机会运行。

  3. 当一个协程正在等待另一个协程完成某个任务，比如等待另一个协程完成某个计算并返回结果时，也会发生协程的切换。

  4. 当多个协程同时等待同一个 Channel 的读写时，只有其中一个协程能够成功地进行读写操作，其他协程都会被阻塞，并被调度器挂起，等待机会再次获得运行权。

  需要注意的是，在协程的切换过程中，上下文信息需要保存在协程自己的栈中，以便于恢复执行状态。协程的切换不会切换进程，而是在同一进程内部进行。这也是协程相比线程更加轻量级的原因之一。

- 如果读写锁占用很长时间，并且后续还有读者不断占用读锁，这就造成了写者饥饿的问题，怎么解决？

  一种解决方法是使用写优先锁，即当写锁等待队列中有写请求时，读锁请求将被阻塞，直到写锁被释放。这样可以确保写锁不会被长时间占用，从而避免写者饥饿的问题。

  另一种解决方法是使用公平锁，即按照请求的先后顺序来分配锁资源。这样可以确保所有请求都有公平的机会获取锁资源，从而避免某些请求长时间等待的情况。

  无论采用哪种方法，都需要根据具体的场景和需求来选择合适的锁机制，并进行适当的优化和调整。


- 如果多个线程同时判断到当前对象未创建，应该怎么解决？

  如果多个线程同时判断到当前对象未创建，就可能会出现多个线程同时创建同一个对象的问题，这称为竞态条件（Race Condition）。为了解决这个问题，可以采用以下两种方法：

  1. 使用互斥锁

  可以使用互斥锁（Mutex）来保护资源的访问，当一个线程要访问共享资源时，首先尝试获得互斥锁，如果锁已经被其他线程占用，就必须等待锁被释放后才能访问，从而避免了多个线程同时创建同一个对象的情况。可以使用C++11提供的std::mutex来实现互斥锁。

  2. 使用双重检查锁定模式

  双重检查锁定模式（Double-Check Locking Pattern）是一种常见的单例模式的实现方式，可以避免多线程创建同一个对象的问题。具体实现方法如下：

  ```cpp
  class Singleton {
  private:
      static Singleton* instance;
      static std::mutex mtx;
  
      Singleton() {}
  
  public:
      static Singleton* getInstance() {
          if (instance == nullptr) { // 第一次检查
              std::lock_guard<std::mutex> lock(mtx); // 加锁
              if (instance == nullptr) { // 第二次检查
                  instance = new Singleton();
              }
          }
  
          return instance;
      }
  };
  
  Singleton* Singleton::instance = nullptr;
  std::mutex Singleton::mtx;
  ```

  在getInstance()函数中，第一次检查是为了提高效率，如果instance已经被创建，则可以直接返回；第二次检查是为了避免多个线程同时创建同一个对象，只有在获取到锁之后才会进行创建。这样，即使多个线程同时调用getInstance()函数，也不会创建多个对象。

  总之，在多线程编程中，需要特别注意竞态条件的问题，尽可能采用互斥锁、读写锁、信号量等同步机制来保护共享资源的访问。同时，在实现单例模式等共享资源的场景下，还需要特别注意线程安全的实现方式。

- 析构函数可以抛异常么？

  理论上析构函数可以抛出异常。但是，这样做可能会导致一些问题，因此通常不建议在析构函数中抛出异常。

  首先，如果析构函数抛出了异常，那么很可能导致对象没有完全被销毁。因为在抛出异常的情况下，程序会跳过后续的清理工作，导致对象没有被正确地析构。这可能会导致资源泄露等问题。

  其次，如果在析构函数中抛出了异常，并且该异常没有被捕获和处理，那么程序就会调用 `std::terminate` 函数来结束程序运行。这样可能会导致一些未预料到的问题，比如内存泄漏和数据损坏等。

  因此，最好的做法是在析构函数中避免抛出异常。如果必须要在析构函数中抛出异常，那么建议在析构函数中进行必要的安全措施，以确保在抛出异常的情况下对象能够被正确地销毁。同时，也需要在代码中进行相应的异常处理，以避免程序调用 `std::terminate` 函数而崩溃。

- 怎么用 C++ 读取进程的内存占用情况

  要读取进程的内存占用情况，需要使用 Linux 系统的 /proc 文件系统。/proc 文件系统是 Linux 内核提供的一种虚拟文件系统，它可以让用户程序直接访问内核数据结构，包括系统信息、进程信息等。

  以下是使用 C++ 读取进程内存占用情况的代码示例：

  ```cpp
  #include <iostream>
  #include <fstream>
  #include <string>
  
  using namespace std;
  
  int main() {
      int pid = 1234; // 进程 ID
      string mem_file = "/proc/" + to_string(pid) + "/statm"; // 进程内存信息文件路径
      ifstream ifs(mem_file); // 打开文件
      if (!ifs) {
          cerr << "Failed to open file: " << mem_file << endl;
          return 1;
      }
      int size, resident, shared; // 内存占用信息
      ifs >> size >> resident >> shared; // 读取文件内容
      ifs.close(); // 关闭文件
      cout << "Process memory usage:" << endl;
      cout << "Size: " << size << " pages" << endl;
      cout << "Resident: " << resident << " pages" << endl;
      cout << "Shared: " << shared << " pages" << endl;
      return 0;
  }
  ```

  上述代码中，我们通过读取 /proc/[pid]/statm 文件来获取进程的内存占用情况。该文件的第一行包含了三个数字，分别表示进程的总内存大小（单位为页面）、进程的驻留内存大小（单位为页面）和进程的共享内存大小（单位为页面）。我们可以通过 ifstream 类来打开文件，并使用流操作符来读取文件内容。读取完毕后，记得关闭文件流。最后，我们将读取到的内存占用信息输出到控制台。

  需要注意的是，/proc 文件系统的某些文件只能被 root 用户或进程本身访问，因此在读取某些进程的内存占用情况时，可能需要以 root 用户或者该进程的身份来运行程序。

- 先来先服务和短作业优先适用于哪种类型的操作系统？

  先来先服务和短作业优先算法适用于不同类型的操作系统。

  先来先服务算法适用于批处理操作系统，作业通常按照提交的顺序进行处理，所以先来先服务算法很适合。在这种情况下，作业按照先后顺序依次进入队列，CPU依次执行每个作业，直到该作业执行完毕或者阻塞，才会执行下一个作业。

  短作业优先算法适用于实时操作系统，可以确保较短的任务获得更快的响应时间，从而满足实时性要求。在这种情况下，作业的执行时间需要预测或估计，优先执行执行时间短的作业，可以避免长作业的饥饿现象，同时也可以提高系统的响应速度。

  因此，先来先服务和短作业优先算法适用于不同类型的操作系统，需要根据不同的场景选择合适的算法才能更好地满足系统的需求。


# Linux

- CPU占用过高如何检测？

1. 使用top命令，实时显示进程CPU百分比和内存使用情况，找出CPU占用较高的进程pid。

2. 使用ps命令，查询进程中哪个线程的cpu占用率高，记住TID：`ps -mp pid -o THREAD,tid,time`。

   其中，-m显示所有的线程，-p表示pid进程使用cpu的时间，-o表示该参数后是用户自定义格式，如：THREAD,tid,time表示线程、线程ID号、线程占用的时间。

3. 将TID转换为16进制格式（英文小写格式） `printf “%x\n” tid`

4. 通过`jstack`命令获取占用资源异常的线程栈：

   ```php
   jstack pid > jstack.pid.log #先保存文件，再从文件中查看
   或者
   jstack 514 |grep 202 -A 30  #直接命令行查看
   ```

5. 从上面日志文件或者命令行查看日志，从日志中能看到自己编写的代码的类和方法，一般情况是对应代码处产生了死循环。

- kill和kill -9的区别

kill和kill -9，两个命令在linux中都有杀死进程的效果。执行kill命令，系统会发送一个`SIGTERM`信号给对应的程序。程序接收到该信号后，会先释放自己的资源，然后再停止。但是也有程序可能接收信号后，做一些其他的事情（如果程序正在等待IO，可能就不会立马做出响应），也就是说，SIGTERM多半是会被阻塞的。而`kill -9`命令，系统给程序发送的信号是`SIGKILL`，即exit。exit信号不会被系统阻塞，所以kill -9能顺利杀掉进程。

- 写时拷贝

写时拷贝（copy on write, COW）。

父进程 fork 出的子进程与父进程共享内存空间，一开始父进程的数据不会复制给子进程，这样创建子进程的速度就很快了 (不用复制，直接指向父进程的物理空间)。只有当父子进程中有写入操作，再为子进程分配相应的物理空间。

fork之后，内核把父进程中所有的内存页的权限设置为只读，然后子进程的地址空间指向父进程，与父进程共享数据。当父子进程都只读内存时，正常执行。当某个进程写内存时，CPU检测到内存页是只读的，就会触发页异常中断，内核就会把触发异常的页复制一份出来，这样父子进程就各自持有独立的异常页（其余的页还是共享父进程的）。

写时拷贝可以减少分配和复制大量资源时带来的时间消耗；检查不必要的资源分配，比如fork进程时，并不是所有的页面都需要复制，父进程的代码段和只读数据段都不被允许修改，所以无需复制。

- gdb调试多进程、多线程

- GDB调试多线程

  1. info threads 显示当前可调式的所有线程 

  2. thread ID 切换当前调试的线程为指定ID的线程

  3. thread apply all command 所以的线程都执行command命令

  4. thread apply ID1,ID2.... command  指定线程执行command命令

  5. set scheduler-locking off|on|step： 
     在使用step或continue命令调试当前被调试线程的时候，其他线程也是同时执行的，如果我们只想要被调试的线程执行，而其他线程停止等待，那就要锁定要调试的线程，只让它运行。 
     - off：不锁定任何线程，所有线程都执行。 
     - on：只有当前被调试的线程会执行。 
     - step：阻止其他线程在当前线程单步调试的时候抢占当前线程。只有当next、continue、util以及finish的时候，其他线程才会获得重新运行的
  6. show scheduler-locking： 查看当前锁定线程的模式
  7. i threads 实现线程间切换

- GDB调试多进程

  1. 设置方法

     ```
     set follow-fork-mode [parent][child] 
     set detach-on-fork [on|off] 
     ```

  2. 查看上述两个属性的值

     ```
        show follow-fork-mode //查看系统默认的模式
        show detach-on-fork
        /* 
        	parent                   on               只调试主进程（GDB默认）
        	child                    on               只调试子进程
        	parent                   off              同时调试两个进程，gdb跟主进程，子进程block在fork位置
        	child                    off              同时调试两个进程，gdb跟子进程，主进程block在fork位置
        */
     ```

  3. 查询正在调试的进程

     ```
     info inferiors  //查询正在调试的进程
     inferior 进程编号 // 切换调试的进程
     ```

  4. add-inferior [-copies n] [-exec executable] //添加新的调试进程

  5. detach inferior [进程编号] //释放掉 

  6. kill inferior [进程编号] 

  7. remove-inferior [进程编号] //删除该进程

  8. set schedule-multiple 

  9. set print interior-events on/off

- 如何调试死锁

- 借助Core Dump。在程序莫名其妙down掉了，此时操作系统会把当前的内存状况存储在一个core文件中，通过查看core文件就可以直观的看到程序是因为什么而垮掉了。有时候程序down了，但是core文件却没有生成，core文件的生成跟当前系统的环境设置有关系，可以用下面的语句设置一下，然后再运行程序便会生成core文件。

  ```bash
  ulimit -c unlimited
  ```

  core文件生成的位置一般于运行程序的路径相同，文件名一般为core.进程号。

  那么如何在多线程调试中使用Core Dump：

  1. 使用 kill 命令产生 core dump文件：`kill -11 pid`产生core文件。
  2. 使用gdb工具打开core文件：`gdb dead_lock_demo core`
  3. 打印堆栈信息：`thread apply all bt`

- gdb调试core文件

在一个程序崩溃时，它一般会在指定目录下生成一个core文件。core文件仅仅是一个内存映象(同时加上调试信息)，主要是用来调试的。通过core文件调试步骤：

1. ulimit -c unlimted（打开core，默认没有打开）
2. 运行./a.out（编译的时候加调试选项-g） 死锁阻塞,Ctrl+\ 产生core dump
3. gdb ./a.out core.xxx
4. thread apply all bt查看死锁位置

- 怎么使一个命令在后台运行?

  使用 & 在命令结尾来让程序自动运行。(命令后可以不追加空格)

- 用什么命令对一个文件的内容进行统计？(行号、单词数、字节数)

  wc ：- c 统计字节数 - l 统计行数 - w 统计字数。(word count)

- scp：本地和远程互传文件

- ps：查看当前进程

  ![img](https://gcore.jsdelivr.net/gh/gp868/myFigures/img/818047-20200905084700484-530981088.png)

- top：可实时显示进程CPU百分比和内存使用情况

  [Linux top命令详解 - 牛奔 - 博客园 (cnblogs.com)](https://www.cnblogs.com/niuben/p/12017242.html)

  ![img](https://gcore.jsdelivr.net/gh/gp868/myFigures/img/1303876-20191210152709726-52408463.png)

- job：查看后台任务

- lsof：查看所有被进程打开的文件(list opened files)

- 如何查看进程打开的文件

  - ps -aux 获得当前所有的进程，获得pid
  - lsof -p $PID
  - lsof -c programe-name
  - 看文件对应的进程： lsof file-name

- 介绍nm与ldd命令

  - nm (name) ：查看文件中的符号表，如常用的函数名、变量等，以及这些符号存储的区域，`nm [option(s)] [file(s)]`
  - ldd (list dynamic dependencies)：列出程序运行所需要的动态链接库，`ldd 可执行程序路径`

- shell命令查内存，端口 ，io访问量，读写速率

  - top监控系统状态

- 常见命令netstat iptable tcpdump top

  - tcpdump：root权限下使用的抓包工具，只能抓取流经本机的数据包
  - netstate：用于显示网络状态，netstate -a 显示所有连线中的socket
  - top：监控Linux的系统状况
  - iptables：对Linux系统中通信的数据包进行一定的检测，达到防火墙的目的

- gdb查看堆栈中所有遍历

  可以使用gdb的backtrace命令来查看堆栈中所有的遍历。

  步骤如下：

  1. 在终端中使用gdb命令打开要调试的程序。

  2. 在gdb中输入run命令以运行程序。

  3. 当程序出现问题时，使用ctrl+c来中断程序的执行。

  4. 输入backtrace命令来查看堆栈中所有的遍历。

  例如：

  ```
  (gdb) backtrace
  #0 0x0000000000400520 in main ()
  #1 0x00007ffff7a1e830 in __libc_start_main (main=0x400510, argc=1, argv=0x7fffffffe1d8, init=<optimized out>, fini=<optimized out>, rtld_fini=<optimized out>, stack_end=0x7fffffffe1c8) at libc-start.c:291
  #2 0x00000000004003d9 in _start ()
  ```

- ctrl+c 发的是什么信号

  Ctrl+C：发送 SIGINT 信号（程序终止(interrupt)信号）给前台进程组中的所有进程，常用于终止正在运行的程序；

  Ctrl+Z：发送 SIGTSTP 信号（停止进程的运行，但该信号可以被处理和忽略）给前台进程组中的所有进程，常用于挂起一个进程。如果需要恢复到前台使用fg命令，恢复到后台使用bg命令。

  Ctrl+D：不是发送信号，而是表示一个特殊的二进制值，表示 EOF。EOF是End Of File的缩写，通常在文本末尾使用此字符表示文本结束。

- Linux如何查服务运行在哪个端口？

  Linux可以使用以下命令来查找服务运行在哪个端口：

  1. netstat命令

  使用netstat命令可以列出当前系统上所有的网络连接和监听端口。可以使用以下命令来查找某个服务所使用的端口：

  ```
  netstat -anp | grep 服务名
  ```

  其中，-a表示列出所有的连接和监听端口，-n表示以数字形式显示端口号，-p表示显示与端口相关的进程信息，grep用于查找服务名。

  2. lsof命令

  lsof是一个可以列出当前系统打开的所有文件和网络连接的工具。可以使用以下命令来查找某个服务所使用的端口：

  ```
  lsof -i :端口号
  ```

  其中，-i表示查找网络连接，:端口号表示要查找的端口号。

  3. ss命令

  ss是一个更快速和更高效的netstat替代品，可以用来列出当前系统上所有的网络连接和监听端口。可以使用以下命令来查找某个服务所使用的端口：

  ```
  ss -ant | grep 端口号
  ```

  其中，-a表示列出所有的连接和监听端口，-n表示以数字形式显示端口号，-t表示只列出TCP连接，grep用于查找端口号。

- chmod 741 代表什么

  文件权限主要有3部分组成，user用户的权限，group用户组的权限，other其他用户的权限；每部分权限都由 r(读)-w(写)-x(执行) 3部分组成组成，其中的代表数值为： r(4)-w(2)-x(1) ，修改权限的时候，只要通过命令给文件赋予对应的值即可。

  chmod 741 myFile #这里是修改myFile文件，这里的的741每个数字分别代表着不同部分的权限，user 用户赋予 (r-w-x =既4+2+1=7) 的权限，group 赋予 w(4) 权限，other 赋予 x(1) 权限

- Linux中du,df两个命令的区别

  Linux中du和df是两个常用的磁盘空间查询命令，它们的区别如下：

  1. du命令是用来查看指定目录或文件所占用的磁盘空间大小，它会递归地统计目录下所有文件和子目录的大小，并将结果显示出来；df命令是用来显示文件系统的磁盘空间使用情况，它会列出文件系统的名称、总容量、已用空间、可用空间和挂载点等信息。
  2. du命令的单位默认为字节，可以通过参数-k、-m、-g等来指定显示单位为KB、MB、GB等；df命令的单位默认为KB，可以通过参数-h、-H等来指定显示单位为可读性更好的GB、MB等。
  3. du命令只能查看指定目录或文件的大小，而df命令可以查看整个文件系统的磁盘空间使用情况。

  因此，du和df命令的作用不同，使用场景也不同。一般来说，du命令用于查看某个目录或文件所占用的空间大小，df命令用于查看文件系统的磁盘空间使用情况。

- Linux下的/var 目录有什么用

  在Linux中，`/var`目录主要用于存放在系统运行过程中动态产生的变化文件，包括缓存、日志文件和软件运行时需要的其他数据等。具体来说，`/var`目录下常见子目录的作用如下：

  - `/var/cache`: 存放被程序缓存的文件，例如apt等软件包管理器下载的软件包。
  - `/var/log`: 存放系统的日志文件，包括内核日志、应用程序日志、登录记录和错误日志等。在这个目录下，还有许多子目录可以进一步分类和存储不同类型的日志信息，例如`/var/log/messages`是记录系统消息的文件，`/var/log/auth.log`是记录身份验证相关信息的文件。
  - `/var/spool`: 存放需要等待处理的任务，例如邮件队列、打印队列等。
  - `/var/lib`: 存放某些软件的库文件、数据库等数据文件。例如MySQL数据库的数据文件默认就会存放在这个目录下。
  - `/var/run`: 存放正在运行的进程相关信息，例如PID文件等。

  需要注意的是，由于`/var`目录下的文件通常是动态生成的，因此其中的数据可能随着时间的推移不断增长，占用硬盘空间。因此，在设计文件系统的时候，我们需要考虑给`/var`目录足够的空间，并及时清理其中不必要的或已经过期的文件。



# 单例模式

实现思路：私有化它的构造函数，以防止外界创建单例类的对象；使用类的私有静态指针变量指向类的唯一实例，并用一个公有的静态方法获取该实例。

单例模式有两种实现方法，分别是**懒汉**和**饿汉**模式。懒汉模式在第一次被使用时才进行初始化，饿汉模式在程序运行时立即初始化。

```cpp
// 经典懒汉式，使用双检测锁
class single{
public:
    static single* getinstance();
private:
    static single* p;
    static pthread_mutex_t lock;
    single(){
        pthread_mutex_init(&lock, NULL);
    };
    ~single(){};
}

pthread_mutex_t single::p;
single* single::p = NULL;
single* single::getinstance(){
    if(p ==NULL){
        pthread_mutex_lock(&lock);
        if(p == NULL){
            p = new single();
        }
        pthread_mutex_unlock(&lock);
    }
    return p;
} 
    
// 懒汉式
class single{
public:
    static single* getinstance();
private:
    single(){};
    ~single(){};
}

single* single::getinstance(){
    static single p;
    return &p;
}

// 饿汉式
class single{
public:
    static single* getinstance();
private:
    single(){};
    ~single(){};
    static single* p;
}
single* single::p = new single();
single* single::getinstance(){
	return p;
}
```

经典懒汉式为什么要用双检测，只检测一次不行吗？

如果只检测一次，在每次调用获取实例的方法时，都需要加锁，这将严重影响程序性能。双层检测可以有效避免这种情况，仅在第一次创建单例的时候加锁，其他时候都不再符合NULL == p的情况，直接返回已创建好的实例。

# 情景

- 有一个很大的文件（1w个字符以上）通过多线程异步来统计里面出现次数最多的单词，说一说设计思路，手撕算法

  多线程异步统计单词出现次数可以采用以下设计思路：

  1. 读取文件：将文件按照大小平均分成若干个区块，每个线程负责读取一个区块中的内容，并将读取到的字符串传递给后续的单词统计线程。

  2. 单词切分：由于文件中包含空格、标点符号等字符，因此需要对每个字符串进行单词切分，即将字符串切分成若干个单词。在单词切分过程中，需要注意去掉单词中的大小写、特殊字符等非单词元素，将其转换成小写字母。

  3. 单词计数：将每个单词保存在一个哈希表中，并记录单词出现的次数。当所有线程执行完毕后，将各个线程统计得到的哈希表合并起来，得到最终的单词统计结果。

  根据以上设计思路，可以编写以下伪代码实现：

  ```c++
  // 定义哈希表结构体
  struct HashTable {
      std::unordered_map<std::string, int> table;
      std::mutex mtx;  // 哈希表锁
  };
  
  // 定义单词统计函数
  void wordCount(const std::string& str, HashTable& ht) {
      std::stringstream ss(str);
      std::string word;
      while (ss >> word) {  // 循环取出每个单词
          std::transform(word.begin(), word.end(), word.begin(), ::tolower);  // 转换为小写
          for (auto& c : word) {  // 去除标点符号等非单词元素
              if (!isalpha(c)) {
                  c = ' ';
              }
          }
          std::stringstream ss_word(word);
          while (ss_word >> word) {  // 把单词插入哈希表中
              std::lock_guard<std::mutex> lock(ht.mtx);  // 加锁
              ++ht.table[word];  // 单词计数
          }
      }
  }
  
  int main() {
      std::ifstream ifs("filename.txt");
      std::vector<std::future<void>> futures;
      HashTable ht;
  
      // 计算出每个线程要处理的字符数
      const int num_threads = std::thread::hardware_concurrency();
      const int block_size = fs::file_size("filename.txt") / num_threads;
      const int remain_size = fs::file_size("filename.txt") - block_size * num_threads;
  
      for (int i = 0; i < num_threads; ++i) {
          int start_pos = i * block_size;
          int end_pos = (i + 1) * block_size - 1;
          if (i == num_threads - 1) {
              end_pos += remain_size;
          }
  
          // 异步读取文件
          futures.emplace_back(std::async(std::launch::async, [start_pos, end_pos, &ifs, &ht] {
              ifs.seekg(start_pos);
  
              // 读取完整的一行
              std::string line;
              std::getline(ifs, line);
              const size_t len = line.length();
  
              // 读取部分行数据
              if (ifs && !line.empty() && start_pos != end_pos) {
                  for (size_t i = len; i < block_size && ifs; ++i) {
                      char c;
                      ifs.get(c);
                      if (ifs.eof()) break;
                      line += c;
                      if (c == '\n') break;
                  }
              }
  
              // 统计单词出现次数
              wordCount(line, ht);
          }));
      }
  
      // 等待所有线程执行完成
      for (auto& future : futures) {
          future.wait();
      }
  
      // 输出结果
      for (const auto& item : ht.table) {
          std::cout << item.first << ": " << item.second << std::endl;
      }
  
      return 0;
  }
  ```

  以上代码实现了多线程异步读取文件，并统计其中出现次数最多的单词。其中使用了哈希表来保存单词和出现次数的映射关系，并利用互斥锁来确保多线程操作哈希表时的安全性。

- 写一个宏，表示求 a 和 b 的最小值

  可以使用以下宏定义来表示求 a 和 b 的最小值：

  ```c++
  #define MIN(a, b) ((a) < (b) ? (a) : (b))
  ```

  这个宏定义接受两个参数 a 和 b，然后用三目运算符来比较它们的大小，并返回较小的值。需要注意的是，在比较 a 和 b 的大小时，要用括号将它们括起来，以避免在宏替换时产生错误。

  使用这个宏定义求 a 和 b 的最小值的示例代码如下：

  ```c++
  #include <iostream>
  
  #define MIN(a, b) ((a) < (b) ? (a) : (b))
  
  int main() {
      int a = 10, b = 20;
      std::cout << "MIN(" << a << ", " << b << ") = " << MIN(a, b) << std::endl;
      return 0;
  }
  ```

  输出结果为：

  ```cpp
  MIN(10, 20) = 10
  ```

- 一个不知道头节点的单链表，如何在p节点前插入一个节点

  这个问题需要分两种情况来讨论。

  第一种情况是p节点是头节点。如果不知道头节点，那么我们可以先遍历整个链表，找到第一个节点，然后将新节点插入到它的前面。代码如下：

  ```python
  # 定义链表节点类
  class ListNode:
      def __init__(self, val=0, next=None):
          self.val = val
          self.next = next
  
  def insert_before_p(head: ListNode, p: ListNode, new_node: ListNode) -> ListNode:
      # 如果p节点是头节点
      if p == head:
          new_node.next = head
          return new_node
  
      # 遍历链表，找到p节点的前一个节点
      cur = head
      while cur.next != p:
          cur = cur.next
  
      # 将新节点插入到p节点的前面
      cur.next = new_node
      new_node.next = p
      return head
  ```

  第二种情况是p节点不是头节点。如果不知道头节点，那么我们可以先遍历整个链表，找到p节点的前一个节点，然后将新节点插入到它的后面。代码如下：

  ```python
  # 定义链表节点类
  class ListNode:
      def __init__(self, val=0, next=None):
          self.val = val
          self.next = next
  
  def insert_before_p(head: ListNode, p: ListNode, new_node: ListNode) -> ListNode:
      # 遍历链表，找到p节点的前一个节点
      cur = head
      while cur.next != p:
          cur = cur.next
  
      # 将新节点插入到p节点的前面
      cur.next = new_node
      new_node.next = p
      return head
  ```

  注意，这两种情况的代码是不一样的。在第一种情况中，如果p节点是头节点，那么新节点的next指针应该指向原来的头节点；在第二种情况中，新节点的next指针应该指向p节点。

- 不用变量交换两个整型有什么方式

  有几种方式可以不用变量来交换两个整型的值，其中比较常见的方式包括：

  1. 算术运算法：利用加、减法运算来实现交换。具体来说，设有两个整型变量`a`和`b`，则可以使用如下的算术运算法交换它们的值：

  ```cpp
  a = a + b;
  b = a - b;
  a = a - b;
  ```

  上面的代码将`a`与`b`的值交换了。

  2. 异或运算法：利用异或运算来实现交换。具体来说，设有两个整型变量`a`和`b`，则可以使用如下的异或运算法交换它们的值：

  ```cpp
  a = a ^ b;
  b = a ^ b;
  a = a ^ b;
  ```

  上面的代码同样将`a`与`b`的值交换了。

  需要注意的是，这两种方法虽然可以在不使用中间变量的情况下交换两个整型变量的值，但是在某些特殊情况下可能会导致数据溢出或者其他问题，因此在实际应用中需要慎重考虑。另外，使用中间变量来交换两个值也是一种比较常见的、通用的方式，同时也更加安全可靠。


- 怎么用程序判断一个系统是大端字节序还是小端字节序

  - 大段字节序：数据的低位存储在高地址位，数据的高位存储在低地址位，大端字节序称为MSB；
  - 小段字节序：数据的低位存储在低地址位，数据的高位存储在高地址位，小端字节序称为LSB；

  ```cpp
  #include <stdio.h>
  
  int main()
  {
      int  a = 0x12345678;
      char *p = NULL;
      p = (char *)&a;
      if(*p == 0x78)
      {
          printf("小端字节序\n");
      }
      else if(*p == 0x12)
      {
           printf("大端字节序\n");
      }
      printf("%x\n",*p);   
      return 0;
  }
  ```

  指针将会指向整型数的首地址，而当我们调用 *p 往地址里取值时，系统会根据指针的类型的大小取对应大小的值。

  例如，char类型的指针就会从他指向的地址往后取char类型（1个字节）大小的值。所以，当我们使用char类型的指针指向一个int类型的数，再通过 *p 取值时，只会去取其低地址位的1个字节的内容。

  如果结果是 *p = 0x78，说明在地址中，低地址位存储了该数据的低位，就可以判断系统是小端字节序；如果 *p = 0x12，则说明低地址位存储了数据的高位，可判断系统是大端字节序。

- 如何实现一个守护进程

  实现一个守护进程的一般步骤如下：

  1. 在父进程中调用fork()函数，然后在子进程中调用setsid()函数，创建新的会话，并使子进程成为会话组长和进程组长。

  2. 在子进程中再次调用fork()函数，然后在子进程中退出，使子进程不再是进程组长，从而保证它不能获取控制终端。

  3. 在子进程中修改当前目录为根目录，以避免守护进程的工作目录被卸载的文件系统影响。

  4. 在子进程中关闭所有不需要的文件描述符，以避免守护进程对终端、网络等资源的依赖。

  5. 在子进程中执行守护进程的核心逻辑，例如读取配置文件、初始化资源等。

  6. 在守护进程的核心逻辑执行完毕后，调用exit()函数退出子进程。

  示例代码如下：

  ```cpp
  #include <unistd.h>
  #include <stdlib.h>
  #include <stdio.h>
  #include <sys/stat.h>
  #include <fcntl.h>
  #include <string.h>
  
  int main() {
      pid_t pid = fork();
      if (pid < 0) {
          perror("fork error");
          exit(1);
      } else if (pid > 0) {
          exit(0);
      }
  
      // 子进程
      setsid(); // 创建新的会话
  
      pid = fork();
      if (pid < 0) {
          perror("fork error");
          exit(1);
      } else if (pid > 0) {
          exit(0);
      }
  
      // 子进程
      chdir("/"); // 修改当前目录为根目录
      umask(0); // 设置文件权限掩码为0
  
      int maxfd = getdtablesize(); // 获取文件描述符的最大数量
      for (int i = 0; i < maxfd; i++) {
          close(i); // 关闭所有不需要的文件描述符
      }
  
      // 执行守护进程的核心逻辑
      while (1) {
          // TODO: 守护进程的核心逻辑
      }
  
      exit(0);
  }
  ```

  在上面的代码中，首先调用fork()函数创建子进程，然后在子进程中调用setsid()函数创建新的会话，并使子进程成为会话组长和进程组长。接着再次调用fork()函数，然后在子进程中退出，使子进程不再是进程组长，从而保证它不能获取控制终端。然后修改当前目录为根目录，设置文件权限掩码为0，关闭所有不需要的文件描述符，最后执行守护进程的核心逻辑。









