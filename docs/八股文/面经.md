# 面经

# cpp

## 语言基础

- i++和++i 的区别，哪个效率高？i++线程安全吗？

  1. 区别：

  - i++是先赋值，然后再自增；++i是先自增，后赋值；
  - i++ 不能作为左值，而++i可以；

  2. 效率：

  当考虑自定义类的时候，两者效率有区别。

  i++是先用临时对象保存原来的对象，然后对原对象自增，再返回临时对象，不能作为左值；++i是直接对原对象进行自增，然后返回原对象的引用，可以作为左值。

  由于要生成临时对象，i++需要调用两次拷贝构造函数与析构函数（将原对象赋给临时对象一次，临时对象以值传递方式返回一次）；++i由于不用生成临时变量，且以引用方式返回，故没有构造与析构的开销，效率更高。

  所以在使用类等自定义类型的时候，应尽量使用++i。

  3. 线程安全：

  - 如果i是局部变量（在方法里定义的），那么是线程安全的。因为局部变量是线程私有的，别的线程访问不到；

  - 如果i是全局变量（类的成员变量），那么是线程不安全的。因为如果是全局变量的话，同一进程中的不同线程都有可能访问到。

- i++操作是否能保证线程安全

  i++ 操作本质上不是线程安全的，因为它包含了读取和更新操作，这些操作可能会被多个线程同时执行，导致竞态条件（Race Condition）的出现。在多线程环境中，如果多个线程同时对同一个变量进行读取和更新操作，那么就可能会出现数据不一致的问题。

  例如，当一个线程在执行 i++ 操作时，可能会读取 i 的值并将它加1，但是在执行加1操作之前，另一个线程也可能读取i的值并进行加1操作，这样就会导致 i 的值只增加了1，而不是增加了2。这种情况称为竞态条件。

  为了避免竞态条件的出现，可以使用同步机制来保证 i++ 操作的线程安全。例如，可以使用互斥锁（Mutex）来保护对 i 的访问，确保每次只有一个线程可以访问 i，从而避免竞态条件的出现。此外，还可以使用原子操作来实现 i++ 操作的线程安全，原子操作可以确保对 i 的读取和更新操作是不可分割的，从而避免了竞态条件的出现。

  需要注意的是，单个的 i++ 操作可能不会导致竞态条件的出现，因为编译器会将它编译成原子指令。但是，如果在多线程环境中多次执行 i++ 操作，就可能会出现竞态条件的问题。因此，在多线程环境中，应该总是使用同步机制来保证对共享变量的访问是线程安全的。

- 函数指针和指针函数的区别？

  - 函数指针：int (*f)(int x, int y);

  - 指针函数：int *f(int x, int y);

  函数指针本质是一个指针，其指向一个函数；指针函数本质是一个函数，其返回值为指针。

- 回调函数和普通函数的区别

  回调函数（Callback Function）是指在函数运行过程中，将函数指针作为参数传递给另一个函数，并在另一个函数中调用该函数指针，从而完成一定的操作。普通函数则是指没有回调机制，直接按照函数的定义和调用方式执行的函数。 回调函数和普通函数的主要区别如下：

  1. 使用方式不同：回调函数是将函数指针作为参数传递给另一个函数，并在另一个函数中调用该函数指针；而普通函数则是直接按照函数的定义和调用方式执行的函数。
  2. 调用时机不同：回调函数的调用时机是由另一个函数来确定，一般在某个事件发生时被回调；而普通函数的调用时机则是由函数的调用者来确定。
  3. 灵活性不同：由于回调函数是将函数指针作为参数传递，因此可以在运行时动态指定要调用的函数，从而使程序更加灵活；而普通函数则是在编译时确定的，不具备动态性。
  4. 作用不同：回调函数主要用于事件驱动型程序中，例如GUI程序、操作系统等；而普通函数则是用于完成特定的功能。

  需要注意的是，回调函数和普通函数并不是完全独立的概念，有些函数既可以作为普通函数使用，也可以作为回调函数使用。

- 静态变量的初始化时间

  - 静态初始化，用常量来对静态变量进行初始化

    在main()函数之前，程序加载时初始化；

  - 动态初始化，需要调用函数才能完成的初始化，比如类的构造函数

    全局静态变量或者类的静态成员变量，是在main()函数执行前，运行时初始化；局部静态变量在函数第一次执行到该初始化语句时初始化。


- const int* a, int* const a, int const* a 的区别

  - const int* a：指针指向地址的内容不能被改变，但是指针指向的地址可以更改；
  - int const* a：和const int* a相同；
  - int* const a：指针指向的地址不能更改，但是指针指向地址的内容可以更改；

- int a[10]; 这个数组的数组变量和数组内容都是存在哪里的？

  数组变量存储在栈内存中：在 C++ 中，数组变量是一个指向数组首元素的指针，它存储在栈内存中。对于 `int a[10];` 这个数组变量，它在内存中的存储位置是栈内存的某个位置，用于存储指向数组首元素的指针。

  数组内容存储在堆内存或栈内存中：数组内容存储在内存中的位置取决于数组的定义方式和存储位置。对于 `int a[10];` 这个数组，它是在函数栈内存中定义的，其内容也存储在栈内存中。而对于使用 new 运算符动态分配内存的数组，则其内容存储在堆内存中。

- 指针数组和数组指针的区别？

  数组指针本质是指针，是指向数组的指针；指针数组本质是数组，是保存指针的数组。

  ```c
  int (*p)[4]; // 数组指针
  // int类型的指针p指向int[4]数组首地址，数组的每一个元素是一个int类型的变量，数组大小为4
  int *p[4];  // 指针数组
  // 数组长度为4，所有元素均为int类型的指针
  ```

- 求一个表达式的值：

  ```c
  int a = (int)(((int*)0)+4);  
  ```

  a =16，相当于把`(int*)`，这个整形指针加4，即移动`4*sizeof（int）`个字节，即16个字节，然后把这个指针转为int就是16，`(int*)0`地址0，加上16字节后，为0x00000010。

- 下面这段代码最终打印什么

  ```c
  int main () {
    fork();
    fork();
    fork();
    printf("hello world\n");
    exit(0);
  }
  // 打印2的3次方即8行hello world
  int main()
  {
  	fork();
  	printf("hello\n");
  	fork();	
  	printf("hello\n");
  }
  // 打印6行hello world
  ```

- const int func(const char *const p) const 四个 const 的作用

  1. const修饰函数返回值，可以防止函数返回值被修改；
  2. 指针指向地址的内容不可更改；
  3. 指针指向的地址不可以更改；
  4. const修饰类成员函数，可以防止成员函数修改对象的内容；

- assert 函数说一下？abort 函数调用后程序会咋样？

  `assert` 是宏，而不是函数。它的原型定义在头文件 assert中：

  ```c
  void assert( int expression );
  ```

  宏 assert 经常用于在函数开始处检验传入参数的合法性，可以将其看作是异常处理的一种高级形式。assert 的作用是先计算表达式expression，然后判断：

  - 如果表达式值为假，那么它先向 stderr 打印错误信息，然后通过调用 abort 来终止程序运行；
  - 如果表达式值为真，继续运行后面的程序；

  注意：`assert` 只在 `DEBUG` 下生效，在调试结束后，可以通过在 `#include <assert.h>` 语句之前插入 `#define NDEBUG` 来禁用 assert 调用。频繁的调用assert函数会极大的影响程序的性能，增加额外的开销。

  ```c
  #define NDEBUG
  #include <assert.h>
  ```

  abort()函数的原型位于头文件cstdlib（或stdlib.h）中，作用是异常终止一个进程，意味着abort后面的代码将不再执行。调用abort()时，不进行任何清理工作，直接终止程序。abort()函数通过发出一个SIGABRT信号终止程序的执行。

- 二维数组的按行和按列获取元素顺序有什么异同，哪个效果好，为什么

  按行获取时，同一行的元素在内存中是连续存储的；而按列获取时，同一列的元素在内存中不是连续存储的。

  - 对于连续遍历所有元素的情况，按行获取效果更好。因为按行获取的元素在内存中是连续存储的，这样可以充分利用 CPU 缓存，提高程序的运行效率。
  - 对于查找某一行或某一列的所有元素的情况，按列获取效果更好。按列获取元素的优点是可以利用程序的局部性原理，因为二维数组在内存中是连续存储的，所以在按列获取元素时，CPU可以预先将该列的所有元素加载到缓存中，这样可以减少CPU的缓存失效率，提高程序的效率。

  综上所述，如果需要遍历所有元素，建议按行获取；如果需要查找某一行或某一列的所有元素，建议按列获取。

- 运算符重载和函数重载的区别

  函数重载是指在同一作用域内的若干个参数特征不同的函数可以使用相同的函数名字；运算符重载是指同一个运算符可以施加于不同类型的操作数上面。就是对已有的运算符重新进行定义，赋予其另一种功能，以适应不同的数据类型。

  1. 定义方式不同：运算符重载是通过在函数名前加上运算符关键字和符号来定义的，例如重载加法运算符可以使用`operator+`来定义；而函数重载是在函数名相同的情况下，通过参数列表的不同来定义的。
  2. 使用方式不同：运算符重载可以像使用内置运算符一样来使用，例如 `a+b`，其中 `+` 运算符被重载了；而函数重载需要在调用时根据传递的参数列表来确定具体调用哪个函数。
  3. 限制不同：运算符重载只能重载 C++ 中现有的运算符，而函数重载可以重载任何函数名。
  4. 返回值类型不同：运算符重载的返回值通常是运算结果，而函数重载的返回值可以是任何类型。
  5. 参数个数不同：运算符重载通常只有一个参数，即运算符左侧的操作数，但有些运算符重载可能有两个参数，例如重载赋值运算符 `operator=`；而函数重载可以有任意数量的参数。

- 内存对齐有什么用？

  内存对齐是指在分配内存时，按照一定的规则和字节对齐方式分配，使得数据存储在内存中的地址能够被 CPU 高效地访问，从而提高程序的执行效率和性能。 内存对齐的主要作用有以下几个方面：

  1. 提高访问效率：CPU 访问对齐的数据的速度是非对齐数据的速度的两倍。这是因为对于对齐的数据，CPU 可以通过一次内存读取操作就能够读取到所需的数据，而对于非对齐的数据，CPU 需要进行两次内存读取操作，从而造成额外的开销。
  2. 保证数据结构的正确性：内存对齐可以保证数据结构中的每个元素都被正确地存放在其应该存放的地址上，从而避免了数据被错误地访问或修改的情况。
  3. 与硬件的兼容性：一些硬件设备要求数据必须按照一定的规则和字节对齐方式存储，否则可能会引起硬件异常或错误。
  4. 提高缓存效率：CPU 的缓存系统通常也需要对数据进行对齐。如果数据没有按照对齐的方式存储，可能会造成缓存失效，从而降低程序的执行效率。 

  总之，内存对齐是一种优化技术，可以提高程序的执行效率和性能。在编写程序时，应该尽可能地遵循内存对齐的规则，从而使程序更加高效、稳定和可靠。

  先来看下内存对齐的规则：

  1. 对于结构的各个成员，第一个成员位于偏移为0的位置，以后每个数据成员的偏移量必须是min(#pragma pack()指定的数，这个数据成员的自身长度) 的倍数。#pragma pack(n) 表示设置为n字节对齐，VC6默认8字节对齐；

  2. 在数据成员完成各自对齐之后，结构(或联合)本身也要进行对齐，对齐将按照#pragma pack指定的数值和结构(或联合)最大数据成员长度中，比较小的那个进行。

   ```c
  // 环境：vc6 + windows sp2
  #include <iostream>
  using namespace std;
  struct st1 {
      char a ;
      int  b ;
      short c ;
  };
  struct st2{
      short c ;
      char  a ;
      int   b ;
  };
  // sizeof(st1) is 12
  // sizeof(st2) is 8
   ```

  St1 ：char占一个字节，起始偏移为0 ，int 占4个字节，min(#pragma pack()指定的数，这个数据成员的自身长度) = 4（VC6默认8字节对齐），所以int按4字节对齐，起始偏移必须为4的倍数，所以起始偏移为4，在char后编译器会添加3个字节的额外字节，不存放任意数据。short占2个字节，按2字节对齐，起始偏移为8，正好是2的倍数，无须添加额外字节。到此规则1的数据成员对齐结束，此时的内存状态为：

  ```c
  oxxx|oooo|oo
  0123 4567 89 （地址）
  （x表示额外添加的字节）
  ```

  共占10个字节，还要继续进行结构本身的对齐。对齐将按照#pragma pack指定的数值和结构(或联合)最大数据成员长度中，比较小的那个进行，st1结构中最大数据成员长度为int，占4字节，而默认的#pragma pack 指定的值为8，所以结果本身按照4字节对齐，结构总大小必须为4的倍数，需添加2个额外字节使结构的总大小为12 。此时的内存状态为：

  ```c
  oxxx|oooo|ooxx
  0123 4567 89ab  （地址）
  ```

  到此内存对齐结束，St1占用了12个字节而非7个字节。St2 的对齐方法和st1相同，st2结构体总大小为8。

- 如何在 main 函数之前执行一些操作

  在 C++ 中，可以使用静态变量（static variable）和全局变量（global variable）来在 `main` 函数之前执行一些操作。因为静态变量和全局变量的初始化顺序是在 `main` 函数之前的。 

  具体来说，可以定义一个全局变量或静态变量，将其初始化为一个函数指针，在其构造函数中执行需要在 `main` 函数之前执行的操作。当程序启动时，全局变量和静态变量的构造函数会自动执行，从而实现在 `main` 函数之前执行一些操作。 

  下面是一个示例代码，演示了如何在 `main` 函数之前执行一些操作：

  ```c
  #include <iostream>
  using namespace std;
  class Init {
  public:
      Init() {
          cout << "Before main." << endl;
      }
  };
  Init init;
  int main() {
      cout << "In main." << endl;
      return 0;
  }
  ```

  在这个示例代码中，我们定义了一个 `Init` 类，将其实例化为一个全局变量 `init`，在其构造函数中输出一条消息。然后，我们定义了 `main` 函数，输出另一条消息。运行这个程序，输出结果如下：

  ```c
  Before main.
  In main.
  ```

  从输出结果可以看出，在 `main` 函数之前，全局变量 `init` 的构造函数已经执行了，输出了一条消息。这说明我们成功地在 `main` 函数之前执行了一些操作。

- explicit 的作用

  `explicit` 是 C++ 中的一个关键字，用于修饰单参构造函数或者转换函数，其作用是防止隐式转换，只能显式调用。

  举个例子，当我们在定义一个只有一个参数的构造函数时，有时候我们不希望这个构造函数被自动调用进行隐式转换，而是需要在使用的时候显式地调用它。这时候就可以使用 `explicit` 关键字进行修饰。 下面是一个示例代码，演示了 `explicit` 关键字的使用：

  ```c
  class A {
  public:
      A(int i) : m_i(i) {}
  private:
      int m_i;
  };
  void fun(A a) {
      // do something
  }
  int main() {
      A a1 = 10; // ok，隐式转换
      A a2(10); // ok，显式构造
      fun(10); // error，不能隐式转换为 A 类型
      fun(A(10)); // ok，显式构造
      return 0;
  }
  ```

  在上面的示例中，我们定义了一个类 `A`，它有一个带有 `int` 类型参数的构造函数。如果我们没有在构造函数前面加上 `explicit` 关键字，那么在 `main` 函数中，我们可以用整型常量值 `10` 隐式地创建一个 `A` 类型的对象 `a1`。但是，如果我们在构造函数前面加上 `explicit` 关键字，则不能用整型常量值隐式地创建 `A` 类型的对象，必须显式地调用构造函数。

  同时，如果我们定义了一个函数 `fun`，它的参数是 `A` 类型的对象，如果我们没有在构造函数前面加上 `explicit` 关键字，则函数 `fun` 的参数可以隐式地将整型常量值 `10` 转换为 `A` 类型的对象，但是如果我们在构造函数前面加上 `explicit` 关键字，则不能进行隐式转换，必须显式地调用构造函数。

- sizeof 和 strlen的区别

  1. strlen是一个库函数，使用时需要引用#include<string.h>这个头文件，而sizeof是一个运算符号；
  2. strlen计算的是'\0'之前的字符个数，sizeof计算的是所占空间内存的大小，单位是字节；
  3. strlen计算时不包含'\0'，而sizeof包含'\0'，strlen遇到'\0'才结束；
  4. strlen计算字符串的具体长度 (只能是字符串)，不包括字符串结束符，返回的是字符个数。
  5. strlen的参数是指针类型，所以传过来的参数为指针才对。

- 一个函数的形参是数组，在函数内部调用 sizeof 和 strlen 分别得到什么答案

  ```c
  #include <stdio.h>
  #include <string.h>
  
  void print_array(char arr[]) {
      printf("sizeof(arr) = %lu\n", sizeof(arr));
      printf("strlen(arr) = %lu\n", strlen(arr));
  }
  
  int main() {
      char str[] = "Hello, world!";
      printf("sizeof(str) = %lu\n", sizeof(str));
      printf("strlen(str) = %lu\n", strlen(str));
      print_array(str);
      return 0;
  }
  ```

  输出结果为：

  ```c
  sizeof(str) = 14
  strlen(str) = 13
  sizeof(arr) = 8
  strlen(arr) = 13
  ```

  在主函数中，我们定义了一个字符数组 str，并使用 sizeof 和 strlen 函数分别计算了其大小和长度。由于该数组包含了 14 个字符（包括结尾的空字符），因此 sizeof(str) 返回 14，而 strlen(str) 返回 13（不包括结尾的空字符）。

  接着，我们调用了一个名为 print_array 的函数，将数组 str 作为参数传递给该函数。在 print_array 函数内部，我们同样使用了 sizeof 和 strlen 函数来计算数组的大小和长度。由于数组形参在函数内部被解释为指向数组首元素的指针，因此 sizeof(arr) 返回的是指针的大小（通常是 8 字节，取决于系统的位数）。而 strlen(arr) 返回的仍然是原数组中第一个元素到空字符之间的字符个数，即 13。

  ```c
  #include <stdio.h>
  #include <string.h>
  
  void print_array(char arr[], int n) {
      printf("sizeof(arr) = %lu\n", sizeof(arr));
      printf("strlen(arr) = %lu\n", strlen(arr));
      for (int i = 0; i < n; i++) {
          printf("%c ", arr[i]);
      }
      printf("\n");
  }
  
  int main() {
      char str[10] = {'H', 'e', 'l', 'l', 'o'};
      printf("sizeof(str) = %lu\n", sizeof(str));
      printf("strlen(str) = %lu\n", strlen(str));
      print_array(str, 5);
      return 0;
  }
  ```

  输出结果为：

  ```c
  sizeof(str) = 10
  strlen(str) = 5
  sizeof(arr) = 8
  strlen(arr) = 5
  H e l l o
  ```

  在主函数中，我们定义了一个长度为 10 的字符数组 str，并使用 sizeof 和 strlen 函数分别计算了其大小和长度。由于该数组中只有 5 个元素被初始化，因此 sizeof(str) 返回 10，而 strlen(str) 返回 5（不包括结尾的空字符）。

  接着，我们调用了一个名为 print_array 的函数，将数组 str 作为参数传递给该函数，并传递了数组中实际被初始化的元素个数 5。在 print_array 函数内部，我们同样使用了 sizeof 和 strlen 函数来计算数组的大小和长度。由于数组形参在函数内部被解释为指向数组首元素的指针，因此 sizeof(arr) 返回的是指针的大小（通常是 8 字节，取决于系统的位数）。而 strlen(arr) 返回的仍然是原数组中第一个元素到空字符之间的字符个数，即 5。

  最后，我们在 print_array 函数内部使用 for 循环遍历了数组中实际被初始化的元素，并将其输出到控制台上。

- 在主函数中对一个指向字符串的指针分别调用sizeof 和 strlen分别得到什么答案

  1. 指针指向字符串数组的第一个元素：

  ```c
  #include <stdio.h>
  #include <string.h>
  
  int main() {
      char str_arr[] = {'H', 'e', 'l', 'l', 'o', ',', ' ', 'w', 'o', 'r', 'l', 'd', '!', '\0'};
      char *str_ptr = str_arr;
      printf("sizeof(str_ptr) = %lu\n", sizeof(str_ptr));
      printf("strlen(str_ptr) = %lu\n", strlen(str_ptr));
      return 0;
  }
  ```

  输出结果为：

  ```c
  sizeof(str_ptr) = 8
  strlen(str_ptr) = 13
  ```

  在主函数中，我们定义了一个字符数组 str_arr，并将其初始化为一个字符串。接着，我们定义了一个指向字符的指针 str_ptr，将其指向字符串数组的第一个元素。在调用 sizeof 和 strlen 函数时，指针被解释为指向字符串的指针，因此 sizeof(str_ptr) 返回指针类型的大小，而 strlen(str_ptr) 返回字符串的长度。

  2. 指针指向字符串常量：

  ```c
  #include <stdio.h>
  #include <string.h>
  
  int main() {
      char *str_ptr = "Hello, world!";
      printf("sizeof(str_ptr) = %lu\n", sizeof(str_ptr));
      printf("strlen(str_ptr) = %lu\n", strlen(str_ptr));
      return 0;
  }
  ```

  输出结果为：

  ```c
  sizeof(str_ptr) = 8
  strlen(str_ptr) = 13
  ```

  在主函数中，我们定义了一个指向字符串常量的指针 str_ptr。由于字符串常量存储在程序的只读数据段中，因此 sizeof(str_ptr) 返回指针类型的大小，而 strlen(str_ptr) 返回字符串的长度。

  3. 指针指向空字符串：

  ```c
  #include <stdio.h>
  #include <string.h>
  
  int main() {
      char *str_ptr = "";
      printf("sizeof(str_ptr) = %lu\n", sizeof(str_ptr));
      printf("strlen(str_ptr) = %lu\n", strlen(str_ptr));
      return 0;
  }
  ```

  输出结果为：

  ```
  sizeof(str_ptr) = 8
  strlen(str_ptr) = 0
  ```

  在主函数中，我们定义了一个指向空字符串的指针 str_ptr。在调用 sizeof 函数时，指针被解释为指向字符串的指针，因此返回指针类型的大小。而在调用 strlen 函数时，由于空字符串中没有任何字符（包括空字符），因此返回值为 0。

  需要注意的是，在处理指向字符串的指针时，必须保证指针指向的内存位置是有效的，并且字符串以空字符结尾。否则，调用 strlen 函数可能会访问到不属于该字符串的内存位置，导致程序出现未定义的行为。

- strcpy 与 memcpy 的区别

  1. 复制的内容不同。strcpy只能复制字符串，而memcpy可以复制任意内容，例如字符数组、整型、结构体、类等；
  2. 复制的方法不同。strcpy不需要指定长度，它遇到被复制字符的串结束符"\0"才结束，如果空间不够，就会引起内存溢出。memcpy则是根据其第3个参数决定复制的长度；
  3. 用途不同。通常在复制字符串时用strcpy，而需要复制其他类型数据时则一般用memcpy，由于字符串是以“\0”结尾的，所以对于在数据中包含“\0”的数据只能用memcpy；
  4. 从s1复制字符串到s2。strncpy和memcpy很相似，只不过它在一个终止的空字符处停止。当n>strlen(s1)时，给s2不够数的空间里填充“\0”（n为s2的空间大小）；当n<=strlen(s1)时，s2是没有结束符“\0”的，所以使用strncpy时，确保s2的最后一个字符是“\0”。

- memove和memcpy有什么区别

  memmove和memcpy是C++中的两个函数，它们的作用都是复制内存区块，但是它们有以下区别：

  1. 目标内存区域与源内存区域重叠时，memmove可以正确处理，而memcpy则不能。

  2. memmove的复制过程是从前往后进行，即使目标内存区域在源内存区域的后面，也是先将前面的数据复制过去，再将后面的数据复制过去。而memcpy则没有这个限制，可以从前往后复制，也可以从后往前复制。

  3. memmove的复制速度通常比memcpy慢，因为它要判断内存区域是否重叠，而memcpy则没有这个开销。

  总的来说，如果目标内存区域与源内存区域可能会重叠，应该使用memmove，否则使用memcpy。

- 函数重载，变量前有无const是否可以重载

  fun(int i) 和 fun(const int i)，不能重载。二者是一样的，是因为函数调用中存在实参和形参的结合。假如我们用的实参是 int a，那么这两个函数都不会改变 a 的值，这两个函数对于 a 来说是没有任何区别的，所以不能通过编译，提示重定义。

  fun(char *a) 和 fun(const char *a)，可以重载。因为 char *a 中 a 指向的是一个字符串变量，而 const char *a 指向的是一个字符串常量，所以当参数为字符串常量时，调用第二个函数，而当函数是字符串变量时，调用第一个函数。

  fun(char *a) 和fun(char * const a) ，不能重载。这两个都是指向字符串变量，不同的是 char *a 是指针变量 而 char const *a 是指针常量，这就和 int i 和 const int i 的关系一样了，所以也会提示重定义。

  int &i 和const int & i 也是可以重载的。对于引用，比如 int &i 和 const int & i 也是可以重载的，原因是第一个 i 引用的是一个变量，而第二个i引用的是一个常量，两者是不一样的，类似于上面指向变量的指针和指向常量的指针。

- volatile 能保证线程安全吗，不能的话怎么解决

  volatile 关键字是 C/C++ 中的一个类型修饰符，用于告诉编译器一个变量是易变的，需要在每次访问时重新读取。但是，volatile 关键字不能保证线程安全，因为它只能保证变量在多线程或多进程环境下的可见性，而不能保证原子性和有序性，因此在并发环境下使用 volatile 关键字仍然存在数据竞争和死锁等问题。

  为了解决线程安全问题，可以使用互斥锁、条件变量、原子操作等方法来保证数据的原子性和有序性，避免数据竞争和死锁问题。互斥锁是一种常用的线程同步机制，可以保证在同一时刻只有一个线程可以访问共享资源，从而避免数据竞争问题。条件变量可以用来等待共享资源的状态改变，原子操作可以保证对共享变量的操作是不可分割的，从而避免数据竞争和死锁问题。

  总之，volatile 关键字不能保证线程安全，需要采用其他的线程同步机制来保证数据的原子性和有序性，避免数据竞争和死锁问题。

- struct 和 union 区别

  struct 和 union 都是 C/C++ 中的数据类型，它们的主要区别在于存储方式和内存使用方式：

  struct 是一种自定义的数据类型，可以包含多个不同类型的成员变量，每个成员变量占用独立的内存空间，结构体的大小等于所有成员变量的大小之和，不同成员变量之间没有关联。

  union：union 也是一种自定义的数据类型，可以包含多个不同类型的成员变量，但只有一个成员变量可以被赋值和访问，不同成员变量共享同一块内存空间，共用一个内存地址，结构体的大小等于最大的成员变量的大小。因此，union 可以节省内存空间，但存在数据安全问题，因为不同的成员变量共用同一块内存空间，修改一个成员变量的值可能会影响其他成员变量的值，而 struct 没有这个问题。 

- 头文件中 #ifdef，#endif 有什么作用

  避免头文件被重复引用。在一个大型软件工程编写code，可能会有多个文件同时包含一个头文件，当这些文件编译链接成一个可执行文件时，就会出现大量重定义的错误。在头文件中实用#ifndef #define #endif能避免头文件的重定义。

  如编写头文件ArrayList.h，在头文件开头写上两行：

  ```c
  #ifndef _Array_List_h
  #define ArrayList.h //一般是文件名的大写
  ```

  头文件结尾写上一行：#endif，这样一个工程文件里同时包含两个ArrayList.h时，就不会出现重定义的错误了。

  分析：当第一次包含ArrayList.h时，由于没有定义_Array_List_h，条件为真，这样就会包含（执行）#ifndef _Array_List_h和#endif之间的代码，当第二次包含test.h时前面一次已经定义了_Array_List_h，条件为假，#ifndef _Array_List_h和#endif之间的代码也就不会再次被包含，这样就避免了重定义了。主要用于防止重复定义宏和重复包含头文件。

- 模板的编译过程，模板是什么时候实例化的

  模板是 C++ 中的一种特殊的类型，它的编译过程和普通的函数或类的编译过程有所不同。模板的编译分为两个阶段：声明和实例化。

  声明阶段：在源代码中定义模板时，编译器只会对模板进行语法和类型检查，不会生成任何代码。在编译器遇到使用模板的语句时，只会对模板进行简单的语法检查，然后将其标记为待实例化。

  实例化阶段：当编译器需要生成实际的代码时，会根据使用模板的具体情况实例化模板。也就是说，模板是在使用时才进行实例化。实例化的过程包括将模板中的类型参数替换为具体的类型，生成对应的代码，并进行编译和链接，生成可执行文件。

   总之，模板的编译过程分为声明阶段和实例化阶段。模板只有在使用时才会进行实例化，根据具体的类型参数生成对应的代码。

- #include<> 和 #include"" 的区别

  1. 引用的头文件不同。#include< >引用的是编译器的类库路径里面的头文件；#include“ ”引用的是你程序目录的相对路径中的头文件。
  2. 用法不同。#include< >用来包含标准头文件(例如stdio.h或stdlib.h)；#include“ ”用来包含非标准头文件。
  3. 调用文件的顺序不同。#include< >编译程序会先到标准函数库中调用文件；#include“ ”编译程序会先从当前目录中调用文件。
  4. 预处理程序的指示不同。#include< >指示预处理程序到预定义的缺省路径下寻找文件；#include“ ”指示预处理程序先到当前目录下寻找文件，再到预定义的缺省路径下寻找文件。

- free 和 delete 的区别

  `free`和`delete`都可以用于释放动态分配的内存，但它们之间有几个重要的区别：

  1. 动态分配方式不同：`new`和`malloc`是不同的内存分配方式，对应的释放操作也不同。`delete`用于释放使用`new`分配的内存，`free`用于释放使用`malloc`分配的内存。

  2. 对象销毁方式不同：`delete`操作除了释放内存以外，还会自动调用对象的析构函数，从而保证对象被正确销毁；而`free`只会释放内存，不会调用任何对象的析构函数。

  3. 参数类型不同：`free`仅接受`void*`类型的指针作为参数，而`delete`需要传入指向动态分配的对象的指针。

  4. 风险不同：使用`delete`可避免出现忘记释放内存的情况，因为`delete`的语义已经包含了释放内存的操作。而`free`则需要程序员显式地调用才能释放内存，容易出现遗漏的情况，从而引发内存泄漏等问题。

  因此，在C++中，应该优先使用`new/delete`，而不是使用`malloc/free`。不过，对于C语言开发者来说，由于`new/delete`是C++特有的操作符，因此在C项目中还是需要使用`malloc/free`来分配和释放内存。

- 空指针和野指针的区别

  - 指向的地址为空的指针是空指针；
  - 指向的地址是不可知的、随机的、没有明确限制的指针是野指针；

  1. 指针未初始化；2. 指针越界访问；3. 指针指向的空间释放。

- 什么是野指针，怎么检测

  野指针是指指向无效内存地址的指针。这通常发生在指针被释放或初始化之前，或者指针指向的对象已经被销毁或移动了。当程序访问野指针时，可能会导致程序崩溃、数据损坏、安全漏洞等问题。

  检测野指针可以通过以下方法：

  1. 编译器选项：现代编译器通常提供一些开关来检测野指针，如gcc的"-Wuninitialized"选项可以检测未初始化的变量和指针。

  2. 静态分析工具：静态分析工具可以扫描代码并检测潜在的野指针问题。例如，Clang Static Analyzer、Coverity等工具都提供了野指针的检测功能。

  3. 动态调试工具：动态调试工具可以在程序运行时检测野指针。例如，Valgrind是一款常用的动态调试工具，可以检测内存泄漏、野指针等问题。

  总之，尽可能避免野指针的出现是最好的方法，可以通过合理的内存管理、指针初始化等方式来减少野指针问题的发生。

- 在一台内存为 2G 的机器上，使用 malloc 分配 20G 会发生什么，new 20G 呢

  在一台内存为2G的机器上，使用malloc分配20GB内存会导致分配失败，因为需要的内存空间已经超出了可用的物理内存大小，malloc会返回NULL指针，表明分配失败。

  而对于new操作符，如果使用的是标准的C++库，那么在同样的情况下也无法成功分配20GB内存，它会抛出std::bad_alloc异常。但是，某些实现可能会尝试通过申请虚拟内存来满足请求，这可能会导致系统变得非常慢，甚至崩溃。

  需要注意的是，即使内存分配成功了，也要确保能够在程序中正确和及时地释放这些内存，否则可能导致内存泄漏等问题。通常情况下，应该在动态分配内存后，及时释放不再需要的内存，以便其他程序可以使用这些内存空间。

  总之，为了避免这种情况的发生，应该在编写程序时仔细估计所需的内存量，并尽可能地避免过多地申请内存空间。另外，在分配内存之前，还可以通过查询可用内存或进行内存回收等操作来提高系统可用内存的效率。

- 一般程序中栈大小多少

  栈大小在不同的操作系统和编译器下可能有所不同。在大多数操作系统中，每个线程都有自己的栈，操作系统会为每个线程分配一定大小的栈空间。在Windows系统下，默认的栈大小为1MB，而在Linux系统下，栈大小通常为8MB。在编写程序时，如果使用了递归、大量的局部变量或者过多的函数嵌套等操作，可能会导致栈溢出。因此，在编写程序时需要注意控制栈的大小，避免出现栈溢出的情况。

- 全局变量定义在头文件中有什么问题

  在头文件中定义全局变量可能会导致重复定义错误。因为当多个C++源文件包含同一个头文件时，其中的全局变量会在每个源文件中都被定义一次。

  例如，在头文件`globals.h`中定义了一个全局变量`int x = 0;`，并在C++源文件`file1.cpp`和`file2.cpp`中分别包含`globals.h`头文件进行编译。则在编译时，由于`globals.h`被包含了两次，全局变量`x`也被定义了两次，这将导致重复定义错误。

  为避免这种错误，通常建议在头文件中使用`extern`关键字声明全局变量，并在一个C++源文件中定义它。例如，在`globals.h`头文件中可以声明`extern int x;`，而在`globals.cpp`源文件中定义`int x = 0;`。这样，任何需要使用全局变量`x`的源文件只需要包含`globals.h`头文件即可。

  总之，尽管在C++中允许在头文件中定义全局变量，但为了避免重复定义错误，通常应该在头文件中使用`extern`关键字声明全局变量，并在一个源文件中定义它。

- c++11 中可以用什么特性替换单例模式中的 static 写法？

  在C++11标准中，可以使用局部静态变量（local static variable）来替代单例模式中的静态变量写法。这种实现方法也被称为"Meyers Singleton"，它具有如下特点：

  1. 只有在第一次访问单例对象时才会创建该对象，避免了懒汉式单例中可能存在的线程安全问题；
  2. 局部静态变量在多线程环境下自动初始化，并且保证了初始化过程的线程安全性。

  下面是一个使用局部静态变量实现的单例类的示例代码：

  ```c
  class Singleton {
  public:
      static Singleton& getInstance() {
          static Singleton instance; // 局部静态变量，只在首次调用时初始化
          return instance;
      }
  
      void doSomething() {
          // ...
      }
  
  private:
      Singleton() = default;
      ~Singleton() = default;
      Singleton(const Singleton&) = delete;
      Singleton& operator=(const Singleton&) = delete;
  };
  ```

  在上述代码中，`getInstance()`函数返回一个引用类型的`Singleton`对象，其中`instance`是一个局部静态变量，只在第一次调用时初始化。由于局部静态变量的初始化过程是线程安全的，因此这种实现方式避免了懒汉式单例中可能存在的线程安全问题。同时，该实现方式也避免了饿汉式单例中可能存在的静态初始化顺序问题。

  需要注意的是，为了防止单例被复制或移动，上述代码将拷贝构造函数和赋值运算符声明为删除函数。此外，为了防止单例在程序结束前被销毁，通常将析构函数声明为`default`以使用默认行为。

- g++如何链接动态库，如何生成动态库，库和二进制文件分别在哪些目录

  1. 链接动态库：

  在编译时使用`-l`选项指定动态库的名称，同时使用`-L`选项指定动态库所在的目录。例如，链接名为`libexample.so`的动态库，可以使用以下命令：

  ```
  g++ main.cpp -o main -l example -L /path/to/lib/
  ```

  2. 生成动态库：

  使用`-shared`选项生成动态库，例如：

  ```
  g++ -shared -o libexample.so example.cpp
  ```

  3. 库和二进制文件分别在哪些目录：

  一般情况下，库文件会被安装到`/usr/lib`或`/usr/local/lib`目录下，而二进制文件则被安装到`/usr/bin`或`/usr/local/bin`目录下。但是在开发过程中，库和二进制文件可以放在任何目录下，只需要在编译时使用`-L`选项指定库所在的目录即可。

- 如果我 new 了一个内存，然后在 delete 之前这个进程被系统杀死了，那这样是内存泄露吗？

  是的，如果程序在使用 `new` 动态分配内存后，未使用 `delete` 释放该内存，并且进程在释放该内存之前被系统杀死，那么这就是一种内存泄漏现象。因为当进程被杀死时，它占用的所有内存都被操作系统回收，但由于该内存未被释放，因此操作系统无法回收这部分内存，导致内存泄漏。

  内存泄漏是一种非常严重的问题，可能导致内存资源的耗尽和程序运行效率的降低。为了避免内存泄漏，我们需要在程序中养成良好的内存管理习惯，及时释放不再使用的内存空间，从而提高程序的稳定性和可靠性。

- malloc分配的是虚拟内存还是物理内存？

  malloc分配的是虚拟内存。

  虚拟内存是一种抽象概念，它使得应用程序可以访问比物理内存更大的地址空间。虚拟内存由操作系统负责管理，在应用程序看来，它是一段连续的地址空间，而实际上，这些地址空间可能分散在物理内存和硬盘上。

  当调用malloc函数时，操作系统会分配一段虚拟内存，并将其映射到物理内存或者硬盘上。如果物理内存中有空闲的空间，那么虚拟内存就会被映射到物理内存中。如果物理内存中没有足够的空间，那么虚拟内存就会被映射到硬盘上，并且在需要访问这段虚拟内存时，操作系统会将其从硬盘中读入到物理内存中。

  由于操作系统负责管理虚拟内存和物理内存的映射关系，因此应用程序不需要关心虚拟内存和物理内存的具体细节。应用程序只需要使用malloc函数来分配虚拟内存，然后使用指针来访问这段虚拟内存即可。

  需要注意的是，虚拟内存的分配和释放是由操作系统负责的，而不是由应用程序负责的。因此，在使用malloc函数分配内存时，应用程序不需要关心内存的具体分配情况，只需要确保在使用完毕后及时调用free函数释放内存即可。

- memset操作malloc的指针，是操作物理内存还是虚拟内存？

  memset函数是C标准库中的一个函数，用于将一段内存空间中的数据全部设置为指定的值。memset函数的原型如下：

  ```c
  void *memset(void *s, int c, size_t n);
  ```

  其中，参数`s`是指向要设置的内存空间的指针，参数`c`是要设置的值，参数`n`是要设置的内存空间大小。

  当调用memset函数时，它会将指定的虚拟内存地址中的数据全部设置为指定的值。也就是说，memset函数不关心数据存储在物理内存还是硬盘上，它只关心数据存储在虚拟内存中的哪个位置。

  虚拟内存是一种在操作系统中实现的内存管理技术。它使得每个应用程序都能够看到一段连续的地址空间，而实际上这些地址空间可能分散在物理内存和硬盘上。虚拟内存的出现解决了物理内存不足的问题，让应用程序能够使用比物理内存更大的内存空间。

  当调用malloc函数分配内存时，操作系统会分配一段虚拟内存，并将其映射到物理内存或者硬盘上。当调用memset函数时，它会将指定的虚拟内存地址中的数据全部设置为指定的值。也就是说，memset函数实际上是操作虚拟内存中的数据。

  需要注意的是，由于虚拟内存和物理内存之间的映射关系是由操作系统负责管理的，因此memset函数实际上不一定会直接修改物理内存中的数据。当调用memset函数时，操作系统会将虚拟内存中的数据拷贝到物理内存中，然后再进行修改。这个过程是透明的，应用程序无需关心数据存储在物理内存还是虚拟内存中。

  需要注意的是，在使用memset函数时，应该确保指定的内存空间已经被分配，否则可能会出现未定义的行为。此外，应该避免使用memset函数来修改指向常量的指针或者指向未定义的内存空间的指针，否则可能会导致程序崩溃或者出现其他问题。

- share-ptr 销毁了但还有 weak-ptr 指向那个对象，weak-ptr 怎么知道这个对象已销毁

  当使用`std::shared_ptr`智能指针时，可以通过创建`std::weak_ptr`弱指针来解决循环引用问题。当`std::shared_ptr`指向的对象被销毁后，如果仍有`std::weak_ptr`指向该对象，那么这些`std::weak_ptr`指针会自动变为空指针，避免了悬垂指针的问题。

  在实际使用中，可以通过`std::weak_ptr`的`expired()`方法来检查该对象是否已经被销毁。如果`expired()`方法返回`true`，说明这个对象已经被销毁，弱指针不再指向有效的对象；如果`expired()`方法返回`false`，说明这个对象仍然存在，弱指针仍然指向有效的对象。

  例如，假设有一个`std::shared_ptr`对象`sp`，它指向一个对象，同时还有一个`std::weak_ptr`对象`wp`也指向同一个对象。当`sp`被销毁后，可以通过`wp.expired()`方法来检查该对象是否已经被销毁，代码如下：

  ```c
  std::shared_ptr<int> sp(new int(42));
  std::weak_ptr<int> wp(sp);
  
  sp.reset();   // 销毁 std::shared_ptr 智能指针
  
  if (wp.expired()) {
      std::cout << "对象已经被销毁" << std::endl;
  } else {
      std::cout << "对象仍然存在" << std::endl;
  }
  ```

  在上述代码中，`sp.reset()`语句销毁了`std::shared_ptr`智能指针，此时可以通过`wp.expired()`方法来检查对象是否已经被销毁。如果返回`true`，说明对象已经被销毁；如果返回`false`，说明对象仍然存在。

  需要注意的是，如果要使用`std::weak_ptr`来检查对象是否已经被销毁，那么在创建`std::weak_ptr`时，必须使用`std::shared_ptr`的`shared_from_this()`方法来创建。这是因为，只有通过`shared_from_this()`方法创建的`std::shared_ptr`对象，才能正确地管理指向同一个对象的所有`std::shared_ptr`和`std::weak_ptr`指针。

- override和overload的区别

  `override` 和 `overload` 都是 C++ 中的关键字，但它们的含义和用法有所不同。

  1. `override`：是 C++11 引入的一个关键字，用于表示派生类中的虚函数覆盖了基类中的虚函数。在派生类中使用 `override` 关键字可以明确表示当前函数为虚函数的重写，提高代码的可读性和可维护性。示例代码如下：

     ```c
     class Base {
     public:
         virtual void foo();
     };
     
     class Derived : public Base {
     public:
         void foo() override;  // 重写基类中的虚函数
     };
     ```

  2. `overload`：是 C++ 中的一个概念，表示在同一个作用域内，可以定义多个名称相同但参数类型和个数不同的函数。函数重载可以提高代码的可读性和可维护性，同时允许不同类型的参数使用相同的函数名。示例代码如下：

     ```c
     void foo(int x);
     void foo(double x);
     void foo(int x, double y);
     ```

  总之，`override` 和 `overload` 都是 C++ 中的关键字，但它们的用法和含义有所不同。`override` 用于表示派生类中的虚函数覆盖了基类中的虚函数，提高代码的可读性和可维护性；`overload` 用于表示在同一个作用域内，可以定义多个名称相同但参数类型和个数不同的函数，提高代码的可读性和可维护性，同时允许不同类型的参数使用相同的函数名。

- 浮点数0.3能精确表达吗？有没有简易的方式判断浮点数能不能精确表达？

  浮点数 0.3 不能用二进制精确地表示，因为在二进制中，0.3 无限循环。这是因为浮点数在计算机中以二进制形式存储，而二进制的小数表示方式有时与十进制不同，因此可能会导致精度损失。

  在 C++ 中，可以使用头文件 `<cmath>` 中的 `std::fabs` 函数来判断两个浮点数之间的差值是否小于某个阈值，从而判断浮点数是否精确。示例代码如下：

  ```c
  #include <cmath>
  
  bool is_equal(float x, float y) {
      const float epsilon = 1e-5;
      return std::fabs(x - y) < epsilon;
  }
  
  int main() {
      float a = 0.3f;
      float b = 0.1f + 0.1f + 0.1f;
      if (is_equal(a, b)) {
          // a 和 b 在精度范围内相等
      } else {
          // a 和 b 不相等
      }
      return 0;
  }
  ```

  在上述代码中，`is_equal` 函数用于比较两个浮点数之间的差值是否小于某个阈值 `epsilon`，如果小于，则认为两个浮点数是相等的。需要注意的是，这种方法只是判断浮点数是否在某个误差范围内相等，不能完全解决浮点数精度问题，因此在实际应用中需要根据具体情况进行处理。

- extern变量在哪个数据段

  extern关键字用于声明一个在其他文件中定义的全局变量，它的作用是告诉编译器该变量的存在，但是并不分配内存空间，因此在定义extern变量时不需要指定初始值。

  extern变量在编译阶段并不会分配内存空间，而是在链接阶段进行内存分配。因此，extern变量可以在多个文件中使用，但是必须在某个文件中定义该变量，否则会出现链接错误。

  在内存中，所有的全局变量都会被分配到静态数据段，包括已经初始化的全局变量、未初始化的全局变量以及extern变量。静态数据段通常也被称为BSS段或者数据段。其中，已经初始化的全局变量存储在数据段中，而未初始化的全局变量和extern变量则存储在BSS段中。

  在程序运行时，数据段和BSS段都会被加载到进程的虚拟地址空间中，因此extern变量也会被分配到静态数据段或BSS段中。具体分配到哪个段取决于变量的类型和初始化状态，如果变量已经被初始化，则分配到数据段中，否则分配到BSS段中。

  总的来说，extern变量在内存中分配的数据段取决于变量的类型和初始化状态，通常情况下会被分配到静态数据段或BSS段中。



## 面向对象

- C++空类会默认创建哪些函数

  缺省构造函数，拷贝构造函数，析构函数，赋值运算符，取址运算符，取址运算符 const。

  ```c
  class Empty{
    public:
        Empty(); // 缺省构造函数
        Empty( const Empty& ); // 拷贝构造函数
        ~Empty(); // 析构函数
         Empty& operator=( const Empty& ); // 赋值运算符
         Empty* operator&(); // 取址运算符
         const Empty* operator&() const; // 取址运算符 const
  };
  ```

- 调用析构函数的时候类型是 void 类型，指向的是类对象，会正确调用析构函数吗？

  - void指向系统自建类型，可以使用delete void；
  - void*所指向的对象在析构函数里释放会丢失内存，因为它不执行析构函数。需要强制转换类型，然后delete；

- 析构函数可以抛异常么？

  理论上析构函数可以抛出异常。但是，这样做可能会导致一些问题，因此通常不建议在析构函数中抛出异常。

  首先，如果析构函数抛出了异常，那么很可能导致对象没有完全被销毁。因为在抛出异常的情况下，程序会跳过后续的清理工作，导致对象没有被正确地析构。这可能会导致资源泄露等问题。

  其次，如果在析构函数中抛出了异常，并且该异常没有被捕获和处理，那么程序就会调用 `std::terminate` 函数来结束程序运行。这样可能会导致一些未预料到的问题，比如内存泄漏和数据损坏等。

  因此，最好的做法是在析构函数中避免抛出异常。如果必须要在析构函数中抛出异常，那么建议在析构函数中进行必要的安全措施，以确保在抛出异常的情况下对象能够被正确地销毁。同时，也需要在代码中进行相应的异常处理，以避免程序调用 `std::terminate` 函数而崩溃。

- 条件变量为什么需要加锁？

  条件变量是多线程编程中的一种同步机制，通常与互斥锁一起使用，在多线程中实现线程之间的同步和通信。条件变量的作用是当某个条件被满足时，唤醒正在等待该条件的线程。 条件变量需要加锁的原因如下：

  1. 确保线程安全：在使用条件变量时，需要先获取相关的互斥锁，然后再对条件变量进行操作。这是因为条件变量的操作通常需要访问共享资源，如果没有加锁，多个线程可能会同时访问共享资源，导致数据竞争和线程安全问题。
  2. 避免竞争条件：条件变量的等待和唤醒操作通常需要依赖互斥锁来保证其原子性和同步性。如果没有加锁，多个线程可能会同时调用条件变量的等待和唤醒操作，导致竞争条件和线程安全问题。
  3. 避免死锁：条件变量和互斥锁通常是成对使用的，如果在使用条件变量时没有获取相应的互斥锁，可能会导致死锁问题。 

  因此，为了保证线程安全、避免竞争条件和死锁问题，条件变量需要加锁。在使用条件变量时，通常需要先获取相关的互斥锁，然后再对条件变量进行操作。

- 虚函数可以内联吗

  虚函数可以是内联函数，但是当虚函数表现多态性的时候不能内联。内联发生在编译阶段，而虚函数的多态性在运行期，编译器无法知道运行期调用哪个代码，因此虚函数表现为多态性时（运行期）不可以内联。

  inline virtual 唯一可以内联的时候是：编译器知道所调用的对象是哪个类，这只有在编译器具有实际对象而不是对象的指针或引用时才会发生。

  ```c
  #include <iostream>  
  using namespace std;
  class Base{
  public:
  	inline virtual void who()
  	{
  		cout << "I am Base\n";
  	}
  	virtual ~Base() {}
  };
  class Derived : public Base{
  public:
  	inline void who()  // 不写inline时隐式内联
  	{
  		cout << "I am Derived\n";
  	}
  };
  
  int main(){
  	// 此处的虚函数 who()，是通过类（Base）的具体对象（b）来调用的，
      // 编译期间就能确定了，所以它可以是内联的，但最终是否内联取决于编译器。 
  	Base b;
  	b.who();
  
  	// 此处的虚函数是通过指针调用的，呈现多态性，需要在运行时期间才能确定，所以不能为内联。  
  	Base *ptr = new Derived();
  	ptr->who();
  
  	// 因为Base有虚析构函数（virtual ~Base() {}），所以 delete 时，
      // 会先调用派生类（Derived）析构函数，再调用基类（Base）析构函数，防止内存泄漏。
  	delete ptr;
  	ptr = nullptr;
  } 
  ```

- 一个类有多个基类，内存中怎么虚函数表是怎么分布的？

  在派生类对象的内存中，虚表指针放在最前面，和对象的地址相同。然后是成员变量，基类的成员变量在派生类的成员变量前面，基类和派生类的成员变量分别按类中的声明顺序排列。

  对于多继承的情况，假如派生类有n个直接基类，那么派生类对象中就有n个虚表指针。派生类对象的内存可以划分为n+1块，首先存放第1个基类的虚表指针和成员变量，然后存放第2个基类的虚表指针和成员变量，以此类推。派生类自己的成员变量放在最后1块。

  虚表中虚函数的顺序是按声明顺序排列的，基类虚函数的声明先于派生类。派生类的虚函数和第一个直接基类共用一张虚表，并且在这张虚表中，基类的虚函数在前，派生类的虚函数在后。如果派生类覆盖了基类的一个虚函数，那么虚表中本来存放这个基类虚函数地址的位置改为存放派生类版本的虚函数地址。

- 拷贝构造函数为什么传引用

  因为调用拷贝构造函数是实参向形参传值，如果传进来的不是引用，那么就是值传递，那么就会在函数里又重新创建一个对象，而重新创建又是通过调用拷贝构造函数，所以如果不是引用的话，就会无穷递归地调用拷贝构造函数。另外调用拷贝构造函数时不需要消耗另外的内存空间。


- 构造函数里面可以调用成员函数吗

  1. 构造函数调用成员函数的顺序应该在初始化列表中指定。因为初始化列表是在进入构造函数的主体之前执行的，所以成员函数调用必须放在初始化列表中。
  2. 在构造函数中调用成员函数时，需要注意成员变量的值是否已经初始化。如果成员变量的值还没有初始化，可能会导致成员函数调用出错。
  3. 如果成员函数是虚函数，那么在构造函数中调用虚函数是有风险的，因为在构造函数中，对象还没有完全构造完成，此时调用虚函数可能会导致不可预测的行为。 下面是一个示例代码，演示了如何在构造函数中调用成员函数：

  ```c
  class MyClass {
  public:
      MyClass(int value) : m_value(value) {
          m_data = new int[m_value];
          InitData();
      }
      ~MyClass() {
          delete[] m_data;
          m_data = nullptr;
      }
  private:
      int m_value;
      int* m_data;
      void InitData() {
          for (int i = 0; i < m_value; i++) {
              m_data[i] = i;
          }
      }
  };
  ```

  在这个示例代码中，我们定义了一个 MyClass 类，包含了一个构造函数和一个 InitData 成员函数。

  在构造函数中，我们首先使用初始化列表将 m_value 成员变量初始化，然后在构造函数主体中调用 new 操作符动态分配了一个数组，并将其赋值给 m_data 成员变量。接着，我们调用了 InitData 成员函数，用于初始化 m_data 数组中的值。

  在析构函数中，我们使用 delete[] 操作符释放了 m_data 数组所占用的内存。 需要注意的是，在构造函数中调用成员函数时，需要特别小心，确保成员变量的值已经被正确初始化。此外，在构造函数中调用虚函数是有风险的，请尽量避免这种情况的发生。

- 移动语义和移动构造函数

  引入右值引用的目的之一是实现移动语义。移动语义的引入是为了解决在进行大数据复制的时候，将动态申请的内存空间的所有权直接转让出去，不用进行大量的数据移动，既节省空间又提高效率。移动语义可能修改右值的值，所以，右值引用参数不能是const。

  通过复制构造函数来实现复制语义，通过移动构造函数来实现移动语义。复制构造使用const &引用，而移动构造函数使用非const && 引用，需要传入右值引用。

  被移动语义的数据交出了所有权，为了不出现析构两次同一数据区，要将交出所有权的数据的指向动态申请内存区的指针赋值为nullptr，即空指针，对空指针执行delete[]是合法的。

  移动构造函数：右值主要用来实现移动构造函数，资源给了新的移动构造函数的对象，移动构造函数只交换资源的所有权。也就是说，移动构造函数事实上做了一个浅拷贝，将右值的地址给调用了移动构造函数的对象，并将原来的指针置空。

  ```c
  class MyString {
  public:
      // 普通构造函数
      MyString(const char* str = nullptr) {
          if (str == nullptr) {
              m_data = new char[1];
              *m_data = '\0';
          } else {
              int len = strlen(str);
              m_data = new char[len+1];
              strcpy(m_data, str);
          }
      }
      // 移动构造函数
      MyString(MyString&& other) {
          m_data = other.m_data;
          other.m_data = nullptr;
      }
      // 析构函数
      ~MyString() {
          if (m_data != nullptr) {
              delete[] m_data;
              m_data = nullptr;
          }
      }
  private:
      char* m_data;
  };
  ```

  在这个示例代码中，我们定义了一个 MyString 类，包含了一个普通构造函数和一个移动构造函数。在移动构造函数中，我们将 other 对象的内部资源移动到了新对象中，并将 other.m_data 置为 nullptr，以避免析构函数重复释放内存。

  使用移动构造函数可以减少不必要的内存复制操作，提高程序的性能和效率。需要注意的是，在定义移动构造函数时，需要将源对象的指针置为 nullptr，以避免重复释放内存。

- unique_ptr如何实现独占对象

  unique_ptr实现独占对象的关键在于禁止复制和移动操作，只允许通过move函数进行所有权的转移。

  具体实现方式如下：

  1. 禁止复制构造函数和复制赋值运算符

  在类的定义中声明为私有，并不提供实现。这样可以防止其他代码通过复制操作来获取对象的所有权，确保对象只能被一个unique_ptr实例所拥有。

  2. 实现移动构造函数和移动赋值运算符

  移动构造函数和移动赋值运算符可以通过std::move函数将对象的所有权转移给另一个unique_ptr实例。在转移所有权后，原来的unique_ptr实例将不再拥有对象的所有权，避免了资源的重复释放。

  3. 在析构函数中释放资源

  unique_ptr的析构函数会自动调用对象的析构函数，并释放资源。由于unique_ptr只能拥有一个对象的所有权，因此在析构函数中只需要释放一次资源，避免了资源的重复释放。

  总之，unique_ptr通过禁止复制和移动操作，以及在析构函数中释放资源的方式，实现了独占对象的功能。

- 一个类对象数据的初始化顺序

  一个类对象的数据初始化顺序是先调用基类的构造函数，然后按照派生类中非静态成员变量的定义顺序依次初始化这些成员变量，最后调用派生类的构造函数。需要注意的是，静态成员变量的初始化是在程序启动时进行的，不属于类对象的初始化顺序。

  总之，一个类对象的数据初始化顺序遵循基类构造函数先于派生类构造函数，派生类中非静态成员变量按照定义顺序初始化的规则。

- 如何让类不能被继承

  在C++中，可以通过声明一个类为`final`来防止其被继承。使用`final`关键字修饰的类称为最终类（或密封类），这些类不能再被其他类所继承。

  例如，下面的代码定义了一个最终类`MyClass`：

  ```c
  class MyClass final {
    // 类定义
  };
  ```

  在这个例子中，`final`关键字用于修饰类`MyClass`，表示该类不能再被其他类所继承。

  需要注意的是，`final`只能用于类的声明中，而不能用于类的定义中。同时，如果一个类被声明为最终类，那么它的成员函数也都将自动成为最终函数，不能被派生类覆盖。

  除了使用`final`关键字，还可以通过将类的构造函数声明为`private`来实现类无法被继承。由于不能在派生类中访问基类的私有成员，因此这样定义的类无法被继承。例如：

  ```c
  class MyClass {
  private:
    MyClass() {}  // 将构造函数声明为私有，防止类被继承
    friend class SomeFriend; // 友元类可以调用私有构造函数
  };
  
  // 不能继承MyClass，因为其构造函数是私有的
  class MyDerived : public MyClass {
    // 类定义
  };
  ```

  在这个例子中，`MyClass`的构造函数被声明为私有，在`MyDerived`中无法访问到该构造函数，因此`MyDerived`无法继承`MyClass`。

  总之，可以通过将类声明为`final`、将构造函数声明为`private`等方式来实现类不能被继承。选择哪种方式取决于具体的要求和场景。

- 如何禁止构造函数的使用

  有两种方法可以禁止构造函数的使用：

  1. 将构造函数声明为私有（private）或受保护（protected），这样就无法从外部访问和调用构造函数。例如：

  ```c
  class MyClass {
  private:
      MyClass() {}
  };
  ```

  在这个例子中，将`MyClass`的构造函数声明为`private`，这样在类的外部就无法调用构造函数来创建对象。

  2. 继承一个不可复制（uncopyable）的基类。不可复制的基类中包含了私有的构造函数和赋值运算符，并将它们声明为`delete`，以防止任何尝试复制该类的操作。例如：

  ```c
  class Uncopyable {
  protected:
      Uncopyable() {}
      ~Uncopyable() {}
  
  private:
      Uncopyable(const Uncopyable&) = delete;
      Uncopyable& operator=(const Uncopyable&) = delete;
  };
  
  class MyClass : private Uncopyable {
  public:
      // ...
  };
  ```

  在这个例子中，`MyClass`继承了`Uncopyable`类，因此在编译期间会检测到任何尝试复制或移动`MyClass`对象的操作，并报告编译错误。

  总之，以上两种方法都可以禁止构造函数的使用，具体取决于需要实现的场景。

- 如果多重继承，只有一个虚表指针吗

  在多重继承情况下，一个子类会继承来自多个父类的成员和方法，这些父类中可能都有虚函数。因此，在这种情况下，每个父类都有自己的虚函数表，而一个子类也会有对应数量的虚函数表指针。具体来说，如果一个子类中继承了n个父类，则存在n个指向虚函数表的指针。

  虚函数表指针的数量等于子类的直接父类的数量加上1，其中这1个指针指向子类自己的虚函数表。还需要注意的是，虚函数表指针的顺序与直接父类在声明时的顺序相同，即先声明的父类的虚函数表指针排在前面。

  请注意，在一些操作系统或编译器的实现中，虚函数表和虚函数表指针的布局有所不同，但通常都会遵循上述原则。

- 如果禁止类实例化时候的动态分配方式

  如果要禁止类实例化时的动态分配方式，可以将类的构造函数声明为私有，并提供一个静态成员函数来创建类的对象。由于构造函数是私有的，类的对象只能通过该静态成员函数来创建，从而限制了动态分配方式。

  下面是一个示例代码：

  ```c
  class MyClass {
  private:
      MyClass() {}  // 将构造函数声明为私有
  
  public:
      static MyClass createInstance() {
          return MyClass();  // 静态成员函数来创建对象
      }
  };
  
  int main() {
      //MyClass* ptr = new MyClass();  // 错误：无法动态分配对象
      MyClass obj = MyClass::createInstance();  // 用静态成员函数创建对象
      return 0;
  }
  ```

  在这个例子中，将`MyClass`的构造函数声明为`private`，这样就无法在类的外部通过`new`运算符来动态分配内存以创建对象。但是通过提供一个公共的静态成员函数`createInstance()`，可以在类的外部调用该函数来创建对象，从而避免了动态分配对象的问题。

  需要注意的一点是，尽管这种方法可以禁止动态分配对象，但仍然可以使用栈空间和全局变量等方式来创建对象。因此，如果需要确保对象不被任何方式所创建，可以考虑将类的构造函数声明为`private`并删除该类的拷贝构造函数和赋值运算符重载函数。

- C++能否在有参构造函数中调用无参构造函数，无参构造函数中如果有修改类成员会不会对当前正在构造的类产生影响，这种调用方式有什么优势或者缺点。

  在 C++ 中，有参构造函数可以调用无参构造函数，这样的语法被称为委派构造函数（Delegating constructors）。委派构造函数的语法如下：

  ```c
  class MyClass {
  public:
      MyClass(int x, int y) : MyClass() { // 委派构造函数
          // ...
      }
  
      MyClass() : member(0) { // 无参构造函数
          // ...
      }
  
  private:
      int member;
  };
  ```

  在上面的示例中，有参构造函数 `MyClass(int x, int y)` 中调用了无参构造函数 `MyClass()`，并且使用了委派构造函数的语法。

  需要注意的是，如果无参构造函数中修改了类成员，那么在调用委派构造函数之后，这些修改的结果会被覆盖。例如：

  ```c
  class MyClass {
  public:
      MyClass(int x, int y) : MyClass() {
          member = x + y;
      }
  
      MyClass() : member(0) {
          member = 1; // 修改类成员
      }
  
  private:
      int member;
  };
  
  int main() {
      MyClass obj(1, 2);
      std::cout << obj.member << std::endl; // 输出 3，而不是 1
      return 0;
  }
  ```

  在上面的示例中，调用 `MyClass(int x, int y)` 时会先调用 `MyClass()`，在 `MyClass()` 中修改了 `member` 的值为 1，但是在 `MyClass(int x, int y)` 中又对 `member` 进行了修改，因此最终输出的是 3。

  委派构造函数的优点在于可以避免代码重复，提高代码的复用性和可维护性。委派构造函数的缺点在于可能会导致代码结构更加复杂，特别是当多个构造函数之间存在复杂的依赖关系时。此外，需要注意避免构造函数之间的无限递归调用。

## STL


- vector的push_back操作的时间复杂度

  vector的push_back操作的时间复杂度为O(1)（摊还时间复杂度）。这是因为vector采用的是连续的内存空间，当向vector的末尾添加元素时，只需要在已分配的内存空间最后一个位置插入元素即可，时间复杂度为常数级别。但是，当vector的内存空间不足时，需要重新分配更大的内存空间并将原有元素复制到新的内存空间中，此时的时间复杂度为O(n)。但是，由于这种情况出现的概率很小，因此可以将其视为摊还时间复杂度为O(1)。

- 栈的时间复杂度、空间复杂度

  时间复杂度：栈的基本操作包括入栈和出栈，它们的时间复杂度都是 O(1)，即常数级别的时间复杂度。因为栈只允许在栈顶进行插入和删除操作，所以不需要遍历整个栈来查找元素，从而使得栈的操作非常高效。

  空间复杂度：栈的空间复杂度取决于栈的使用情况和实现方式。对于静态数组实现的栈，它的空间复杂度是固定的，即 O(n)，其中 n 表示数组的长度。而对于动态数组或链表实现的栈，它的空间复杂度会根据实际情况进行动态调整，最坏情况下为 O(n)，其中 n 表示栈中元素的个数。

- STL中仿函数有什么用，和函数指针有什么不同，哪个效率高

  STL 中的仿函数（Functor）是一种重载了函数调用运算符 () 的类，它可以像函数一样被调用。仿函数可以作为函数对象传递给 STL 算法或容器，用于自定义排序、查找、统计等操作的比较规则或操作规则。与函数指针相比，仿函数具有更高的灵活性和可定制性，可以通过类的成员变量来保存状态，也可以通过模板参数来实现更加通用的操作。 与函数指针相比，仿函数有以下优点：

  1. 仿函数可以保存状态，因为仿函数是一个类，可以将需要保存的状态保存在类的成员变量中，这样就可以在连续调用中保留状态，而函数指针不能保存状态；
  2. 仿函数可以通过模板参数来实现更加通用的操作，因为仿函数可以定义多个重载的 operator() 函数，可以根据需要进行不同的操作，而函数指针只能指向一个函数；
  3. 仿函数可以使用函数对象适配器来适应不同的算法或容器，例如，可以使用 std::bind 和 std::function 来适配不同的参数列表或返回类型。 

  相比之下，仿函数的效率可能稍低于函数指针，因为仿函数是一个类，需要实例化对象，而函数指针只需要保存一个指针。但是，由于仿函数可以保存状态，因此在一些需要保存状态的场合，例如排序算法，仿函数比函数指针更加有效。此外，现代编译器对于使用仿函数进行的优化，可能会使其效率更高。

- 使用 map 不是基础数据类型需要重载什么运算符

  使用 `map` 存储自定义类型时，需要重载 `<` 运算符，以便 `map` 能够正确地进行排序和查找。因为 `map` 是一种关联容器，它的内部实现依赖于对元素的排序，而排序依赖于元素之间的比较。如果没有重载 `<` 运算符，编译器不知道如何比较两个元素的大小，也就无法对 `map` 进行正确的排序和查找。 

  下面是一个示例代码，演示了如何重载 `<` 运算符来实现 `map` 的自定义类型：

  ```c
  #include <iostream>
  #include <map>
  using namespace std;
  class Person {
  public:
      Person(string name, int age) : m_name(name), m_age(age) {}
      string GetName() const { return m_name; }
      int GetAge() const { return m_age; }
  private:
      string m_name;
      int m_age;
  };
  bool operator<(const Person& lhs, const Person& rhs) {
      if (lhs.GetAge() < rhs.GetAge()) {
          return true;
      } else if (lhs.GetAge() == rhs.GetAge()) {
          return lhs.GetName() < rhs.GetName();
      } else {
          return false;
      }
  }
  int main() {
      map<Person, int> people;
      people[Person("Tom", 25)] = 1;
      people[Person("John", 30)] = 2;
      people[Person("Alice", 20)] = 3;
      for (const auto& p : people) {
          cout << p.first.GetName() << " " << p.first.GetAge() << " " << p.second << endl;
      }
      return 0;
  }
  ```

  在这个示例代码中，我们定义了一个 `Person` 类，包含了姓名和年龄两个成员变量。接着，我们重载了 `<` 运算符，按照年龄从小到大排序，如果年龄相等，则按照姓名从小到大排序。然后，我们定义了一个 `map` 对象 `people`，用于存储 `Person` 对象和一个整数。最后，我们遍历 `people` 对象，并输出每个 `Person` 对象的姓名、年龄和对应的整数。运行这个程序，输出结果如下：

  ```c
  Alice 20 3
  Tom 25 1
  John 30 2
  ```

  从输出结果可以看出，`map` 按照年龄从小到大排序，如果年龄相等，则按照姓名从小到大排序，这是由于我们重载了 `<` 运算符的缘故。

- STL容器的线程安全性

  线程安全的情况：

  - 多个读取者是安全的。多线程可能同时读取一个容器的内容，这将正确地执行。当然，在读取时不能有任何写入者操作这个容器；

  - 对不同容器的多个写入者是安全的，多线程可以同时写不同的容器；

  线程不安全的情况：

  - 在对同一个容器进行多线程的读写、写操作时；

  - 在每次调用容器的成员函数期间都要锁定该容器；

  - 在每个容器返回的迭代器（例如通过调用begin或end）的生存期之内都要锁定该容器；

  - 在每个在容器上调用的算法执行期间锁定该容器；

- 什么情况用栈什么情况用队列

  栈的应用：非常广泛，在CPU内部就有提供栈这个机制。主要用途：函数调用和返回，数字转字符，表达式求值，走迷宫等等。在CPU内部栈主要是用来进行子程序调用和返回，中断时数据保存和返回。在编程语言中：主要用来进行函数的调用和返回。可以说在计算机中，只要数据的保存满足先进后出的原理，都优先考虑使用栈，所以栈是计算机中不可缺的机制。

  队列的应用：队列主要用在和时间有关的地方，特别是操作系统中，队列是实现多任务的重要机制。windows中的消息机制就是通过队列来实现的。进程调度也是使用队列来实现，所以队列也是一个重要的机制，只要满足数据的先进先出原理就可以使用队列。

- vector扩容和realloc是需要直接拷贝吗？

  vector 扩容时会调用 `realloc` 或者分配新的内存，具体是哪种方式取决于当前内存的分配策略。

  如果当前内存是通过 `malloc` 系列函数分配的，那么扩容时会使用 `realloc` 进行内存的重新分配。`realloc` 会尝试在原有内存块的末尾或者相邻的空闲内存块中分配新的内存，如果找到合适的位置，就直接扩大内存块并返回指向原内存块的指针；如果找不到合适的位置，就会分配新的内存块，并将原内存块中的数据拷贝到新内存块中，最后释放原内存块。

  如果当前内存是通过 C++ 的 `new` 运算符分配的，那么扩容时会先分配新的内存块，然后将原内存块中的数据拷贝到新内存块中，最后释放原内存块。

  无论是使用 `realloc` 还是分配新的内存块，都需要将原有内存块中的数据拷贝到新的内存块中，因此 vector 扩容时是需要进行数据拷贝的。但是，在使用 `realloc` 进行内存重分配时，如果找到了相邻的空闲内存块，就可以避免数据拷贝，提高效率。

- push_back和emplace_back的区别

  `push_back` 和 `emplace_back` 都是 C++ STL 中 vector 容器的方法，它们的主要区别在于：

  1. 参数类型不同：`push_back` 的参数是一个对象，而 `emplace_back` 的参数是该对象的构造函数所需要的参数。

  2. 插入方式不同：`push_back` 在容器末尾添加一个元素，而 `emplace_back` 在容器末尾构造一个元素。

  3. 效率不同：由于 `emplace_back` 可以直接在容器末尾构造一个元素，而无需创建一个临时对象，因此 `emplace_back` 比 `push_back` 更高效。

  具体来说，`push_back` 会创建一个对象并将其复制到容器的末尾，在对象较大的情况下，这可能会导致效率低下。而 `emplace_back` 直接在容器的末尾构造一个对象，避免了对象复制的开销，因此效率更高。

  总之，`push_back` 和 `emplace_back` 在实现上有所不同，使用时需要根据具体的情况进行选择。如果需要将一个已经构造好的对象添加到容器中，可以使用 `push_back`；如果需要在容器中直接构造一个新的对象，可以使用 `emplace_back`。

- 怎么回收vector的空间

  在 C++11 之前，vector 中的空间只能用 `swap` 或 `clear` 方法来进行回收。

  1. 使用 `swap` 方法：可以把一个空的 vector 对象和需要回收空间的 vector 对象进行交换，从而实现空间的回收。示例代码如下：

     ```c
     std::vector<int>().swap(vec);
     ```

  2. 使用 `clear` 方法：可以清空 vector 中所有的元素，但并不会释放 vector 占用的内存空间。示例代码如下：

     ```c
     vec.clear();
     ```

  在 C++11 及以后的版本中，vector 提供了 `shrink_to_fit` 方法，可以释放 vector 占用的内存空间。示例代码如下：

  ```c
  vec.clear();
  vec.shrink_to_fit();
  ```

  需要注意的是，`shrink_to_fit` 方法并不是强制释放内存，而是请求释放多余的内存空间，具体是否释放内存取决于具体实现。如果需要确保 vector 释放了占用的内存空间，可以使用 `swap` 方法交换一个空的 vector 对象来实现。

  总之，回收 vector 的空间可以使用 `swap`、`clear` 或 `shrink_to_fit` 方法，需要根据具体情况选择适当的方法。



# 计网

- osi 七层和五层，合并在哪

  七层模型：

  - 物理层：利用传输介质（双绞线、光纤、wifi-电磁波）为数据链路层提供物理连接，实现比特流的透明传输，可靠的物理型号：0和1—通过网卡（MAC地址）定位电脑

  - 数据链路层：将IP数据报组装成帧，控制信息在相邻两节点的链路上进行传输—局域网内部，提供了通讯过程中要用到的MAC地址（物理地址）

  - 网络层：IP — 通过IP找到网关（局域网内部负责人），再找到局域网

  - 传输层：TCP、UDP，不同端口对应不同的应用，控流校验

  - 会话层：建立两个app直接的会话

  - 表示层：对底层命令和数据进行解释

  - 应用层：应用层协议：DNS、HTTP、SMTP等，用户在这一层与网络进行交互

  五层模型：

  TCP/IP五层协议就是把OSI七层网络模型的会话层、表示层、应用层合并成了应用层。

  - 应用层：负责应用程序之间的数据传输和通信。这个层级包括所有的应用程序，如电子邮件、FTP、HTTP、SSH等。

  - 传输层：提供端到端的数据传输服务，确保数据在源和目标之间可靠传输。这个层级包括TCP和UDP协议。
  - 网络层：负责数据包的传输，将数据包从源主机传到目标主机。这个层级包括IP协议。
  - 数据链路层：负责将数据包转换成物理层可以传输的信号。这个层级包括以太网协议。
  - 物理层：负责在物理媒介上传输数据，如光纤、电缆等。

- 网络层有哪些作用？

  网络层是OSI七层模型或TCP/IP五层模型中的第三层，位于传输层和数据链路层之间。其作用是为分组交换网上的不同主机之间提供端到端的通信服务，促进了网络内部和网络之间的数据传输。

  网络层有以下主要作用：

  1. 路由选择：通过路由选择协议，选择合适的路径将数据包从源地址传输到目的地址。

  2. 数据转发：将接收到的数据包移动到正确的出口端口，并发送到下一跳设备。

  3. 网络拥塞控制：使用一定策略来避免在网络中发生大量数据包同时传输导致的网络拥塞问题。

  4. 数据包分片和重组：将大数据包分割成小的数据包进行传输，并在接收端重组为原始的数据包。

  5. 网际互连：使得不同的网络之间可以互相通信，实现了互联网的主要功能。

  总之，网络层是整个互联网体系结构的重要组成部分，对于保证数据在网络中的流动、实现网络互联等方面具有不可替代的作用。

- 数据链路层有哪些协议？物理层使用到了些什么？

  数据链路层主要有以下协议：

  1. 以太网协议（Ethernet）：以太网是最常用的局域网协议，使用CSMA/CD（载波监听多路访问/碰撞检测）协议来解决数据冲突问题。

  2. 无线局域网协议（Wi-Fi）：Wi-Fi是一种无线局域网协议，采用CSMA/CA（载波监听多路访问/碰撞避免）协议来解决数据冲突问题。

  3. PPP协议（Point-to-Point Protocol）：PPP协议是一种点对点协议，常用于拨号上网和虚拟专用网（VPN）等场景。

  4. HDLC协议（High-level Data Link Control）：HDLC协议是一种数据链路层协议，常用于广域网（WAN）和数据通信等场景。

  5. SLIP协议（Serial Line Internet Protocol）：SLIP协议是一种串行线路协议，常用于串行线路上的IP数据传输。

  物理层使用到的技术主要有以下几种：

  1. 传输介质：物理层使用传输介质来传输数据，包括双绞线、同轴电缆、光纤等。

  2. 编码技术：物理层使用编码技术将数字信号转换为模拟信号，包括非归零编码、曼彻斯特编码等。

  3. 调制技术：物理层使用调制技术将数字信号转换为模拟信号，包括调幅、调频、调相等。

  4. 传输速率：物理层定义了不同的传输速率标准，包括10Mbps、100Mbps、1Gbps等。

  需要注意的是，数据链路层和物理层是OSI模型中最底层的两层，主要负责数据的传输和物理信号的转换。

- https 的 SSL 建立连接的过程会导致效率下降，如何优化

  HTTPS的SSL建立连接过程中确实会导致一定的性能损耗，主要是因为SSL握手过程需要进行非对称加密和数字签名等操作，而这些操作需要耗费CPU资源。

  以下是一些优化HTTPS性能的方法：

  1. 使用TLS 1.3协议：TLS 1.3协议在握手过程中使用了更快的加密算法，可以减少握手时间。

  2. 使用会话重用：在握手过程中，服务器可以生成一个会话ID或者会话密钥，客户端可以在下一次连接时重用这个会话ID或者会话密钥，从而避免重复进行SSL握手过程。

  3. 使用证书缓存：客户端可以缓存服务器的证书，避免每次连接都需要重新获取证书。

  4. 使用HTTP/2协议：HTTP/2协议使用了多路复用技术，可以在一个连接上同时传输多个请求和响应，从而减少握手次数。

  5. 使用CDN加速：将静态资源放在CDN上，可以减少HTTPS连接的数量，从而提高性能。

  6. 使用硬件加速：使用专门的硬件加速器可以加速SSL握手过程中的加密和解密操作，从而提高性能。

- https 整个握手交互的过程总共花了多少 rtt

  RTT(Round-Trip Time)为数据完全发送完（完成最后一个比特推送到数据链路上）到收到确认信号的时间。https的握手过程是在tcp三次握手之后额外添加2次RTT来完成。

  - TCP 握手（ 1 RTT）

    和服务器建立 TCP 连接，客户端向服务器发送 SYN 包，服务端返回确认的 ACK 包，这会花费一个往返（1 RTT）。

  - TLS 握手 （2 RTT）

    该部分客户端会和服务器交换密钥，同时设置加密链接，对于 TLS 1.2 或者更早的版本，这步需要 2 个 RTT。

  - 建立 HTTP 连接（1 RTT）

    一旦 TLS 连接建立，浏览器就会通过该连接发送加密过的 HTTP 请求。

  从开始到建立一个完整的 HTTPS 连接一共需要 4 个 RTT。如果是浏览刚刚已经访问过的站点的话，通过 TLS 的会话恢复机制，第三步 TLS 握手能够从 2 RTT 变为 1 RTT。

  **注意：**虽然握手过程有1.5个来回，但是最后客户端向服务器发送的第一条应用数据不需要等待服务器返回的信息，因此握手延时是1*RTT。

- 端口复用和地址复用

  端口复用和地址复用是网络编程中的两个概念，它们的作用是优化网络资源的利用。

  1. 端口复用

  端口复用是指在同一个主机上，多个进程可以同时监听同一个端口。在传统的网络编程中，如果一个进程需要监听某个端口，那么其他进程就不能再监听这个端口了，这就造成了资源的浪费。而端口复用技术可以让多个进程同时监听同一个端口，从而提高了网络资源的利用率。

  在实现时，需要使用SO_REUSEPORT选项，让不同的进程可以绑定同一个端口。

  2. 地址复用

  地址复用是指在同一个主机上，多个进程可以同时绑定同一个IP地址和端口。在传统的网络编程中，如果一个进程需要绑定某个IP地址和端口，那么其他进程就不能再绑定这个IP地址和端口了，这就造成了资源的浪费。而地址复用技术可以让多个进程同时绑定同一个IP地址和端口，从而提高了网络资源的利用率。

  在实现时，需要使用SO_REUSEADDR选项，让不同的网络接口可以使用同一个IP地址。

  需要注意的是，端口复用和地址复用只能在同一个主机上使用，不能跨主机使用。而且，在使用端口复用和地址复用时，需要注意保证各个进程之间的通信不会出现冲突。

- TCP如何感知对方断开链接

  TCP使用一种称为“心跳检测”的机制来感知对方是否断开连接。通过发送称为“keep-alive”消息的特殊TCP数据包，TCP可以检测到对方是否还处于连接状态。如果TCP在一定时间内没有收到对方的响应，则会认为对方已经断开连接。这个时间通常被称为“keep-alive超时时间”，默认情况下为2小时。当然，这个时间可以根据需要进行调整。

- tcp 返回 EGIAN 是什么问题？

  当应用程序在socket中设置O_NONBLOCK属性后，如果发送缓存被占满，send就会返回EAGAIN或EWOULDBLOCK 的错误。

  当需要向socket发送数据时，现将数据压入发送缓存区，并且将socket加入可写事件监听。当socket触发可写事件（EPOLLOUT）时，调用 socket_send函数发送数据，所有数据发送完毕，再清除EPOLLOUT事件。

- close_wait 状态下可以收发数据吗？

  在 `CLOSE_WAIT` 状态下，应用程序已经调用了 `close()` 函数，但是仍然有可能收到对方发来的数据，因此可以继续接收数据。但是，应用程序不能再向对方发送数据，因为连接已经被对方关闭，发送数据会收到 `RST` 响应。在这个状态下，TCP 会等待应用程序处理完所有未读取的数据后，发送 `FIN` 报文给对方，然后进入 `LAST_ACK` 状态等待对方的确认。

- 接收端和发生端之间有个 TCP 长连接，接收端应用层一直不处理缓冲区数据，发送端一直发，最后发送端，接收端，TCP 一些属性，会有什么变化？

  在这种情况下，如果接收端一直不处理缓冲区数据，那么缓冲区会不断累积，直到达到一定的阈值，此时发送端的数据将会被阻塞，因为TCP的拥塞控制会认为网络出现了拥塞，从而触发拥塞避免算法，减少发送速率。同时，发送端和接收端的TCP会根据网络状况自动调整拥塞窗口大小，以达到更好的网络利用率和传输效率。

  在这种情况下，如果发送端一直发送数据，而接收端一直不读取数据，会导致接收端的TCP缓冲区被填满，从而触发TCP的流量控制机制，发送端的数据发送速率将被限制，从而保证接收端的TCP缓冲区不会溢出。同时，发送端和接收端的TCP会根据网络状况自动调整拥塞窗口大小，以达到更好的网络利用率和传输效率。

  如果这种情况持续较长时间，可能会导致发送端和接收端的TCP连接被超时关闭，从而需要重新建立TCP连接。

- UDP 包想一次性发送 2K 的数据，接收端 1K1K 的读，能成功么

  TCP可以，但是UDP不可以。

  TCP是以数据流来发送的，发送端可以是1K1K的发送数据，而接收端的应用程序可以是2K2K地提取数据，也可以一次性全部提走，或者一次只提取几个字节的数据。应用程序所看到的数据是一个整体，或者说是一个流(stream) ，一条消息有多少个字节对应用程序是不可见的，因此TCP协议是面向流的协议，这也是容易出现粘包问题的原因。

  而UDP协议是面向消息的协议，每个UDP字段都是一条消息，应用程序必须以消息为单位提取数据，不能一次性提取任意字节的数据，这和TCP很不相同。TCP协议下，一条消息的发送，无论底层如何分段分片，TCP协议层会把构成整条消息的数据段排序完成后才呈现在内核缓冲区。

- MSS和MTU

  MSS和MTU是TCP/IP协议栈中的两个重要参数，分别代表最大分段大小和最大传输单元。它们的含义和作用如下：

  - MSS（Maximum Segment Size）：指的是TCP数据包中的数据部分的最大长度，不包括TCP头部和IP头部。MSS的大小是由对端的TCP栈在建立连接时协商决定的，通常是MTU减去IP和TCP头部的长度。MSS的大小决定了TCP分段的大小，也就是说，如果TCP发送的数据包长度超过了MSS，那么就需要将数据分成多个MSS大小的分段进行传输。

  - MTU（Maximum Transmission Unit）：指的是网络能够传输的最大的TCP数据包的大小，不包括链路层头部和尾部的长度。MTU的大小是由网络设备决定的，不同的网络设备MTU大小可能不同。如果TCP要发送的数据包长度超过了MTU，那么就需要将数据分成多个MTU大小的分段进行传输。

  MSS和MTU之间的关系是：MSS = MTU - IP头部长度 - TCP头部长度。在TCP建立连接时，双方会协商MSS的大小，以保证TCP数据包不会超过MTU的大小，从而避免IP分片和重组的问题，提高网络传输效率。

- 服务端主动请求关闭连接，会发生什么？

  当服务器进程被终止时，会关闭其打开的所有文件描述符，此时就会向客户端发送一个FIN 的报文，客户端则响应一个ACK 报文，但是这样只完成了“四次挥手”的前两次挥手，也就是说这样只实现了半关闭，客户端仍然可以向服务器写入数据。

  但是当客户端向服务器写入数据时，由于服务器端的套接字进程已经终止，此时连接的状态已经异常了，所以服务端进程不会向客户端发送ACK 报文，而是发送了一个RST 报文请求将处于异常状态的连接复位。如果客户端此时还要向服务端发送数据，将诱发服务端TCP向服务端发送SIGPIPE信号，SIGPIPE信号的默认处理是终止程序，导致客户端进程退出。

- TCP的keep-alive和HTTP的keep-alive有什么区别？

  HTTP 的 Keep-Alive 也叫 HTTP 长连接，该功能是由「应用程序」实现的，可以使得用同一个 TCP 连接来发送和接收多个 HTTP 请求/应答，减少了 HTTP 短连接带来的多次 TCP 连接建立和释放的开销。

  TCP 的 Keepalive 也叫 TCP 保活机制，该功能是由「内核」实现的，当客户端和服务端长达一定时间没有进行数据交互时，内核为了确保该连接是否还有效，就会发送探测报文，来检测对方是否还在线，然后来决定是否要关闭该连接。

- 延时与吞吐率的区别

  延迟（Latency）是指从发送数据到接收数据所需的时间，也就是数据在网络中传输的时间。延迟一般是以毫秒（ms）为单位进行计算，是指网络传输速度的快慢，通常用于测量网络的响应速度。

  吞吐率（Throughput）是指在单位时间内通过网络的数据量，通常以比特每秒（bps）或字节每秒（Bps）为单位进行计算，是指网络的传输能力。吞吐率通常用于测量网络的容量大小，即网络传输速率的大小。

  延迟和吞吐率都是网络性能的重要指标，但它们的重点不同。延迟是关注网络的响应速度，而吞吐率则关注网络的传输能力。在实际应用中，延迟和吞吐率都是需要考虑的因素，不同的应用场景需要不同的重点。

- 服务端一下子涌入大量数据怎么办

  如果服务端一下子涌入大量数据，可能会导致服务端无法及时处理这些数据，甚至会导致服务端崩溃。为了避免这种情况的发生，可以采取以下几种方法：

  1. 增加服务端的处理能力：可以增加服务端的处理能力，例如增加服务器的硬件配置、优化代码等，以提高服务端的处理速度和稳定性。

  2. 限制客户端发送数据的速率：可以通过限制客户端发送数据的速率，以减少服务端处理数据的压力。可以通过限制客户端的带宽、设置发送数据的时间间隔等方式实现。

  3. 分批处理数据：可以将大量数据分批处理，每次处理一部分数据，以减少服务端的压力。可以通过设置缓存区、分段传输数据等方式实现。

  4. 采用异步处理方式：可以采用异步处理方式，将数据存储到队列中，由服务端异步处理，以提高服务端的处理效率和稳定性。可以通过使用线程池、消息队列等方式实现。

  5. 采用负载均衡技术：可以将请求分发到多个服务端上进行处理，以提高服务端的处理能力和稳定性。可以通过使用负载均衡器、集群等方式实现。

- TCP的拥塞控制和流量控制有什么区别？

  流量控制解决因发送方发送数据太快而导致接收方来不及接收使接收方缓存溢出的问题。流量控制的基本方法就接收方根据自己的接收能力控制发送方的发送速率，TCP采用接收方控制发送方发送窗口大小的方法来实现在TCP连接上的流量控制。

  流量控制利用滑动窗口协议控制发送端流量，是为了解决发送数据过快导致接收方来不及接收的问题。接收方会发送流量控制报文，通知发送方窗口大小，发送方发送的数据大小不能超过窗口大小。如果发送者发送数据过快，接收者来不及接收，那么就会有报文丢失。为了避免报文丢失，控制发送者的发送速度，使得接收者来得及接收，这就是流量控制。流量控制根本目的是防止报文丢失，它是构成TCP可靠性的一方面。

  拥塞控制就是防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不致过载。TCP的发送方维持一个叫做拥塞窗口的状态变量。拥塞窗口的大小取决于网络的拥塞程度，当网络拥塞时减小拥塞窗口的大小，控制TCP发送方的发送速率。TCP发送方的发送窗口大小取接收窗口和拥塞窗口的最小值。

  - 区别

  流量控制：流量控制是作用于接收者的，控制发送者的发送速度从而使接收者来得及接收，防止报文丢失。

  拥塞控制：拥塞控制是作用于网络的，防止过多的数据注入到网络中，避免出现网络负载过大的情况。常用的方法就是：慢启动、拥塞避免、拥塞发生、快速恢复。

- TCP是全双工的，HTTP是哪种？全双工半双工单工？

  1. 单工： 数据传输只允许在一个方向上的传输，只能一方来发送数据，另一方来接收数据并发送。例如：对讲机
  2. 半双工：数据传输允许两个方向上的传输，但是同一时间内，只可以有一方发送或接受消息。例如：打电话
  3. 全双工：同时可进行双向传输。例如：`websocket`

  HTTP是半双工的。 

  在半双工通信中，通信双方都可以发送和接收数据，但不能同时进行。在HTTP中，客户端向服务器发送请求，服务器响应请求并返回数据，此时客户端不能再向服务器发送请求，直到服务器响应完毕。因此，HTTP是一种半双工通信协议。 
  
  相比之下，TCP是一种全双工通信协议，因为在TCP连接中，通信双方可以同时进行发送和接收数据。

- TCP 报文长度字段设置在哪里

  kind=2，最大报文段长度（MSS）选项。

  TCP连接初始化时，通信双方使用该选项来协商最大报文段长度。TCP模块通常将MSS设置为（MTU-40）字节（减掉的这40字节包括20字节的TCP头部和20字节的IP头部）。这样携带TCP报文段的IP数据报的长度就不会超过MTU（假设TCP头部和IP头部都不包含选项字段，并且这也是一般情况），从而避免本机发生IP分片。对以太网而言，MSS值是1460（1500-40）字节。

  TCP 报文长度字段被设置在TCP头部中的数据偏移字段中。它指定了TCP头部的长度（以32位字长为单位），因为TCP头部长度是可变的，所以数据偏移字段指定了TCP头部的字节数，这样接收端就可以正确地解析TCP报文。TCP头部的最小长度为20字节，最大长度为60字节。

- socket调用write返回值表示的意义

  1. 当read()或者write()函数返回值大于0时，表示实际从缓冲区读取或者写入的字节数目；
  2. 当read()函数返回值为0时，表示对端已经关闭了 socket，这时候也要关闭这个socket，否则会导致socket泄露。netstat命令查看下，如果有closewait状态的socket,就是socket泄露了。当write()函数返回0时，表示当前写缓冲区已满，是正常情况，下次再来写就行了；
  3. 当read()或者write()返回-1时，一般要判断errno。如果errno == EINTR,表示系统当前中断了，直接忽略。如果errno == EAGAIN或者EWOULDBLOCK，非阻塞socket直接忽略；如果是阻塞的socket,一般是读写操作超时了，还未返回。这个超时是指socket的SO_RCVTIMEO与SO_SNDTIMEO两个属性。所以在使用阻塞socket时，不要将超时时间设置的过小。不然返回了-1，你也不知道是socket连接是真的断开了，还是正常的网络抖动。一般情况下，阻塞的socket返回了-1，都需要关闭重新连接；
  4. 如果返回值为正数，表示成功发送了指定数量的字节；如果返回值为0，表示对方已经关闭了连接；如果返回值为-1，表示发送失败，此时可以通过errno来确定错误的具体原因。 在发送数据时，write函数会尽可能地将数据写入Socket的发送缓冲区，然后返回已经写入的字节数。如果写入的数据量超过了发送缓冲区的大小，write函数可能会阻塞，等待发送缓冲区有足够的空间。如果在一定时间内发送缓冲区还没有空间，write函数可能会返回-1，并设置errno为EAGAIN或EWOULDBLOCK，表示发送缓冲区已满，需要等待一段时间再尝试发送。
- 路由器和交换器的区别

  1. 工作层次不同 路由器工作在网络层，主要负责不同网络之间的数据转发和路由选择；而交换机工作在数据链路层，主要负责同一网络内部的数据交换。
  1. 转发方式不同 路由器使用IP地址进行转发，根据IP地址进行路由选择；而交换机使用MAC地址进行转发，根据MAC地址进行数据交换。
  1. 范围不同 路由器通常连接不同的网络，可以跨越不同的地域范围；而交换机通常连接同一网络内的设备，范围相对较小。
  1. 能力不同 路由器具备路由选择的功能，可以在不同网络之间进行数据转发；而交换机只能在同一网络内部进行数据交换。
  1. 安全性不同 由于路由器可以进行路由选择和网络隔离，因此具有更高的安全性；而交换机只能在同一网络内部进行数据交换，安全性相对较低。

- Accept函数与三次握手关系

  1. 当客户端调用connect时，触发了连接请求，向服务器发送了SYN J包，这时connect进入阻塞状态；
  2. 服务器监听到连接请求，即收到SYN J包，调用accept函数接收请求，向客户端发送SYN K ，ACK J+1，这时accept进入阻塞状态；
  3. 客户端收到服务器的SYN K ，ACK J+1之后，这时connect返回，并对SYN K进行确认；服务器收到ACK K+1时，accept返回，至此三次握手完毕，连接建立。


- IP层如何找MAC地址？如果对应IP不在局域网呢

  在局域网内，IP地址和MAC地址之间的映射关系可以通过ARP协议来获取。当一台主机需要发送数据包给另一台主机时，它会首先检查目标IP地址是否在本地网络中。如果是，它会使用ARP广播来询问目标主机的MAC地址。目标主机收到ARP请求后，会回复一个ARP响应包，其中包含自己的MAC地址。

  如果目标IP地址不在本地网络中，发送主机会将数据包发送到默认网关。默认网关会根据路由表将数据包转发到下一个网络。在这种情况下，发送主机会使用ARP广播来获取默认网关的MAC地址，然后将数据包发送到默认网关。默认网关收到数据包后，会根据路由表将数据包转发到目标主机所在的网络。

  如果攻击者在局域网中进行ARP欺骗攻击，它会发送伪造的ARP响应包，欺骗其他主机将攻击者的MAC地址与目标IP地址关联起来。这样，攻击者就可以拦截、修改或重定向其他主机的数据流量，从而实现窃取信息或进行中间人攻击等恶意行为。

- 为什么DNS使用UDP而不是TCP？

  DNS（Domain Name System）使用UDP（User Datagram Protocol）而不是TCP（Transmission Control Protocol）是因为：

  1. UDP是无连接的，没有建立和维护连接的开销，可以更快地完成查询和响应，适合短消息的传输。而TCP是面向连接的，需要进行三次握手建立连接，然后再进行数据传输，会增加一定的延迟和开销。

  2. DNS是一个轻量级的协议，一般传输的数据包较小，可以通过UDP一次性传输完整的数据包，而TCP需要将数据包分成多个段进行传输，增加了数据包的大小和传输的开销。

  3. DNS使用UDP可以更好地处理网络拥塞的情况，因为UDP不会对网络拥塞作出反应，而TCP会根据网络拥塞情况调整数据传输的速率，可能会导致延迟和丢包。

  虽然UDP存在一定的缺陷，如可能丢包、重复、乱序等，但对于DNS这样的应用场景，这些问题并不会对查询和响应的准确性产生太大影响。而且，DNS还有一些机制可以处理UDP传输中的一些问题，如使用DNSSEC（DNS Security Extensions）保证数据的完整性和安全性，使用EDNS（Extension mechanisms for DNS）扩展DNS的功能。


- 当有两个近远的IP地址，怎么做出调整让DNS选择近的？

  要让DNS选择近的IP地址，可以通过以下步骤进行调整：

  1. 确定哪个IP地址更近：使用ping命令或traceroute命令测试两个IP地址的延迟和路由跳数，确定哪个IP地址更近。

  2. 在DNS服务器上设置优先级：在DNS服务器上设置优先级，将近的IP地址优先级设置为高，远的IP地址优先级设置为低。

  3. 使用DNS负载均衡器：使用DNS负载均衡器可以根据用户的位置和网络状况自动选择最近的IP地址，提高网站的访问速度和稳定性。

  4. 使用CDN服务：使用CDN服务可以将网站的内容分发到全球各地的服务器上，根据用户的位置自动选择最近的服务器，提高访问速度和稳定性。

  综上所述，通过以上步骤可以让DNS选择近的IP地址，提高网站的访问速度和稳定性。


- ARP攻击/ARP欺骗

  ARP（Address Resolution Protocol）攻击，也叫ARP欺骗，是一种利用局域网上的ARP协议缺陷，欺骗目标主机的MAC地址，从而达到网络攻击的目的。

  攻击者通过伪造ARP响应包，将自己的MAC地址伪装成目标主机的MAC地址，然后发送给局域网上的其他主机，使得这些主机将攻击者的MAC地址缓存起来，从而将攻击者伪装成目标主机。这样，攻击者就可以通过ARP欺骗，窃取目标主机的数据包，或者劫持目标主机的网络连接，进行中间人攻击等恶意行为。

  ARP攻击可以分为主动式攻击和被动式攻击。主动式攻击是指攻击者主动伪造ARP响应包，欺骗目标主机；被动式攻击是指攻击者监听网络上的ARP请求和响应包，然后进行欺骗。

  为了防止ARP攻击，可以采取以下措施：

  1. 使用静态ARP表，手动维护IP地址和MAC地址的对应关系。

  2. 使用动态ARP缓存，设置ARP缓存的过期时间，定期清除缓存。

  3. 使用ARP防火墙，限制ARP请求和响应包的发送和接收。

  4. 使用虚拟局域网（VLAN）技术，将不同的主机分隔开来，减少攻击面。

  5. 使用加密技术，保护数据包的安全传输。

- 网际控制报文协议ICMP的过程

  网际控制报文协议（ICMP）是一种用于在IP网络上发送错误消息的协议。它的主要作用是在网络中传递控制信息和错误消息。以下是 ICMP 的过程：

  1. 发送方向目标主机发送 ICMP 报文。

  2. 目标主机接收到 ICMP 报文后，根据报文类型进行相应的处理。例如，如果是 Ping 请求报文，则目标主机会返回 Ping 应答报文。

  3. 如果目标主机无法处理 ICMP 报文，则会向发送方发送一个 ICMP 错误报文，告诉发送方发生了什么错误。

  4. 发送方接收到 ICMP 错误报文后，可以根据报文内容进行相应的处理。例如，如果是目标主机不可达的错误报文，则发送方可以尝试使用其他路径发送数据包。

  在 ICMP 过程中，主要使用了 IP 协议和 ICMP 协议。IP 协议用于将 ICMP 报文从发送方传输到目标主机，而 ICMP 协议则用于发送控制信息和错误消息。

- ping 的过程，分别用到了哪些协议

  Ping 的过程主要用到了两个协议：ICMP 和 IP。

  Ping 是一种用于测试网络连接的常用命令，其原理是向目标主机发送 ICMP 回显请求，然后等待目标主机返回 ICMP 回显应答。在这个过程中，Ping 命令首先使用 IP 协议将 ICMP 数据包发送到目标主机，然后目标主机收到 ICMP 数据包后，使用 ICMP 协议进行回应。具体来说，Ping 的过程如下：

  1. 发送端主机构建 ICMP 回显请求数据包，并使用 IP 协议将数据包发送到目标主机。

  2. 目标主机接收到 ICMP 数据包后，使用 ICMP 协议回应 ICMP 回显应答数据包。

  3. 发送端主机接收到 ICMP 回显应答数据包后，计算出往返时间（RTT），并显示在 Ping 命令的输出中。

  在这个过程中，Ping 命令使用了 ICMP 协议来发送和接收数据包，同时也使用了 IP 协议来进行数据包的路由和传输。

- 动态主机配置协议DHCP的过程

  DHCP（Dynamic Host Configuration Protocol，动态主机配置协议）是一种网络协议，它可以自动为计算机分配IP地址、子网掩码、默认网关、DNS服务器等网络配置信息，从而简化网络管理和配置。DHCP的过程如下：

  1. DHCP Discover：客户端在加入网络时发送一个广播消息，请求DHCP服务器提供IP地址和其他配置信息。

  2. DHCP Offer：DHCP服务器接收到客户端的广播消息后，向客户端发送一个包含IP地址和其他配置信息的DHCP Offer消息。

  3. DHCP Request：客户端收到DHCP Offer消息后，向DHCP服务器发送一个DHCP Request消息，确认接受所提供的配置信息。

  4. DHCP Acknowledge：DHCP服务器收到客户端的DHCP Request消息后，向客户端发送一个DHCP Acknowledge消息，确认分配IP地址和其他配置信息。

  5. DHCP Lease Renewal：客户端在租期到期前向DHCP服务器发送DHCP Request消息，请求续租IP地址和其他配置信息。

  6. DHCP Lease Expired：如果客户端在租期到期后没有向DHCP服务器发送DHCP Request消息，则DHCP服务器会释放该IP地址，以便其他客户端使用。

  通过DHCP，网络管理员可以轻松管理网络中的IP地址和其他配置信息，避免了手动配置的繁琐和错误，提高了网络管理的效率。

- NAT（Network Address Translation，网络地址转换）是一种网络协议，主要用于将内部网络的私有IP地址转换为合法的公网IP地址，以便实现内部网络与外部网络的通信。NAT的主要工作流程可以概括如下：

  1. 在内部网络中，客户端设备发送数据包到公网服务器时，数据包的源IP地址是客户端设备的私有IP地址，目标IP地址是公网服务器的公网IP地址。
  2. NAT设备接收到这个数据包后，会将源IP地址和源端口号进行修改，将其改为NAT设备的公网IP地址和一个随机的端口号，并记录这个映射关系。
  3. NAT设备将修改后的数据包发送到公网服务器。
  4. 公网服务器接收到数据包后，将响应数据包发送回NAT设备，并将目标IP地址和目标端口号设置为NAT设备的公网IP地址和之前记录的随机端口号。
  5. NAT设备接收到响应数据包后，根据记录的映射关系将目标IP地址和目标端口号还原成客户端设备的私有IP地址和端口号，并将响应数据包发送回客户端设备。

  NAT设备在转换IP地址时，会根据每个数据包的源IP地址、目标IP地址、源端口号和目标端口号等信息来进行映射。因此，在内网中，不同设备的私有IP地址和端口号不同，NAT设备可以根据这些信息来区分不同设备发送的数据包，并对其进行转换。

  当内网中的设备之间进行通信时，数据包的源IP地址和目标IP地址都是内网中的私有IP地址，NAT设备可以根据这些信息来确定数据包的目标设备，并将其传递到相应的设备。在这种情况下，NAT设备不需要对数据包进行IP地址转换。


- UDP协议的最大长度，超过最大长度会怎么样

  UDP（User Datagram Protocol，用户数据报协议）是一个无连接的、不可靠的、面向数据报的传输层协议。

  UDP报文的最大长度由其16位长度字段决定。该字段指定了整个报文（包括报头和数据）的长度。因此，UDP报文的最大长度是 2^16 - 1 字节，即65,535字节。需要注意的是，这里的长度包括了8字节的UDP报头，所以最大的有效载荷长度是 65,527 字节。

  如果试图发送长度超过最大长度的UDP报文，以下情况可能会发生：

  1. **应用程序错误**：操作系统或编程语言的socket库可能会报告错误，提示报文长度过长。在这种情况下，数据可能无法发送。

  2. **分片**：如果操作系统或网络设备支持IP分片，那么超过最大长度的UDP报文可能会被分成多个较小的IP分片。接收端将尝试重新组合这些分片以重建原始UDP报文。但是，这会增加网络负载，同时由于UDP的不可靠性，任何丢失的分片都可能导致整个报文无法正确接收。

  3. **数据截断**：如果UDP报文被发送，但超过了最大长度，某些数据可能会被截断。接收端收到的报文将不完整，可能导致处理错误或数据丢失。

  为了避免这些问题，可以考虑将大数据分成多个较小的UDP报文发送，或者使用具备可靠性和流量控制的传输协议（如TCP）替代UDP。

- udp大量传输应该注意什么

  udp大量传输应该注意以下几点:

  1. 控制报文大小。udp没有拥塞控制,过大的报文容易导致网络拥塞,影响传输效率。一般控制在MTU(最大传输单元)范围内。

  2. 快速重传机制。udp本身不 guaranteetransmission,需要应用层实现重传机制,来应对报文丢失的情况。通常使用定时器以及序列号来实现。

  3. 拥塞控制。虽然udp本身没有拥塞控制,但应用层可以实现拥塞控制算法,比如slow start,拥塞避免等,来在一定程度上控制网络拥塞。

  4. 误差校验。udp不提供任何错误校验能力,应用层需要实现CRC或其它检验码来检测传输错误。

  5. 负载分片。如果应用数据过大,可以在应用层进行分片,然后通过多个udp数据报传输。接收端需要进行重组。

  6. 重传次数上限。对于无响应的包,应用层需要重传,但重传次数不应该无限,需要设置一个上限,超过上限判定对端不可达。

  7. 心跳包。当长时间没有数据报文传输时,可以定期发送心跳包来维持端到端的连接,防止NAT / 防火墙将端口映射删除。

  8. 过载保护。发送端需要控制发送速率,防止接收端处理能力被过载,导致大量报文丢失。可以通过接收端反馈的丢包率来调整发送速率。

  9. 时间同步。在某些应用场景下,发送端和接收端需要保持较为精确的时间同步,这需要应用层自己实现时间同步机制。

- udp 为什么是不可靠的？bind 和 connect 对于 udp 的作用是什么

  UDP协议是不可靠的，主要有以下两个方面的原因：

  1. UDP协议没有提供数据确认和重传机制，因此无法保证数据的可靠性。如果一个数据包在传输过程中丢失或损坏，UDP协议没有任何手段来检测并重传这个数据包，接收方也没有办法知道是否漏掉了数据包。

  2. UDP协议没有提供流量控制和拥塞控制机制，因此在网络拥塞或数据量大的情况下，UDP协议可能会导致数据丢失或延迟。

  bind和connect对于UDP的作用如下：

  1. bind函数用于将一个UDP套接字绑定到一个特定的IP地址和端口号，以便监听指定的IP地址和端口号上的数据报文。在UDP协议中，bind操作是可选的，如果不进行bind操作，系统会随机分配一个端口号。

  2. connect函数用于将一个UDP套接字连接到一个特定的目的IP地址和端口号。在UDP协议中，connect操作是可选的，如果不进行connect操作，则在发送数据时需要在sendto函数中指定目的IP地址和端口号。

  通过bind和connect操作，UDP应用程序可以指定发送和接收数据的IP地址和端口号，以便在网络中正确地路由数据报文。同时，connect操作还可以将UDP套接字关联到一个特定的目的地址，从而使应用程序不必在每次发送数据时都指定目的地址，提高了应用程序的效率。但是需要注意的是，UDP协议仍然是不可靠的，因此在应用程序中需要进行一些额外的处理来确保数据的可靠性和完整性。

- TCP 怎么保证发送数据顺序性（数据包乱序问题）？

  在TCP协议中，为了保证发送数据的顺序性，使用了以下几种机制：

  1. 序列号：TCP协议在发送数据时，会给每个数据包分配一个唯一的序列号，用于区分每个数据包。接收方会通过序列号来确定数据包的顺序，以及是否有丢失的数据包。

  2. 确认应答：接收方在收到数据包后，会向发送方发送一个确认应答（ACK），用于告诉发送方已经接收到数据包。发送方在收到ACK后，会认为该数据包已经成功发送，并将下一个数据包发送出去。

  3. 滑动窗口：TCP协议使用滑动窗口机制来控制发送方发送数据的速度。滑动窗口的大小是动态调节的，接收方可以通过发送窗口（Receiver Window）来告诉发送方可以接收多少数据，发送方将根据发送窗口的大小来控制发送数据的速度。

  通过上述机制，TCP协议可以保证发送数据的顺序性。发送方会按照数据的顺序发送数据包，并等待接收方的确认应答。如果接收方没有收到某个数据包，则会通知发送方重新发送该数据包。同时，滑动窗口机制可以帮助发送方控制发送数据的速度，避免发送过快导致数据包丢失或错误。

- TCP的序列号为什么是随机的？能不能固定从1开始？为什么？

  TCP序列号是为了保证数据传输的可靠性而设计的，它的随机性可以提高数据传输的安全性和可靠性。具体原因如下：

  1. 防止数据包重复：TCP序列号可以防止数据包在传输过程中重复发送或被重复接收，从而保证数据传输的可靠性。

  2. 防止数据包被篡改：TCP序列号可以防止数据包被篡改或冒充，从而保证数据传输的安全性。

  3. 防止攻击者利用序列号进行攻击：如果TCP序列号是固定的，攻击者可以通过猜测序列号来执行攻击，例如TCP SYN Flood攻击。

  因此，TCP序列号通常是随机生成的，以提高数据传输的安全性和可靠性。如果TCP序列号从1开始，攻击者可以轻易地猜测下一个序列号，并进行攻击。此外，TCP序列号的随机性可以保证TCP连接的唯一性，避免不同的连接使用相同的序列号，从而导致数据混乱或错误。

- TCP滑动窗口最大值

  TCP滑动窗口的最大值取决于接收方和发送方的实现以及网络状况。TCP滑动窗口的大小是动态调整的，发送方和接收方会根据网络状况和对方的处理能力来动态调整滑动窗口的大小。

  在TCP协议中，发送方和接收方都有一个窗口大小的参数，分别称为发送窗口和接收窗口。发送方的发送窗口表示可以发送的数据量，而接收方的接收窗口表示可以接收的数据量。发送方和接收方会通过TCP报文段中的窗口字段来告知对方它们的窗口大小。

  发送方会根据接收方的接收窗口来调整自己的发送窗口大小，以控制发送数据的速率。如果接收方的接收窗口变小，发送方就会减小自己的发送窗口，以避免发送过多的数据导致数据包丢失。如果接收方的接收窗口变大，发送方就会增大自己的发送窗口，以提高发送数据的速率。

  因此，TCP滑动窗口的最大值取决于网络状况、对方的处理能力以及实现的具体细节。在实际应用中，TCP滑动窗口的最大值一般会根据具体情况进行调整，以达到最优的网络性能。


- UDP怎么实现TCP的拥塞控制？

  UDP是一种无连接的传输协议，它不提供可靠性、流量控制和拥塞控制的机制，因此在网络拥塞的情况下容易出现数据丢失和网络性能下降的问题。相比之下，TCP是一种基于连接、可靠性高、流量控制和拥塞控制都较为完善的传输协议。

  虽然UDP本身并不提供拥塞控制的机制，但是可以通过一些手段来实现类似于TCP的拥塞控制。以下是几种常见的实现方式：

  1. 使用带拥塞控制的UDP协议：一些厂商和组织提供了一些基于UDP的带拥塞控制的协议，例如QUIC、SCTP等。这些协议在UDP的基础上增加了可靠性、流量控制和拥塞控制等机制，可以提供类似于TCP的性能。

  2. 自行实现拥塞控制：应用程序可以自行实现拥塞控制的算法，例如类似于TCP的拥塞窗口算法。应用程序可以根据网络拥塞程度动态地调整发送速率，避免网络拥塞导致数据丢失和网络性能下降的问题。

  3. 使用反馈机制：应用程序可以通过向接收端发送反馈数据包，获取网络拥塞情况。例如，可以通过接收端返回的ACK数据包的延迟时间、重传次数等信息来判断网络拥塞情况，并根据情况调整发送速率。

  需要注意的是，UDP本身并不提供拥塞控制的机制，因此实现类似于TCP的拥塞控制需要应用程序进行处理。同时，实现拥塞控制可能会增加应用程序的复杂性和开发成本，需要根据实际情况进行权衡。

- TCP如何控制发送数据的大小

  TCP通过拥塞窗口算法来控制发送数据的大小。拥塞窗口算法是一种动态调整发送数据速率的算法，它根据网络拥塞程度动态调整拥塞窗口的大小，从而控制数据的发送速率。

  在TCP中，发送方维护一个拥塞窗口的大小，这个大小表示发送方可以发送的数据量。拥塞窗口的大小是动态调整的，具体调整方法如下：

  1. 慢启动阶段：发送方初始拥塞窗口大小为一个MSS（最大报文段长度），即一个TCP数据包的大小。发送方通过不断发送数据包，每当接收到一个ACK确认时，就将拥塞窗口大小加倍。这个过程就是慢启动阶段，它能够快速将拥塞窗口大小增加到一个合适的值，以达到最大传输速率。

  2. 拥塞避免阶段：当拥塞窗口大小达到一个阈值后，发送方就进入拥塞避免阶段。在拥塞避免阶段，发送方将拥塞窗口大小线性增加，而不是指数增加。这样可以避免网络拥塞。

  3. 拥塞发生阶段：如果网络出现拥塞，接收方会返回一个重复的ACK或者超时重传的数据包，而发送方就会认为网络出现了拥塞。在这个时候，发送方将拥塞窗口大小减半，然后进入慢启动阶段重新开始调整拥塞窗口大小。

  通过拥塞窗口算法，TCP能够根据网络拥塞程度动态调整发送数据的大小，从而实现流量控制和拥塞控制。这样可以避免网络拥塞导致数据丢失和网络性能下降的问题，保证数据传输的可靠性和稳定性。


- socket 本地通信需要通过 TCP/IP 协议栈吗

  在一些操作系统（如Linux和Windows）中，socket本地通信是通过本地协议栈来实现的，而不需要经过TCP/IP协议栈。本地协议栈是操作系统提供的一种机制，用于在同一台计算机的不同进程之间进行通信。

  本地协议栈通常使用Unix域套接字（Unix domain socket）来进行通信，它是一种专门用于进程间通信的套接字类型。与TCP/IP套接字不同，Unix域套接字不需要经过网络协议栈，而是直接在内核中进行数据传输，因此具有更高的性能和更低的延迟。

  在Unix-like系统中，本地协议栈通常是通过Unix域套接字来实现的。在Windows系统中，本地协议栈使用命名管道（Named Pipes）来实现进程间通信。

  因此，对于本地通信，如果使用本地协议栈（如Unix域套接字或命名管道），就不需要经过TCP/IP协议栈。但如果使用TCP/IP协议栈来进行本地通信，就需要经过TCP/IP协议栈的处理，会增加额外的网络开销和延迟。

- 怎么知道 http 的报文长度

  在HTTP协议中，有多种方法可以确定HTTP报文的长度，其中常用的包括：

  1. Content-Length首部字段：当HTTP报文中包含消息体时，可以使用Content-Length首部字段来指定消息体的长度。例如，Content-Length: 123表示消息体的长度为123个字节。

  2. Transfer-Encoding首部字段：如果HTTP报文采用分块传输编码（chunked transfer encoding）方式进行传输，就可以使用Transfer-Encoding首部字段来指定每个分块的长度。例如，Transfer-Encoding: chunked表示采用分块传输编码方式进行传输。

  3. Connection首部字段：如果HTTP报文采用持久连接（persistent connection）方式进行传输，就可以使用Connection首部字段来指定消息体的长度。例如，Connection: Keep-Alive，表示使用持久连接方式进行传输。

  在实际应用中，通常会根据具体情况选择合适的方法来确定HTTP报文的长度。如果HTTP报文中包含消息体，建议使用Content-Length首部字段来指定消息体的长度。如果采用分块传输编码方式进行传输，就可以使用Transfer-Encoding首部字段来指定每个分块的长度。如果采用持久连接方式进行传输，就可以使用Connection首部字段来指定消息体的长度。

- 如果你访问一个网站很慢，怎么排查和解决

  如果访问一个网站很慢，可以按照以下步骤进行排查和解决：

  1. 检查网络连接：首先需要检查自己的网络连接是否正常。可以通过打开其他网站或者使用ping或traceroute命令测试网络是否正常。

  2. 清除浏览器缓存：浏览器缓存可能会导致网站访问变慢，可以尝试清除浏览器缓存并重新访问网站。

  3. 检查DNS解析：DNS解析也可能是导致网站访问变慢的原因之一。可以使用nslookup或dig命令检查DNS解析是否正常，如果不正常，可以尝试切换到其他DNS服务器。

  4. 检查网站服务器：网站服务器可能出现宕机或者负载过高等问题，可以使用ping或traceroute命令检查网站服务器是否正常，如果不正常，可以联系网站管理员。

  5. 检查网络延迟：网络延迟也可能导致网站访问变慢，可以使用网络诊断工具（如ping或traceroute）检查网络延迟是否过高，如果过高，可以尝试使用VPN或者更换网络环境。

  6. 检查网站内容：网站内容过大或者包含大量的媒体文件可能会导致网站访问变慢，可以使用浏览器的开发者工具检查网站的加载时间和资源大小，如果过大，可以尝试优化网站内容或者使用CDN加速服务。

  7. 使用其他浏览器或设备：如果以上方法都没有解决问题，可以尝试使用其他浏览器或设备访问网站，以确定问题是否与浏览器或设备有关。

  总之，排查和解决网站访问变慢的问题需要综合考虑多方面因素，并且需要有耐心和细心地进行排查和测试。

- TIME_WAIT状态会导致什么问题，怎么解决

  TIME_WAIT状态是指TCP连接关闭后，等待一段时间（通常为2倍MSL，即两倍的最长报文段生存时间）才会释放连接。TIME_WAIT状态可以避免网络中残留的数据包影响下一次连接，但同时也会导致以下问题：

  1. 资源浪费：在高并发场景下，TIME_WAIT状态会占用大量的系统资源，导致资源浪费。

  2. 端口耗尽：在短时间内频繁创建和销毁TCP连接时，TIME_WAIT状态会占用大量的端口资源，导致端口耗尽问题。

  为了解决TIME_WAIT状态带来的问题，可以采取以下措施：

  1. 调整TCP参数：可以通过修改操作系统的TCP参数来缩短TIME_WAIT状态的时间，例如修改tcp_fin_timeout参数等。

  2. 优化应用程序：在应用程序中，可以采用连接池等技术来复用TCP连接，减少TCP连接的创建和销毁，从而避免TIME_WAIT状态的产生。

  3. 使用SO_REUSEADDR选项：在TCP连接关闭时，可以使用SO_REUSEADDR选项来重用端口，避免端口耗尽问题。

  4. 使用负载均衡器：在高并发场景下，可以使用负载均衡器来分发请求，从而减少单个服务器上的TCP连接数量，缓解TIME_WAIT状态带来的负面影响。

  需要注意的是，对TCP参数的调整需要根据具体的应用场景和操作系统而定，同时也需要谨慎进行调整，避免引入其他问题。

- 半连接、半打开、半关闭

  半连接、半打开和半关闭都是TCP协议中的概念，具体含义如下：

  1. 半连接（SYN_SENT状态）：指TCP客户端向服务器发出连接请求，但是服务器还没有进行确认的状态。在这种状态下，TCP客户端等待服务器的响应，如果服务器不响应或响应超时，客户端会重试连接请求。

  2. 半打开（SYN_RCVD状态）：指TCP服务器收到客户端的连接请求后，向客户端发送确认消息，但是还没有完成连接的状态。在这种状态下，TCP服务器等待客户端的确认消息，如果客户端没有响应或响应超时，服务器会重新发送确认消息。

  3. 半关闭（FIN_WAIT_1、FIN_WAIT_2状态）：指TCP连接中的一端主动关闭连接，但是另一端还没有进行确认的状态。在这种状态下，主动关闭的一端等待对方的确认消息，如果对方没有响应或响应超时，主动关闭的一端会重新发送关闭请求。

  需要注意的是，半连接、半打开和半关闭都属于TCP协议中的状态，用于描述TCP连接的建立、维护和关闭过程。在实际应用中，这些状态会对TCP连接的性能和可靠性产生一定的影响，因此需要进行合理的配置和优化。

- 如何关闭处于close_wait 状态的TCP连接？

  在网络编程中，当一个连接的一方发送了 FIN 包（结束包）但对方没有响应时，这个连接就会处于 CLOSE_WAIT 状态。如果有大量的 CLOSE_WAIT 连接堆积在服务器上，可能会导致服务器资源浪费和性能下降。

  要关闭这些 CLOSE_WAIT 连接，可以使用以下几种方法：

  1. 重启应用程序或者服务器：重启应用程序或者服务器可以清除所有的 CLOSE_WAIT 连接，但这种方法会中断当前正在进行的连接和会话，可能会导致用户体验下降。

  2. 调整 TCP 超时时间：可以通过调整 TCP 超时时间来减少 CLOSE_WAIT 连接的数量。在 Linux 系统中，可以使用 sysctl 命令来调整 TCP 超时时间。例如，可以使用以下命令将 TCP 超时时间设置为 60 秒：

     ```
     sudo sysctl -w net.ipv4.tcp_fin_timeout=60
     ```

  3. 使用 TCPKILL 工具：TCPKILL 是一个可以强制关闭指定连接的工具。可以使用以下命令安装 TCPKILL 工具：

     ```
     sudo apt-get install dsniff
     ```

     安装完成后，可以使用以下命令关闭指定 IP 地址和端口号的连接：

     ```
     sudo tcpkill host <IP> and port <port>
     ```

     其中，<IP> 表示要关闭的连接的 IP 地址，<port> 表示要关闭的连接的端口号。

  总之，关闭 CLOSE_WAIT 连接可以使用重启应用程序或者服务器、调整 TCP 超时时间、使用 TCPKILL 工具等方法。需要根据具体情况选择合适的方法来解决问题。

- 如何判断两个 ip 是否在同一个子网

  判断两个 IP 是否在同一个子网，可以根据两个 IP 地址和它们对应的子网掩码来进行计算，具体步骤如下：

  1. 将两个 IP 地址和它们对应的子网掩码转换成二进制形式。

  2. 对两个 IP 地址和子网掩码进行逐位与运算，得到网络地址。即将两个 IP 地址中每一位与对应的子网掩码中的每一位进行与运算，得到网络地址。

  3. 判断两个 IP 地址的网络地址是否相同，如果相同则说明它们在同一个子网中。

  例如，假设有两个 IP 地址分别为 192.168.1.100 和 192.168.2.100，它们对应的子网掩码分别为 255.255.255.0 和 255.255.0.0。则进行如下计算：

  - 将两个 IP 地址和子网掩码转换成二进制形式：
    ```c
    192.168.1.100 -> 11000000 10101000 00000001 01100100
    255.255.255.0 -> 11111111 11111111 11111111 00000000
    192.168.2.100 -> 11000000 10101000 00000010 01100100
    255.255.0.0 -> 11111111 11111111 00000000 00000000
    ```

  - 对两个 IP 地址和子网掩码进行逐位与运算，得到网络地址：

    ```c
    192.168.1.100 & 255.255.255.0 -> 11000000 10101000 00000001 00000000
    192.168.2.100 & 255.255.0.0 -> 11000000 10101000 00000000 00000000
    ```

  - 判断两个 IP 地址的网络地址是否相同：

    ```c
    11000000 10101000 00000001 00000000 = 192.168.1.0
    11000000 10101000 00000000 00000000 = 192.168.0.0
    ```

  由此可见，这两个 IP 地址的网络地址不相同，因此它们不在同一个子网中。

  注意，如果两个 IP 地址对应的子网掩码不同，则需要将它们转换成同一个掩码后再进行计算。具体可以使用子网掩码的长度来进行转换。例如，将子网掩码 255.255.255.0 转换成子网掩码长度为 24，将子网掩码 255.255.0.0 转换成子网掩码长度为 16。然后将两个 IP 地址按照相同的子网掩码长度进行逐位与运算，得到它们的网络地址，再进行比较。

- https会不会出现中间人攻击

  HTTPS 协议通过使用 SSL/TLS 加密技术，可以提供一定程度的数据传输安全性，防止数据在传输过程中被窃取、篡改或伪造。但是，HTTPS 协议仍然有可能被中间人攻击。

  中间人攻击是指攻击者通过篡改或仿冒目标服务器的证书，使得客户端与攻击者之间建立起安全连接，从而获取客户端与服务器之间的通信内容。攻击者可以在中间人攻击过程中窃取敏感信息、篡改数据包、劫持用户会话等。

  中间人攻击主要有两种方式：

  1. 篡改证书：攻击者可以通过攻击证书颁发机构、DNS 劫持等方式，获取目标服务器的证书，然后自己生成一个伪造证书，将伪造证书发送给客户端，使客户端认为自己与目标服务器建立了安全连接。攻击者可以在客户端和服务器之间进行数据窃取、篡改等操作。

  2. 仿冒服务器：攻击者可以自己建立一个服务器，将自己的证书伪装成目标服务器的证书，然后将自己的服务器地址伪装成目标服务器的地址，欺骗客户端与自己建立安全连接。攻击者可以在客户端和服务器之间进行数据窃取、篡改等操作。

  为了防止中间人攻击，HTTPS 协议采用了一些安全机制，如数字证书、数字签名、证书链、证书撤销等。数字证书可以证明服务器的身份和公钥，数字签名可以保证证书的完整性和真实性，证书链可以证明证书的信任链，证书撤销可以及时撤回失效的证书。此外，HTTPS 协议还包括了一些安全头部和安全策略，可以进一步提高安全性。

  虽然 HTTPS 协议可以提供一定的安全保障，但是仍然可能被中间人攻击，因此在使用 HTTPS 协议时，应注意确保证书的真实性和完整性，避免使用不安全的网络环境，以及使用其他安全机制和策略来提高安全性。

- IPv4和IPv6的区别

  IPv4和IPv6是两种不同的IP地址格式。IPv4是目前广泛使用的IP地址格式，而IPv6则是一个新的IP地址格式，旨在解决IPv4地址短缺和安全性等问题。以下是它们之间的主要区别：

  1. 地址长度：IPv4地址长度为32位（即4个字节），而IPv6地址长度为128位（即16个字节）。

  2. 地址数量：由于IPv4地址长度的限制，IPv4地址数量有限，只有约43亿个可用的地址。而IPv6地址长度更长，可以提供更多的地址空间，理论上有3.4×10^38个可用的地址，足以支持未来的互联网发展。

  3. 地址表示：IPv4地址通常表示为点分十进制数，如192.168.0.1。而IPv6地址通常表示为八组四位十六进制数，以冒号分隔，如2001:0db8:85a3:0000:0000:8a2e:0370:7334。

  4. 协议支持：IPv4是互联网最早的协议，广泛使用于互联网中的各种应用。而IPv6是IPv4的升级版，支持更多的协议，如IPSec安全协议，可以提供更高的安全性和可靠性。

  5. 网络性能：IPv6可以提供更快的网络速度和更低的延迟，可以提高网络性能和吞吐量。

  总的来说，IPv6相对于IPv4来说是一种更加先进、更加安全、更加可靠和更加灵活的IP地址格式，可以满足未来互联网的需求。但由于IPv6的推广和普及需要时间和成本，目前IPv4仍然是互联网主要的IP地址格式，两种格式仍然需要共存一段时间。

- 子网掩码的作用

  子网掩码是一种用于划分IP地址的技术，它指定了一个IP地址中哪些部分是网络地址，哪些部分是主机地址。子网掩码的作用主要有以下几个方面：

  1. 确定网络地址和主机地址：子网掩码可以将一个IP地址分成两部分，即网络地址和主机地址，从而确定该IP地址所属的网络和主机。

  2. 划分子网：通过修改子网掩码，可以将一个网络划分成多个子网。这样可以更好地管理网络资源，提高网络的性能和安全性。

  3. 控制广播域：子网掩码可以控制广播域的大小，从而减少广播包的数量，提高网络的性能。

  4. 确定有效IP地址范围：子网掩码可以确定一个网络中可用的IP地址范围，从而帮助管理员进行地址分配和管理。

  5. 提高网络安全性：子网掩码可以限制不同网络之间的通信，从而提高网络的安全性。

  需要注意的是，子网掩码的设置必须与网络中所有设备的IP地址一致，否则就会出现通信故障。此外，子网掩码的设置也需要考虑到网络的规模和需求，设置不当会影响网络的性能和安全性。

- 每一次客户端发送一个tcp包，服务端都会刷新定时器吗

  在TCP协议中，每当服务端接收到客户端发送的数据包时，服务端都会回复一个ACK确认报文，告诉客户端已经成功接收到数据包。在回复ACK报文的同时，服务端会重置定时器，以便在一定时间内等待客户端发送下一个数据包。因此，可以说每一次客户端发送TCP包，服务端都会刷新定时器。

  具体来说，在TCP协议中，如果服务端在一定时间内没有收到客户端的数据包，就会认为网络出现了问题，会触发超时重传机制，重新发送之前发送过的数据包。因此，为了避免不必要的超时重传，服务端需要设置合适的定时器超时时间，以便在规定时间内等待客户端的数据包。

  需要注意的是，TCP协议中的定时器超时时间是动态调整的，根据网络状况和拥塞情况进行自适应调整，以达到更好的性能和可靠性。因此，服务端在刷新定时器时，需要根据具体情况进行调整，以保证数据传输的效率和可靠性。

- 客户端服务端的窗口是怎么设定的，服务端假设能力比较强，窗口会大一些，客户端能力比较弱，窗口会小一些吗

  在TCP协议中，客户端和服务端的窗口大小是由其接收缓冲区大小和拥塞窗口大小共同决定的。接收缓冲区大小是指能够存储接收数据的缓冲区大小，而拥塞窗口大小是指在网络拥塞控制的机制下，能够用于发送数据的窗口大小。因此，客户端和服务端的窗口大小都是动态调整的，根据网络状况和拥塞情况进行自适应调整。

  一般来说，服务端的接收能力比客户端强，因此服务端的接收缓冲区和拥塞窗口大小可能会比客户端大一些。但这并不是绝对的，因为客户端和服务端的实际能力取决于多种因素，如网络带宽、延迟、负载等等。因此，客户端和服务端的窗口大小需要根据具体情况进行调整，以达到最佳的数据传输效率和可靠性。

  需要注意的是，客户端和服务端的窗口大小不仅受到自身能力的限制，还受到网络状况和其他设备的影响。在实际应用中，需要进行网络监测和流量控制，以便及时调整窗口大小，避免网络拥塞和数据丢失。

- 刚开始窗口大小是固定的吗，然后后面再去协商，设置为多少

  在TCP协议中，刚开始的窗口大小是由初始拥塞窗口（Initial Congestion Window，简称ICW）决定的。ICW是TCP连接刚开始建立时，初始的拥塞窗口大小，其值由操作系统内核决定。通常情况下，ICW的大小是一个固定值，不会根据网络状况进行动态调整。

  在建立TCP连接后，发送方会不断地根据网络状况和反馈信息调整拥塞窗口大小。具体来说，当TCP连接刚开始建立时，发送方会先发送一个小的数据包，以便测试网络状况和延迟。如果发送方接收到ACK确认报文，表示网络状况良好，就会逐步增大拥塞窗口大小，增加发送数据的速度。如果发送方接收到重传请求或其他拥塞信号，就会减小拥塞窗口大小，降低发送数据的速度。

  在实际应用中，TCP发送方和接收方可以通过TCP选项字段进行窗口大小的协商和调整。例如，TCP协议中的Selective Acknowledgement（SACK）选项可以使发送方知道接收方已经成功接收了哪些数据，从而更准确地调整拥塞窗口大小。另外，TCP协议还提供了一些其他的拥塞控制机制，如Slow Start、Congestion Avoidance和Fast Recovery等，可以帮助发送方和接收方更好地协商和调整窗口大小。

- 假设服务端接受能力强，窗口大小能接收一万个包，那客户端窗口大小也会扩大到一万吗

  在TCP协议中，客户端和服务端的窗口大小是由网络状况和拥塞窗口大小共同决定的，而不是由某一方的接收能力决定的。因此，即使服务端的接收能力很强，其接收缓冲区和拥塞窗口大小可以达到一万个包，但客户端的窗口大小也不一定会扩大到一万个包。

  客户端和服务端的窗口大小是由TCP拥塞控制机制共同决定的。在TCP连接建立时，客户端和服务端会根据自己的初始拥塞窗口大小和拥塞控制机制，逐步调整窗口大小，以适应不同的网络状况和拥塞情况。具体来说，TCP拥塞控制机制包括Slow Start、Congestion Avoidance、Fast Retransmit和Fast Recovery等机制，可以根据网络状况和拥塞信号进行窗口大小的动态调整。

  因此，客户端和服务端的窗口大小是动态变化的，取决于网络状况和拥塞控制机制的共同作用。即使服务端的接收能力很强，客户端的窗口大小也可能会受到其他因素的影响，如延迟、丢包率等等。在实际应用中，需要进行网络监测和流量控制，以便及时调整窗口大小，避免网络拥塞和数据丢失。

- 如果有很多连接的第三次握手丢包，会发生什么？如何解决这样的问题？

  如果有很多连接的第三次握手丢包，会导致连接无法建立，从而导致客户端无法与服务端通信。

  在TCP协议中，当客户端发送SYN包后，服务端会回复一个SYN+ACK包作为确认，然后客户端再回复一个ACK包，完成三次握手。如果第三次握手的ACK包丢失，服务端会一直等待客户端的回复，而客户端会认为连接已经建立，等待服务端的响应。这样就会导致连接无法建立。

  为了解决这个问题，可以采取以下措施：

  1. 增加重传次数：TCP协议中有一个重传机制，当一个包没有得到确认时，会进行多次重传。可以通过增加重传次数来提高连接建立的成功率。

  2. 减小重传超时时间：TCP协议中的重传时间间隔会逐渐增加，如果逐渐增加的速度过慢，就会导致连接建立的时间过长。可以通过减小重传超时时间，使得重传速度更快，从而提高连接建立的成功率。

  3. 使用TCP Fast Open（TFO）：TFO是一种优化TCP连接建立的机制，它允许在第一次握手时传输数据，从而避免第三次握手的延迟。使用TFO可以有效地提高连接建立的成功率。

  4. 增加服务端的并发处理能力：如果服务端的并发处理能力不足，就会导致连接建立的延迟增加。可以通过增加服务端的处理能力来加快连接建立的速度。

  需要注意的是，解决连接建立的延迟问题需要根据具体情况进行调整，不同的应用场景可能需要采取不同的措施。在实际应用中，需要根据具体情况进行优化，以达到最佳的性能和稳定性。

- socket的keep_alive的时间间隔

  TCP Keep-Alive 是一种机制，用于检测空闲连接并防止连接超时。Keep-Alive 可以通过在套接字上设置 SO_KEEPALIVE 选项来启用，该选项将使操作系统自动在空闲连接上发送探测报文段，并等待对方的响应，以判断连接是否仍然可用。

  在 Linux 中，Keep-Alive 的默认参数如下：

  - TCP_KEEPIDLE：表示 TCP 连接上没有数据传输的时间，超过该时间后将开始发送探测报文段。默认值为 2 小时，单位是秒。
  - TCP_KEEPINTVL：表示发送探测报文段的时间间隔。默认值为 75 秒，单位是秒。
  - TCP_KEEPCNT：表示发送探测报文段的次数。默认值为 9 次。

  这些参数可以通过以下命令进行查看和修改：

  ```shell
  # 查看 Keep-Alive 参数
  $ cat /proc/sys/net/ipv4/tcp_keepalive_time
  7200
  $ cat /proc/sys/net/ipv4/tcp_keepalive_intvl
  75
  $ cat /proc/sys/net/ipv4/tcp_keepalive_probes
  9
  
  # 修改 Keep-Alive 参数
  $ echo 1800 > /proc/sys/net/ipv4/tcp_keepalive_time
  $ echo 60 > /proc/sys/net/ipv4/tcp_keepalive_intvl
  $ echo 5 > /proc/sys/net/ipv4/tcp_keepalive_probes
  ```

  需要注意的是，Keep-Alive 参数的修改可能会影响整个操作系统上的 TCP 连接，因此需要慎重进行。此外，Keep-Alive 参数的值应根据具体情况进行调整，以平衡空闲连接的检测和网络带宽的占用。

- 心跳连接正常就可以保证服务器活着吗？怎样的心跳才能保证服务器一定活着？

  心跳连接是一种通信机制，可以用来检测服务器是否存活。它的原理是客户端定期向服务器发送心跳包，服务器收到心跳包后即可确认客户端仍然存活。但是仅仅通过心跳连接是否正常来保证服务器存活是不够的，因为心跳连接本身也可能出现问题。

  为了保证服务器一定存活，需要考虑以下几点：

  1. 心跳包的发送频率：心跳包的发送频率应该足够高，以便及时发现服务器的异常情况。一般来说，心跳包的发送间隔应该在几秒钟到几分钟之间，具体取决于具体的应用场景。

  2. 心跳包的响应时间：服务器应该在接收到心跳包后及时响应，以便客户端能够及时发现服务器的异常情况。如果服务器响应时间过长，则可能会被误判为异常情况。

  3. 心跳包的内容：心跳包的内容应该足够简单，以便在网络传输中能够快速传输。可以采用一些特定的标识符来表示心跳包，从而减少数据传输量。

  4. 心跳连接的检测机制：除了发送心跳包之外，还应该设置一些检测机制来检测服务器的存活情况。例如，可以采用ping命令或者TCP keepalive机制来检测服务器是否存活。

  综上所述，仅仅通过心跳连接是否正常来保证服务器存活是不够的，还需要考虑心跳包的发送频率、响应时间、内容以及检测机制等因素，从而确保服务器的存活。

- 哪些业务适合长连接，哪些适合短链接

  一般来说，长连接适合于需要频繁通信的业务，而短链接适合于单次请求完成即可的业务。

  下面是一些常见的业务场景和对应的连接方式：

  1. 实时通信：长连接。例如聊天室、在线游戏等，需要保持与服务器的连接，实时发送和接收数据。

  2. 长轮询：长连接。例如在线聊天、在线客服等，客户端向服务器发送请求后，服务器会阻塞等待新的消息，直到有新的消息到来或者超时才返回响应。

  3. 文件上传下载：短连接。例如HTTP文件下载，客户端向服务器发送请求，服务器返回文件数据，传输完成即可关闭连接。

  4. Web应用：短连接。例如HTTP网页请求，客户端向服务器发送请求，服务器返回网页内容，传输完成后关闭连接。

  5. 数据库访问：短连接。例如MySQL数据库访问，客户端向服务器发送SQL语句，服务器返回查询结果，传输完成后关闭连接。

  6. 定时任务：长连接或短连接。如果定时任务需要频繁执行，则可以使用长连接，保持与服务器的连接，定时发送请求执行任务。如果定时任务不需要频繁执行，则可以使用短连接，每次执行任务时建立连接，执行完成后关闭连接。

  需要注意的是，连接的建立和断开都需要消耗一定的资源，因此过多的长连接或短连接都会对服务器产生一定的压力。在设计应用时，需要根据具体业务场景和实际情况选择适当的连接方式，以达到最优的性能和资源利用率。

- 

  

# OS

- 为什么要区分内核态和用户态？

  区分内核态和用户态是为了保证操作系统的稳定性和安全性。

  在内核态下，操作系统可以直接访问硬件资源，执行特权指令，进行系统管理和维护任务，如进程调度、内存管理、设备驱动等。而在用户态下，应用程序只能通过系统调用接口向操作系统发起请求，操作系统会在内核态下完成相应的任务并返回结果给应用程序。

  通过区分内核态和用户态，可以有效地隔离应用程序和操作系统，防止应用程序的错误或恶意行为对操作系统的稳定性和安全性产生影响。同时，也可以提高操作系统的性能和效率，因为内核态下的操作系统可以直接访问硬件资源，而不需要经过系统调用的开销和限制。

* 内核态和用户态的区别
  1. 权限不同：内核态具有更高的权限，可以访问系统的所有资源，而用户态只能访问受限的资源。

  2. 运行环境不同：内核态运行在操作系统内部，用户态运行在操作系统外部。

  3. 调用方式不同：内核态通过系统调用方式调用操作系统提供的服务，而用户态通过库函数调用操作系统提供的服务。

  4. 响应速度不同：内核态响应速度更快，因为它可以直接访问硬件资源，而用户态需要通过操作系统提供的接口访问硬件资源。

  5. 安全性不同：内核态具有更高的安全性，因为它可以保护系统资源不被用户态非法访问。

  6. 内存管理不同：内核态可以直接访问所有内存，而用户态只能访问自己的内存空间。

  7. 中断处理不同：内核态可以处理所有中断，而用户态只能处理非关键性中断。

- 导致从用户态切换到内核态的操作

  - 系统调用

    很多程序开始时运行于用户态，但在执行的过程中，一些操作需要在内核权限下才能执行，这就涉及到一个从**用户态切换到内核态**的过程。比如C函数库中的内存分配函数 malloc()，它具体是使用 sbrk() 系统调用来分配内存，当malloc() 调用 sbrk() 的时候就涉及一次从用户态到内核态的切换，类似的函数还有 printf()，调用的是 wirte() 系统调用来输出字符串，等等。
  
  
    - 异常事件
      
        当 CPU 正在执行运行在用户态的程序时，突然发生某些预先不可知的异常事件，就会触发从当前用户态执行的进程转向内核态执行相关的异常事件，典型的如缺页异常。
  
  
    - 外围设备中断
      
        当外围设备完成用户的请求操作后，会向 CPU 发出中断信号，此时，CPU 就会暂停执行下一条即将要执行的指令，转而去执行中断信号对应的处理程序，如果先前执行的指令是在用户态下，则自然就发生从用户态到内核态的转换。
  


- 用户态的应用程序可以通过三种方式来访问内核态的资源：

  - 系统调用

  - 库函数

  - Shell 脚本


- 中断实现的原理

  中断是一种计算机硬件和软件协同工作的机制，它允许处理器在执行程序时，暂停当前任务，转而去处理其他任务，然后在完成这些任务后，再回到原来的任务继续执行。

  中断的实现原理主要包括以下几个方面：

  1. 中断请求的产生：中断请求可以来自于硬件设备，如键盘、鼠标、磁盘等，也可以来自于软件，如操作系统的系统调用、异常处理等。

  2. 中断向量表的建立：中断向量表是一个存储中断处理程序入口地址的数据结构，每个中断请求都有一个唯一的中断向量号，当中断请求产生时，处理器会根据中断向量号在中断向量表中查找对应的中断处理程序入口地址。

  3. 中断处理程序的执行：当处理器接收到中断请求后，会暂停当前任务，保存现场信息（如程序计数器、寄存器等）并跳转到中断向量表中对应的中断处理程序入口地址，执行中断处理程序。

  4. 中断处理程序的返回：中断处理程序执行完后，会恢复现场信息并返回到原来的任务继续执行。

  总之，中断机制的实现离不开中断请求的产生、中断向量表的建立、中断处理程序的执行和返回等关键步骤，这些步骤的协同工作使得处理器能够在多任务环境下有效地处理各种中断请求。

- 系统中断、中断向量、中断向量表

  - 系统中断是指由硬件或软件触发的一种机制，用于打断正在执行的程序，以便处理特定的事件或请求；
  - 中断向量是一个指向中断处理程序的地址，它由中断控制器提供，并用于确定应该执行哪个中断处理程序；
  - 中断向量表是一个包含所有中断向量的表格，通常存储在内存中，并由操作系统维护。当一个中断被触发时，处理器会查询中断向量表，找到相应的中断向量，并跳转到相应的中断处理程序中去执行。

- 软中断和硬中断区别

  软中断和硬中断是计算机系统中的两种中断类型，它们的区别在于中断的来源和处理方式。

  - 软中断

    软中断是由操作系统内核自身产生的中断，它们不是由硬件设备触发的。软中断通常用于处理计时器、网络数据包、文件系统等事件。软中断是通过调用操作系统内核中的函数来触发的，因此也被称为系统调用。

  - 硬中断

    硬中断是由硬件设备触发的中断，例如键盘、鼠标、网络卡等。硬中断通常由硬件设备发送一个中断请求信号（IRQ）给操作系统内核，内核会暂停正在执行的任务来处理这个中断请求。硬中断的处理需要较高的优先级，因为它们需要及时响应硬件设备的请求。

  软中断和硬中断是两种不同的中断类型，软中断是由操作系统内核自身产生的中断，硬中断是由硬件设备触发的中断。软中断通常用于处理计时器、网络数据包、文件系统等事件，而硬中断通常由键盘、鼠标、网络卡等设备触发。

- 异常和中断的区别

  异常和中断都是计算机系统中的两种不同的事件处理方式，它们的区别如下：

  1. 异常：是指在程序执行过程中由于出现了非法操作或者错误的数据等原因导致程序无法继续执行的情况。异常通常是由程序本身引起的，例如除零、空指针引用等。

  2. 中断：是指由外部设备或者程序发出的一种请求，要求处理器暂停当前的任务，转而去处理该请求。中断通常是由外部设备引起的，例如键盘输入、定时器等。

  因此，异常和中断的主要区别在于它们的来源不同，异常是由程序本身引起的，而中断是由外部设备引起的。另外，异常通常是在程序执行过程中发生的，而中断则可以在任何时候发生。

- 系统调用和中断的区别

  系统调用是一种机制，它允许用户程序请求内核执行某些特权操作，如文件读写、进程管理等。用户程序通过调用特定的系统调用接口来发起请求，内核根据请求参数执行相应的操作，并返回结果给用户程序。

  中断是一种事件，它可以被硬件或软件触发，用于打断当前程序的执行，转而执行中断处理程序。中断可以被用于处理硬件故障、时钟中断、网络数据包到达等事件。当中断发生时，CPU会保存当前程序的状态，然后跳转到中断处理程序执行相应的操作，处理完后再返回原程序继续执行。

  因此，系统调用和中断的区别在于：

  1. 作用不同：系统调用是用户程序请求内核执行特权操作的机制，而中断是打断当前程序执行的事件。

  2. 触发方式不同：系统调用是由用户程序主动发起的，而中断是由硬件或软件触发的。

  3. 实现方式不同：系统调用是用户态程序切换到内核态执行的过程，需要进行上下文切换和特权级切换；而中断是在当前程序执行过程中被打断，操作系统会保存当前程序的上下文并处理中断，然后再恢复被打断的程序继续执行。

  4. 返回方式不同：系统调用返回时，操作系统会将结果返回给用户程序；而中断处理完成后，控制权会返回到被打断的程序继续执行。

  总的来说，系统调用和中断都是操作系统中的重要机制，它们各自有着不同的作用和实现方式，但都为操作系统提供了强大的功能和灵活性。

- 系统调用和函数调用的区别

  系统调用和函数调用的区别如下：

  1. 调用方式不同：系统调用是通过操作系统提供的接口进行调用的，而函数调用是在程序内部进行调用的。

  2. 执行环境不同：系统调用是在内核态下执行的，而函数调用是在用户态下执行的。

  3. 功能不同：系统调用是提供给用户程序使用操作系统资源的接口，比如读写文件、创建进程等操作；而函数调用是程序内部实现某一特定功能的代码块。

  4. 开销不同：系统调用需要进行上下文切换，从用户态切换到内核态，需要进行堆栈切换等操作，开销比较大；而函数调用只需要进行简单的函数调用和返回操作，开销比较小。

  5. 安全性不同：系统调用会检查用户程序的权限，确保用户程序不能越权操作系统资源，保证系统的安全性；而函数调用不会进行权限检查，用户程序可以自由地调用函数，可能会对系统造成安全威胁。

  综上所述，系统调用和函数调用虽然都是程序中的调用方式，但是其执行环境、功能、开销、安全性等方面都有很大的区别。

- 系统调用进入内核态的过程

  当应用程序需要执行一些需要特权级别的操作时，比如读写文件、网络通信、内存管理等，就需要通过系统调用进入内核态。系统调用是用户程序与操作系统之间进行通信的接口，它可以让用户程序请求操作系统执行某些任务。

  以下是系统调用进入内核态的过程：

  1. 用户程序执行系统调用指令，将控制权转移到内核态。

  2. CPU从用户态切换到内核态，将程序计数器(PC)和堆栈指针(SP)压入内核栈中，保存用户程序的现场。

  3. 内核态的操作系统检查系统调用参数，验证权限，执行相应的操作。

  4. 操作系统将结果返回给用户程序，将控制权转移回用户态。

  5. CPU从内核态切换回用户态，将程序计数器(PC)和堆栈指针(SP)恢复，继续执行用户程序。

  需要注意的是，系统调用的执行过程中会涉及到内核态和用户态之间的切换，这个过程需要花费一定的时间和资源，因此在编写程序时应尽量减少系统调用的次数，提高程序的效率。

- 内存映射工作机制，内存映射和共享内存区别？

  内存映射是一种将文件或设备映射到进程地址空间的机制。它允许进程像访问内存一样访问文件或设备，从而避免了繁琐的文件或设备I/O操作。内存映射是通过调用mmap()系统调用来实现的，它将文件或设备的数据映射到进程的虚拟地址空间中。内存映射工作机制如下：

  1. 调用mmap函数，将文件映射到进程的地址空间中。

  2. 操作系统将文件的内容读入内存中，并建立一个虚拟内存区域。

  3. 进程可以通过指针来访问这个虚拟内存区域，就像访问内存一样。

  4. 当进程对这个虚拟内存区域进行读写操作时，操作系统会自动将数据写回到文件中。

  内存映射和共享内存的区别在于，内存映射是将文件或设备映射到进程的地址空间中，而共享内存是将一块内存映射到多个进程的地址空间中，使得多个进程可以共享同一块内存。共享内存通常用于进程间通信，而内存映射则更多地用于文件和设备访问。

- 共享内存存在于进程地址空间中哪个部分？未初始化数据段怎么存入数据？共享内存区增长方向？一般存啥？

  共享内存存在于进程地址空间中的堆区或者数据段中。未初始化数据段存入数据时，操作系统会在该段内存中分配一块空间，并将其清零。共享内存区的增长方向通常是向上增长，即地址值越来越大。一般来说，共享内存区存储的是需要在多个进程之间共享的数据，比如进程间通信的消息队列、共享缓存等。

- TLB 是干嘛的？TLB 和磁盘缓存是一样的吗？

  TLB（Translation Lookaside Buffer）是一种硬件缓存，用于加速虚拟地址到物理地址的转换过程。TLB存储了最近使用过的虚拟地址与物理地址的映射关系，当CPU需要访问某个虚拟地址时，先在TLB中查找对应的物理地址，如果命中则可以直接访问物理地址，否则需要进行完整的地址转换流程。

  磁盘缓存是一种软件缓存，用于加速磁盘读写操作。磁盘缓存存储了最近读取过的磁盘数据，当需要再次读取时，可以直接从缓存中获取，避免了频繁的磁盘读取操作。

  因此，TLB和磁盘缓存的作用不同，TLB是用于加速虚拟地址到物理地址的转换，而磁盘缓存是用于加速磁盘读写操作。两者的实现方式也不同，TLB是硬件缓存，而磁盘缓存是软件缓存。

- 线程安全、线程安全函数、可重入函数、信号安全函数

  1. 线程安全

  线程安全是指多个线程同时访问同一份数据时，不会出现数据竞争和不一致的情况。线程安全的实现可以通过使用互斥量、信号量、读写锁等同步机制来保证。

  2. 线程安全函数

  线程安全函数是指在多线程环境下可以安全调用的函数。这些函数要么不使用全局变量，要么使用全局变量时使用同步机制来保证线程安全。例如，C标准库中的strtok_r函数就是线程安全函数。

  3. 可重入函数

  可重入函数是指在多线程环境下可以重复调用的函数。这些函数不使用全局变量，而是使用局部变量或者参数来保存状态信息。可重入函数的实现可以通过使用静态变量或者动态分配内存的方式来保存状态信息。

  4. 信号安全函数

  信号安全函数是指在信号处理函数中可以安全调用的函数。由于信号处理函数的执行是在中断上下文中进行的，因此不能使用会修改全局变量的函数，也不能使用会阻塞的函数。例如，C标准库中的malloc函数就不是信号安全函数。

- 浏览器中点击+号创建新的标签页，是开启了一个新线程还是新进程，以及原因

  在大多数浏览器中，点击+号创建新的标签页会开启一个新的进程。这是因为现代浏览器通常使用多进程架构，每个标签页都在单独的进程中运行，这样可以提高浏览器的稳定性和安全性，同时也可以更好地利用多核处理器的优势。每个进程都有自己的内存空间，这样即使一个标签页崩溃了，其他标签页也不会受到影响。当然，也有一些浏览器会在同一个进程中运行多个标签页，这取决于浏览器的具体实现。

- 产生缺页中断的几种情况：

  1. CPU所需访问的页面不在内存中，就需要将页面调入内存，如果内存已满，就需要执行相应的页面置换算法；
  2. 使用 mmap 函数在堆中创建一块虚拟内存，第一次访问时才会通过缺页中断机制映射到物理页中；
  3. fork() 创建子进程，读时共享，写时拷贝，缺页中断；


- 什么是缺页异常，什么情况下会缺页异常

  缺页异常（Page Fault）是指当程序访问一个尚未在内存中的页面时，操作系统会将其从磁盘或其他存储设备中读入内存，此过程就是缺页异常。当程序试图访问某个虚拟地址时，如果对应的物理页不在内存中，就会发生缺页异常。

  缺页异常通常发生在以下情况下：

  1. 程序第一次访问某个页面，该页面尚未被加载到内存中。

  2. 程序访问的页面已经被换出到磁盘或其他存储设备中，需要重新加载到内存中。

  3. 程序访问的页面已经被修改，需要将其写回到磁盘或其他存储设备中，并且加载新的页面到内存中。

  缺页异常是操作系统中常见的机制之一，它可以有效地利用内存资源，提高系统的性能和效率。

- 为什么ssh客户端关闭了会影响服务端的运行?

  当终端接口检测到网络连接断开，将挂断信号SIGHUP发送给控制进程(会话期首进程)。如果会话期首进程终止，则该信号发送到该会话期前台进程组。一个进程退出导致一个孤儿进程组产生时，如果任意一个孤儿进程组进程处于STOP状态，则会发送 SIGHUP 和 SIGCONT 信号到该进程组中所有进程。因此当网络断开或终端窗口关闭后，也就是SSH断开以后，控制进程收到 SIGHUP 信号退出，会导致该会话期内其他进程退出。也就是 ssh 打开以后，bash等都是他的子程序，一旦ssh关闭，系统将所有相关进程杀掉，导致一旦ssh关闭, 执行中的任务就取消了。

  那如何解决呢？

  在远端开启 tmux，在 tmux 里运行程序，此时运行的程序属于 tmux 的进程组，不属于 ssh 进程组；使用 `nohup `命令。

- 线程池里的线程数设置为多少最优？

  线程池里的线程数设置为多少最优，取决于以下因素：

  1. CPU核心数：线程池中的线程数应该小于等于CPU核心数，否则会导致CPU过度切换线程而降低性能。

  2. 任务类型：任务类型对线程池的大小也有影响。如果任务是I/O密集型，线程池中的线程数应该设置得更大，以便更好地利用I/O等待时间。如果任务是CPU密集型，线程池中的线程数应该设置得更小，以避免过度切换线程。

  3. 系统负载：系统负载也会影响线程池的大小。如果系统负载较高，线程池中的线程数应该设置得更小，以避免过度消耗系统资源。

  因此，线程池中的线程数应该根据以上因素进行适当调整，以达到最优的性能和资源利用率。


- 32和64位操作系统地址空间分别是多大？

  32位：2^32^ = 4 GB，64位：2^64^ 字节

- 构成一个计算机需要什么，各个组件做什么工作

  计算机由五大部件组成，包括运算器、控制器、存储器、输入设备和输出设备组成。

  1、控制器：计算机的控制系统，是计算机的神经中枢，指挥着计算机中各个部件自动协调工作。在控制器的控制下，计算机能够自动按照程序设定的步骤进行一系列操作，以完成特定任务。

  2、运算器：计算机的运算系统，计算机中执行各种算术和逻辑运算操作的部件。

  3、存储器：计算机存储系统，是一种利用半导体、磁性介质等技术制成的存储资料的电子设备。其电子电路中的资料以二进制方式存储。

  4、输入设备：向计算机输入数据和信息的设备，是计算机与用户或其他设备通信的桥梁。

  5、输出设备：是计算机硬件系统的终端设备，用于接收计算机数据的输出显示、打印、声音、控制外围设备等。

- 计算机的位数是由什么来决定的

  计算机的位数是由其处理器（CPU）的寄存器的位数决定的。寄存器是一种非常快速的存储器件，用于存储计算机正在处理的数据和指令。每个寄存器都有一个特定的位数，表示它可以存储的二进制位数。例如，一个32位的处理器具有32位的寄存器，可以处理32位的二进制数据。同样，64位的处理器具有64位的寄存器，可以处理64位的二进制数据。因此，计算机的位数决定了它可以处理的最大二进制数的位数，从而影响了其性能和处理能力。

- 线程创建 pthread_create 底层调用函数是啥

  pthread_create 底层调用的函数是 clone()。clone() 是 Linux 内核提供的系统调用，用于创建一个新的进程或线程。在 Linux 中，线程本质上也是一个进程，只是与创建它的进程共享了一部分资源。因此，pthread_create() 函数实际上是通过调用 clone() 创建一个新的线程，并将其加入到进程的线程池中。

- 段错误有什么原因

  段错误是一种常见的程序错误，通常是由于程序访问了不合法的内存地址或者内存越界引起的。具体来说，段错误可能由以下原因引起：

  1. 访问未分配内存：程序试图访问未分配的内存地址，比如使用空指针或者释放了已经被释放的内存。

  2. 内存越界：程序试图访问超出数组或者指针范围的内存地址，比如数组下标越界或者指针偏移量超出了指针指向的内存空间。

  3. 栈溢出：程序使用了过多的栈空间，导致栈溢出，比如递归调用过深或者在栈上分配过多的内存。

  为了避免段错误，可以采取以下措施：

  1. 避免使用空指针或者已经被释放的内存。

  2. 对于数组和指针，要确保访问的下标或者偏移量不越界。

  3. 在使用递归时，要注意控制递归深度，避免栈溢出。

  4. 使用工具进行内存检查，比如valgrind等工具可以检查程序中的内存错误。

  5. 编写高质量的代码，遵循良好的编程习惯，比如避免使用未初始化的变量等。

- Epoll是阻塞/非阻塞？异步/同步？

  Epoll是非阻塞/异步的。它使用事件通知机制，当有事件发生时，它会立即返回而不会阻塞线程，同时也不需要轮询来检查事件是否发生。这种异步的方式可以提高系统的并发性和响应性能。同时，Epoll也可以使用边缘触发模式，可以在数据可读/写时立即通知应用程序，从而实现异步处理。

- 服务器有一个连接进来，到应用程序读取到数据，需要经过几次内核态/用户态切换？需要几次缓冲区数据的拷贝？

  4次内核态/用户态切换：

  1. 用户应用进程调用read函数，向操作系统发起IO调用，上下文从用户态转为内核态（切换1）；
  2. DMA控制器把数据从磁盘中，读取到内核缓冲区；
  3. CPU把内核缓冲区数据，拷贝到用户应用缓冲区，上下文从内核态转为用户态（切换2），read函数返回；
  4. 用户应用进程通过write函数，发起IO调用，上下文从用户态转为内核态（切换3）；
  5. CPU将用户缓冲区中的数据，拷贝到socket缓冲区；
  6. DMA控制器把数据从socket缓冲区，拷贝到网卡设备，上下文从内核态切换回用户态（切换4），write函数返回；

  4次缓冲区数据的拷贝：

  1. 第一次拷贝：将磁盘中的数据拷贝到内核的缓冲区中；
  2. 第二次拷贝：内核将数据处理完，接着拷贝到用户缓冲区中；
  3. 第三次拷贝：此时需要通过socket将数据发送出去，将用户缓冲区中的数据拷贝至内核中socket的缓冲区中；
  4. 第四次拷贝：把内核中socket缓冲区的数据拷贝到网卡的缓冲区中，通过网卡将数据发送出去。


- 多线程和多进程区别

  多线程和多进程是并发编程中的两种常见方式，它们的主要区别在于：

  1. 资源占用：多进程需要独立的内存空间和系统资源，因此它的资源占用比多线程更大。而多线程共享进程的资源，因此资源占用较少。

  2. 通信方式：多进程之间的通信需要使用IPC（进程间通信）方式，如管道、消息队列、共享内存等。而多线程之间的通信可以直接使用共享变量、锁等线程同步机制。

  3. CPU利用率：多进程因为需要切换进程，因此CPU利用率较低。而多线程因为共享进程的资源，因此切换线程的开销较小，CPU利用率较高。

  4. 稳定性：多线程的稳定性较差，因为一个线程的崩溃可能会导致整个进程的崩溃。而多进程的稳定性较好，因为一个进程的崩溃不会影响其他进程的运行。

  5. 编程复杂度：多线程的编程复杂度较低，因为它不需要考虑进程间通信的问题。而多进程的编程复杂度较高，因为需要考虑进程间通信的问题。

  综上所述，多线程适用于需要共享资源、处理并发请求的场景，而多进程适用于需要处理大量计算密集型任务、需要提高系统稳定性的场景。

- 多进程和多线程的使用场景

  多线程和多进程都是并发编程的实现方式，但是它们适用的场景不同。

  多线程适用于以下情况：

  1. 程序需要同时处理多个任务，但是每个任务的执行时间比较短，且需要共享数据。

  2. 程序需要同时处理多个任务，但是每个任务的执行时间较长，且需要频繁地进行IO操作。

  3. 程序需要实现GUI界面，需要同时处理用户的输入和输出。

  4. 程序需要实现网络编程，需要同时处理多个客户端请求。

  多进程适用于以下情况：

  1. 程序需要处理大量的计算密集型任务，需要充分利用多核CPU的性能。

  2. 程序需要保证高可靠性和安全性，需要将不同的任务分配给不同的进程，避免一个任务的错误影响其他任务。

  3. 程序需要利用多台机器的计算资源，需要通过进程间通信来协调不同机器上的任务。

  总之，多线程适合处理IO密集型任务，而多进程适合处理计算密集型任务。在实际应用中，需要根据具体情况选择合适的并发编程方式。

- 什么是协程，什么情况下可以使用协程

  协程（Coroutine）是一种轻量级的线程，与线程相比，协程的切换不需要操作系统介入，因此可以实现更高效的并发编程。

  协程可以用于需要处理大量IO操作的场景，例如网络编程、文件读写等。在这些场景中，线程会因为等待IO操作完成而被阻塞，而协程可以在等待IO操作的同时切换到其他任务，从而提高CPU利用率。

  协程的优势包括：

  1. 更轻量级：协程的切换不需要操作系统介入，因此比线程更轻量级，可以创建更多的协程。

  2. 更高效：协程的切换比线程更快，因此可以实现更高效的并发编程。

  3. 更容易编写和维护：协程的代码结构更简单，可以避免线程的锁和同步问题，从而更容易编写和维护。

  4. 更容易调试：协程的调试比线程更容易，因为协程的调用栈比线程更清晰。

  总之，协程是一种高效、轻量级、易于编写和维护的并发编程模型，可以帮助开发者更好地处理并发编程问题。

- 协程在什么时候进行切换？

  协程的切换在以下几种情况下会发生：

  1. 当当前协程遇到阻塞操作，比如等待 I/O 操作完成或者等待其他协程的消息时，协程的控制权就会被剥夺并被切换出去，其他可执行的协程就会被调度到运行状态。

  2. 当一个协程主动放弃 CPU 运行权，比如调用 `runtime.Gosched()` 函数或者 `yield` 等操作时，协程也会被切换出去，让其他可执行的协程获得机会运行。

  3. 当一个协程正在等待另一个协程完成某个任务，比如等待另一个协程完成某个计算并返回结果时，也会发生协程的切换。

  4. 当多个协程同时等待同一个 Channel 的读写时，只有其中一个协程能够成功地进行读写操作，其他协程都会被阻塞，并被调度器挂起，等待机会再次获得运行权。

  需要注意的是，在协程的切换过程中，上下文信息需要保存在协程自己的栈中，以便于恢复执行状态。协程的切换不会切换进程，而是在同一进程内部进行。这也是协程相比线程更加轻量级的原因之一。


- 如果多个线程同时判断到当前对象未创建，应该怎么解决？

  如果多个线程同时判断到当前对象未创建，就可能会出现多个线程同时创建同一个对象的问题，这称为竞态条件（Race Condition）。为了解决这个问题，可以采用以下两种方法：

  1. 使用互斥锁

  可以使用互斥锁（Mutex）来保护资源的访问，当一个线程要访问共享资源时，首先尝试获得互斥锁，如果锁已经被其他线程占用，就必须等待锁被释放后才能访问，从而避免了多个线程同时创建同一个对象的情况。可以使用C++11提供的std::mutex来实现互斥锁。

  2. 使用双重检查锁定模式

  双重检查锁定模式（Double-Check Locking Pattern）是一种常见的单例模式的实现方式，可以避免多线程创建同一个对象的问题。具体实现方法如下：

  ```c
  class Singleton {
  private:
      static Singleton* instance;
      static std::mutex mtx;
  
      Singleton() {}
  
  public:
      static Singleton* getInstance() {
          if (instance == nullptr) { // 第一次检查
              std::lock_guard<std::mutex> lock(mtx); // 加锁
              if (instance == nullptr) { // 第二次检查
                  instance = new Singleton();
              }
          }
  
          return instance;
      }
  };
  
  Singleton* Singleton::instance = nullptr;
  std::mutex Singleton::mtx;
  ```

  在getInstance()函数中，第一次检查是为了提高效率，如果instance已经被创建，则可以直接返回；第二次检查是为了避免多个线程同时创建同一个对象，只有在获取到锁之后才会进行创建。这样，即使多个线程同时调用getInstance()函数，也不会创建多个对象。

  总之，在多线程编程中，需要特别注意竞态条件的问题，尽可能采用互斥锁、读写锁、信号量等同步机制来保护共享资源的访问。同时，在实现单例模式等共享资源的场景下，还需要特别注意线程安全的实现方式。

- 先来先服务和短作业优先适用于哪种类型的操作系统？

  先来先服务和短作业优先算法适用于不同类型的操作系统。

  先来先服务算法适用于批处理操作系统，作业通常按照提交的顺序进行处理，所以先来先服务算法很适合。在这种情况下，作业按照先后顺序依次进入队列，CPU依次执行每个作业，直到该作业执行完毕或者阻塞，才会执行下一个作业。

  短作业优先算法适用于实时操作系统，可以确保较短的任务获得更快的响应时间，从而满足实时性要求。在这种情况下，作业的执行时间需要预测或估计，优先执行执行时间短的作业，可以避免长作业的饥饿现象，同时也可以提高系统的响应速度。

  因此，先来先服务和短作业优先算法适用于不同类型的操作系统，需要根据不同的场景选择合适的算法才能更好地满足系统的需求。

- vfork 什么作用？fork和vfork的区别

  `vfork()` 是一种创建子进程的系统调用，与 `fork()` 类似，但是 `vfork()` 会与父进程共享地址空间，直到子进程调用 `execve()`、 `_exit()` 或发生错误时才会分离地址空间。`vfork()` 的主要作用是在创建子进程时避免复制父进程的地址空间，从而提高创建进程的效率。

  `fork()` 与 `vfork()` 的区别在于，`fork()` 会复制父进程的地址空间，而 `vfork()` 不会复制父进程的地址空间，直接在父进程的地址空间中运行子进程。因此，使用 `vfork()` 可以在创建子进程时避免复制大量的数据，提高创建进程的效率。但是，由于 `vfork()` 与父进程共享地址空间，因此必须保证子进程不会修改父进程的数据，否则可能会导致未定义的行为。 在使用 `vfork()` 时，需要注意以下几点：

  1. 子进程必须要调用 `execve()`、 `_exit()` 或发生错误时才能分离地址空间，否则可能会导致未定义的行为。
  2. 子进程不能修改父进程的数据，否则可能会破坏父进程的状态。
  3. 父进程在调用 `vfork()` 后应该立即调用 `wait()` 或 `waitpid()` 等待子进程结束，否则可能会导致子进程成为僵尸进程。 总的来说，`vfork()` 可以在创建进程时提高效率，但是需要注意子进程与父进程之间的共享问题，避免出现未定义的行为。

- 写时拷贝的原理

  写时拷贝（copy on write, COW）。

  父进程 fork 出的子进程与父进程共享内存空间，一开始父进程的数据不会复制给子进程，这样创建子进程的速度就很快了 (不用复制，直接指向父进程的物理空间)。只有当父子进程中有写入操作，再为子进程分配相应的物理空间。

  fork之后，内核把父进程中所有的内存页的权限设置为只读，然后子进程的地址空间指向父进程，与父进程共享数据。当父子进程都只读内存时，正常执行。当某个进程写内存时，CPU检测到内存页是只读的，就会触发页异常中断，内核就会把触发异常的页复制一份出来，这样父子进程就各自持有独立的异常页（其余的页还是共享父进程的）。

  写时拷贝可以减少分配和复制大量资源时带来的时间消耗；检查不必要的资源分配，比如fork进程时，并不是所有的页面都需要复制，父进程的代码段和只读数据段都不被允许修改，所以无需复制。

- 硬链接和软链接的区别

  硬链接（Hard Link）： 硬链接是指多个文件名指向同一个物理数据块，不同文件名的文件在文件系统中的 inode 号是相同的，它们占用的硬盘空间也是相同的。当其中一个文件被删除时，由于其它文件还指向同一个物理数据块，因此文件的数据不会被删除，只是将文件的链接数减 1，当链接数为 0 时才会真正删除文件数据。

  软链接（Symbolic Link）： 软链接是指类似于 Windows 中的快捷方式，它是一个特殊的文件，其中包含的是链接文件的路径。软链接与原文件是两个独立的文件，它们的 inode 号是不同的，占用的硬盘空间也不同。当原文件被删除时，软链接失效，因为它指向的文件已经不存在了。但是软链接本身不会被删除，如果需要删除软链接，需要使用 `rm` 命令。

  综上所述，硬链接和软链接的最大区别在于：硬链接是多个文件名指向同一份数据，它们之间是互相独立的，而软链接则是一个文件指向另一个文件，软链接本身是一个特殊的文件，它指向的文件删除后就失效了。

- 文件系统的inode，硬链接与软链接

  文件系统中的inode是指索引节点（Index Node），它是文件系统中的一个数据结构，用于存储文件的元数据信息，例如文件的访问权限、所有者、大小等信息。每个文件都与一个唯一的inode相关联，文件名只是inode的一种别名。

  硬链接是指在文件系统中创建一个指向已有文件inode的新文件名，这两个文件名实际上是同一个文件，它们共享同一个inode。因此，硬链接可以使得多个文件名指向同一个文件，从而节省文件系统的存储空间。

  软连接（Symbolic Link）是指在文件系统中创建一个特殊的文件，它包含了指向另一个文件的路径信息。软连接本身并不包含文件的内容，而是指向另一个文件的路径信息。因此，软连接可以使得一个文件名指向另一个文件名，从而方便用户对文件进行操作。

  总的来说，硬链接和软连接都是用于创建文件系统中的别名，它们的主要区别在于：

  1. 硬链接创建的是一个新的文件名，它与原始文件名指向同一个文件，而软连接创建的是一个特殊的文件，它包含了指向另一个文件的路径信息。
  2. 硬链接只能在同一文件系统中创建，而软连接可以跨越文件系统创建。
  3. 硬链接不能对目录进行创建，而软连接可以对目录进行创建。
  4. 硬链接可以使用原始文件名进行访问，而软连接需要使用软连接文件名和指向的文件名进行访问。

  在实际使用中，硬链接和软连接都可以用于实现文件系统中的别名和共享，但需要根据具体的场景和需求进行选择。

- 重启进程后，原共享内存是否可以操作？对于普通的进程又是如何呢？

  在重启进程后，原共享内存不可以直接操作，因为共享内存是进程间共享的一段内存区域，仅仅是在操作系统的内存空间中保持一段固定的物理内存块，不属于任何一个进程，多个进程可以通过映射同一块共享内存来实现进程间通信。共享内存的生命周期与进程无关，只有在显式地进行删除或者系统关闭时才会被释放。

  因此，当进程被重启后，原共享内存仍然存在，但是它所属的进程已经不存在了，无法访问和操作共享内存。如果需要在重启后仍然可以使用共享内存，需要重新创建共享内存并将数据恢复到新的共享内存中。

  对于普通的进程，重启后，进程所占用的内存空间会被释放，进程所使用的所有资源（包括文件句柄、套接字、管道等）也会被关闭和释放。因此，在重启后，原进程所占用的内存和资源已经不存在了，无法访问和操作。如果需要在重启后继续使用这些资源，需要重新创建和初始化。

- 孤儿进程和僵尸进程，产生的原因，什么样的代码会产生僵尸进程？

  孤儿进程和僵尸进程是Linux系统中常见的两种进程状态。

  孤儿进程是指父进程先于子进程退出，而子进程还在运行的情况下，子进程成为孤儿进程。孤儿进程由init进程接管，并由init进程负责将其退出，释放资源。

  僵尸进程是指子进程先于父进程退出，但是父进程没有处理子进程的退出状态信息的情况下，子进程成为僵尸进程。僵尸进程虽然已经退出，但是其占用的系统资源（例如进程ID、内存等）没有被释放，如果存在大量的僵尸进程，会导致系统的性能下降。

  产生孤儿进程的原因通常是父进程在创建子进程后退出，而子进程继续运行。产生僵尸进程的原因是父进程没有对子进程进行处理，没有调用wait或waitpid等函数获取子进程的退出状态信息。

  在编写代码时，如果父进程没有及时处理子进程的退出状态信息，会产生僵尸进程。以下是一个简单的示例代码：

  ```c
  #include <stdio.h>
  #include <stdlib.h>
  #include <unistd.h>
  
  int main() {
      pid_t pid;
  
      pid = fork();
      if (pid < 0) {
          perror("fork error");
          exit(1);
      } else if (pid == 0) {
          printf("child process %d\n", getpid());
          exit(0);
      } else {
          printf("parent process %d\n", getpid());
          sleep(10);
      }
  
      return 0;
  }
  ```

  在该代码中，父进程创建了一个子进程，但是没有对子进程进行处理，也没有调用wait或waitpid函数获取子进程的退出状态信息。因此，当子进程退出后，成为了一个僵尸进程，占用系统资源，等待父进程处理。如果父进程一直没有处理，就会导致系统中存在大量的僵尸进程，影响系统性能。

  为避免产生僵尸进程，父进程需要及时处理子进程的退出状态信息，可以调用wait或waitpid等函数来获取子进程的退出状态信息并释放僵尸进程的资源。

- 系统创建进程的时候会给进程分配哪些资源

  当系统创建一个进程时，会为其分配一些资源，这些资源包括：

  1. 进程标识符（PID）：系统为每个进程分配一个唯一的 PID，用于标识该进程。

  2. 进程地址空间：系统为每个进程分配一个虚拟地址空间，该空间包括代码段、数据段、堆和栈等。

  3. 进程上下文：系统为每个进程分配一个上下文，包括进程状态、寄存器值、堆栈指针等。

  4. 文件描述符表：每个进程都有一个文件描述符表，其中存储了进程打开的文件和网络连接等信息。

  5. 信号处理器：系统为每个进程分配一组信号处理器，用于处理进程收到的不同类型的信号。

  6. 资源限制：系统会为每个进程设置一些资源限制，包括 CPU 时间、内存使用量、文件打开数等。

  7. 进程优先级：系统会为每个进程设置一个优先级，用于调度器在进程之间进行调度。

  8. 环境变量：系统会为每个进程设置一个环境变量列表，用于存储进程运行环境相关的信息。

  除了以上列出的资源之外，系统还会为进程分配一些其他的资源，例如进程间通信机制、共享内存、消息队列等，这些资源也是进程运行所必需的。

  需要注意的是，不同的操作系统在进程创建时会分配的资源可能会有所不同，但大体上都会涵盖以上列出的资源。

- 线程中包含哪些资源

  线程是操作系统中的一种轻量级进程，它与进程共享一些资源，同时也有一些自己独有的资源。线程中包含的资源主要包括：

  1. 线程标识符（TID）：系统为每个线程分配一个唯一的 TID，用于标识该线程。

  2. 线程栈：线程需要有自己的栈空间，用于存储线程的局部变量、函数参数和返回值等。

  3. 寄存器：线程需要使用一些寄存器来存储线程的上下文信息，例如程序计数器、堆栈指针等。

  4. 线程私有数据：线程可以有自己的一些私有数据，例如线程局部变量等。

  5. 线程同步和通信机制：线程之间需要进行同步和通信，例如互斥锁、条件变量等。

  6. 调度属性：系统会为每个线程设置一些调度属性，例如线程的优先级、调度策略等。

  需要注意的是，线程与进程共享一些资源，例如进程地址空间、文件描述符表等，这些资源也属于线程的资源范畴。此外，线程的资源与操作系统的实现方式有关，不同的操作系统可能会分配不同的资源给线程。

  总之，线程中包含的资源与进程有些类似，但线程也有自己独有的资源，例如线程栈、线程私有数据等。了解线程的资源结构可以帮助程序员编写高效、正确的多线程程序。

- 进程切换时都有哪些改变

  进程切换时，操作系统需要进行一系列的改变，以下是一些可能的改变：

  1. 程序计数器（PC）的值会被保存。PC 指向当前正在执行的指令，进程切换后需要将其保存，以便下次切换回来时能够继续执行。

  2. CPU 寄存器的值也会被保存。CPU 寄存器中保存了进程正在使用的变量和临时存储的数据，这些值需要在进程切换时被保存。否则，当进程切换回来时，原来保存在寄存器中的数据可能已经被覆盖掉了，导致程序出错。

  3. 进程状态的改变。进程切换时，当前进程的状态会被保存，包括进程的优先级、时间片、内存映像、打开文件等信息。操作系统需要将这些信息保存下来，并为将要切换到的进程恢复相应的状态。

  4. 内核栈的切换。内核栈是进程在内核态下使用的栈，进程切换时需要切换内核栈，以便在内核态下正常运行。

  5. 切换到不同的地址空间。不同的进程可能使用不同的地址空间，进程切换时需要将当前进程的地址空间切换到将要切换到的进程的地址空间。

  6. 切换到不同的用户态栈。用户态栈是进程在用户态下使用的栈，进程切换时需要切换用户态栈，以便在用户态下正常运行。

  7. 更新进程控制块（PCB）。进程切换时，系统需要更新当前进程的 PCB 信息，包括进程的状态和其他信息。

  需要注意的是，不同的操作系统可能会有不同的实现方式，以上列出的改变并不是绝对的，但是它们是常见的进程切换过程中可能发生的改变。

- 如何发现和避免线程栈溢出

  当线程栈溢出时，通常会出现一些异常情况，例如程序崩溃、段错误等。但有时候线程栈溢出可能不会导致程序崩溃，这时需要通过其他方式来发现线程栈溢出的问题。

  以下是一些发现线程栈溢出的方法：

  1. 监控线程的栈空间使用情况：可以通过操作系统提供的一些工具来监控线程的栈空间使用情况，例如 Linux 中的 pmap 工具可以查看线程的内存使用情况。如果发现线程的栈空间使用率过高，就有可能存在栈溢出的问题。

  2. 检查程序日志：如果线程发生栈溢出时程序没有崩溃，可以通过程序日志来查看是否存在栈溢出的迹象，例如栈内存访问越界等异常情况。

  3. 增加栈空间大小：如果发现线程的栈空间不够用，可以尝试增加线程的栈空间大小。在编写程序时，可以通过调用操作系统提供的一些函数来动态分配栈空间，例如 pthread_attr_setstacksize 函数可以设置线程的栈空间大小。

  总之，线程栈溢出可能会导致程序崩溃或发生异常情况，但有时候也可能不会导致程序崩溃，这时需要通过其他方式来发现栈溢出的问题。为了避免线程栈溢出，程序员应该合理地分配线程的栈空间大小，避免栈空间不足的情况发生。

  当线程栈空间不足时，就有可能会发生线程栈溢出的问题。线程栈溢出可能会导致程序崩溃、数据丢失等严重后果，因此程序员需要注意如何避免线程栈溢出的问题。

  以下是一些避免线程栈溢出的方法：

  1. 合理分配线程的栈空间大小：程序员应该根据线程的需要，合理地分配线程的栈空间大小。如果线程需要大量的栈空间，可以考虑使用动态分配的方式来分配栈空间。

  2. 使用静态分配的栈空间：在编写程序时，可以使用静态分配的方式来分配栈空间。静态分配的栈空间通常比较大，可以避免栈空间不足的情况发生。

  3. 使用线程池：线程池是一种常见的多线程编程技术，它可以避免线程频繁的创建和销毁，从而减少线程栈空间的使用。线程池通常会预先创建一定数量的线程，当有任务需要执行时，就将任务分配给空闲的线程来执行，从而减少线程的创建和销毁次数。

  4. 使用堆空间：在编写程序时，可以使用堆空间来存储一些大型的数据结构，避免占用过多的栈空间。例如可以使用动态分配的内存或者全局变量来存储大型的数据结构。

  总之，避免线程栈溢出需要程序员在编写程序时注意合理分配线程的栈空间大小，使用静态分配的栈空间、线程池等技术来减少线程的创建和销毁次数，从而避免线程栈溢出的问题。

- mmap 的地址怎么确定

  mmap是一种将文件映射到内存的系统调用，它可以将一个文件或设备映射到进程的地址空间中，从而使得进程可以直接访问文件或设备中的内容。在调用mmap时，需要指定映射的起始地址和映射的长度，这些参数通常是由操作系统自动分配的，但也可以手动指定。

  当手动指定映射的起始地址时，需要考虑以下几个因素：

  1. 起始地址必须是操作系统内存页面大小（通常是4KB）的整数倍，否则会导致段错误（segmentation fault）。

  2. 起始地址不能和已经映射的内存区域重叠，否则会导致数据的覆盖或丢失。

  3. 起始地址不能和进程的代码、数据、堆栈等区域重叠，否则会导致程序崩溃或不可预测的行为。

  因此，手动指定映射的起始地址需要进行仔细的计算和分析，以确保映射的正确性和可靠性。

  当未手动指定映射的起始地址时，操作系统会自动分配一个合适的地址，并返回这个地址给调用者。这个地址通常是由操作系统的虚拟内存管理模块根据当前进程的内存布局和可用内存空间进行计算和分配的，具体实现细节与操作系统的实现方式有关，通常会考虑以下因素：

  1. 进程的代码、数据、堆栈等区域的地址和大小。

  2. 已经映射到进程地址空间中的文件、设备等的地址和大小。

  3. 空闲内存的地址和大小。

  根据这些因素，操作系统会选择一个合适的地址作为映射的起始地址，并返回给调用者。需要注意的是，由于操作系统会自动分配地址，因此在多次调用mmap时，映射的地址可能会发生变化，因此需要进行相应的处理和调整。

- 不同线程共享的是什么

  不同线程共享的是进程的地址空间和各种资源，包括打开的文件、共享内存、信号量、网络连接等等。

  每个进程都有自己的地址空间，包括代码段、数据段、堆栈段等。不同线程共享进程的地址空间，也就意味着它们可以访问同一个进程的全局变量、静态变量、函数等等。

  此外，不同线程还可以共享一些资源，比如打开的文件、共享内存、信号量、网络连接等等。这些资源是进程级别的，不同线程可以通过相应的API共享这些资源，以实现线程之间的协作和通信。

  需要注意的是，不同线程共享的资源需要进行适当的同步和互斥，以避免竞态条件和数据不一致等问题。在多线程编程中，通常会使用锁、信号量、条件变量等同步机制来保证线程之间的正确协作。

- 服务端的连接数上限由什么决定？

  服务端的连接数上限由多个因素共同决定：

  1. 系统资源：服务端的连接数受限于系统资源，如CPU、内存、网络带宽等。如果系统资源不足，会导致服务端无法处理更多的连接请求。

  2. 操作系统：不同操作系统对于连接数的限制也不同，比如Linux内核默认情况下可以支持数万个TCP连接，而Windows操作系统则有较低的默认连接数限制。

  3. 网络设备：服务端连接数还受限于网络设备的处理能力，如路由器、交换机等。如果网络设备的处理能力不足，会导致连接数上限无法扩大。

  4. 应用程序：应用程序本身也会对连接数进行限制，如使用线程池、连接池等机制来控制连接数。

  5. 连接的性质：不同类型的连接对连接数的限制也不同，如长连接和短连接的限制就不同。长连接需要占用更多的系统资源，因此对连接数的限制会更严格。

  需要注意的是，连接数的上限是一个动态的概念，它会随着系统资源的变化和应用程序的调整而变化。在实际应用中，需要根据具体情况进行调整，以达到最佳的性能和稳定性。

- 自旋锁和可重入锁的区别，什么时候使用

  自旋锁和可重入锁是两种不同类型的锁，它们的区别如下：

  1. 实现方式不同：自旋锁是通过在获取锁失败时不断地循环尝试获取锁直到成功，而可重入锁则是通过记录锁的持有者以及持有次数来实现的。

  2. 锁的性质不同：自旋锁是一种非阻塞锁，它不会将线程挂起，而可重入锁是一种阻塞锁，它会将线程挂起等待锁的释放。

  3. 适用场景不同：自旋锁适用于锁的持有时间很短的情况，因为自旋锁不会将线程挂起，如果锁的持有时间过长，就会导致CPU资源的浪费。而可重入锁适用于锁的持有时间较长的情况，因为可重入锁可以防止死锁，并且可以保证同一个线程多次获取同一个锁时不会出现死锁问题。

  4. 线程安全性不同：自旋锁是非线程安全的，因为它没有记录锁的持有者的信息，所以不适用于多线程环境。而可重入锁是线程安全的，因为它记录了锁的持有者以及持有次数，可以支持多个线程同时获取同一个锁。

  在实际应用中，需要根据具体情况选择自旋锁或可重入锁。如果锁的持有时间较短，且是在单线程环境下使用，可以选择自旋锁来避免线程挂起的开销；如果锁的持有时间较长，或者需要在多线程环境下使用，可以选择可重入锁来防止死锁，并且支持多线程同时获取同一个锁。

- 死锁和死循环的判断，日志或者其他方案？

  在 C++ 中判断死锁和死循环的方法主要有以下几种：

  1. 使用互斥量和条件变量来实现线程同步，同时在程序中添加日志记录，记录每个线程获取锁的顺序和等待的时间。
  2. 使用计数器或者时间戳等机制，避免线程陷入无限循环，同时在程序中添加日志记录。
  3. 使用诸如 Valgrind、GDB 等调试工具来检测死锁和死循环。

- `join()` 和 `detach()` 

  在多线程编程中，使用 `join()` 和 `detach()` 是非常常见的操作。下面是一些需要注意的事项：

  1. 一旦线程被 `join()` 或 `detach()`，它就不能再次被 `join()` 或 `detach()`。调用 `join()` 或 `detach()` 时应该确保线程仍然存在，否则会导致程序崩溃。
  2. 在使用 `join()` 时，当前线程会被阻塞，直到被等待的线程执行完毕。这种方式适合用于协调线程之间的执行顺序，但可能会降低程序的并发性。
  3. 在使用 `detach()` 时，被分离的线程将变成后台线程，不再与当前线程同步执行，也不需要等待其执行完毕。这种方式适合用于一些独立运行的任务，可以提高程序的并发性，但也需要注意线程的生命周期和资源管理。
  4. 在使用 `join()` 和 `detach()` 时，需要注意线程的异常处理。如果在线程中抛出了异常，如果线程被 `join()`，则异常会被重新抛出到当前线程中，否则可能会导致程序崩溃。
  5. 在使用 `join()` 和 `detach()` 时，需要注意线程的资源管理。如果线程需要访问一些共享资源，需要使用锁来保护这些资源，避免多个线程同时访问导致数据不一致或程序崩溃。

  总之，在使用 `join()` 和 `detach()` 时，需要仔细考虑线程的生命周期、资源管理和异常处理等方面，以确保程序的正确性和稳定性。

- 线程池的任务队列爆炸怎么办

  当线程池的任务队列过大时，可能会导致系统资源的浪费和性能下降，甚至可能会导致系统崩溃。以下是一些解决线程池任务队列爆炸的方法：

  1. 增加任务队列的容量：可以通过增加任务队列的容量来避免队列溢出。但是，如果任务队列容量过大，可能会导致系统资源的浪费。因此，需要根据系统的实际需求来确定任务队列的容量。
  2. 限制任务的提交速率：可以通过限制任务的提交速率来避免任务队列爆炸。例如，可以通过限制任务的提交速率来控制任务的数量，从而避免任务队列溢出。
  3. 优化任务的处理速率：可以通过优化任务的处理速率来避免任务队列爆炸。例如，可以对任务进行优化，使得任务的处理时间更短，从而减少任务在队列中的等待时间。
  4. 使用分布式任务队列：当单机的任务队列无法满足系统需求时，可以考虑使用分布式任务队列。分布式任务队列可以将任务分散到多个节点上进行处理，从而避免单机任务队列的爆炸。
  5. 使用异步编程模型：可以使用异步编程模型来避免任务队列爆炸。异步编程模型可以将任务的执行和结果的处理分离开来，并通过回调函数的方式进行处理，从而避免任务在队列中的等待时间过长。

  需要根据具体的系统需求和情况来选择合适的解决方法。

- 线程池怎么减少队列中锁的争用

  线程池的任务队列是多线程共享的资源，当多个线程同时对任务队列进行操作时，会产生锁的竞争，从而影响系统的性能。以下是一些减少队列中锁的争用的方法：

  1. 使用无锁队列：无锁队列是一种基于 CAS（Compare And Swap）操作实现的队列，它可以避免锁的使用，从而减少锁的争用。无锁队列的实现比较复杂，需要考虑线程安全和内存模型等问题，但是可以提高系统的性能。
  2. 减少锁的粒度：可以通过减少锁的粒度来减少锁的争用。例如，可以将任务队列分为多个子队列，每个子队列使用独立的锁进行保护，从而减少锁的争用。
  3. 优化队列操作：可以通过优化队列的插入和删除操作来减少锁的争用。例如，可以使用双端队列或者链表等数据结构来避免队列头部的锁争用，从而提高队列的插入和删除效率。
  4. 任务优先级管理：可以通过任务的优先级来控制任务的执行顺序，从而减少任务在队列中的等待时间，降低锁的争用。例如，可以将高优先级的任务放到任务队列的前面，优先执行。
  5. 使用异步编程模型：可以通过使用异步编程模型来避免锁的争用。异步编程模型可以将任务的执行和结果的处理分离开来，并通过回调函数的方式进行处理，从而避免任务在队列中的等待时间过长。

  需要根据具体的系统需求和情况来选择合适的方法来减少锁的争用。

- 多进程可以监听同一个端口吗？会出现什么问题？怎么解决？多线程可以监听同一个端口吗？

  多进程可以监听同一个端口，但是会出现惊群问题。

  惊群问题是指多个进程同时在等待同一个事件（例如一个连接请求），当事件触发时，多个进程同时被唤醒，竞争同一个资源，从而导致性能下降。在网络编程中，惊群问题常常出现在多个进程同时监听同一个端口的情况下。

  解决惊群问题的方法有以下几种：

  1. 使用单进程监听端口，然后通过进程间通信的方式将连接请求分配给其他进程处理。

  2. 在多进程中，只有一个进程负责监听端口，其他进程通过进程间通信的方式告知监听进程需要处理的连接请求。

  3. 使用 SO_REUSEPORT 选项，让多个进程可以同时绑定同一个端口，但是每个进程只会处理一部分连接请求，从而避免惊群问题。

  多线程可以监听同一个端口，因为多个线程可以共享同一个进程的资源，避免了惊群问题。在多线程编程中，通常使用线程池来处理连接请求，从而提高程序的性能。

- 服务器怎么做负载均衡

  针对浏览器访问一个HTTP服务器会同时向该服务器发起多个TCP连接的情况，可以采用以下几种负载均衡的方法：

  1. 基于轮询的负载均衡：将请求轮流分配给不同的TCP连接，保证每个TCP连接都能够被充分利用。这种方法简单易行，但是无法根据连接的负载情况进行调节。

  2. 基于权重的负载均衡：根据每个TCP连接的负载情况以及服务器的性能等因素，给不同的TCP连接分配不同的权重，从而实现负载均衡。这种方法可以根据实际情况动态地调节负载均衡的策略，但是需要对服务器的性能进行实时监测和调整。

  3. 基于哈希的负载均衡：根据请求的特定信息（例如URL、IP地址等）计算哈希值，然后将请求分配给对应的TCP连接，从而实现负载均衡。这种方法可以保证相同的请求总是被分配到同一个TCP连接上，从而避免了一些潜在的问题，但是需要对哈希算法进行优化，从而避免哈希冲突。

  需要注意的是，在实际应用中，负载均衡的方法往往不是单独采用一种方法，而是结合多种方法，从而实现更加灵活、高效的负载均衡策略。

- 协程切换的时候要保存哪些数据，是所有的CPU寄存器值都需要压栈吗？

  协程切换时需要保存当前协程的状态，包括程序计数器、栈指针、寄存器等。保存寄存器的值是为了保证协程切换后能够恢复上下文，继续执行协程中的代码。

  一般来说，协程切换时只需要保存一部分寄存器的值，不需要保存所有的寄存器。具体需要保存哪些寄存器的值和保存的顺序可能会因不同的编程语言、操作系统和硬件平台而有所不同。在 C++ 中，常见的需要保存的寄存器包括通用寄存器（如 EAX、EBX、ECX、EDX 等）、栈指针（ESP）、基址指针（EBP）等。在其他编程语言或平台中，可能还需要保存其他寄存器的值。

  需要注意的是，协程切换时，除了保存当前协程的状态外，还需要恢复另一个协程的状态。因此，协程切换时需要保存当前协程的状态，并将另一个协程的状态加载到寄存器中，从而继续执行另一个协程中的代码。

  总之，在协程切换时需要保存当前协程的状态，包括一部分寄存器的值，以便恢复上下文，继续执行协程中的代码。

- 协程栈的管理有哪些方法

  协程栈是协程运行时的重要组成部分，管理好协程栈对于协程的正常运行和性能优化至关重要。以下是一些常见的协程栈管理方法：

  1. 预分配栈空间：在创建协程时，预分配一定大小的栈空间，避免在运行时频繁申请和释放内存。这种方法可以提高协程的性能，但需要根据协程的实际需求来确定预分配的栈空间大小。
  2. 动态调整栈空间：在协程运行时，根据栈空间的使用情况动态调整栈空间大小。当栈空间不足时，动态申请更多的栈空间；当栈空间过大时，释放一部分空间。这种方法需要实现一些复杂的内存管理和调度算法，但可以提高内存利用率和系统的可靠性。
  3. 禁止递归调用：在协程中禁止使用递归调用，避免栈空间溢出。如果需要递归调用，可以使用循环或迭代等方法来代替。
  4. 栈空间监控：在协程中加入栈空间监控代码，及时检测栈空间的使用情况，避免栈空间溢出。例如，可以在协程中加入栈空间监控函数，在栈空间不足时及时报警或进行自动扩容等操作。
  5. 栈空间共享：在多个协程之间共享栈空间，避免重复申请和释放内存。这种方法可以提高内存利用率和系统的可靠性，但需要注意协程之间的数据隔离和安全性问题。

  需要根据具体的应用场景和需求来选择合适的协程栈管理方法。

- 共享栈的会导致切换的时候有两次拷贝，有更好的方法吗？

  确实，使用共享栈的方式，由于多个协程共享同一个栈空间，因此在协程切换时需要进行两次拷贝，一次是将当前协程的栈数据拷贝到栈空间中，另一次是将栈空间中的数据拷贝到下一个协程的栈中。这样的拷贝操作会增加协程切换的开销，降低系统的性能。

  为了避免这种情况，可以使用分段栈的方式来管理协程的栈空间。具体来说，可以将协程的栈空间分成多个段，每个段单独管理，避免多个协程同时使用同一段栈空间。在协程切换时，只需要切换当前段的栈指针和当前段的状态，不需要进行栈数据的拷贝操作，从而避免了拷贝操作带来的开销。

  另一种更加高效的方法是使用汇编语言来实现协程切换。汇编语言可以直接控制处理器的寄存器和栈指针，从而实现协程切换的高效操作。在汇编语言中，可以使用类似于跳转指令（jmp）的指令，直接跳转到下一个协程的栈中，避免了拷贝操作的开销。

  需要注意的是，使用汇编语言实现协程切换需要对底层硬件和系统有一定的了解和掌握，同时也需要考虑系统的可移植性和安全性等问题，因此需要谨慎使用。

- 

# Linux

- CPU占用过高如何检测？

  1. 使用top命令，实时显示进程CPU百分比和内存使用情况，找出CPU占用较高的进程pid。

  2. 使用ps命令，查询进程中哪个线程的cpu占用率高，记住TID：`ps -mp pid -o THREAD,tid,time`。

   其中，-m显示所有的线程，-p表示pid进程使用cpu的时间，-o表示该参数后是用户自定义格式，如：THREAD,tid,time表示线程、线程ID号、线程占用的时间。

  3. 将TID转换为16进制格式（英文小写格式） `printf “%x\n” tid`

  4. 通过`jstack`命令获取占用资源异常的线程栈：

   ```c
   jstack pid > jstack.pid.log #先保存文件，再从文件中查看
   或者
   jstack 514 |grep 202 -A 30  #直接命令行查看
   ```

  5. 从上面日志文件或者命令行查看日志，从日志中能看到自己编写的代码的类和方法，一般情况是对应代码处产生了死循环。

- kill和kill -9的区别

  1. 杀死进程的方式不同：kill命令发送的是SIGTERM信号，它是一个可以被捕获或忽略的信号，可以让进程有机会进行清理和保存数据。而kill -9命令发送的是SIGKILL信号，它是一个不能被捕获或忽略的信号，会强制终止进程，不会给进程进行任何清理操作的机会。

  2. 对进程的影响不同：kill命令发送SIGTERM信号可以让进程有机会进行清理和保存数据，可以有效避免数据丢失的情况。kill -9命令强制终止进程，可能会导致未完成的数据丢失，甚至会对系统造成影响。

  因此，在正常情况下应该尽量使用kill命令，避免使用kill -9命令。只有在进程无法响应其他信号时，或者必须立即终止一个进程时，才应该使用kill -9命令。

- GDB如何使用

  GDB是一种用于调试程序的工具，可以帮助程序员找出程序中的错误和问题。下面是使用GDB的基本步骤：

  1. 编译程序时加上-g选项，生成可调试的程序。

  2. 打开终端，输入gdb命令，进入GDB调试环境。

  3. 在GDB环境中，输入run命令，运行程序。

  4. 如果程序出现错误，GDB会停止程序的执行，并显示出错的位置。

  5. 可以使用backtrace命令查看函数调用栈，使用print命令查看变量的值，使用step命令逐行执行程序，使用break命令设置断点等。

  6. 如果需要退出GDB环境，可以使用quit命令。

  需要注意的是，GDB调试需要一定的技巧和经验，对于复杂的程序，可能需要花费较长的时间来找出问题。因此，建议在编写程序时尽可能避免出现错误，以减少调试的时间和精力。

  GDB是一款常用的调试工具，可以帮助程序员在开发过程中定位和解决程序中的错误。更详细的GDB使用方法：

  1. 编译程序时需要加上调试信息选项：-g

  例如：

  ```
  gcc -g -o myprogram myprogram.c
  ```

  2. 启动GDB

  在命令行中输入：

  ```
  gdb myprogram
  ```

  3. 设置断点

  在需要调试的代码行前加上断点：

  ```
  break main
  ```

  或者直接在GDB中输入：

  ```
  b main
  ```

  4. 运行程序

  在GDB中输入：

  ```
  run
  ```

  5. 调试程序

  程序运行到断点处时会停止，可以使用以下命令进行调试：

  - step：单步执行程序，进入函数内部
  - next：单步执行程序，不进入函数内部
  - print：打印变量的值
  - backtrace：查看函数调用栈
  - continue：继续执行程序直到下一个断点或程序结束

  6. 查看变量值

  在GDB中输入：

  ```
  print variable_name
  ```

  可以查看变量的值。

  7. 修改变量值

  在GDB中输入：

  ```
  set variable_name = new_value
  ```

  可以修改变量的值。

  8. 退出GDB

  在GDB中输入：

  ```
  quit
  ```

- 怎么使一个命令在后台运行?

  使用 & 在命令结尾来让程序自动运行。(命令后可以不追加空格)

- 用什么命令对一个文件的内容进行统计？(行号、单词数、字节数)

  wc ：- c 统计字节数 - l 统计行数 - w 统计字数。(word count)

- scp：本地和远程互传文件

- ps：查看当前进程

  ![img](https://gcore.jsdelivr.net/gh/gp868/myFigures/img/818047-20200905084700484-530981088.png)

- top：可实时显示进程CPU百分比和内存使用情况

  [Linux top命令详解 - 牛奔 - 博客园 (cnblogs.com)](https://www.cnblogs.com/niuben/p/12017242.html)

  ![img](https://gcore.jsdelivr.net/gh/gp868/myFigures/img/1303876-20191210152709726-52408463.png)

- job：查看后台任务

- lsof：查看所有被进程打开的文件(list opened files)

- 如何查看进程打开的文件

  - ps -aux 获得当前所有的进程，获得pid
  - lsof -p $PID
  - lsof -c programe-name
  - 看文件对应的进程： lsof file-name

- 介绍nm与ldd命令

  - nm (name) ：查看文件中的符号表，如常用的函数名、变量等，以及这些符号存储的区域，`nm [option(s)] [file(s)]`
  - ldd (list dynamic dependencies)：列出程序运行所需要的动态链接库，`ldd 可执行程序路径`

- shell命令查内存，端口 ，io访问量，读写速率

  - top监控系统状态

- 常见命令netstat iptable tcpdump top

  - tcpdump：root权限下使用的抓包工具，只能抓取流经本机的数据包
  - netstate：用于显示网络状态，netstate -a 显示所有连线中的socket
  - top：监控Linux的系统状况
  - iptables：对Linux系统中通信的数据包进行一定的检测，达到防火墙的目的

- gdb查看堆栈中所有遍历

  可以使用gdb的backtrace命令来查看堆栈中所有的遍历。

  步骤如下：

  1. 在终端中使用gdb命令打开要调试的程序。

  2. 在gdb中输入run命令以运行程序。

  3. 当程序出现问题时，使用ctrl+c来中断程序的执行。

  4. 输入backtrace命令来查看堆栈中所有的遍历。

  例如：

  ```
  (gdb) backtrace
  #0 0x0000000000400520 in main ()
  #1 0x00007ffff7a1e830 in __libc_start_main (main=0x400510, argc=1, argv=0x7fffffffe1d8, init=<optimized out>, fini=<optimized out>, rtld_fini=<optimized out>, stack_end=0x7fffffffe1c8) at libc-start.c:291
  #2 0x00000000004003d9 in _start ()
  ```

- ctrl+c 发的是什么信号

  Ctrl+C：发送 SIGINT 信号（程序终止(interrupt)信号）给前台进程组中的所有进程，常用于终止正在运行的程序；

  Ctrl+Z：发送 SIGTSTP 信号（停止进程的运行，但该信号可以被处理和忽略）给前台进程组中的所有进程，常用于挂起一个进程。如果需要恢复到前台使用fg命令，恢复到后台使用bg命令。

  Ctrl+D：不是发送信号，而是表示一个特殊的二进制值，表示 EOF。EOF是End Of File的缩写，通常在文本末尾使用此字符表示文本结束。

- Linux如何查服务运行在哪个端口？

  Linux可以使用以下命令来查找服务运行在哪个端口：

  1. netstat命令

  使用netstat命令可以列出当前系统上所有的网络连接和监听端口。可以使用以下命令来查找某个服务所使用的端口：

  ```
  netstat -anp | grep 服务名
  ```

  其中，-a表示列出所有的连接和监听端口，-n表示以数字形式显示端口号，-p表示显示与端口相关的进程信息，grep用于查找服务名。

  2. lsof命令

  lsof是一个可以列出当前系统打开的所有文件和网络连接的工具。可以使用以下命令来查找某个服务所使用的端口：

  ```
  lsof -i :端口号
  ```

  其中，-i表示查找网络连接，:端口号表示要查找的端口号。

  3. ss命令

  ss是一个更快速和更高效的netstat替代品，可以用来列出当前系统上所有的网络连接和监听端口。可以使用以下命令来查找某个服务所使用的端口：

  ```
  ss -ant | grep 端口号
  ```

  其中，-a表示列出所有的连接和监听端口，-n表示以数字形式显示端口号，-t表示只列出TCP连接，grep用于查找端口号。

- chmod 741 代表什么

  文件权限主要有3部分组成，user用户的权限，group用户组的权限，other其他用户的权限；每部分权限都由 r(读)-w(写)-x(执行) 3部分组成组成，其中的代表数值为： r(4)-w(2)-x(1) ，修改权限的时候，只要通过命令给文件赋予对应的值即可。

  chmod 741 myFile #这里是修改myFile文件，这里的的741每个数字分别代表着不同部分的权限，user 用户赋予 (r-w-x =既4+2+1=7) 的权限，group 赋予 w(4) 权限，other 赋予 x(1) 权限

- Linux中du,df两个命令的区别

  Linux中du和df是两个常用的磁盘空间查询命令，它们的区别如下：

  1. du命令是用来查看指定目录或文件所占用的磁盘空间大小，它会递归地统计目录下所有文件和子目录的大小，并将结果显示出来；df命令是用来显示文件系统的磁盘空间使用情况，它会列出文件系统的名称、总容量、已用空间、可用空间和挂载点等信息。
  2. du命令的单位默认为字节，可以通过参数-k、-m、-g等来指定显示单位为KB、MB、GB等；df命令的单位默认为KB，可以通过参数-h、-H等来指定显示单位为可读性更好的GB、MB等。
  3. du命令只能查看指定目录或文件的大小，而df命令可以查看整个文件系统的磁盘空间使用情况。

  因此，du和df命令的作用不同，使用场景也不同。一般来说，du命令用于查看某个目录或文件所占用的空间大小，df命令用于查看文件系统的磁盘空间使用情况。

- Linux下的/var 目录有什么用

  在Linux中，`/var`目录主要用于存放在系统运行过程中动态产生的变化文件，包括缓存、日志文件和软件运行时需要的其他数据等。具体来说，`/var`目录下常见子目录的作用如下：

  - `/var/cache`: 存放被程序缓存的文件，例如apt等软件包管理器下载的软件包。
  - `/var/log`: 存放系统的日志文件，包括内核日志、应用程序日志、登录记录和错误日志等。在这个目录下，还有许多子目录可以进一步分类和存储不同类型的日志信息，例如`/var/log/messages`是记录系统消息的文件，`/var/log/auth.log`是记录身份验证相关信息的文件。
  - `/var/spool`: 存放需要等待处理的任务，例如邮件队列、打印队列等。
  - `/var/lib`: 存放某些软件的库文件、数据库等数据文件。例如MySQL数据库的数据文件默认就会存放在这个目录下。
  - `/var/run`: 存放正在运行的进程相关信息，例如PID文件等。

  需要注意的是，由于`/var`目录下的文件通常是动态生成的，因此其中的数据可能随着时间的推移不断增长，占用硬盘空间。因此，在设计文件系统的时候，我们需要考虑给`/var`目录足够的空间，并及时清理其中不必要的或已经过期的文件。

- free命令：用于显示系统内存的情况，包括内存总量、已用内存、空闲内存等。常用的命令选项包括“free”和“free -h”，可以显示内存的详细信息。
- tcpdump命令：用于抓取网络数据包并分析其内容，可以用于网络故障排除、网络安全等方面。常用的命令选项包括“tcpdump -i 网卡名称”和“tcpdump -n”，可以抓取指定网卡的数据包并显示详细信息。

- 有一个运行的进程突然挂掉，怎么查看它是哪里出问题了？

  当一个进程突然挂掉时，我们需要查看系统日志来确定出问题的原因。具体的操作步骤如下：

  1. 使用命令 `ps -ef | grep 进程名` 查看进程是否还在运行。如果进程已经退出，输出为空；如果进程仍在运行，输出进程的相关信息，包括进程的PID。

  2. 使用命令 `dmesg` 或 `journalctl` 查看系统日志，查找和该进程相关的日志信息。可以使用 `dmesg | grep 进程名` 或 `journalctl -u 进程名` 来过滤相关的日志信息。如果没有找到任何有用的信息，可以使用 `dmesg -T` 或 `journalctl -u 进程名 -n 100` 来显示更多的日志信息。

  3. 如果系统日志中没有找到有用的信息，可以使用进程监控工具来查看进程的运行情况。常用的进程监控工具包括 `top`、`htop`、`ps`、`pidstat` 等。可以使用命令 `top -p 进程PID` 或 `htop -p 进程PID` 来查看进程的CPU、内存等资源占用情况；使用 `ps -p 进程PID -o pid,ppid,%cpu,%mem,cmd` 来查看进程的PID、PPID、CPU占用率、内存占用率和命令行等信息；使用 `pidstat -p 进程PID` 来查看进程的CPU、内存等资源使用情况。

  4. 最后，如果以上方法都没有找到问题的原因，可以尝试重启进程或者重启系统，以解决问题。同时，建议记录下系统日志和进程监控信息，以便后续分析和排查类似问题。

  除了前面提到的方法，还有一些其他的技巧可以用来定位和解决进程挂掉的问题，例如：

  1. 使用 `strace` 命令来跟踪进程的系统调用，以查看进程与系统之间的交互情况。可以使用 `strace -p 进程PID` 命令来跟踪进程的系统调用，从而确定进程是否存在异常的系统调用。

  2. 使用 `gdb` 命令来调试进程，以查看进程在运行时的内部状态。可以使用 `gdb -p 进程PID` 命令来附加到进程并进入调试模式，从而查看进程的堆栈、寄存器、变量等信息，以确定进程是否存在内存泄漏、代码异常等问题。

  3. 使用 `lsof` 命令来查看进程打开的文件和网络连接。可以使用 `lsof -p 进程PID` 命令来查看进程打开的文件、套接字和网络连接等信息，以确定进程是否存在文件句柄泄漏、网络连接异常等问题。

  4. 使用 `perf` 命令来进行性能分析，以查看进程的性能问题。可以使用 `perf record -p 进程PID` 命令来记录进程的性能数据，使用 `perf report` 命令来生成性能报告，从而确定进程是否存在性能瓶颈、死锁等问题。

  总之，确定进程挂掉的原因需要使用多种方法综合分析，有时需要结合多种工具和技术来进行定位和解决。

- linux系统运行缓慢，通过什么命令查看

  当 Linux 系统运行缓慢时，可以使用以下命令来查看系统的性能瓶颈和资源占用情况：

  1. `top` 命令：可以实时查看系统的 CPU、内存、I/O 等资源占用情况，以及进程的 CPU 占用率、内存占用率等信息。可以使用 `top -c` 命令来显示完整的进程命令行信息。

  2. `htop` 命令：类似于 `top` 命令，但是支持鼠标交互和颜色显示，更加直观和易用。

  3. `vmstat` 命令：可以查看系统的虚拟内存、CPU、I/O 等性能指标。可以使用 `vmstat 1` 命令来实时监控系统的性能指标。

  4. `iostat` 命令：可以查看系统的磁盘 I/O 情况，包括磁盘读写速度、IOPS、响应时间等指标。可以使用 `iostat -x 1` 命令来实时监控磁盘 I/O 情况。

  5. `sar` 命令：可以查看系统的 CPU、内存、磁盘、网络等性能指标，支持生成报告和图表分析。可以使用 `sar -u 1` 命令来实时监控 CPU 使用情况。

  6. `free` 命令：可以查看系统的内存使用情况，包括物理内存和交换空间的使用情况。可以使用 `free -h` 命令来以人类可读的方式显示内存使用情况。

  7. `netstat` 命令：可以查看系统的网络连接情况，包括 TCP、UDP 连接、监听端口等信息。可以使用 `netstat -anp` 命令来显示所有连接和进程信息。

  以上命令只是常用的一部分，还有其他一些工具和命令可以用来监视和分析系统的性能瓶颈和资源占用情况。

  当 Linux 系统运行缓慢时，还可以使用以下命令和技巧来查看问题和解决问题：

  1. `ps` 命令：可以查看系统的进程信息，包括进程的 PID、命令、CPU 占用率、内存占用率等信息。可以使用 `ps -ef` 命令来显示所有进程信息。

  2. `lsof` 命令：可以查看系统中打开的文件和网络连接，包括文件名、文件描述符、进程 ID 等信息。可以使用 `lsof -i` 命令来显示所有打开的网络连接。

  3. `strace` 命令：可以跟踪进程的系统调用，以查看进程与系统之间的交互情况。可以使用 `strace -p 进程PID` 命令来跟踪进程的系统调用。

  4. `iotop` 命令：可以查看系统的磁盘 I/O 情况，包括进程的 I/O 占用情况、磁盘读写速度等信息。可以使用 `iotop -o` 命令来按照 I/O 占用率排序。

  5. `sar` 命令：可以查看系统的 CPU、内存、磁盘、网络等性能指标，支持生成报告和图表分析。可以使用 `sar -u 1` 命令来实时监控 CPU 使用情况。

  6. 使用 `top` 或 `htop` 命令，查看系统进程的 CPU 占用率、内存占用率等指标，并根据需要进行进程的调整和优化。

  7. 检查系统日志，查看是否有异常信息和错误信息，例如 `/var/log/messages`、`/var/log/syslog` 等。

  8. 检查系统磁盘空间和文件系统，查看是否存在磁盘空间不足、文件系统错误等问题。

  以上命令和技巧可以帮助我们找到系统运行缓慢的原因，并采取相应的措施来解决问题。



# 单例模式

实现思路：私有化它的构造函数，以防止外界创建单例类的对象；使用类的私有静态指针变量指向类的唯一实例，并用一个公有的静态方法获取该实例。

单例模式有两种实现方法，分别是**懒汉**和**饿汉**模式。懒汉模式在第一次被使用时才进行初始化，饿汉模式在程序运行时立即初始化。

```c
// 经典懒汉式，使用双检测锁
#include<pthread.h>

class single{
public:
    static single* getinstance();

private:
    static pthread_mutex_t lock;
    static single* p;
    single(){
        pthread_mutex_init(&lock, nullptr);
    }
    ~single(){}
};

single* single::p = nullptr;
pthread_mutex_t single::lock;
single* single::getinstance(){
    if(p == nullptr){
        pthread_mutex_lock(&lock);
        if(p == nullptr){
            p = new single();
        }
        pthread_mutex_unlock(&lock);
    }
    return p;
}
    
// 懒汉式
class single{
public:
    static single* getinstance();
private:
    single(){};
    ~single(){};
}

single* single::getinstance(){
    static single p;
    return &p;
}

// 饿汉式
class single{
public:
    static single* getinstance();
private:
    single(){};
    ~single(){};
    static single* p;
}
single* single::p = new single();
single* single::getinstance(){
	return p;
}
```

经典懒汉式为什么要用双检测，只检测一次不行吗？

如果只检测一次，在每次调用获取实例的方法时，都需要加锁，这将严重影响程序性能。双层检测可以有效避免这种情况，仅在第一次创建单例的时候加锁，其他时候都不再符合NULL == p的情况，直接返回已创建好的实例。

# MySQL

- 主键索引的 B+Tree 和二级索引的 B+Tree 区别如下：

  - 主键索引的 B+Tree 的叶子节点存放的是实际数据，所有完整的用户记录都存放在主键索引的 B+Tree 的叶子节点里；
  - 二级索引的 B+Tree 的叶子节点存放的是主键值，而不是实际数据。


- 联合索引的最左匹配原则

  InnoDB中的联合索引是指由多个列组成的索引，也称为组合索引或复合索引。与单列索引不同，联合索引是通过多个列的值来确定索引的位置，因此可以提高查询效率和性能。

  例如，一个表中有两个列a和b，需要查询a和b的值，那么可以使用联合索引来优化查询。在创建联合索引时，可以将a和b列一起作为索引列，这样就可以在查询时直接使用联合索引来定位数据行，而不需要对两个列进行分别查询，可以大大提高查询效率和性能。

  联合索引的最左匹配原则，在遇到范围查询（如 >、<）的时候，就会停止匹配，也就是范围查询的字段可以用到联合索引，但是在范围查询字段的后面的字段无法用到联合索引。注意，对于 >=、<=、BETWEEN、like 前缀匹配的范围查询，并不会停止匹配。

  例子：

  `select * from t_table where a > 1 and b = 2`， a 字段用到了联合索引进行索引查询，而 b 字段并没有使用到联合索引；

  `select * from t_table where a >= 1 and b = 2`，a 和 b 字段都用到了联合索引进行索引查询；

  `SELECT * FROM t_table WHERE a BETWEEN 2 AND 8 AND b = 2`，a 和 b 字段都用到了联合索引进行索引查询；

  `SELECT * FROM t_user WHERE name like 'j%' and age = 22`， a 和 b 字段都用到了联合索引进行索引查询；

- 最左匹配原则为什么会失效

  最左匹配原则在一些情况下会失效，主要是因为以下原因：

  1. 不符合索引顺序：最左匹配原则要求查询条件必须从联合索引的最左侧开始匹配，如果查询条件的顺序与联合索引的顺序不一致，则无法使用索引进行查询优化。

  2. 未使用第一个索引列：最左匹配原则要求查询条件必须包含联合索引的第一个列，如果查询条件不包含联合索引的第一个列，则无法使用索引加速查询。

  3. 使用了函数或表达式：如果查询条件使用了函数或表达式，例如 WHERE YEAR(col1) = 2021，则无法使用索引进行查询优化。

  4. 数据列类型不同：如果联合索引的列类型不同，例如一个是字符串类型，另一个是数字类型，则最左匹配原则无法生效。

  5. 模糊匹配：如果查询条件使用了模糊匹配符号，例如 LIKE '%abc%'，则最左匹配原则无法生效。

  需要注意的是，最左匹配原则失效并不意味着查询一定会变慢，而是无法使用索引进行查询优化。在这种情况下，可以考虑对查询条件进行优化，例如调整查询条件的顺序、避免使用函数或表达式、使用全文索引等方式来提高查询效率。

- 什么时候适用索引？

  - 字段有唯一性限制的，比如商品编码；
  - 经常用于 `WHERE` 查询条件的字段，这样能够提高整个表的查询速度，如果查询条件不是一个字段，可以建立联合索引。
  - 经常用于 `GROUP BY` 和 `ORDER BY` 的字段，这样在查询的时候就不需要再去做一次排序了，因为我们都已经知道了建立索引之后在 B+Tree 中的记录都是排序好的。

- 什么时候不需要创建索引？

  - WHERE条件， GROUP BY， ORDER BY 里用不到的字段；
  - 字段中存在大量重复数据，不需要创建索引；
  - 表数据太少的时候，不需要创建索引；
  - 经常更新的字段不用创建索引；

- 防止索引失效

  - 使用左或者左右模糊匹配，也就是 `like %xx` 或者 `like %xx%`这两种方式都会造成索引失效；
  - 查询条件中对索引列做了计算、函数、类型转换操作，这些情况下都会造成索引失效；
  - 联合索引要能正确使用需要遵循最左匹配原则，也就是按照最左优先的方式进行索引的匹配，否则就会导致索引失效。
  - 在 WHERE 子句中，如果在 OR 前的条件列是索引列，而在 OR 后的条件列不是索引列，那么索引会失效。

- MySQL 默认的存储引擎 InnoDB 采用的是 B+ 作为索引的数据结构，原因有：

  - B+ 树的非叶子节点不存放实际的记录数据，仅存放索引，因此数据量相同的情况下，相比存储即存索引又存记录的 B 树，B+树的非叶子节点可以存放更多的索引，因此 B+ 树可以比 B 树更「矮胖」，查询底层节点的磁盘 I/O次数会更少。

  - B+ 树有大量的冗余节点（所有非叶子节点都是冗余索引），这些冗余索引让 B+ 树在插入、删除的效率都更高，比如删除根节点的时候，不会像 B 树那样会发生复杂的树的变化；

  - B+ 树叶子节点之间用链表连接了起来，有利于范围查询，而 B 树要实现范围查询，因此只能通过树的遍历来完成范围查询，这会涉及多个节点的磁盘 I/O 操作，范围查询效率不如 B+ 树。


- 有哪些手段可以优化数据库的 SQL 查询效率？
  - 对查询进行优化，应尽量避免全表扫描，首先应考虑在 where 及 order by 涉及的列上建立索引；
  - 应尽量避免在 where 子句中使用!=或<>操作符，否则将引擎放弃使用索引而进行全表扫描；
  - 应尽量避免在 where 子句中使用 or 来连接条件，否则将导致引擎放弃使用索引而进行全表扫描；
  - 使用左或者左右模糊匹配，也就是 `like %xx` 或者 `like %xx%`这两种方式都会造成索引失效；
  - 应尽量避免在 where 子句中对字段进行表达式操作或者函数操作，这将导致引擎放弃使用索引而进行全表扫描；

- 主键和唯一索引的区别

  - 主键是一种约束，而唯一索引是一种索引；

  - 主键一定会创建一个唯一索引，有唯一索引的列不一定为主键；
  - 主键不允许空值，唯一索引列允许空值；
  - 一个表只能有一个主键，但是可以有多个唯一索引；
  - 主键可以被其它表引用为外键，唯一索引列不可以；

- 事务的ACID特性：

  - 原子性（Atomicity）

    一个事务中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节，而且事务在执行过程中发生错误，会被回滚到事务开始前的状态，就像这个事务从来没有执行过一样；

  - 一致性（Consistency）

    数据库总是从一个一致性的状态转移到另一个一致性的状态。一致性确保了即使在执行第三、第四条语句之间时系统崩溃，前面执行的第一、第二条语句也不会生效，因为事务最终没有提交，所有事务中所作的修改也不会保存到数据库中。

  - 隔离性（Isolation）

    一个事务的执行不能其它事务干扰，一个事务内部的操作及使用的数据对其它并发事务是隔离的，并发执行的各个事务之间不能互相干扰。

  - 持久性（Durability）

    事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。


- InnoDB 引擎通过什么技术来保证事务的这四个特性的呢？

  - 原子性是通过 undo log（回滚日志） 来保证的；

  - 一致性则是通过持久性+原子性+隔离性来保证；

  - 隔离性是通过 MVCC（多版本并发控制） 或锁机制来保证的；
  - 持久性是通过 redo log （重做日志）来保证的；

- 并发事务引发的问题

  在同时处理多个事务的时候，就可能出现**脏读、不可重复读、幻读**的问题。

  - 脏读

    读到其他事务未提交的数据；

  - 不可重复读

    前后读取的数据不一致；

  - 幻读

    前后读取的记录数量不一致。

- 事务的隔离级别

  三种现象的严重性排序：脏读 > 不可重复读 > 幻读

  四种隔离级别：

  - 读未提交

    一个事务还没提交时，它做的变更就能被其他事务看到；

  - 读已提交

    一个事务提交之后，它做的变更才能被其他事务看到；

  - 可重复读

    一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，MySQL InnoDB 引擎的默认隔离级别；

  - 串行化

    会对记录加上读写锁，在多个事务对这条记录进行读写操作时，如果发生了读写冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行；

  隔离水平高低排序：串行化  > 可重复读 > 读已提交 > 读未提交，隔离级别越高，性能效率就越低。

  - 在「读未提交」隔离级别下，可能发生脏读、不可重复读和幻读现象；
  - 在「读已提交」隔离级别下，可能发生不可重复读和幻读现象，但是不可能发生脏读现象；
  - 在「可重复读」隔离级别下，可能发生幻读现象，但是不可能脏读和不可重复读现象；
  - 在「串行化」隔离级别下，脏读、不可重复读和幻读现象都不可能会发生。

  所以，要解决脏读现象，就要升级到「读提交」以上的隔离级别；要解决不可重复读现象，就要升级到「可重复读」的隔离级别，要解决幻读现象不建议将隔离级别升级到「串行化」。

  MySQL InnoDB 引擎的默认隔离级别虽然是「可重复读」，但是它很大程度上避免幻读现象，解决的方案有两种：

  - 针对快照读（普通 select 语句），是通过 MVCC 方式解决了幻读，因为可重复读隔离级别下，事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，即使中途有其他事务插入了一条数据，是查询不出来这条数据的，所以就很好了避免幻读问题；
  - 针对当前读（select ... for update 等语句），是通过 next-key lock（记录锁+间隙锁）方式解决了幻读，因为当执行 select ... for update 语句的时候，会加上 next-key lock，如果有其他事务在 next-key lock 锁范围内插入了一条记录，那么这个插入语句就会被阻塞，无法成功插入，所以就很好了避免幻读问题。

  对于「读提交」和「可重复读」隔离级别的事务来说，它们是通过 Read View 来实现的，它们的区别在于创建 Read View 的时机不同：

  - 「读提交」隔离级别是在每个 select 都会生成一个新的 Read View，也意味着，事务期间的多次读取同一条数据，前后两次读的数据可能会出现不一致，因为可能这期间另外一个事务修改了该记录，并提交了事务。
  - 「可重复读」隔离级别是启动事务时生成一个 Read View，然后整个事务期间都在用这个 Read View，这样就保证了在事务期间读到的数据都是事务启动前的记录。

  这两个隔离级别实现是通过「事务的 Read View 里的字段」和「记录中的两个隐藏列」的比对，来控制并发事务访问同一个记录时的行为，这就叫 MVCC（多版本并发控制）。

- 主键和唯一索引的区别

  - 主键是一种约束，而唯一索引是一种索引；

  - 主键一定会创建一个唯一索引，有唯一索引的列不一定为主键；
  - 主键不允许空值，唯一索引列允许空值；
  - 一个表只能有一个主键，但是可以有多个唯一索引；
  - 主键可以被其它表引用为外键，唯一索引列不可以；

- InnoDB 的普通索引和主键索引有什么区别

  Mysql各种索引区别：

  - 普通索引：最基本的索引，没有任何限制

  - 唯一索引：与"普通索引"类似，不同的就是：索引列的值必须唯一，但允许有空值。

  - 主键索引：它是一种特殊的唯一索引，一个表只能有一个主键，不允许有空值；索引列的值必须是唯一的。简单来说：主键索引是加速查询 + 列值唯一（不可以有null）+ 表中只有一个；

  - 全文索引：仅可用于 MyISAM 表，针对较大的数据，生成全文索引很耗时好空间。

  - 联合索引：为了更多的提高mysql效率可建立组合索引，遵循”最左前缀“原则。创建复合索引时应该将最常用（频率）作限制条件的列放在最左边，依次递减。

- MySQL用char和varchar什么区别？

  1. varchar比char更节省空间。

     varchar类型用于存储可变长度字符串，实际存储的空间=字符串内容+字符串长度，需要使用1或2个额外字节记录字符串的长度。char类型是固定长度的，一旦定义了字段类型char(10)，哪怕只是存了3个字符，那么也是用了10个字符长度的存储空间，其中7个为空字符/无效字符。

  2. char的性能比varchar要更好。

     char根据定义的字符串长度分配了足够的空间。varchar在更新长度时（比原来长度更长），有可能导致分裂页，导致出现碎片问题。根据存储结构的特性，也导致了更新数据时，char的性能比varchar要更好。

  3. 适合varchar的场景：

     - 字符串的最大长度比平均长度大很多；

     - 列的更新很少，所以碎片不是问题。

  4. 适合char的场景:

     - 存储很短的字符串或者所有值都接近同一个长度，例如md5、ip等信息。

     - 经常变更的数据，不容易产生碎片。

- MySQL数据库有哪两种引擎？它们之间有什么区别和联系

  MyISAM和InnoDB都是MySQL数据库的存储引擎，它们之间有以下区别：

  1. 事务支持：InnoDB支持事务处理，可以使用ACID（原子性、一致性、隔离性、持久性）来保证数据的完整性和一致性。而MyISAM不支持事务处理，不能保证数据的一致性。
  2. 锁机制：InnoDB采用行级锁定，只锁定需要修改的行，提高并发性能。而MyISAM采用表级锁定，会锁定整个表，如果多个用户同时访问一个表，就会出现互相等待的情况，降低并发性能。
  3. 外键约束：InnoDB支持外键约束，可以通过外键约束实现关联查询和级联删除等功能。而MyISAM不支持外键约束。
  4. 性能：MyISAM在读取数据方面的性能表现较好，在大量读取的情况下效率更高。而InnoDB在处理事务和大量并发查询的情况下性能更好。

  综上所述，如果需要支持事务处理、外键约束和高并发性能，建议使用InnoDB存储引擎。如果主要是用于大量读取数据的应用程序，建议使用MyISAM存储引擎。

- 联合索引有什么性质？

  联合索引是由多个列组成的索引，它具有以下性质：

  1. 联合索引可以加速多列条件查询。当查询语句中包含联合索引中的多个列时，数据库可以使用联合索引来快速定位符合条件的行，从而提高查询效率。

  2. 联合索引的顺序很重要。联合索引的顺序决定了索引的使用效果，因为数据库只能使用索引的最左边一部分来加速查询。因此，需要将最常用的列放在联合索引的最左边，以获得最佳的查询性能。

  3. 联合索引对单个列的查询效率可能不如单独的列索引。如果查询语句只包含联合索引中的一部分列，那么数据库可能无法使用联合索引来加速查询，这时单独为每个列建立索引可能更为有效。

  4. 联合索引的维护成本较高。由于联合索引包含多个列，因此它的维护成本较高。当表中的数据发生变化时，需要更新联合索引的所有列，这可能会导致索引的更新成本和存储空间成本增加。

  总的来说，联合索引可以加速多列条件查询，但是需要注意索引的顺序和维护成本，以获得最佳的查询性能。

- 可重复读和读已提交如何实现

  可重复读和读已提交是数据库中常用的两种事务隔离级别，它们的实现方式有所不同。

  1. 可重复读的实现方式：

  在可重复读隔离级别下，数据库需要为每个事务开启一个独立的视图，用于保存事务开始时读取的数据快照。当事务需要读取数据时，数据库会从该视图中读取数据，而不是从实际的数据表中读取。同时，数据库会对事务读取的数据进行加锁，以保证其他事务不能修改已经读取的数据。当事务结束时，数据库会将该视图和相关的锁释放。

  2. 读已提交的实现方式：

  在读已提交隔离级别下，数据库需要为每个事务开启一个独立的视图，用于保存事务开始时读取的数据快照。当事务需要读取数据时，数据库会从实际的数据表中读取最新的数据，而不是从事务自己的视图中读取。同时，数据库会对事务读取的数据进行加锁，以保证其他事务不能修改已经读取的数据。当事务提交时，数据库会将相关的锁释放。

  实现可重复读和读已提交的方式有很多种，具体的实现方式取决于数据库的具体实现。常见的实现方式包括基于锁的实现、基于多版本并发控制（MVCC）的实现、基于快照隔离的实现等。不同的实现方式各有优缺点，需要根据具体的业务场景和性能需求选择合适的实现方式。

- Innodb 的行锁是怎么实现的

  InnoDB是MySQL的一种存储引擎，其行锁是通过多版本并发控制（MVCC）实现的。MVCC是保证并发控制的一种机制，通过为每个事务分配一个唯一的事务ID，以及为每个数据行分配一个版本号来实现。

  以下是InnoDB的行锁实现过程：

  1. 当一个事务更新一行数据时，InnoDB会为该行数据创建一个新的版本，并将该版本的版本号与事务ID关联。同时，在该行数据的版本链表中记录该版本，并将该行数据的当前版本号更新为新版本号。

  2. 当另一个事务需要锁定该行数据时，InnoDB会查找该行数据的版本链表，并根据事务ID和版本号来判断是否可以进行锁定。如果该行数据的当前版本号与事务ID相关，则表示该事务已经锁定该行数据。否则，InnoDB会创建一个新的版本，并将该版本的版本号与事务ID相关联。

  3. 当一个事务提交时，InnoDB会将该事务所修改的行数据的版本号更新为当前版本号，并将该事务ID从该行数据的版本链表中删除。同时，InnoDB会清理已经提交的事务所创建的所有版本。

  需要注意的是，InnoDB的行锁是基于索引实现的。如果没有使用索引或使用了全表扫描，InnoDB将会使用表锁来保证并发控制。此时，多个事务需要争用同一个锁，可能会导致性能瓶颈。

  InnoDB的行锁实现过程是复杂的，但是可以提供高并发的支持，保证数据的一致性和可靠性。同时，需要注意事务的设计和隔离级别的选择，以避免死锁等并发控制问题。

- msyql 间隙锁：什么时候会产生间隙锁？

  MySQL的间隙锁（Gap Lock）是一种用于保护事务并发操作的锁机制。它的作用是锁定一个范围内的值，而不是具体的某个值，从而避免其他事务在同一范围内进行插入或更新操作。

  在MySQL中，间隙锁会在以下情况下产生：

  1. 当使用范围查询语句（例如WHERE col BETWEEN 1 AND 10）时，MySQL会为查询范围中的每个间隙（即两个相邻的值之间的空隙）产生一个间隙锁。这样，其他事务就无法在这些间隙中插入新的数据。

  2. 当使用锁定读（FOR UPDATE）或共享锁（LOCK IN SHARE MODE）时，MySQL会产生间隙锁来保护查询结果中的间隙。例如，如果一个事务使用FOR UPDATE查询了id列在1和10之间的数据，那么MySQL会为id=1和id=10之间的间隙产生一个间隙锁，防止其他事务在这个范围内进行插入或更新操作。

  需要注意的是，间隙锁只会在使用范围查询、锁定读或共享锁时产生，而不会在使用普通的等值查询时产生。此外，间隙锁只会在InnoDB存储引擎中产生，而不会在MyISAM等其他存储引擎中产生。

  在实际应用中，间隙锁可以有效地避免并发操作的冲突，但是也会增加锁的数量和粒度，可能会影响系统的性能。因此，在使用间隙锁时需要仔细考虑锁的范围和粒度，以提高系统的并发性能。

- next-key 锁？如何实现？

  Next-key锁是MySQL InnoDB存储引擎中的一种锁机制，它的作用是避免幻读问题。Next-key锁是InnoDB存储引擎中行锁和间隙锁的组合，通过同时锁定索引上的行和间隙来保证数据的一致性。

  Next-key锁的实现过程可以分为以下几个步骤：

  1. 当一个事务需要锁定一个索引上的行时，InnoDB会先锁定该行，然后锁定该行之前的间隙（如果存在）。这样，其他事务就无法在这个间隙中插入新的数据，从而保证了数据的一致性。

  2. 当一个事务需要锁定一个索引上的间隙时，InnoDB会先锁定该间隙，然后锁定该间隙后面的行（如果存在）。这样，其他事务就无法在这个行和间隙之间插入新的数据，从而保证了数据的一致性。

  需要注意的是，Next-key锁只会在使用范围查询、锁定读或共享锁时产生，而不会在使用普通的等值查询时产生。此外，Next-key锁只会在InnoDB存储引擎中产生，而不会在MyISAM等其他存储引擎中产生。

  在实际应用中，Next-key锁可以有效地避免幻读问题，提高系统的数据一致性。但是，Next-key锁也会增加锁的数量和粒度，可能会影响系统的性能。因此，在使用Next-key锁时需要仔细考虑锁的范围和粒度，以提高系统的并发性能。

- sql：表格中有人员 id与歌 id，找到被不同人听了两次以上的歌（每个人可能会听很多次）

  ```sql
  SELECT song_id
  FROM person_song
  GROUP BY song_id, person_id
  HAVING COUNT(DISTINCT person_id) >= 2
  ```


- 什么是聚类索引和非聚类索引

  在数据库中，索引是一种数据结构，用于加速数据查询操作。聚集索引和非聚集索引是两种不同类型的索引。

  1. 聚集索引（Clustered Index）：聚集索引是一种索引方式，它是按照索引的顺序来存储表中的数据。在聚集索引中，数据行的物理顺序与索引顺序相同。每个表只能有一个聚集索引，它通常是主键索引。聚集索引可以提高数据的查询性能，因为它可以减少磁盘 I/O 操作。

  2. 非聚集索引（Non-Clustered Index）：非聚集索引是一种索引方式，它是在独立的数据结构中存储索引和数据。在非聚集索引中，数据行的物理顺序与索引顺序不同。每个表可以有多个非聚集索引。非聚集索引可以提高数据的查询性能，因为它可以减少磁盘 I/O 操作。

  总之，聚集索引和非聚集索引都是数据库中常见的索引类型，它们在索引的存储方式和数据访问方式上有所不同。聚集索引按照索引顺序来存储表中的数据，而非聚集索引是在独立的数据结构中存储索引和数据。需要根据具体的数据访问需求来选择合适的索引类型。

- InooDB 为什么要使用聚类索引

  InnoDB使用聚集索引是因为它的数据存储方式导致了数据行的组织方式与MyISAM等其他存储引擎不同。InnoDB使用的是基于聚集索引的数据存储方式，因此每张表都必须有一个主键，主键将作为聚集索引来使用。

  聚集索引将表的数据按照主键的顺序存储在一起，因此它可以极大地提高主键的查询效率，尤其是范围查询和排序操作。在使用聚集索引的情况下，查询主键的效率可以与使用B+树一样高效，因为聚集索引的数据存储方式与B+树的数据存储方式类似。

  另外，InnoDB的表都是按照聚集索引的顺序存储的，因此如果需要根据其他索引进行查询，也需要通过聚集索引来访问表的数据。如果没有聚集索引，那么查询其他索引时需要进行两次磁盘IO操作，一次读取索引，一次读取数据，这样会导致查询效率变得非常低下。

  因此，InnoDB使用聚集索引来提高查询效率和性能，同时也保证了表的数据行的组织方式与其他存储引擎的不同，使得InnoDB能够支持更高的并发性和事务处理能力。

- 给出一个表 A 有 a1~a5 个列，联合索引（a2,a1），select a5 from A where a2=1 and a1=2。请问用到联合索引了吗？ 它的具体过程呢，怎么回的表？

  根据给出的联合索引（a2,a1），查询条件中包含了联合索引的前两个列a2和a1，因此可以使用联合索引来优化查询，查询过程如下：

  1. 首先，根据联合索引（a2,a1）查找a2=1和a1=2的数据行在索引中的位置。

  2. 然后，通过索引定位到数据行的位置后，可以直接获取该数据行中a5列的值。

  因此，使用了联合索引来定位数据行，查询效率会比较高。

  具体过程如下：

  1. 根据联合索引（a2,a1）查找a2=1和a1=2的数据行在索引中的位置。

  2. 找到索引中a2=1的第一个数据行，然后在该数据行的后面逐个查找，直到找到a2=1且a1=2的数据行。

  3. 找到a2=1且a1=2的数据行后，可以直接获取该数据行中a5列的值。

  注意，如果表A中的a2和a1列的组合存在多个相同的值，那么可能会有多个数据行满足查询条件a2=1和a1=2，此时需要逐个定位每个数据行，直到找到第一个满足条件的数据行为止。

- 为什么 Myisam 查询插入效率高

  MyISAM 存储引擎的查询和插入效率相对较高，主要原因如下：

  1. MyISAM 存储引擎采用的是表级锁定，对于插入操作来说，只需要锁定整个表，而不需要锁定具体的行，从而避免了锁的竞争和死锁的发生，提高了插入效率。

  2. MyISAM 存储引擎在插入数据时使用的是追加写入的方式，即将新的数据追加到数据文件的末尾。这种方式可以避免数据的移动和重组，从而减少了插入操作的时间和开销，提高了插入效率。

  3. MyISAM 存储引擎在查询操作时，采用的是全表扫描的方式，对于大量数据的查询效率相对较高。这种方式可以避免使用索引造成的额外开销，同时也可以利用磁盘预读技术，提高查询效率。

  需要注意的是，MyISAM 存储引擎虽然查询和插入效率相对较高，但是在并发访问和事务处理方面相对较弱。因此，在实际应用中，需要根据具体情况选择合适的存储引擎，同时也需要进行适当的优化和调整，以保证系统的稳定性和性能。

- 乐观锁和悲观锁、乐观锁实现方式

  乐观锁和悲观锁都是并发控制的方式，用于解决多个线程同时访问共享资源时可能出现的数据不一致问题。

  悲观锁是一种悲观的思想，它认为在并发环境下，每次访问共享资源时都会发生冲突，因此采用加锁的方式对资源进行保护，防止其他线程对资源的访问。常见的悲观锁实现方式包括数据库中的行级锁、表级锁等。

  乐观锁则是一种乐观的思想，它认为并发环境下，冲突不是每次都会发生，因此不采用加锁的方式，而是采用版本号等方式来进行控制。当多个线程同时访问同一个共享资源时，每个线程会先获取该资源的版本号等信息，然后进行操作。在操作完成后，如果该资源的版本号等信息发生了变化，则说明有其他线程对该资源进行了修改，此时需要重新操作，直到修改成功。

  乐观锁的实现方式有多种，常见的方式包括：

  1. 版本号控制：在数据库中添加版本号字段，每次更新时检查版本号是否一致，如果一致则进行更新，否则抛出异常或重新尝试。

  2. 时间戳控制：在数据库中添加时间戳字段，每次更新时检查时间戳是否一致，如果一致则进行更新，否则抛出异常或重新尝试。

  3. CAS（Compare and Swap）操作：CAS 是一种无锁算法，用于解决并发环境下的原子性问题。在进行更新操作时，先获取资源的当前值和版本号等信息，在本地进行修改，然后使用 CAS 操作将新值和版本号等信息写回到共享资源中。如果写回成功，则说明没有其他线程对该资源进行了修改，操作完成；否则需要重新获取最新的资源信息，重新进行操作。

  总的来说，乐观锁和悲观锁都有各自的优缺点和适用场景。在并发量较高、冲突较为频繁的情况下，悲观锁可能更适合；而在并发量较低、冲突较少的情况下，乐观锁可能更适合。



# 情景

- 写一个宏，表示求 a 和 b 的最小值

  可以使用以下宏定义来表示求 a 和 b 的最小值：

  ```c
  #define MIN(a, b) ((a) < (b) ? (a) : (b))
  ```

  这个宏定义接受两个参数 a 和 b，然后用三目运算符来比较它们的大小，并返回较小的值。需要注意的是，在比较 a 和 b 的大小时，要用括号将它们括起来，以避免在宏替换时产生错误。

  使用这个宏定义求 a 和 b 的最小值的示例代码如下：

  ```c
  #include <iostream>
  
  #define MIN(a, b) ((a) < (b) ? (a) : (b))
  
  int main() {
      int a = 10, b = 20;
      std::cout << "MIN(" << a << ", " << b << ") = " << MIN(a, b) << std::endl;
      return 0;
  }
  ```
  
  输出结果为：
  
  ```c
  MIN(10, 20) = 10
  ```
  
- 不用变量交换两个整型有什么方式

  有几种方式可以不用变量来交换两个整型的值，其中比较常见的方式包括：

  1. 算术运算法：利用加、减法运算来实现交换。具体来说，设有两个整型变量`a`和`b`，则可以使用如下的算术运算法交换它们的值：

  ```c
  a = a + b;
  b = a - b;
  a = a - b;
  ```
  
  上面的代码将`a`与`b`的值交换了。
  
  2. 异或运算法：利用异或运算来实现交换。具体来说，设有两个整型变量`a`和`b`，则可以使用如下的异或运算法交换它们的值：
  
  ```c
  a = a ^ b;
  b = a ^ b;
  a = a ^ b;
  ```
  
  上面的代码同样将`a`与`b`的值交换了。
  
  需要注意的是，这两种方法虽然可以在不使用中间变量的情况下交换两个整型变量的值，但是在某些特殊情况下可能会导致数据溢出或者其他问题，因此在实际应用中需要慎重考虑。另外，使用中间变量来交换两个值也是一种比较常见的、通用的方式，同时也更加安全可靠。
  


- 怎么用程序判断一个系统是大端字节序还是小端字节序

  - 大段字节序：数据的低位存储在高地址位，数据的高位存储在低地址位，大端字节序称为MSB；
  - 小段字节序：数据的低位存储在低地址位，数据的高位存储在高地址位，小端字节序称为LSB；

  ```c
  #include <stdio.h>
  
  int main()
  {
      int  a = 0x12345678;
      char *p = NULL;
      p = (char *)&a;
      if(*p == 0x78)
      {
          printf("小端字节序\n");
      }
      else if(*p == 0x12)
      {
           printf("大端字节序\n");
      }
      printf("%x\n",*p);   
      return 0;
  }
  ```

  指针将会指向整型数的首地址，而当我们调用 *p 往地址里取值时，系统会根据指针的类型的大小取对应大小的值。

  例如，char类型的指针就会从他指向的地址往后取char类型（1个字节）大小的值。所以，当我们使用char类型的指针指向一个int类型的数，再通过 *p 取值时，只会去取其低地址位的1个字节的内容。

  如果结果是 *p = 0x78，说明在地址中，低地址位存储了该数据的低位，就可以判断系统是小端字节序；如果 *p = 0x12，则说明低地址位存储了数据的高位，可判断系统是大端字节序。

- 如何实现一个守护进程

  实现一个守护进程的一般步骤如下：

  1. 在父进程中调用fork()函数，然后在子进程中调用setsid()函数，创建新的会话，并使子进程成为会话组长和进程组长。

  2. 在子进程中再次调用fork()函数，然后在子进程中退出，使子进程不再是进程组长，从而保证它不能获取控制终端。

  3. 在子进程中修改当前目录为根目录，以避免守护进程的工作目录被卸载的文件系统影响。

  4. 在子进程中关闭所有不需要的文件描述符，以避免守护进程对终端、网络等资源的依赖。

  5. 在子进程中执行守护进程的核心逻辑，例如读取配置文件、初始化资源等。

  6. 在守护进程的核心逻辑执行完毕后，调用exit()函数退出子进程。

  示例代码如下：

  ```c
  #include <unistd.h>
  #include <stdlib.h>
  #include <stdio.h>
  #include <sys/stat.h>
  #include <fcntl.h>
  #include <string.h>
  
  int main() {
      pid_t pid = fork();
      if (pid < 0) {
          perror("fork error");
          exit(1);
      } else if (pid > 0) {
          exit(0);
      }
  
      // 子进程
      setsid(); // 创建新的会话
  
      pid = fork();
      if (pid < 0) {
          perror("fork error");
          exit(1);
      } else if (pid > 0) {
          exit(0);
      }
  
      // 子进程
      chdir("/"); // 修改当前目录为根目录
      umask(0); // 设置文件权限掩码为0
  
      int maxfd = getdtablesize(); // 获取文件描述符的最大数量
      for (int i = 0; i < maxfd; i++) {
          close(i); // 关闭所有不需要的文件描述符
      }
  
      // 执行守护进程的核心逻辑
      while (1) {
          // TODO: 守护进程的核心逻辑
      }
  
      exit(0);
  }
  ```

  在上面的代码中，首先调用fork()函数创建子进程，然后在子进程中调用setsid()函数创建新的会话，并使子进程成为会话组长和进程组长。接着再次调用fork()函数，然后在子进程中退出，使子进程不再是进程组长，从而保证它不能获取控制终端。然后修改当前目录为根目录，设置文件权限掩码为0，关闭所有不需要的文件描述符，最后执行守护进程的核心逻辑。

- 如何实现memcpy内存拷贝函数

  下面是一种实现void *memcpy(void *dest, const void *src, size_t num)内存拷贝函数的方法：

  ```c
  #include <iostream>
  using namespace std;
  
  void *memcpy(void *dest, const void *src, size_t n) {
      char *d = (char *)dest;
      const char *s = (const char *)src;
      for(size_t i = 0; i < n; i++){
          *d++ = *s++;
      }
      return dest;
  }
  
  int main() {
      char src[] = "Hello, world!";
      char dest[20];
      memcpy(dest, src, sizeof(src));
      cout << "Source string: " << src << endl;
      cout << "Destination string: " << dest << endl;
      return 0;
  }
  
  ```

  解释：首先将目标地址和源地址强制转换成char类型的指针，然后使用while循环逐个字节地拷贝源地址的内容到目标地址中，直到拷贝的字节数为0为止。最后返回目标地址的指针即可。

  需要注意的是，这里的指针类型为void *，表示不具体指向某种类型的指针，因此在使用时需要根据实际情况进行强制类型转换。此外，为了避免内存访问越界的问题，还需要对拷贝的字节数进行判断和限制。

- 如何实现memmove内存拷贝函数

  下面是一种实现void *memmove(void *dest, const void *src, size_t count)内存移动函数的方法：

  ```c
  #include <iostream>
  using namespace std;
  
  void *memmove(void *dest, const void *src, size_t n){
      char *d = (char *)dest;
      const char *s = (const char *)src;
      if (d < s){
          for(size_t i = 0; i < n; i++){
              *d++ = *s++;
          }
      }else{
          char *lasts = (char *)s + (n - 1);
          char *lastd = d + (n - 1);
          for(size_t i = 0; i < n; i++){
              *lastd-- = *lasts--;
          }
      }
      return dest;
  }
  
  int main(){
      char s[] = "Hello, world!";
      cout << "Before: " << s << endl;
      memmove(s + 2, s, 7);
      cout << "After: " << s << endl;
      return 0;
  }
  ```

  解释：首先将目标地址和源地址强制转换成char类型的指针，然后根据目标地址和源地址的位置关系分为两种情况。如果目标地址在源地址的前面，就可以直接从前往后逐个字节地拷贝源地址的内容到目标地址中；如果目标地址在源地址的后面，就需要从后往前逐个字节地拷贝源地址的内容到目标地址中，以避免内存重叠的问题。为了避免内存访问越界的问题，还需要对移动的字节数进行判断和限制。

  需要注意的是，这里的指针类型为void *，表示不具体指向某种类型的指针，因此在使用时需要根据实际情况进行强制类型转换。

- 从 20 亿数据中挑选 top10000 数据，怎么处理

  处理大规模数据的情况下，可以使用外部排序（External Sorting）来解决这个问题。外部排序是一种在磁盘上对大文件进行排序的算法，可以有效地处理大规模数据。

  具体的处理方法如下：

  1. 将 20 亿的数据分为多个小文件。每个文件中的数据可以使用快速排序等算法进行排序。

  2. 对于每个小文件，选取其中的 top10000 数据，并将这些数据保存到一个新的文件中。

  3. 将所有新的文件合并成一个大文件，并进行排序。可以使用归并排序等算法进行排序。

  4. 从排序后的文件中选取前 10000 条数据，即为 top10000 数据。

  需要注意的是，对于第一步中的分割大小，需要根据磁盘空间和处理能力进行选择。如果分割得太小，可能会导致文件过多，而分割得太大，可能会导致内存不足。因此，在实际操作中需要根据具体情况进行调整。

  另外，由于本题只需要求 top10000 数据，因此可以在第二步中使用堆排序等算法来找到 top10000 数据，从而避免第三步中的排序操作。

- 一亿个数找最大的一万个

  对于一亿个数找最大的一万个，可以使用堆排序算法来实现。具体步骤如下：

  1. 从数据源中读取一亿个数，并存储在一个数组或向量中。

  2. 创建一个大小为一万的最小堆，用于存储当前找到的最大的一万个数。可以使用 STL 中的 priority_queue 或手动实现堆数据结构。

  3. 依次遍历数组中的每个数，将其与堆顶元素进行比较。如果当前数比堆顶元素大，则将其插入堆中，并将堆顶元素弹出；否则继续遍历下一个数。

  4. 遍历结束后，堆中存储的即为最大的一万个数。

  需要注意的是，对于一亿个数的排序，可能会占用大量的内存和 CPU 资源，因此需要根据实际情况进行优化和调整。可以考虑使用分治法等高效算法来实现排序，或者对数据进行分块处理，每次处理一部分数据，降低排序的开销。

  另外，如果数据源不是文件而是数据库，可以考虑使用数据库的排序功能来实现。可以根据具体情况使用 SQL 语句或者调用数据库的 API 来实现排序操作。

  综上所述，使用堆排序算法可以实现一亿个数找最大的一万个。需要根据具体情况进行优化和调整，同时也需要注意对数据的质量和安全进行保证。


- 将阿拉伯数字转换成中文，如输入 110010，输出 十一万零一十，cpp实现

  ```c
  #include <iostream>
  #include <string>
  using namespace std;
  
  // 中文数字及单位的字符串数组
  string digit[] = {"零", "一", "二", "三", "四", "五", "六", "七", "八", "九"};
  string unit[] = {"", "十", "百", "千", "万"};
  
  // 将整数转换成中文数字的函数
  string convert(int n) {
      string s = "";
      int i = 0;
      while (n > 0) {
          int r = n % 10; // 取出最后一位数字
          if (r != 0 || i % 4 == 0) { // 如果数字不为0，或者位数是万位，则需要加上对应的单位
              s = digit[r] + unit[i % 4] + s; // 拼接中文数字和单位
          }
          if (i % 4 == 0 && n % 10000 != 0) { // 如果位数是万位，并且后四位数字不全为0，则需要加上万的单位
              s = unit[4] + s;
          }
          n /= 10; // 去掉最后一位数字
          i++; // 位数加1
      }
      if (s[0] == '一' && s.length() > 1) { // 处理一十的情况
          s = s.substr(1);
      }
      return s;
  }
  
  int main() {
      int n = 110010;
      cout << convert(n) << endl; // 输出：十一万零一十
      return 0;
  }
  ```

  在convert函数中，我们用while循环不断取出n的最后一位数字r，然后判断r是否为0或者当前位数是否为万位，如果是，则需要将中文数字和单位拼接在一起。例如，对于数字110010，当i=0时，r=0，因此不需要拼接任何数字和单位；当i=1时，r=1，需要拼接“一十”；当i=2时，r=0，不需要拼接任何数字和单位；当i=3时，r=0，不需要拼接任何数字和单位；当i=4时，r=1，需要拼接“一万”。

  当i是4的倍数（即万位）并且后四位数字不全为0时，需要加上万的单位。例如，对于数字111110，当i=0时，r=0，不需要拼接任何数字和单位；当i=1时，r=1，需要拼接“一十”；当i=2时，r=1，需要拼接“一百”；当i=3时，r=1，需要拼接“一千”；当i=4时，r=1，需要拼接“一万”。

  最后，我们需要处理一些特殊情况，如去掉“一十”的“一”。

- 两个线程交替输出a、b

  可以使用 C++11 中的 `std::thread` 和 `std::mutex` 来实现两个线程交替输出 `a` 和 `b`。具体实现如下：

  ```c
  #include <iostream>
  #include <thread>
  #include <mutex>
  using namespace std;
  
  // 创建一个互斥量，用于保护共享资源
  mutex mtx;
  
  // 定义一个变量，表示当前到哪个线程输出
  int turn = 0;
  
  // 线程 A 的函数，负责输出 a
  void printA() {
      for (int i = 0; i < 5; i++) {
          // 加锁，保护共享资源
          mtx.lock();
  
          // 如果当前不是线程 A 的轮次，就让出 CPU 时间片
          while (turn != 0) {
              mtx.unlock(); // 先解锁，让其他线程有机会获取锁
              this_thread::yield(); // 让出 CPU 时间片
              mtx.lock(); // 再加锁
          }
  
          // 输出 a
          cout << "a";
  
          // 把轮次设置为线程 B
          turn = 1;
  
          // 解锁，让其他线程有机会获取锁
          mtx.unlock();
      }
  }
  
  // 线程 B 的函数，负责输出 b
  void printB() {
      for (int i = 0; i < 5; i++) {
          // 加锁，保护共享资源
          mtx.lock();
  
          // 如果当前不是线程 B 的轮次，就让出 CPU 时间片
          while (turn != 1) {
              mtx.unlock(); // 先解锁，让其他线程有机会获取锁
              this_thread::yield(); // 让出 CPU 时间片
              mtx.lock(); // 再加锁
          }
  
          // 输出 b
          cout << "b";
  
          // 把轮次设置为线程 A
          turn = 0;
  
          // 解锁，让其他线程有机会获取锁
          mtx.unlock();
      }
  }
  
  // 主函数
  int main() {
      // 创建两个线程，分别执行 printA 和 printB 函数
      thread t1(printA);
      thread t2(printB);
  
      // 等待两个线程执行完毕
      t1.join();
      t2.join();
  
      // 输出换行符，让输出结果更清晰
      cout << endl;
  
      // 返回 0，表示程序正常结束
      return 0;
  
  ```

  在上述代码中，`print_a` 和 `print_b` 分别用于输出 `a` 和 `b`，采用互斥锁和标志位的方式实现两个线程交替输出。其中，`std::unique_lock<std::mutex>` 用于获取互斥锁，`while` 循环用于等待标志位的变化，`std::this_thread::yield()` 用于释放 CPU 资源，避免空转浪费资源。

  需要注意的是，在多线程编程中，需要注意线程安全和竞态条件等问题，避免出现死锁、饥饿等问题。

- 为了加速磁盘的存取速度，一般会使用缓存，缓存要使用什么数据结构才能保证效率最高，LRU如何实现

  为了加速磁盘的存取速度，一般会使用缓存，而缓存一般使用哈希表和双向链表结合的数据结构来实现LRU缓存淘汰算法，保证效率最高。

  具体来说，哈希表用来存储缓存的键值对，可以快速地进行查询和修改操作。而双向链表则用来维护缓存中数据的访问顺序，最近访问过的数据放在链表头部，最久未访问数据放在链表尾部。当缓存空间不足时，就将链表尾部的元素淘汰掉。

  LRU算法的实现过程如下：

  1. 当有新数据访问时，如果这个数据已经在缓存中，则将它从原来的位置删除，并移到链表头部，表示最近访问过。
  2. 如果这个数据不在缓存中，且缓存未满，则将它添加到链表头部，并更新哈希表中的键值对。
  3. 如果这个数据不在缓存中，且缓存已满，则将链表尾部的元素淘汰掉，并将新数据添加到链表头部，并更新哈希表中的键值对。

  整个过程需要在O(1)的时间内完成，因此需要使用哈希表和双向链表结合的数据结构来实现LRU缓存淘汰算法，从而保证缓存的效率最高。
  
  下面是一个使用C++实现LRU缓存淘汰算法的示例：
  
  ```c
  #include <iostream>
  #include <unordered_map>  // 哈希表头文件
  #include <list>  // 双向链表头文件
  using namespace std;
  
  class LRUCache {
  public:
      LRUCache(int capacity) {  // 构造函数，初始化缓存容量
          this->capacity = capacity;
      }
      
      int get(int key) {  // 获取键值对的值
          auto it = cache.find(key);  // 在哈希表中查找键
          if (it == cache.end()) return -1;  // 如果键不存在，返回-1
          pair<int, int> kv = *it->second;  // 获取键值对
          cache_list.erase(it->second);  // 将键值对从链表中移除
          cache_list.push_front(kv);  // 将键值对移到链表头部
          cache[key] = cache_list.begin();  // 更新哈希表中键对应的迭代器
          return kv.second;  // 返回键值对的值
      }
      
      void put(int key, int value) {  // 添加键值对
          auto it = cache.find(key);  // 在哈希表中查找键
          if (it != cache.end()) {  // 如果键已经存在
              cache_list.erase(it->second);  // 将键值对从链表中移除
          } else {  // 如果键不存在
              if (cache.size() == capacity) {  // 如果缓存已满
                  int key_to_del = cache_list.back().first;  // 获取最近最少使用的键
                  cache_list.pop_back();  // 将最近最少使用的键值对从链表中移除
                  cache.erase(key_to_del);  // 将最近最少使用的键值对从哈希表中移除
              }
          }
          cache_list.push_front({key, value});  // 将键值对添加到链表头部
          cache[key] = cache_list.begin();  // 将键值对的迭代器添加到哈希表中
      }
  
  private:
      int capacity;  // 缓存容量
      list<pair<int, int>> cache_list;  // 双向链表，存储键值对
      unordered_map<int, list<pair<int, int>>::iterator> cache;  // 哈希表，存储键值对的迭代器
  };
  
  int main() {
      LRUCache cache(2);  // 创建LRU缓存，容量为2
      cache.put(1, 1);  // 缓存中添加键1，值1
      cache.put(2, 2);  // 缓存中添加键2，值2
      cout << cache.get(1) << endl;  // 从缓存中获取键1的值，输出1
      cache.put(3, 3);  // 缓存中添加键3，值3，此时缓存已满，键2被淘汰
      cout << cache.get(2) << endl;  // 从缓存中获取键2的值，输出-1
      cache.put(4, 4);  // 缓存中添加键4，值4，此时缓存已满，键1被淘汰
      cout << cache.get(1) << endl;  // 从缓存中获取键1的值，输出-1
      cout << cache.get(3) << endl;  // 从缓存中获取键3的值，输出3
      cout << cache.get(4) << endl;  // 从缓存中获取键4的值，输出4
      // 输出为：1 -1 -1 3 4     ^_^
      return 0;
  }
  
  ```
  
  以上代码实现了LRU缓存淘汰算法，使用了双向链表和哈希表结合的方法，可以方便地对键值对进行添加、删除和查找操作。通过使用STL的list、unordered_map和iostream库，代码更加简洁和易读。

- cpp实现线程池

```c
#include <iostream>
#include <thread>
#include <queue>
#include <mutex>
#include <condition_variable>

class ThreadPool {
public:
    using Task = std::function<void()>;

    // 线程池构造函数，创建指定数量的线程
    explicit ThreadPool(size_t threadCount): stop(false) {
        for (size_t i = 0; i < threadCount; ++i) {
            // 向线程池中添加线程
            workers.emplace_back(
                [this] {
                    while (true) {
                        Task task;
                        {
                            // 互斥锁保护任务队列
                            std::unique_lock<std::mutex> lock(this->queueMutex);
                            // 等待条件变量，直到有任务或线程池停止
                            this->condition.wait(lock,
                                [this] { return this->stop || !this->tasks.empty(); });
                            // 如果线程池已经停止并且任务队列为空，则退出线程
                            if (this->stop && this->tasks.empty()) {
                                return;
                            }
                            // 取出任务队列中的任务
                            task = std::move(this->tasks.front());
                            this->tasks.pop();
                        }
                        // 执行任务
                        task();
                    }
                }
            );
        }
    }

    // 禁止线程池的拷贝和赋值操作
    ThreadPool() = default;
    ThreadPool(ThreadPool&&) = default;
    ThreadPool& operator=(ThreadPool&&) = default;

    // 线程池析构函数，停止线程池并等待所有线程退出
    ~ThreadPool() {
        {
            // 互斥锁保护线程池停止标记
            std::unique_lock<std::mutex> lock(queueMutex);
            stop = true;
        }
        // 通知所有线程退出
        condition.notify_all();
        // 等待所有线程退出
        for (std::thread& worker : workers) {
            worker.join();
        }
    }

    // 向任务队列中添加任务
    template<class FunctionType>
    void execute(FunctionType&& f) {
        tasks.emplace(std::forward<FunctionType>(f));
        // 通知一个等待的线程
        condition.notify_one();
    }

private:
    std::vector<std::thread> workers; // 线程池中的线程
    std::queue<Task> tasks; // 任务队列

    std::mutex queueMutex; // 互斥锁
    std::condition_variable condition; // 条件变量

    bool stop; // 线程池停止标记
};

// 示例任务
void printNum(int num) {
    std::cout << "Num: " << num << std::endl;
    std::this_thread::sleep_for(std::chrono::milliseconds(100));
}

int main() {
    ThreadPool pool(4); // 创建一个线程池，包含4个线程
    for (int i = 0; i < 8; ++i) {
        pool.execute([i] { printNum(i); }); // 将8个任务添加到任务队列中
    }
    return 0;
}
```

这个线程池实现了指定线程数的构造函数，执行任务的execute()函数，以及停止线程池的析构函数。任务以std::function<void()>类型的函数对象的形式添加到任务队列中，由线程池中的线程执行。可以看到，使用C++标准库的互斥锁和条件变量可以非常方便地实现线程池的基本功能。

- 两个线程按序打印数组，一个线程只打印奇数，一个线程只打印偶数

以下是一个示例的 C++ 程序，实现了两个线程按序打印数组，一个线程只打印奇数，一个线程只打印偶数：

```c
#include <iostream>
#include <thread>

const int N = 10;

// 数组
int arr[N] = {1, 2, 3, 4, 5, 6, 7, 8, 9, 10};

// 互斥锁
std::mutex mtx;

// 条件变量
std::condition_variable cv;

// 奇数线程函数
void print_odd() {
    for (int i = 0; i < N; i += 2) {
        std::unique_lock<std::mutex> lock(mtx); // 获取互斥锁
        while (arr[i] % 2 == 0) { // 若该元素是偶数，则等待条件变量
            cv.wait(lock);
        }
        std::cout << arr[i] << std::endl; // 打印该元素
        cv.notify_all(); // 唤醒其他线程
    }
}

// 偶数线程函数
void print_even() {
    for (int i = 1; i < N; i += 2) {
        std::unique_lock<std::mutex> lock(mtx); // 获取互斥锁
        while (arr[i] % 2 == 1) { // 若该元素是奇数，则等待条件变量
            cv.wait(lock);
        }
        std::cout << arr[i] << std::endl; // 打印该元素
        cv.notify_all(); // 唤醒其他线程
    }
}

// 主函数
int main() {
    std::thread t1(print_odd); // 创建奇数线程
    std::thread t2(print_even); // 创建偶数线程
    t1.join(); // 等待奇数线程结束
    t2.join(); // 等待偶数线程结束
    return 0;
}
```

说明：

1. `arr` 数组是待打印的数组。

2. `std::mutex` 类型的 `mtx` 对象是用于实现互斥访问的互斥锁。

3. `std::condition_variable` 类型的 `cv` 对象是用于线程间的条件变量通信的条件变量。

4. `print_odd()` 函数是奇数线程的函数，通过循环遍历数组，对于每个奇数元素，先获取互斥锁，若该元素是偶数，则等待条件变量，直到该元素是奇数为止，然后打印该元素，唤醒其他线程，释放互斥锁。

5. `print_even()` 函数是偶数线程的函数，通过循环遍历数组，对于每个偶数元素，先获取互斥锁，若该元素是奇数，则等待条件变量，直到该元素是偶数为止，然后打印该元素，唤醒其他线程，释放互斥锁。

6. 主函数中开启两个线程分别执行 `print_odd()` 和 `print_even()` 函数，并等待两个线程结束。

- 
