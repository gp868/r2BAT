
# OS

- 为什么要区分内核态和用户态？

  区分内核态和用户态是为了保证操作系统的稳定性和安全性。

  在内核态下，操作系统可以直接访问硬件资源，执行特权指令，进行系统管理和维护任务，如进程调度、内存管理、设备驱动等。而在用户态下，应用程序只能通过系统调用接口向操作系统发起请求，操作系统会在内核态下完成相应的任务并返回结果给应用程序。

  通过区分内核态和用户态，可以有效地隔离应用程序和操作系统，防止应用程序的错误或恶意行为对操作系统的稳定性和安全性产生影响。同时，也可以提高操作系统的性能和效率，因为内核态下的操作系统可以直接访问硬件资源，而不需要经过系统调用的开销和限制。

* 内核态和用户态的区别
  1. 权限不同：内核态具有更高的权限，可以访问系统的所有资源，而用户态只能访问受限的资源。

  2. 运行环境不同：内核态运行在操作系统内部，用户态运行在操作系统外部。

  3. 调用方式不同：内核态通过系统调用方式调用操作系统提供的服务，而用户态通过库函数调用操作系统提供的服务。

  4. 响应速度不同：内核态响应速度更快，因为它可以直接访问硬件资源，而用户态需要通过操作系统提供的接口访问硬件资源。

  5. 安全性不同：内核态具有更高的安全性，因为它可以保护系统资源不被用户态非法访问。

  6. 内存管理不同：内核态可以直接访问所有内存，而用户态只能访问自己的内存空间。

  7. 中断处理不同：内核态可以处理所有中断，而用户态只能处理非关键性中断。

- 导致从用户态切换到内核态的操作

  - 系统调用

    很多程序开始时运行于用户态，但在执行的过程中，一些操作需要在内核权限下才能执行，这就涉及到一个从**用户态切换到内核态**的过程。比如C函数库中的内存分配函数 malloc()，它具体是使用 sbrk() 系统调用来分配内存，当malloc() 调用 sbrk() 的时候就涉及一次从用户态到内核态的切换，类似的函数还有 printf()，调用的是 wirte() 系统调用来输出字符串，等等。
  
  
    - 异常事件
      
        当 CPU 正在执行运行在用户态的程序时，突然发生某些预先不可知的异常事件，就会触发从当前用户态执行的进程转向内核态执行相关的异常事件，典型的如缺页异常。
  
  
    - 外围设备中断
      
        当外围设备完成用户的请求操作后，会向 CPU 发出中断信号，此时，CPU 就会暂停执行下一条即将要执行的指令，转而去执行中断信号对应的处理程序，如果先前执行的指令是在用户态下，则自然就发生从用户态到内核态的转换。
  


- 用户态的应用程序可以通过三种方式来访问内核态的资源：

  - 系统调用

  - 库函数

  - Shell 脚本


- 中断实现的原理

  中断是一种计算机硬件和软件协同工作的机制，它允许处理器在执行程序时，暂停当前任务，转而去处理其他任务，然后在完成这些任务后，再回到原来的任务继续执行。

  中断的实现原理主要包括以下几个方面：

  1. 中断请求的产生：中断请求可以来自于硬件设备，如键盘、鼠标、磁盘等，也可以来自于软件，如操作系统的系统调用、异常处理等。

  2. 中断向量表的建立：中断向量表是一个存储中断处理程序入口地址的数据结构，每个中断请求都有一个唯一的中断向量号，当中断请求产生时，处理器会根据中断向量号在中断向量表中查找对应的中断处理程序入口地址。

  3. 中断处理程序的执行：当处理器接收到中断请求后，会暂停当前任务，保存现场信息（如程序计数器、寄存器等）并跳转到中断向量表中对应的中断处理程序入口地址，执行中断处理程序。

  4. 中断处理程序的返回：中断处理程序执行完后，会恢复现场信息并返回到原来的任务继续执行。

  总之，中断机制的实现离不开中断请求的产生、中断向量表的建立、中断处理程序的执行和返回等关键步骤，这些步骤的协同工作使得处理器能够在多任务环境下有效地处理各种中断请求。

- 系统中断、中断向量、中断向量表

  - 系统中断是指由硬件或软件触发的一种机制，用于打断正在执行的程序，以便处理特定的事件或请求；
  - 中断向量是一个指向中断处理程序的地址，它由中断控制器提供，并用于确定应该执行哪个中断处理程序；
  - 中断向量表是一个包含所有中断向量的表格，通常存储在内存中，并由操作系统维护。当一个中断被触发时，处理器会查询中断向量表，找到相应的中断向量，并跳转到相应的中断处理程序中去执行。

- 软中断和硬中断区别

  软中断和硬中断是计算机系统中的两种中断类型，它们的区别在于中断的来源和处理方式。

  - 软中断

    软中断是由操作系统内核自身产生的中断，它们不是由硬件设备触发的。软中断通常用于处理计时器、网络数据包、文件系统等事件。软中断是通过调用操作系统内核中的函数来触发的，因此也被称为系统调用。

  - 硬中断

    硬中断是由硬件设备触发的中断，例如键盘、鼠标、网络卡等。硬中断通常由硬件设备发送一个中断请求信号（IRQ）给操作系统内核，内核会暂停正在执行的任务来处理这个中断请求。硬中断的处理需要较高的优先级，因为它们需要及时响应硬件设备的请求。

  软中断和硬中断是两种不同的中断类型，软中断是由操作系统内核自身产生的中断，硬中断是由硬件设备触发的中断。软中断通常用于处理计时器、网络数据包、文件系统等事件，而硬中断通常由键盘、鼠标、网络卡等设备触发。

- 异常和中断的区别

  异常和中断都是计算机系统中的两种不同的事件处理方式，它们的区别如下：

  1. 异常：是指在程序执行过程中由于出现了非法操作或者错误的数据等原因导致程序无法继续执行的情况。异常通常是由程序本身引起的，例如除零、空指针引用等。

  2. 中断：是指由外部设备或者程序发出的一种请求，要求处理器暂停当前的任务，转而去处理该请求。中断通常是由外部设备引起的，例如键盘输入、定时器等。

  因此，异常和中断的主要区别在于它们的来源不同，异常是由程序本身引起的，而中断是由外部设备引起的。另外，异常通常是在程序执行过程中发生的，而中断则可以在任何时候发生。

- 系统调用和中断的区别

  系统调用是一种机制，它允许用户程序请求内核执行某些特权操作，如文件读写、进程管理等。用户程序通过调用特定的系统调用接口来发起请求，内核根据请求参数执行相应的操作，并返回结果给用户程序。

  中断是一种事件，它可以被硬件或软件触发，用于打断当前程序的执行，转而执行中断处理程序。中断可以被用于处理硬件故障、时钟中断、网络数据包到达等事件。当中断发生时，CPU会保存当前程序的状态，然后跳转到中断处理程序执行相应的操作，处理完后再返回原程序继续执行。

  因此，系统调用和中断的区别在于：

  1. 作用不同：系统调用是用户程序请求内核执行特权操作的机制，而中断是打断当前程序执行的事件。

  2. 触发方式不同：系统调用是由用户程序主动发起的，而中断是由硬件或软件触发的。

  3. 实现方式不同：系统调用是用户态程序切换到内核态执行的过程，需要进行上下文切换和特权级切换；而中断是在当前程序执行过程中被打断，操作系统会保存当前程序的上下文并处理中断，然后再恢复被打断的程序继续执行。

  4. 返回方式不同：系统调用返回时，操作系统会将结果返回给用户程序；而中断处理完成后，控制权会返回到被打断的程序继续执行。

  总的来说，系统调用和中断都是操作系统中的重要机制，它们各自有着不同的作用和实现方式，但都为操作系统提供了强大的功能和灵活性。

- 系统调用和函数调用的区别

  系统调用和函数调用的区别如下：

  1. 调用方式不同：系统调用是通过操作系统提供的接口进行调用的，而函数调用是在程序内部进行调用的。

  2. 执行环境不同：系统调用是在内核态下执行的，而函数调用是在用户态下执行的。

  3. 功能不同：系统调用是提供给用户程序使用操作系统资源的接口，比如读写文件、创建进程等操作；而函数调用是程序内部实现某一特定功能的代码块。

  4. 开销不同：系统调用需要进行上下文切换，从用户态切换到内核态，需要进行堆栈切换等操作，开销比较大；而函数调用只需要进行简单的函数调用和返回操作，开销比较小。

  5. 安全性不同：系统调用会检查用户程序的权限，确保用户程序不能越权操作系统资源，保证系统的安全性；而函数调用不会进行权限检查，用户程序可以自由地调用函数，可能会对系统造成安全威胁。

  综上所述，系统调用和函数调用虽然都是程序中的调用方式，但是其执行环境、功能、开销、安全性等方面都有很大的区别。

- 系统调用进入内核态的过程

  当应用程序需要执行一些需要特权级别的操作时，比如读写文件、网络通信、内存管理等，就需要通过系统调用进入内核态。系统调用是用户程序与操作系统之间进行通信的接口，它可以让用户程序请求操作系统执行某些任务。

  以下是系统调用进入内核态的过程：

  1. 用户程序执行系统调用指令，将控制权转移到内核态。

  2. CPU从用户态切换到内核态，将程序计数器(PC)和堆栈指针(SP)压入内核栈中，保存用户程序的现场。

  3. 内核态的操作系统检查系统调用参数，验证权限，执行相应的操作。

  4. 操作系统将结果返回给用户程序，将控制权转移回用户态。

  5. CPU从内核态切换回用户态，将程序计数器(PC)和堆栈指针(SP)恢复，继续执行用户程序。

  需要注意的是，系统调用的执行过程中会涉及到内核态和用户态之间的切换，这个过程需要花费一定的时间和资源，因此在编写程序时应尽量减少系统调用的次数，提高程序的效率。

- 内存映射工作机制，内存映射和共享内存区别？

  内存映射是一种将文件或设备映射到进程地址空间的机制。它允许进程像访问内存一样访问文件或设备，从而避免了繁琐的文件或设备I/O操作。内存映射是通过调用mmap()系统调用来实现的，它将文件或设备的数据映射到进程的虚拟地址空间中。内存映射工作机制如下：

  1. 调用mmap函数，将文件映射到进程的地址空间中。

  2. 操作系统将文件的内容读入内存中，并建立一个虚拟内存区域。

  3. 进程可以通过指针来访问这个虚拟内存区域，就像访问内存一样。

  4. 当进程对这个虚拟内存区域进行读写操作时，操作系统会自动将数据写回到文件中。

  内存映射和共享内存的区别在于，内存映射是将文件或设备映射到进程的地址空间中，而共享内存是将一块内存映射到多个进程的地址空间中，使得多个进程可以共享同一块内存。共享内存通常用于进程间通信，而内存映射则更多地用于文件和设备访问。

- 共享内存存在于进程地址空间中哪个部分？未初始化数据段怎么存入数据？共享内存区增长方向？一般存啥？

  共享内存存在于进程地址空间中的堆区或者数据段中。未初始化数据段存入数据时，操作系统会在该段内存中分配一块空间，并将其清零。共享内存区的增长方向通常是向上增长，即地址值越来越大。一般来说，共享内存区存储的是需要在多个进程之间共享的数据，比如进程间通信的消息队列、共享缓存等。

- TLB 是干嘛的？TLB 和磁盘缓存是一样的吗？

  TLB（Translation Lookaside Buffer）是一种硬件缓存，用于加速虚拟地址到物理地址的转换过程。TLB存储了最近使用过的虚拟地址与物理地址的映射关系，当CPU需要访问某个虚拟地址时，先在TLB中查找对应的物理地址，如果命中则可以直接访问物理地址，否则需要进行完整的地址转换流程。

  磁盘缓存是一种软件缓存，用于加速磁盘读写操作。磁盘缓存存储了最近读取过的磁盘数据，当需要再次读取时，可以直接从缓存中获取，避免了频繁的磁盘读取操作。

  因此，TLB和磁盘缓存的作用不同，TLB是用于加速虚拟地址到物理地址的转换，而磁盘缓存是用于加速磁盘读写操作。两者的实现方式也不同，TLB是硬件缓存，而磁盘缓存是软件缓存。

- 线程安全、线程安全函数、可重入函数、信号安全函数

  1. 线程安全

  线程安全是指多个线程同时访问同一份数据时，不会出现数据竞争和不一致的情况。线程安全的实现可以通过使用互斥量、信号量、读写锁等同步机制来保证。

  2. 线程安全函数

  线程安全函数是指在多线程环境下可以安全调用的函数。这些函数要么不使用全局变量，要么使用全局变量时使用同步机制来保证线程安全。例如，C标准库中的strtok_r函数就是线程安全函数。

  3. 可重入函数

  可重入函数是指在多线程环境下可以重复调用的函数。这些函数不使用全局变量，而是使用局部变量或者参数来保存状态信息。可重入函数的实现可以通过使用静态变量或者动态分配内存的方式来保存状态信息。

  4. 信号安全函数

  信号安全函数是指在信号处理函数中可以安全调用的函数。由于信号处理函数的执行是在中断上下文中进行的，因此不能使用会修改全局变量的函数，也不能使用会阻塞的函数。例如，C标准库中的malloc函数就不是信号安全函数。

- 浏览器中点击+号创建新的标签页，是开启了一个新线程还是新进程，以及原因

  在大多数浏览器中，点击+号创建新的标签页会开启一个新的进程。这是因为现代浏览器通常使用多进程架构，每个标签页都在单独的进程中运行，这样可以提高浏览器的稳定性和安全性，同时也可以更好地利用多核处理器的优势。每个进程都有自己的内存空间，这样即使一个标签页崩溃了，其他标签页也不会受到影响。当然，也有一些浏览器会在同一个进程中运行多个标签页，这取决于浏览器的具体实现。

- 产生缺页中断的几种情况：

  1. CPU所需访问的页面不在内存中，就需要将页面调入内存，如果内存已满，就需要执行相应的页面置换算法；
  2. 使用 mmap 函数在堆中创建一块虚拟内存，第一次访问时才会通过缺页中断机制映射到物理页中；
  3. fork() 创建子进程，读时共享，写时拷贝，缺页中断；


- 什么是缺页异常，什么情况下会缺页异常

  缺页异常（Page Fault）是指当程序访问一个尚未在内存中的页面时，操作系统会将其从磁盘或其他存储设备中读入内存，此过程就是缺页异常。当程序试图访问某个虚拟地址时，如果对应的物理页不在内存中，就会发生缺页异常。

  缺页异常通常发生在以下情况下：

  1. 程序第一次访问某个页面，该页面尚未被加载到内存中。

  2. 程序访问的页面已经被换出到磁盘或其他存储设备中，需要重新加载到内存中。

  3. 程序访问的页面已经被修改，需要将其写回到磁盘或其他存储设备中，并且加载新的页面到内存中。

  缺页异常是操作系统中常见的机制之一，它可以有效地利用内存资源，提高系统的性能和效率。

- 为什么ssh客户端关闭了会影响服务端的运行?

  当终端接口检测到网络连接断开，将挂断信号SIGHUP发送给控制进程(会话期首进程)。如果会话期首进程终止，则该信号发送到该会话期前台进程组。一个进程退出导致一个孤儿进程组产生时，如果任意一个孤儿进程组进程处于STOP状态，则会发送 SIGHUP 和 SIGCONT 信号到该进程组中所有进程。因此当网络断开或终端窗口关闭后，也就是SSH断开以后，控制进程收到 SIGHUP 信号退出，会导致该会话期内其他进程退出。也就是 ssh 打开以后，bash等都是他的子程序，一旦ssh关闭，系统将所有相关进程杀掉，导致一旦ssh关闭, 执行中的任务就取消了。

  那如何解决呢？

  在远端开启 tmux，在 tmux 里运行程序，此时运行的程序属于 tmux 的进程组，不属于 ssh 进程组；使用 `nohup `命令。

- 线程池里的线程数设置为多少最优？

  线程池里的线程数设置为多少最优，取决于以下因素：

  1. CPU核心数：线程池中的线程数应该小于等于CPU核心数，否则会导致CPU过度切换线程而降低性能。

  2. 任务类型：任务类型对线程池的大小也有影响。如果任务是I/O密集型，线程池中的线程数应该设置得更大，以便更好地利用I/O等待时间。如果任务是CPU密集型，线程池中的线程数应该设置得更小，以避免过度切换线程。

  3. 系统负载：系统负载也会影响线程池的大小。如果系统负载较高，线程池中的线程数应该设置得更小，以避免过度消耗系统资源。

  因此，线程池中的线程数应该根据以上因素进行适当调整，以达到最优的性能和资源利用率。


- 32和64位操作系统地址空间分别是多大？

  32位：2^32^ = 4 GB，64位：2^64^ 字节

- 构成一个计算机需要什么，各个组件做什么工作

  计算机由五大部件组成，包括运算器、控制器、存储器、输入设备和输出设备组成。

  1、控制器：计算机的控制系统，是计算机的神经中枢，指挥着计算机中各个部件自动协调工作。在控制器的控制下，计算机能够自动按照程序设定的步骤进行一系列操作，以完成特定任务。

  2、运算器：计算机的运算系统，计算机中执行各种算术和逻辑运算操作的部件。

  3、存储器：计算机存储系统，是一种利用半导体、磁性介质等技术制成的存储资料的电子设备。其电子电路中的资料以二进制方式存储。

  4、输入设备：向计算机输入数据和信息的设备，是计算机与用户或其他设备通信的桥梁。

  5、输出设备：是计算机硬件系统的终端设备，用于接收计算机数据的输出显示、打印、声音、控制外围设备等。

- 计算机的位数是由什么来决定的

  计算机的位数是由其处理器（CPU）的寄存器的位数决定的。寄存器是一种非常快速的存储器件，用于存储计算机正在处理的数据和指令。每个寄存器都有一个特定的位数，表示它可以存储的二进制位数。例如，一个32位的处理器具有32位的寄存器，可以处理32位的二进制数据。同样，64位的处理器具有64位的寄存器，可以处理64位的二进制数据。因此，计算机的位数决定了它可以处理的最大二进制数的位数，从而影响了其性能和处理能力。

- 线程创建 pthread_create 底层调用函数是啥

  pthread_create 底层调用的函数是 clone()。clone() 是 Linux 内核提供的系统调用，用于创建一个新的进程或线程。在 Linux 中，线程本质上也是一个进程，只是与创建它的进程共享了一部分资源。因此，pthread_create() 函数实际上是通过调用 clone() 创建一个新的线程，并将其加入到进程的线程池中。

- 段错误有什么原因

  段错误是一种常见的程序错误，通常是由于程序访问了不合法的内存地址或者内存越界引起的。具体来说，段错误可能由以下原因引起：

  1. 访问未分配内存：程序试图访问未分配的内存地址，比如使用空指针或者释放了已经被释放的内存。

  2. 内存越界：程序试图访问超出数组或者指针范围的内存地址，比如数组下标越界或者指针偏移量超出了指针指向的内存空间。

  3. 栈溢出：程序使用了过多的栈空间，导致栈溢出，比如递归调用过深或者在栈上分配过多的内存。

  为了避免段错误，可以采取以下措施：

  1. 避免使用空指针或者已经被释放的内存。

  2. 对于数组和指针，要确保访问的下标或者偏移量不越界。

  3. 在使用递归时，要注意控制递归深度，避免栈溢出。

  4. 使用工具进行内存检查，比如valgrind等工具可以检查程序中的内存错误。

  5. 编写高质量的代码，遵循良好的编程习惯，比如避免使用未初始化的变量等。

- Epoll是阻塞/非阻塞？异步/同步？

  Epoll是非阻塞/异步的。它使用事件通知机制，当有事件发生时，它会立即返回而不会阻塞线程，同时也不需要轮询来检查事件是否发生。这种异步的方式可以提高系统的并发性和响应性能。同时，Epoll也可以使用边缘触发模式，可以在数据可读/写时立即通知应用程序，从而实现异步处理。

- 服务器有一个连接进来，到应用程序读取到数据，需要经过几次内核态/用户态切换？需要几次缓冲区数据的拷贝？

  4次内核态/用户态切换：

  1. 用户应用进程调用read函数，向操作系统发起IO调用，上下文从用户态转为内核态（切换1）；
  2. DMA控制器把数据从磁盘中，读取到内核缓冲区；
  3. CPU把内核缓冲区数据，拷贝到用户应用缓冲区，上下文从内核态转为用户态（切换2），read函数返回；
  4. 用户应用进程通过write函数，发起IO调用，上下文从用户态转为内核态（切换3）；
  5. CPU将用户缓冲区中的数据，拷贝到socket缓冲区；
  6. DMA控制器把数据从socket缓冲区，拷贝到网卡设备，上下文从内核态切换回用户态（切换4），write函数返回；

  4次缓冲区数据的拷贝：

  1. 第一次拷贝：将磁盘中的数据拷贝到内核的缓冲区中；
  2. 第二次拷贝：内核将数据处理完，接着拷贝到用户缓冲区中；
  3. 第三次拷贝：此时需要通过socket将数据发送出去，将用户缓冲区中的数据拷贝至内核中socket的缓冲区中；
  4. 第四次拷贝：把内核中socket缓冲区的数据拷贝到网卡的缓冲区中，通过网卡将数据发送出去。


- 多线程和多进程区别

  多线程和多进程是并发编程中的两种常见方式，它们的主要区别在于：

  1. 资源占用：多进程需要独立的内存空间和系统资源，因此它的资源占用比多线程更大。而多线程共享进程的资源，因此资源占用较少。

  2. 通信方式：多进程之间的通信需要使用IPC（进程间通信）方式，如管道、消息队列、共享内存等。而多线程之间的通信可以直接使用共享变量、锁等线程同步机制。

  3. CPU利用率：多进程因为需要切换进程，因此CPU利用率较低。而多线程因为共享进程的资源，因此切换线程的开销较小，CPU利用率较高。

  4. 稳定性：多线程的稳定性较差，因为一个线程的崩溃可能会导致整个进程的崩溃。而多进程的稳定性较好，因为一个进程的崩溃不会影响其他进程的运行。

  5. 编程复杂度：多线程的编程复杂度较低，因为它不需要考虑进程间通信的问题。而多进程的编程复杂度较高，因为需要考虑进程间通信的问题。

  综上所述，多线程适用于需要共享资源、处理并发请求的场景，而多进程适用于需要处理大量计算密集型任务、需要提高系统稳定性的场景。

- 多进程和多线程的使用场景

  多线程和多进程都是并发编程的实现方式，但是它们适用的场景不同。

  多线程适用于以下情况：

  1. 程序需要同时处理多个任务，但是每个任务的执行时间比较短，且需要共享数据。

  2. 程序需要同时处理多个任务，但是每个任务的执行时间较长，且需要频繁地进行IO操作。

  3. 程序需要实现GUI界面，需要同时处理用户的输入和输出。

  4. 程序需要实现网络编程，需要同时处理多个客户端请求。

  多进程适用于以下情况：

  1. 程序需要处理大量的计算密集型任务，需要充分利用多核CPU的性能。

  2. 程序需要保证高可靠性和安全性，需要将不同的任务分配给不同的进程，避免一个任务的错误影响其他任务。

  3. 程序需要利用多台机器的计算资源，需要通过进程间通信来协调不同机器上的任务。

  总之，多线程适合处理IO密集型任务，而多进程适合处理计算密集型任务。在实际应用中，需要根据具体情况选择合适的并发编程方式。

- 什么是协程，什么情况下可以使用协程

  协程（Coroutine）是一种轻量级的线程，与线程相比，协程的切换不需要操作系统介入，因此可以实现更高效的并发编程。

  协程可以用于需要处理大量IO操作的场景，例如网络编程、文件读写等。在这些场景中，线程会因为等待IO操作完成而被阻塞，而协程可以在等待IO操作的同时切换到其他任务，从而提高CPU利用率。

  协程的优势包括：

  1. 更轻量级：协程的切换不需要操作系统介入，因此比线程更轻量级，可以创建更多的协程。

  2. 更高效：协程的切换比线程更快，因此可以实现更高效的并发编程。

  3. 更容易编写和维护：协程的代码结构更简单，可以避免线程的锁和同步问题，从而更容易编写和维护。

  4. 更容易调试：协程的调试比线程更容易，因为协程的调用栈比线程更清晰。

  总之，协程是一种高效、轻量级、易于编写和维护的并发编程模型，可以帮助开发者更好地处理并发编程问题。

- 协程在什么时候进行切换？

  协程的切换在以下几种情况下会发生：

  1. 当当前协程遇到阻塞操作，比如等待 I/O 操作完成或者等待其他协程的消息时，协程的控制权就会被剥夺并被切换出去，其他可执行的协程就会被调度到运行状态。

  2. 当一个协程主动放弃 CPU 运行权，比如调用 `runtime.Gosched()` 函数或者 `yield` 等操作时，协程也会被切换出去，让其他可执行的协程获得机会运行。

  3. 当一个协程正在等待另一个协程完成某个任务，比如等待另一个协程完成某个计算并返回结果时，也会发生协程的切换。

  4. 当多个协程同时等待同一个 Channel 的读写时，只有其中一个协程能够成功地进行读写操作，其他协程都会被阻塞，并被调度器挂起，等待机会再次获得运行权。

  需要注意的是，在协程的切换过程中，上下文信息需要保存在协程自己的栈中，以便于恢复执行状态。协程的切换不会切换进程，而是在同一进程内部进行。这也是协程相比线程更加轻量级的原因之一。


- 如果多个线程同时判断到当前对象未创建，应该怎么解决？

  如果多个线程同时判断到当前对象未创建，就可能会出现多个线程同时创建同一个对象的问题，这称为竞态条件（Race Condition）。为了解决这个问题，可以采用以下两种方法：

  1. 使用互斥锁

  可以使用互斥锁（Mutex）来保护资源的访问，当一个线程要访问共享资源时，首先尝试获得互斥锁，如果锁已经被其他线程占用，就必须等待锁被释放后才能访问，从而避免了多个线程同时创建同一个对象的情况。可以使用C++11提供的std::mutex来实现互斥锁。

  2. 使用双重检查锁定模式

  双重检查锁定模式（Double-Check Locking Pattern）是一种常见的单例模式的实现方式，可以避免多线程创建同一个对象的问题。具体实现方法如下：

  ```c
  class Singleton {
  private:
      static Singleton* instance;
      static std::mutex mtx;
  
      Singleton() {}
  
  public:
      static Singleton* getInstance() {
          if (instance == nullptr) { // 第一次检查
              std::lock_guard<std::mutex> lock(mtx); // 加锁
              if (instance == nullptr) { // 第二次检查
                  instance = new Singleton();
              }
          }
  
          return instance;
      }
  };
  
  Singleton* Singleton::instance = nullptr;
  std::mutex Singleton::mtx;
  ```

  在getInstance()函数中，第一次检查是为了提高效率，如果instance已经被创建，则可以直接返回；第二次检查是为了避免多个线程同时创建同一个对象，只有在获取到锁之后才会进行创建。这样，即使多个线程同时调用getInstance()函数，也不会创建多个对象。

  总之，在多线程编程中，需要特别注意竞态条件的问题，尽可能采用互斥锁、读写锁、信号量等同步机制来保护共享资源的访问。同时，在实现单例模式等共享资源的场景下，还需要特别注意线程安全的实现方式。

- 先来先服务和短作业优先适用于哪种类型的操作系统？

  先来先服务和短作业优先算法适用于不同类型的操作系统。

  先来先服务算法适用于批处理操作系统，作业通常按照提交的顺序进行处理，所以先来先服务算法很适合。在这种情况下，作业按照先后顺序依次进入队列，CPU依次执行每个作业，直到该作业执行完毕或者阻塞，才会执行下一个作业。

  短作业优先算法适用于实时操作系统，可以确保较短的任务获得更快的响应时间，从而满足实时性要求。在这种情况下，作业的执行时间需要预测或估计，优先执行执行时间短的作业，可以避免长作业的饥饿现象，同时也可以提高系统的响应速度。

  因此，先来先服务和短作业优先算法适用于不同类型的操作系统，需要根据不同的场景选择合适的算法才能更好地满足系统的需求。

- vfork 什么作用？fork和vfork的区别

  `vfork()` 是一种创建子进程的系统调用，与 `fork()` 类似，但是 `vfork()` 会与父进程共享地址空间，直到子进程调用 `execve()`、 `_exit()` 或发生错误时才会分离地址空间。`vfork()` 的主要作用是在创建子进程时避免复制父进程的地址空间，从而提高创建进程的效率。

  `fork()` 与 `vfork()` 的区别在于，`fork()` 会复制父进程的地址空间，而 `vfork()` 不会复制父进程的地址空间，直接在父进程的地址空间中运行子进程。因此，使用 `vfork()` 可以在创建子进程时避免复制大量的数据，提高创建进程的效率。但是，由于 `vfork()` 与父进程共享地址空间，因此必须保证子进程不会修改父进程的数据，否则可能会导致未定义的行为。 在使用 `vfork()` 时，需要注意以下几点：

  1. 子进程必须要调用 `execve()`、 `_exit()` 或发生错误时才能分离地址空间，否则可能会导致未定义的行为。
  2. 子进程不能修改父进程的数据，否则可能会破坏父进程的状态。
  3. 父进程在调用 `vfork()` 后应该立即调用 `wait()` 或 `waitpid()` 等待子进程结束，否则可能会导致子进程成为僵尸进程。 总的来说，`vfork()` 可以在创建进程时提高效率，但是需要注意子进程与父进程之间的共享问题，避免出现未定义的行为。

- 写时拷贝的原理

  写时拷贝（copy on write, COW）。

  父进程 fork 出的子进程与父进程共享内存空间，一开始父进程的数据不会复制给子进程，这样创建子进程的速度就很快了 (不用复制，直接指向父进程的物理空间)。只有当父子进程中有写入操作，再为子进程分配相应的物理空间。

  fork之后，内核把父进程中所有的内存页的权限设置为只读，然后子进程的地址空间指向父进程，与父进程共享数据。当父子进程都只读内存时，正常执行。当某个进程写内存时，CPU检测到内存页是只读的，就会触发页异常中断，内核就会把触发异常的页复制一份出来，这样父子进程就各自持有独立的异常页（其余的页还是共享父进程的）。

  写时拷贝可以减少分配和复制大量资源时带来的时间消耗；检查不必要的资源分配，比如fork进程时，并不是所有的页面都需要复制，父进程的代码段和只读数据段都不被允许修改，所以无需复制。

- 硬链接和软链接的区别

  硬链接（Hard Link）： 硬链接是指多个文件名指向同一个物理数据块，不同文件名的文件在文件系统中的 inode 号是相同的，它们占用的硬盘空间也是相同的。当其中一个文件被删除时，由于其它文件还指向同一个物理数据块，因此文件的数据不会被删除，只是将文件的链接数减 1，当链接数为 0 时才会真正删除文件数据。

  软链接（Symbolic Link）： 软链接是指类似于 Windows 中的快捷方式，它是一个特殊的文件，其中包含的是链接文件的路径。软链接与原文件是两个独立的文件，它们的 inode 号是不同的，占用的硬盘空间也不同。当原文件被删除时，软链接失效，因为它指向的文件已经不存在了。但是软链接本身不会被删除，如果需要删除软链接，需要使用 `rm` 命令。

  综上所述，硬链接和软链接的最大区别在于：硬链接是多个文件名指向同一份数据，它们之间是互相独立的，而软链接则是一个文件指向另一个文件，软链接本身是一个特殊的文件，它指向的文件删除后就失效了。

- 孤儿进程和僵尸进程，产生的原因，什么样的代码会产生僵尸进程？

  孤儿进程和僵尸进程是Linux系统中常见的两种进程状态。

  孤儿进程是指父进程先于子进程退出，而子进程还在运行的情况下，子进程成为孤儿进程。孤儿进程由init进程接管，并由init进程负责将其退出，释放资源。

  僵尸进程是指子进程先于父进程退出，但是父进程没有处理子进程的退出状态信息的情况下，子进程成为僵尸进程。僵尸进程虽然已经退出，但是其占用的系统资源（例如进程ID、内存等）没有被释放，如果存在大量的僵尸进程，会导致系统的性能下降。

  产生孤儿进程的原因通常是父进程在创建子进程后退出，而子进程继续运行。产生僵尸进程的原因是父进程没有对子进程进行处理，没有调用wait或waitpid等函数获取子进程的退出状态信息。

  在编写代码时，如果父进程没有及时处理子进程的退出状态信息，会产生僵尸进程。以下是一个简单的示例代码：

  ```c
  #include <stdio.h>
  #include <stdlib.h>
  #include <unistd.h>
  
  int main() {
      pid_t pid;
  
      pid = fork();
      if (pid < 0) {
          perror("fork error");
          exit(1);
      } else if (pid == 0) {
          printf("child process %d\n", getpid());
          exit(0);
      } else {
          printf("parent process %d\n", getpid());
          sleep(10);
      }
  
      return 0;
  }
  ```

  在该代码中，父进程创建了一个子进程，但是没有对子进程进行处理，也没有调用wait或waitpid函数获取子进程的退出状态信息。因此，当子进程退出后，成为了一个僵尸进程，占用系统资源，等待父进程处理。如果父进程一直没有处理，就会导致系统中存在大量的僵尸进程，影响系统性能。

  为避免产生僵尸进程，父进程需要及时处理子进程的退出状态信息，可以调用wait或waitpid等函数来获取子进程的退出状态信息并释放僵尸进程的资源。

- 系统创建进程的时候会给进程分配哪些资源

  当系统创建一个进程时，会为其分配一些资源，这些资源包括：

  1. 进程标识符（PID）：系统为每个进程分配一个唯一的 PID，用于标识该进程。

  2. 进程地址空间：系统为每个进程分配一个虚拟地址空间，该空间包括代码段、数据段、堆和栈等。

  3. 进程上下文：系统为每个进程分配一个上下文，包括进程状态、寄存器值、堆栈指针等。

  4. 文件描述符表：每个进程都有一个文件描述符表，其中存储了进程打开的文件和网络连接等信息。

  5. 信号处理器：系统为每个进程分配一组信号处理器，用于处理进程收到的不同类型的信号。

  6. 资源限制：系统会为每个进程设置一些资源限制，包括 CPU 时间、内存使用量、文件打开数等。

  7. 进程优先级：系统会为每个进程设置一个优先级，用于调度器在进程之间进行调度。

  8. 环境变量：系统会为每个进程设置一个环境变量列表，用于存储进程运行环境相关的信息。

  除了以上列出的资源之外，系统还会为进程分配一些其他的资源，例如进程间通信机制、共享内存、消息队列等，这些资源也是进程运行所必需的。

  需要注意的是，不同的操作系统在进程创建时会分配的资源可能会有所不同，但大体上都会涵盖以上列出的资源。

- 线程中包含哪些资源

  线程是操作系统中的一种轻量级进程，它与进程共享一些资源，同时也有一些自己独有的资源。线程中包含的资源主要包括：

  1. 线程标识符（TID）：系统为每个线程分配一个唯一的 TID，用于标识该线程。

  2. 线程栈：线程需要有自己的栈空间，用于存储线程的局部变量、函数参数和返回值等。

  3. 寄存器：线程需要使用一些寄存器来存储线程的上下文信息，例如程序计数器、堆栈指针等。

  4. 线程私有数据：线程可以有自己的一些私有数据，例如线程局部变量等。

  5. 线程同步和通信机制：线程之间需要进行同步和通信，例如互斥锁、条件变量等。

  6. 调度属性：系统会为每个线程设置一些调度属性，例如线程的优先级、调度策略等。

  需要注意的是，线程与进程共享一些资源，例如进程地址空间、文件描述符表等，这些资源也属于线程的资源范畴。此外，线程的资源与操作系统的实现方式有关，不同的操作系统可能会分配不同的资源给线程。

  总之，线程中包含的资源与进程有些类似，但线程也有自己独有的资源，例如线程栈、线程私有数据等。了解线程的资源结构可以帮助程序员编写高效、正确的多线程程序。

- 进程切换时都有哪些改变

  进程切换时，操作系统需要进行一系列的改变，以下是一些可能的改变：

  1. 程序计数器（PC）的值会被保存。PC 指向当前正在执行的指令，进程切换后需要将其保存，以便下次切换回来时能够继续执行。

  2. CPU 寄存器的值也会被保存。CPU 寄存器中保存了进程正在使用的变量和临时存储的数据，这些值需要在进程切换时被保存。否则，当进程切换回来时，原来保存在寄存器中的数据可能已经被覆盖掉了，导致程序出错。

  3. 进程状态的改变。进程切换时，当前进程的状态会被保存，包括进程的优先级、时间片、内存映像、打开文件等信息。操作系统需要将这些信息保存下来，并为将要切换到的进程恢复相应的状态。

  4. 内核栈的切换。内核栈是进程在内核态下使用的栈，进程切换时需要切换内核栈，以便在内核态下正常运行。

  5. 切换到不同的地址空间。不同的进程可能使用不同的地址空间，进程切换时需要将当前进程的地址空间切换到将要切换到的进程的地址空间。

  6. 切换到不同的用户态栈。用户态栈是进程在用户态下使用的栈，进程切换时需要切换用户态栈，以便在用户态下正常运行。

  7. 更新进程控制块（PCB）。进程切换时，系统需要更新当前进程的 PCB 信息，包括进程的状态和其他信息。

  需要注意的是，不同的操作系统可能会有不同的实现方式，以上列出的改变并不是绝对的，但是它们是常见的进程切换过程中可能发生的改变。

- 如何发现和避免线程栈溢出

  当线程栈溢出时，通常会出现一些异常情况，例如程序崩溃、段错误等。但有时候线程栈溢出可能不会导致程序崩溃，这时需要通过其他方式来发现线程栈溢出的问题。

  以下是一些发现线程栈溢出的方法：

  1. 监控线程的栈空间使用情况：可以通过操作系统提供的一些工具来监控线程的栈空间使用情况，例如 Linux 中的 pmap 工具可以查看线程的内存使用情况。如果发现线程的栈空间使用率过高，就有可能存在栈溢出的问题。

  2. 检查程序日志：如果线程发生栈溢出时程序没有崩溃，可以通过程序日志来查看是否存在栈溢出的迹象，例如栈内存访问越界等异常情况。

  3. 增加栈空间大小：如果发现线程的栈空间不够用，可以尝试增加线程的栈空间大小。在编写程序时，可以通过调用操作系统提供的一些函数来动态分配栈空间，例如 pthread_attr_setstacksize 函数可以设置线程的栈空间大小。

  总之，线程栈溢出可能会导致程序崩溃或发生异常情况，但有时候也可能不会导致程序崩溃，这时需要通过其他方式来发现栈溢出的问题。为了避免线程栈溢出，程序员应该合理地分配线程的栈空间大小，避免栈空间不足的情况发生。

  当线程栈空间不足时，就有可能会发生线程栈溢出的问题。线程栈溢出可能会导致程序崩溃、数据丢失等严重后果，因此程序员需要注意如何避免线程栈溢出的问题。

  以下是一些避免线程栈溢出的方法：

  1. 合理分配线程的栈空间大小：程序员应该根据线程的需要，合理地分配线程的栈空间大小。如果线程需要大量的栈空间，可以考虑使用动态分配的方式来分配栈空间。

  2. 使用静态分配的栈空间：在编写程序时，可以使用静态分配的方式来分配栈空间。静态分配的栈空间通常比较大，可以避免栈空间不足的情况发生。

  3. 使用线程池：线程池是一种常见的多线程编程技术，它可以避免线程频繁的创建和销毁，从而减少线程栈空间的使用。线程池通常会预先创建一定数量的线程，当有任务需要执行时，就将任务分配给空闲的线程来执行，从而减少线程的创建和销毁次数。

  4. 使用堆空间：在编写程序时，可以使用堆空间来存储一些大型的数据结构，避免占用过多的栈空间。例如可以使用动态分配的内存或者全局变量来存储大型的数据结构。

  总之，避免线程栈溢出需要程序员在编写程序时注意合理分配线程的栈空间大小，使用静态分配的栈空间、线程池等技术来减少线程的创建和销毁次数，从而避免线程栈溢出的问题。

- mmap 的地址怎么确定

  mmap是一种将文件映射到内存的系统调用，它可以将一个文件或设备映射到进程的地址空间中，从而使得进程可以直接访问文件或设备中的内容。在调用mmap时，需要指定映射的起始地址和映射的长度，这些参数通常是由操作系统自动分配的，但也可以手动指定。

  当手动指定映射的起始地址时，需要考虑以下几个因素：

  1. 起始地址必须是操作系统内存页面大小（通常是4KB）的整数倍，否则会导致段错误（segmentation fault）。

  2. 起始地址不能和已经映射的内存区域重叠，否则会导致数据的覆盖或丢失。

  3. 起始地址不能和进程的代码、数据、堆栈等区域重叠，否则会导致程序崩溃或不可预测的行为。

  因此，手动指定映射的起始地址需要进行仔细的计算和分析，以确保映射的正确性和可靠性。

  当未手动指定映射的起始地址时，操作系统会自动分配一个合适的地址，并返回这个地址给调用者。这个地址通常是由操作系统的虚拟内存管理模块根据当前进程的内存布局和可用内存空间进行计算和分配的，具体实现细节与操作系统的实现方式有关，通常会考虑以下因素：

  1. 进程的代码、数据、堆栈等区域的地址和大小。

  2. 已经映射到进程地址空间中的文件、设备等的地址和大小。

  3. 空闲内存的地址和大小。

  根据这些因素，操作系统会选择一个合适的地址作为映射的起始地址，并返回给调用者。需要注意的是，由于操作系统会自动分配地址，因此在多次调用mmap时，映射的地址可能会发生变化，因此需要进行相应的处理和调整。

- 不同线程共享的是什么

  不同线程共享的是进程的地址空间和各种资源，包括打开的文件、共享内存、信号量、网络连接等等。

  每个进程都有自己的地址空间，包括代码段、数据段、堆栈段等。不同线程共享进程的地址空间，也就意味着它们可以访问同一个进程的全局变量、静态变量、函数等等。

  此外，不同线程还可以共享一些资源，比如打开的文件、共享内存、信号量、网络连接等等。这些资源是进程级别的，不同线程可以通过相应的API共享这些资源，以实现线程之间的协作和通信。

  需要注意的是，不同线程共享的资源需要进行适当的同步和互斥，以避免竞态条件和数据不一致等问题。在多线程编程中，通常会使用锁、信号量、条件变量等同步机制来保证线程之间的正确协作。

- 服务端的连接数上限由什么决定？

  服务端的连接数上限由多个因素共同决定：

  1. 系统资源：服务端的连接数受限于系统资源，如CPU、内存、网络带宽等。如果系统资源不足，会导致服务端无法处理更多的连接请求。

  2. 操作系统：不同操作系统对于连接数的限制也不同，比如Linux内核默认情况下可以支持数万个TCP连接，而Windows操作系统则有较低的默认连接数限制。

  3. 网络设备：服务端连接数还受限于网络设备的处理能力，如路由器、交换机等。如果网络设备的处理能力不足，会导致连接数上限无法扩大。

  4. 应用程序：应用程序本身也会对连接数进行限制，如使用线程池、连接池等机制来控制连接数。

  5. 连接的性质：不同类型的连接对连接数的限制也不同，如长连接和短连接的限制就不同。长连接需要占用更多的系统资源，因此对连接数的限制会更严格。

  需要注意的是，连接数的上限是一个动态的概念，它会随着系统资源的变化和应用程序的调整而变化。在实际应用中，需要根据具体情况进行调整，以达到最佳的性能和稳定性。

- 自旋锁和可重入锁的区别，什么时候使用

  自旋锁和可重入锁是两种不同类型的锁，它们的区别如下：

  1. 实现方式不同：自旋锁是通过在获取锁失败时不断地循环尝试获取锁直到成功，而可重入锁则是通过记录锁的持有者以及持有次数来实现的。

  2. 锁的性质不同：自旋锁是一种非阻塞锁，它不会将线程挂起，而可重入锁是一种阻塞锁，它会将线程挂起等待锁的释放。

  3. 适用场景不同：自旋锁适用于锁的持有时间很短的情况，因为自旋锁不会将线程挂起，如果锁的持有时间过长，就会导致CPU资源的浪费。而可重入锁适用于锁的持有时间较长的情况，因为可重入锁可以防止死锁，并且可以保证同一个线程多次获取同一个锁时不会出现死锁问题。

  4. 线程安全性不同：自旋锁是非线程安全的，因为它没有记录锁的持有者的信息，所以不适用于多线程环境。而可重入锁是线程安全的，因为它记录了锁的持有者以及持有次数，可以支持多个线程同时获取同一个锁。

  在实际应用中，需要根据具体情况选择自旋锁或可重入锁。如果锁的持有时间较短，且是在单线程环境下使用，可以选择自旋锁来避免线程挂起的开销；如果锁的持有时间较长，或者需要在多线程环境下使用，可以选择可重入锁来防止死锁，并且支持多线程同时获取同一个锁。

- 死锁和死循环的判断，日志或者其他方案？

  在 C++ 中判断死锁和死循环的方法主要有以下几种：

  1. 使用互斥量和条件变量来实现线程同步，同时在程序中添加日志记录，记录每个线程获取锁的顺序和等待的时间。
  2. 使用计数器或者时间戳等机制，避免线程陷入无限循环，同时在程序中添加日志记录。
  3. 使用诸如 Valgrind、GDB 等调试工具来检测死锁和死循环。

- `join()` 和 `detach()` 

  在多线程编程中，使用 `join()` 和 `detach()` 是非常常见的操作。下面是一些需要注意的事项：

  1. 一旦线程被 `join()` 或 `detach()`，它就不能再次被 `join()` 或 `detach()`。调用 `join()` 或 `detach()` 时应该确保线程仍然存在，否则会导致程序崩溃。
  2. 在使用 `join()` 时，当前线程会被阻塞，直到被等待的线程执行完毕。这种方式适合用于协调线程之间的执行顺序，但可能会降低程序的并发性。
  3. 在使用 `detach()` 时，被分离的线程将变成后台线程，不再与当前线程同步执行，也不需要等待其执行完毕。这种方式适合用于一些独立运行的任务，可以提高程序的并发性，但也需要注意线程的生命周期和资源管理。
  4. 在使用 `join()` 和 `detach()` 时，需要注意线程的异常处理。如果在线程中抛出了异常，如果线程被 `join()`，则异常会被重新抛出到当前线程中，否则可能会导致程序崩溃。
  5. 在使用 `join()` 和 `detach()` 时，需要注意线程的资源管理。如果线程需要访问一些共享资源，需要使用锁来保护这些资源，避免多个线程同时访问导致数据不一致或程序崩溃。

  总之，在使用 `join()` 和 `detach()` 时，需要仔细考虑线程的生命周期、资源管理和异常处理等方面，以确保程序的正确性和稳定性。

- 多进程可以监听同一个端口吗？会出现什么问题？怎么解决？多线程可以监听同一个端口吗？

  多进程可以监听同一个端口，但是会出现惊群问题。

  惊群问题是指多个进程同时在等待同一个事件（例如一个连接请求），当事件触发时，多个进程同时被唤醒，竞争同一个资源，从而导致性能下降。在网络编程中，惊群问题常常出现在多个进程同时监听同一个端口的情况下。

  解决惊群问题的方法有以下几种：

  1. 使用单进程监听端口，然后通过进程间通信的方式将连接请求分配给其他进程处理。

  2. 在多进程中，只有一个进程负责监听端口，其他进程通过进程间通信的方式告知监听进程需要处理的连接请求。

  3. 使用 SO_REUSEPORT 选项，让多个进程可以同时绑定同一个端口，但是每个进程只会处理一部分连接请求，从而避免惊群问题。

  多线程可以监听同一个端口，因为多个线程可以共享同一个进程的资源，避免了惊群问题。在多线程编程中，通常使用线程池来处理连接请求，从而提高程序的性能。

- c++为多线程提供了哪些工具，除了thread，mutex外

  C++标准库中除了 `std::thread` 和 `std::mutex` 外，还提供了其他一些多线程工具，包括：

  1. `std::condition_variable`：条件变量，用于在多个线程之间等待某个条件成立的信号。通常与 `std::unique_lock` 配合使用。

  2. `std::atomic`：原子操作类型，用于在多个线程之间进行原子操作，保证操作的原子性。可以用于实现锁、计数器等。

  3. `std::future` 和 `std::promise`：异步任务的实现，可以用于在一个线程中执行某个任务，并在另一个线程中获取任务执行结果。`std::promise` 用于保存任务结果，而 `std::future` 用于获取任务结果。

  4. `std::async`：异步执行函数的工具，可以在一个线程中异步执行某个函数，并返回 `std::future` 对象，用于获取函数执行结果。

  5. `std::thread_local`：线程本地存储，用于在每个线程中存储一份局部变量，不同线程之间互不干扰。

  6. `std::atomic_flag`：布尔类型的原子操作类型，用于实现自旋锁。

  7. `std::barrier`：屏障，用于阻塞一组线程，直到所有线程都到达屏障位置。

  8. `std::mutex` 的衍生类型：`std::recursive_mutex`、`std::timed_mutex`、`std::recursive_timed_mutex` 等，用于提供更多的锁类型和功能。

  这些工具的使用可以更方便地实现多线程任务，提高程序的并发性和性能。但需要注意，多线程编程需要谨慎处理共享资源的访问，避免竞态条件和死锁等问题。

- 不同的线程的什么内存空间共享，什么内存空间不共享

  在多线程程序中，不同的线程之间会共享进程的地址空间，也就是说它们可以访问相同的全局变量、静态变量和动态分配的堆内存空间。这些内存空间是不会被复制的，不同线程对它们的访问是直接读写进程的内存空间。

  但是，每个线程都有自己的栈空间和寄存器，它们不会被其他线程共享。线程的栈空间用于存储局部变量、函数参数以及函数调用的返回地址等信息，每个线程都有自己独立的栈空间，不同线程的栈空间是分离的。线程的寄存器也是独立的，不同线程的寄存器状态也是分离的。

  此外，每个线程还有自己的线程局部存储（Thread Local Storage，TLS），TLS 是一种线程专用的变量存储机制，可以用于存储线程特有的数据，不同线程之间的 TLS 是相互独立的。

- 消息队列的特点

  消息队列是一种进程间通信（IPC）的方式，具有以下特点：

  1. 异步性：消息队列支持异步通信，发送方和接收方不必同时存在或者同时处于运行状态。发送方可以将消息放入队列中，然后继续执行其他任务，而不需要等待接收方的响应。接收方可以在合适的时候从队列中取出消息，进行处理。

  2. 解耦性：消息队列实现了发送方和接收方之间的解耦，它们不需要知道对方的存在或者状态，只需要关注消息的格式和语义。这种解耦性使得系统更加灵活和可扩展，可以方便地添加新的模块或者调整模块的顺序。

  3. 缓冲性：消息队列可以作为缓冲区来使用，缓存发送方产生的数据，以避免发送方和接收方之间的速度不匹配导致的数据丢失或者阻塞。接收方可以按照自己的速度从队列中取出数据，而不必担心发送方的速度。

  4. 可靠性：消息队列可以提供可靠的消息传递机制，保证消息不会丢失或者损坏。消息队列通常会采用持久化存储和确认机制来实现可靠性。

  5. 多对多通信：消息队列可以支持多对多的通信，即多个进程可以同时向同一个队列发送消息，也可以同时从同一个队列接收消息。这种多对多的通信方式可以提高系统的并发性和灵活性。

  总的来说，消息队列是一种高效、可靠、异步、解耦的进程间通信方式，适用于分布式系统、高并发系统、异构系统等场景。

- 共享内存的特点

  共享内存是一种进程间通信（IPC）的方式，具有以下特点：

  1. 高效性：共享内存是一种直接的内存访问方式，进程可以直接读写共享内存中的数据，无需进行复制或者传输，因此具有很高的数据传输效率和处理速度。

  2. 实时性：共享内存可以提供实时的数据传输和处理能力，因为数据不需要经过复制和传输，可以直接被读取和处理。

  3. 高并发性：共享内存可以支持多个进程同时对同一块内存进行读写，因此具有高并发性和高吞吐量。

  4. 共享性：共享内存可以实现数据共享，多个进程可以同时访问同一块内存，从而实现数据的共享和协作。

  5. 同步性：共享内存需要考虑同步问题，因为多个进程可能同时访问同一块内存，需要进行同步以避免数据冲突和竞争条件。

  6. 生命周期：共享内存的生命周期由进程控制，创建共享内存的进程退出时，共享内存会被删除，因此需要考虑进程的生命周期和资源管理。

  总的来说，共享内存是一种高效、实时、高并发、共享的进程间通信方式，适用于需要高效传输大量数据、实时处理数据和实现数据共享和协作的场景。但是需要注意同步和资源管理等问题，以确保数据的正确性和系统的稳定性。

- 进程切换的时机？

  在多任务操作系统中，进程切换是指在运行的进程被中断，操作系统暂停当前进程的执行，并将控制权转移到另一个进程上的过程。进程切换的时机取决于以下几个因素：

  1. 时间片到期：在时间片轮转调度算法中，每个进程被分配一个时间片，当时间片用尽时，操作系统会强制切换到下一个就绪进程。
  2. 高优先级进程就绪：当一个高优先级进程就绪时，操作系统会立即切换到该进程执行，以确保高优先级进程能够及时响应用户请求。
  3. 阻塞进程解除阻塞：当一个进程因为等待某些事件而被阻塞时，当这些事件发生并且进程解除阻塞时，操作系统会立即切换到该进程执行。
  4. 优先级改变：当一个进程的优先级发生变化时，操作系统会根据新的优先级重新调度进程，有可能会进行进程切换。
  5. 中断处理：当一个进程因为响应硬件中断而被中断时，操作系统会立即切换到中断处理程序执行。

- ET和LT模式各自应用场景是什么？为什么有了高效的ET还需要LT？

   ET 和 LT 是 Linux 中 epoll I/O 多路复用机制的两种工作模式，具体含义如下：

   - ET 模式（边缘触发模式），在事件发生时只通知一次，需要一直读取数据直到返回 EAGAIN 为止。ET 模式适合处理长连接，尤其是需要高吞吐量的场景。

   - LT 模式（水平触发模式），在事件发生时会一直通知直到数据被处理完，即使处理过程中出现 EAGAIN 等错误，也会再次通知。LT 模式适合处理短连接和低频率的连接。

   ET 和 LT 模式各自应用场景如下：

   - ET 模式适合处理长连接，因为在 ET 模式下，只有在数据发生变化时才会通知应用程序，可以减少不必要的上下文切换，提高处理效率，适合高吞吐量的场景，如网络视频、音频等。

   - LT 模式适合处理短连接和低频率的连接，因为在 LT 模式下，每次事件发生都会通知应用程序，可以保证每个事件都能被及时处理，适合低频率的连接，如 HTTP 请求等。

   为什么有了高效的 ET 模式还需要 LT 模式呢？原因如下：

   - ET 模式需要一直读取数据直到返回 EAGAIN，如果应用程序没有正确地处理 EAGAIN，可能会导致数据丢失或者阻塞。而 LT 模式在每次事件发生时都会通知一次，不会丢失数据，更加安全可靠。

   - ET 模式需要应用程序自己判断何时读取完数据，如果判断不正确，可能会出现死循环等问题。而 LT 模式在每次事件发生时都会通知一次，应用程序无需关心何时读取完数据。

   因此，在实际应用中，应该根据具体场景选择合适的工作模式，ET 模式适合处理长连接和高吞吐量的场景，而 LT 模式适合处理短连接和低频率的连接。同时，为了保证代码的可靠性和健壮性，建议在使用 ET 模式时，应用程序要正确地处理 EAGAIN 错误，避免出现数据丢失或者阻塞等问题。

- 


