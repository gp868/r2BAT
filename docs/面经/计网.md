
# 计网

- osi 七层和五层，合并在哪

  七层模型：

  - 物理层：利用传输介质（双绞线、光纤、wifi-电磁波）为数据链路层提供物理连接，实现比特流的透明传输，可靠的物理型号：0和1—通过网卡（MAC地址）定位电脑

  - 数据链路层：将IP数据报组装成帧，控制信息在相邻两节点的链路上进行传输—局域网内部，提供了通讯过程中要用到的MAC地址（物理地址）

  - 网络层：IP — 通过IP找到网关（局域网内部负责人），再找到局域网

  - 传输层：TCP、UDP，不同端口对应不同的应用，控流校验

  - 会话层：建立两个app直接的会话

  - 表示层：对底层命令和数据进行解释

  - 应用层：应用层协议：DNS、HTTP、SMTP等，用户在这一层与网络进行交互

  五层模型：

  TCP/IP五层协议就是把OSI七层网络模型的会话层、表示层、应用层合并成了应用层。

  - 应用层：负责应用程序之间的数据传输和通信。这个层级包括所有的应用程序，如电子邮件、FTP、HTTP、SSH等。

  - 传输层：提供端到端的数据传输服务，确保数据在源和目标之间可靠传输。这个层级包括TCP和UDP协议。
  - 网络层：负责数据包的传输，将数据包从源主机传到目标主机。这个层级包括IP协议。
  - 数据链路层：负责将数据包转换成物理层可以传输的信号。这个层级包括以太网协议。
  - 物理层：负责在物理媒介上传输数据，如光纤、电缆等。

- 网络层有哪些作用？

  网络层是OSI七层模型或TCP/IP五层模型中的第三层，位于传输层和数据链路层之间。其作用是为分组交换网上的不同主机之间提供端到端的通信服务，促进了网络内部和网络之间的数据传输。

  网络层有以下主要作用：

  1. 路由选择：通过路由选择协议，选择合适的路径将数据包从源地址传输到目的地址。

  2. 数据转发：将接收到的数据包移动到正确的出口端口，并发送到下一跳设备。

  3. 网络拥塞控制：使用一定策略来避免在网络中发生大量数据包同时传输导致的网络拥塞问题。

  4. 数据包分片和重组：将大数据包分割成小的数据包进行传输，并在接收端重组为原始的数据包。

  5. 网际互连：使得不同的网络之间可以互相通信，实现了互联网的主要功能。

  总之，网络层是整个互联网体系结构的重要组成部分，对于保证数据在网络中的流动、实现网络互联等方面具有不可替代的作用。

- 数据链路层有哪些协议？物理层使用到了些什么？

  数据链路层主要有以下协议：

  1. 以太网协议（Ethernet）：以太网是最常用的局域网协议，使用CSMA/CD（载波监听多路访问/碰撞检测）协议来解决数据冲突问题。

  2. 无线局域网协议（Wi-Fi）：Wi-Fi是一种无线局域网协议，采用CSMA/CA（载波监听多路访问/碰撞避免）协议来解决数据冲突问题。

  3. PPP协议（Point-to-Point Protocol）：PPP协议是一种点对点协议，常用于拨号上网和虚拟专用网（VPN）等场景。

  4. HDLC协议（High-level Data Link Control）：HDLC协议是一种数据链路层协议，常用于广域网（WAN）和数据通信等场景。

  5. SLIP协议（Serial Line Internet Protocol）：SLIP协议是一种串行线路协议，常用于串行线路上的IP数据传输。

  物理层使用到的技术主要有以下几种：

  1. 传输介质：物理层使用传输介质来传输数据，包括双绞线、同轴电缆、光纤等。

  2. 编码技术：物理层使用编码技术将数字信号转换为模拟信号，包括非归零编码、曼彻斯特编码等。

  3. 调制技术：物理层使用调制技术将数字信号转换为模拟信号，包括调幅、调频、调相等。

  4. 传输速率：物理层定义了不同的传输速率标准，包括10Mbps、100Mbps、1Gbps等。

  需要注意的是，数据链路层和物理层是OSI模型中最底层的两层，主要负责数据的传输和物理信号的转换。

- https 的 SSL 建立连接的过程会导致效率下降，如何优化

  HTTPS的SSL建立连接过程中确实会导致一定的性能损耗，主要是因为SSL握手过程需要进行非对称加密和数字签名等操作，而这些操作需要耗费CPU资源。

  以下是一些优化HTTPS性能的方法：

  1. 使用TLS 1.3协议：TLS 1.3协议在握手过程中使用了更快的加密算法，可以减少握手时间。

  2. 使用会话重用：在握手过程中，服务器可以生成一个会话ID或者会话密钥，客户端可以在下一次连接时重用这个会话ID或者会话密钥，从而避免重复进行SSL握手过程。

  3. 使用证书缓存：客户端可以缓存服务器的证书，避免每次连接都需要重新获取证书。

  4. 使用HTTP/2协议：HTTP/2协议使用了多路复用技术，可以在一个连接上同时传输多个请求和响应，从而减少握手次数。

  5. 使用CDN加速：将静态资源放在CDN上，可以减少HTTPS连接的数量，从而提高性能。

  6. 使用硬件加速：使用专门的硬件加速器可以加速SSL握手过程中的加密和解密操作，从而提高性能。

- https 整个握手交互的过程总共花了多少 rtt

  RTT(Round-Trip Time)为数据完全发送完（完成最后一个比特推送到数据链路上）到收到确认信号的时间。https的握手过程是在tcp三次握手之后额外添加2次RTT来完成。

  - TCP 握手（ 1 RTT）

    和服务器建立 TCP 连接，客户端向服务器发送 SYN 包，服务端返回确认的 ACK 包，这会花费一个往返（1 RTT）。

  - TLS 握手 （2 RTT）

    该部分客户端会和服务器交换密钥，同时设置加密链接，对于 TLS 1.2 或者更早的版本，这步需要 2 个 RTT。

  - 建立 HTTP 连接（1 RTT）

    一旦 TLS 连接建立，浏览器就会通过该连接发送加密过的 HTTP 请求。

  从开始到建立一个完整的 HTTPS 连接一共需要 4 个 RTT。如果是浏览刚刚已经访问过的站点的话，通过 TLS 的会话恢复机制，第三步 TLS 握手能够从 2 RTT 变为 1 RTT。

  **注意：**虽然握手过程有1.5个来回，但是最后客户端向服务器发送的第一条应用数据不需要等待服务器返回的信息，因此握手延时是1*RTT。

- 端口复用和地址复用

  端口复用和地址复用是网络编程中的两个概念，它们的作用是优化网络资源的利用。

  1. 端口复用

  端口复用是指在同一个主机上，多个进程可以同时监听同一个端口。在传统的网络编程中，如果一个进程需要监听某个端口，那么其他进程就不能再监听这个端口了，这就造成了资源的浪费。而端口复用技术可以让多个进程同时监听同一个端口，从而提高了网络资源的利用率。

  在实现时，需要使用SO_REUSEPORT选项，让不同的进程可以绑定同一个端口。

  2. 地址复用

  地址复用是指在同一个主机上，多个进程可以同时绑定同一个IP地址和端口。在传统的网络编程中，如果一个进程需要绑定某个IP地址和端口，那么其他进程就不能再绑定这个IP地址和端口了，这就造成了资源的浪费。而地址复用技术可以让多个进程同时绑定同一个IP地址和端口，从而提高了网络资源的利用率。

  在实现时，需要使用SO_REUSEADDR选项，让不同的网络接口可以使用同一个IP地址。

  需要注意的是，端口复用和地址复用只能在同一个主机上使用，不能跨主机使用。而且，在使用端口复用和地址复用时，需要注意保证各个进程之间的通信不会出现冲突。

- TCP如何感知对方断开链接

  TCP使用一种称为“心跳检测”的机制来感知对方是否断开连接。通过发送称为“keep-alive”消息的特殊TCP数据包，TCP可以检测到对方是否还处于连接状态。如果TCP在一定时间内没有收到对方的响应，则会认为对方已经断开连接。这个时间通常被称为“keep-alive超时时间”，默认情况下为2小时。当然，这个时间可以根据需要进行调整。

- tcp 返回 EGIAN 是什么问题？

  当应用程序在socket中设置O_NONBLOCK属性后，如果发送缓存被占满，send就会返回EAGAIN或EWOULDBLOCK 的错误。

  当需要向socket发送数据时，现将数据压入发送缓存区，并且将socket加入可写事件监听。当socket触发可写事件（EPOLLOUT）时，调用 socket_send函数发送数据，所有数据发送完毕，再清除EPOLLOUT事件。

- close_wait 状态下可以收发数据吗？

  在 `CLOSE_WAIT` 状态下，应用程序已经调用了 `close()` 函数，但是仍然有可能收到对方发来的数据，因此可以继续接收数据。但是，应用程序不能再向对方发送数据，因为连接已经被对方关闭，发送数据会收到 `RST` 响应。在这个状态下，TCP 会等待应用程序处理完所有未读取的数据后，发送 `FIN` 报文给对方，然后进入 `LAST_ACK` 状态等待对方的确认。

- 接收端和发生端之间有个 TCP 长连接，接收端应用层一直不处理缓冲区数据，发送端一直发，最后发送端，接收端，TCP 一些属性，会有什么变化？

  在这种情况下，如果接收端一直不处理缓冲区数据，那么缓冲区会不断累积，直到达到一定的阈值，此时发送端的数据将会被阻塞，因为TCP的拥塞控制会认为网络出现了拥塞，从而触发拥塞避免算法，减少发送速率。同时，发送端和接收端的TCP会根据网络状况自动调整拥塞窗口大小，以达到更好的网络利用率和传输效率。

  在这种情况下，如果发送端一直发送数据，而接收端一直不读取数据，会导致接收端的TCP缓冲区被填满，从而触发TCP的流量控制机制，发送端的数据发送速率将被限制，从而保证接收端的TCP缓冲区不会溢出。同时，发送端和接收端的TCP会根据网络状况自动调整拥塞窗口大小，以达到更好的网络利用率和传输效率。

  如果这种情况持续较长时间，可能会导致发送端和接收端的TCP连接被超时关闭，从而需要重新建立TCP连接。

- UDP 包想一次性发送 2K 的数据，接收端 1K1K 的读，能成功么

  TCP可以，但是UDP不可以。

  TCP是以数据流来发送的，发送端可以是1K1K的发送数据，而接收端的应用程序可以是2K2K地提取数据，也可以一次性全部提走，或者一次只提取几个字节的数据。应用程序所看到的数据是一个整体，或者说是一个流(stream) ，一条消息有多少个字节对应用程序是不可见的，因此TCP协议是面向流的协议，这也是容易出现粘包问题的原因。

  而UDP协议是面向消息的协议，每个UDP字段都是一条消息，应用程序必须以消息为单位提取数据，不能一次性提取任意字节的数据，这和TCP很不相同。TCP协议下，一条消息的发送，无论底层如何分段分片，TCP协议层会把构成整条消息的数据段排序完成后才呈现在内核缓冲区。

- MSS和MTU

  MSS和MTU是TCP/IP协议栈中的两个重要参数，分别代表最大分段大小和最大传输单元。它们的含义和作用如下：

  - MSS（Maximum Segment Size）：指的是TCP数据包中的数据部分的最大长度，不包括TCP头部和IP头部。MSS的大小是由对端的TCP栈在建立连接时协商决定的，通常是MTU减去IP和TCP头部的长度。MSS的大小决定了TCP分段的大小，也就是说，如果TCP发送的数据包长度超过了MSS，那么就需要将数据分成多个MSS大小的分段进行传输。

  - MTU（Maximum Transmission Unit）：指的是网络能够传输的最大的TCP数据包的大小，不包括链路层头部和尾部的长度。MTU的大小是由网络设备决定的，不同的网络设备MTU大小可能不同。如果TCP要发送的数据包长度超过了MTU，那么就需要将数据分成多个MTU大小的分段进行传输。

  MSS和MTU之间的关系是：MSS = MTU - IP头部长度 - TCP头部长度。在TCP建立连接时，双方会协商MSS的大小，以保证TCP数据包不会超过MTU的大小，从而避免IP分片和重组的问题，提高网络传输效率。

- TCP的keep-alive和HTTP的keep-alive有什么区别？

  HTTP 的 Keep-Alive 也叫 HTTP 长连接，该功能是由「应用程序」实现的，可以使得用同一个 TCP 连接来发送和接收多个 HTTP 请求/应答，减少了 HTTP 短连接带来的多次 TCP 连接建立和释放的开销。

  TCP 的 Keepalive 也叫 TCP 保活机制，该功能是由「内核」实现的，当客户端和服务端长达一定时间没有进行数据交互时，内核为了确保该连接是否还有效，就会发送探测报文，来检测对方是否还在线，然后来决定是否要关闭该连接。

- 延时与吞吐率的区别

  延迟（Latency）是指从发送数据到接收数据所需的时间，也就是数据在网络中传输的时间。延迟一般是以毫秒（ms）为单位进行计算，是指网络传输速度的快慢，通常用于测量网络的响应速度。

  吞吐率（Throughput）是指在单位时间内通过网络的数据量，通常以比特每秒（bps）或字节每秒（Bps）为单位进行计算，是指网络的传输能力。吞吐率通常用于测量网络的容量大小，即网络传输速率的大小。

  延迟和吞吐率都是网络性能的重要指标，但它们的重点不同。延迟是关注网络的响应速度，而吞吐率则关注网络的传输能力。在实际应用中，延迟和吞吐率都是需要考虑的因素，不同的应用场景需要不同的重点。

- TCP的拥塞控制和流量控制有什么区别？

  流量控制解决因发送方发送数据太快而导致接收方来不及接收使接收方缓存溢出的问题。流量控制的基本方法就接收方根据自己的接收能力控制发送方的发送速率，TCP采用接收方控制发送方发送窗口大小的方法来实现在TCP连接上的流量控制。

  流量控制利用滑动窗口协议控制发送端流量，是为了解决发送数据过快导致接收方来不及接收的问题。接收方会发送流量控制报文，通知发送方窗口大小，发送方发送的数据大小不能超过窗口大小。如果发送者发送数据过快，接收者来不及接收，那么就会有报文丢失。为了避免报文丢失，控制发送者的发送速度，使得接收者来得及接收，这就是流量控制。流量控制根本目的是防止报文丢失，它是构成TCP可靠性的一方面。

  拥塞控制就是防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不致过载。TCP的发送方维持一个叫做拥塞窗口的状态变量。拥塞窗口的大小取决于网络的拥塞程度，当网络拥塞时减小拥塞窗口的大小，控制TCP发送方的发送速率。TCP发送方的发送窗口大小取接收窗口和拥塞窗口的最小值。

  - 区别

  流量控制：流量控制是作用于接收者的，控制发送者的发送速度从而使接收者来得及接收，防止报文丢失。

  拥塞控制：拥塞控制是作用于网络的，防止过多的数据注入到网络中，避免出现网络负载过大的情况。常用的方法就是：慢启动、拥塞避免、拥塞发生、快速恢复。

- TCP是全双工的，HTTP是哪种？全双工半双工单工？

  1. 单工： 数据传输只允许在一个方向上的传输，只能一方来发送数据，另一方来接收数据并发送。例如：对讲机
  2. 半双工：数据传输允许两个方向上的传输，但是同一时间内，只可以有一方发送或接受消息。例如：打电话
  3. 全双工：同时可进行双向传输。例如：`websocket`

  HTTP是半双工的。 

  在半双工通信中，通信双方都可以发送和接收数据，但不能同时进行。在HTTP中，客户端向服务器发送请求，服务器响应请求并返回数据，此时客户端不能再向服务器发送请求，直到服务器响应完毕。因此，HTTP是一种半双工通信协议。 
  
  相比之下，TCP是一种全双工通信协议，因为在TCP连接中，通信双方可以同时进行发送和接收数据。

- socket调用write返回值表示的意义

  1. 当read()或者write()函数返回值大于0时，表示实际从缓冲区读取或者写入的字节数目；
  2. 当read()函数返回值为0时，表示对端已经关闭了 socket，这时候也要关闭这个socket，否则会导致socket泄露。netstat命令查看下，如果有closewait状态的socket,就是socket泄露了。当write()函数返回0时，表示当前写缓冲区已满，是正常情况，下次再来写就行了；
  3. 当read()或者write()返回-1时，一般要判断errno。如果errno == EINTR,表示系统当前中断了，直接忽略。如果errno == EAGAIN或者EWOULDBLOCK，非阻塞socket直接忽略；如果是阻塞的socket,一般是读写操作超时了，还未返回。这个超时是指socket的SO_RCVTIMEO与SO_SNDTIMEO两个属性。所以在使用阻塞socket时，不要将超时时间设置的过小。不然返回了-1，你也不知道是socket连接是真的断开了，还是正常的网络抖动。一般情况下，阻塞的socket返回了-1，都需要关闭重新连接；
  4. 如果返回值为正数，表示成功发送了指定数量的字节；如果返回值为0，表示对方已经关闭了连接；如果返回值为-1，表示发送失败，此时可以通过errno来确定错误的具体原因。 在发送数据时，write函数会尽可能地将数据写入Socket的发送缓冲区，然后返回已经写入的字节数。如果写入的数据量超过了发送缓冲区的大小，write函数可能会阻塞，等待发送缓冲区有足够的空间。如果在一定时间内发送缓冲区还没有空间，write函数可能会返回-1，并设置errno为EAGAIN或EWOULDBLOCK，表示发送缓冲区已满，需要等待一段时间再尝试发送。
  
- 路由器和交换器的区别

  1. 工作层次不同 路由器工作在网络层，主要负责不同网络之间的数据转发和路由选择；而交换机工作在数据链路层，主要负责同一网络内部的数据交换。
  1. 转发方式不同 路由器使用IP地址进行转发，根据IP地址进行路由选择；而交换机使用MAC地址进行转发，根据MAC地址进行数据交换。
  1. 范围不同 路由器通常连接不同的网络，可以跨越不同的地域范围；而交换机通常连接同一网络内的设备，范围相对较小。
  1. 能力不同 路由器具备路由选择的功能，可以在不同网络之间进行数据转发；而交换机只能在同一网络内部进行数据交换。
  1. 安全性不同 由于路由器可以进行路由选择和网络隔离，因此具有更高的安全性；而交换机只能在同一网络内部进行数据交换，安全性相对较低。

- Accept函数与三次握手关系

  1. 当客户端调用connect时，触发了连接请求，向服务器发送了SYN J包，这时connect进入阻塞状态；
  2. 服务器监听到连接请求，即收到SYN J包，调用accept函数接收请求，向客户端发送SYN K ，ACK J+1，这时accept进入阻塞状态；
  3. 客户端收到服务器的SYN K ，ACK J+1之后，这时connect返回，并对SYN K进行确认；服务器收到ACK K+1时，accept返回，至此三次握手完毕，连接建立。


- IP层如何找MAC地址？如果对应IP不在局域网呢

  在局域网内，IP地址和MAC地址之间的映射关系可以通过ARP协议来获取。当一台主机需要发送数据包给另一台主机时，它会首先检查目标IP地址是否在本地网络中。如果是，它会使用ARP广播来询问目标主机的MAC地址。目标主机收到ARP请求后，会回复一个ARP响应包，其中包含自己的MAC地址。

  如果目标IP地址不在本地网络中，发送主机会将数据包发送到默认网关。默认网关会根据路由表将数据包转发到下一个网络。在这种情况下，发送主机会使用ARP广播来获取默认网关的MAC地址，然后将数据包发送到默认网关。默认网关收到数据包后，会根据路由表将数据包转发到目标主机所在的网络。

  如果攻击者在局域网中进行ARP欺骗攻击，它会发送伪造的ARP响应包，欺骗其他主机将攻击者的MAC地址与目标IP地址关联起来。这样，攻击者就可以拦截、修改或重定向其他主机的数据流量，从而实现窃取信息或进行中间人攻击等恶意行为。

- 为什么DNS使用UDP而不是TCP？

  DNS（Domain Name System）使用UDP（User Datagram Protocol）而不是TCP（Transmission Control Protocol）是因为：

  1. UDP是无连接的，没有建立和维护连接的开销，可以更快地完成查询和响应，适合短消息的传输。而TCP是面向连接的，需要进行三次握手建立连接，然后再进行数据传输，会增加一定的延迟和开销。

  2. DNS是一个轻量级的协议，一般传输的数据包较小，可以通过UDP一次性传输完整的数据包，而TCP需要将数据包分成多个段进行传输，增加了数据包的大小和传输的开销。

  3. DNS使用UDP可以更好地处理网络拥塞的情况，因为UDP不会对网络拥塞作出反应，而TCP会根据网络拥塞情况调整数据传输的速率，可能会导致延迟和丢包。

  虽然UDP存在一定的缺陷，如可能丢包、重复、乱序等，但对于DNS这样的应用场景，这些问题并不会对查询和响应的准确性产生太大影响。而且，DNS还有一些机制可以处理UDP传输中的一些问题，如使用DNSSEC（DNS Security Extensions）保证数据的完整性和安全性，使用EDNS（Extension mechanisms for DNS）扩展DNS的功能。


- ARP攻击/ARP欺骗

  ARP（Address Resolution Protocol）攻击，也叫ARP欺骗，是一种利用局域网上的ARP协议缺陷，欺骗目标主机的MAC地址，从而达到网络攻击的目的。

  攻击者通过伪造ARP响应包，将自己的MAC地址伪装成目标主机的MAC地址，然后发送给局域网上的其他主机，使得这些主机将攻击者的MAC地址缓存起来，从而将攻击者伪装成目标主机。这样，攻击者就可以通过ARP欺骗，窃取目标主机的数据包，或者劫持目标主机的网络连接，进行中间人攻击等恶意行为。

  ARP攻击可以分为主动式攻击和被动式攻击。主动式攻击是指攻击者主动伪造ARP响应包，欺骗目标主机；被动式攻击是指攻击者监听网络上的ARP请求和响应包，然后进行欺骗。

  为了防止ARP攻击，可以采取以下措施：

  1. 使用静态ARP表，手动维护IP地址和MAC地址的对应关系。

  2. 使用动态ARP缓存，设置ARP缓存的过期时间，定期清除缓存。

  3. 使用ARP防火墙，限制ARP请求和响应包的发送和接收。

  4. 使用虚拟局域网（VLAN）技术，将不同的主机分隔开来，减少攻击面。

  5. 使用加密技术，保护数据包的安全传输。

- 网际控制报文协议ICMP的过程

  网际控制报文协议（ICMP）是一种用于在IP网络上发送错误消息的协议。它的主要作用是在网络中传递控制信息和错误消息。以下是 ICMP 的过程：

  1. 发送方向目标主机发送 ICMP 报文。

  2. 目标主机接收到 ICMP 报文后，根据报文类型进行相应的处理。例如，如果是 Ping 请求报文，则目标主机会返回 Ping 应答报文。

  3. 如果目标主机无法处理 ICMP 报文，则会向发送方发送一个 ICMP 错误报文，告诉发送方发生了什么错误。

  4. 发送方接收到 ICMP 错误报文后，可以根据报文内容进行相应的处理。例如，如果是目标主机不可达的错误报文，则发送方可以尝试使用其他路径发送数据包。

  在 ICMP 过程中，主要使用了 IP 协议和 ICMP 协议。IP 协议用于将 ICMP 报文从发送方传输到目标主机，而 ICMP 协议则用于发送控制信息和错误消息。

- ping 的过程，分别用到了哪些协议

  Ping 的过程主要用到了两个协议：ICMP 和 IP。

  Ping 是一种用于测试网络连接的常用命令，其原理是向目标主机发送 ICMP 回显请求，然后等待目标主机返回 ICMP 回显应答。在这个过程中，Ping 命令首先使用 IP 协议将 ICMP 数据包发送到目标主机，然后目标主机收到 ICMP 数据包后，使用 ICMP 协议进行回应。具体来说，Ping 的过程如下：

  1. 发送端主机构建 ICMP 回显请求数据包，并使用 IP 协议将数据包发送到目标主机。

  2. 目标主机接收到 ICMP 数据包后，使用 ICMP 协议回应 ICMP 回显应答数据包。

  3. 发送端主机接收到 ICMP 回显应答数据包后，计算出往返时间（RTT），并显示在 Ping 命令的输出中。

  在这个过程中，Ping 命令使用了 ICMP 协议来发送和接收数据包，同时也使用了 IP 协议来进行数据包的路由和传输。

- 动态主机配置协议DHCP的过程

  DHCP（Dynamic Host Configuration Protocol，动态主机配置协议）是一种网络协议，它可以自动为计算机分配IP地址、子网掩码、默认网关、DNS服务器等网络配置信息，从而简化网络管理和配置。DHCP的过程如下：

  1. DHCP Discover：客户端在加入网络时发送一个广播消息，请求DHCP服务器提供IP地址和其他配置信息。

  2. DHCP Offer：DHCP服务器接收到客户端的广播消息后，向客户端发送一个包含IP地址和其他配置信息的DHCP Offer消息。

  3. DHCP Request：客户端收到DHCP Offer消息后，向DHCP服务器发送一个DHCP Request消息，确认接受所提供的配置信息。

  4. DHCP Acknowledge：DHCP服务器收到客户端的DHCP Request消息后，向客户端发送一个DHCP Acknowledge消息，确认分配IP地址和其他配置信息。

  5. DHCP Lease Renewal：客户端在租期到期前向DHCP服务器发送DHCP Request消息，请求续租IP地址和其他配置信息。

  6. DHCP Lease Expired：如果客户端在租期到期后没有向DHCP服务器发送DHCP Request消息，则DHCP服务器会释放该IP地址，以便其他客户端使用。

  通过DHCP，网络管理员可以轻松管理网络中的IP地址和其他配置信息，避免了手动配置的繁琐和错误，提高了网络管理的效率。

- NAT的工作原理

  NAT（Network Address Translation，网络地址转换）是一种网络协议，主要用于将内部网络的私有IP地址转换为合法的公网IP地址，以便实现内部网络与外部网络的通信。NAT的主要工作流程可以概括如下：
  
  1. 在内部网络中，客户端设备发送数据包到公网服务器时，数据包的源IP地址是客户端设备的私有IP地址，目标IP地址是公网服务器的公网IP地址。
  2. NAT设备接收到这个数据包后，会将源IP地址和源端口号进行修改，将其改为NAT设备的公网IP地址和一个随机的端口号，并记录这个映射关系。
  3. NAT设备将修改后的数据包发送到公网服务器。
  4. 公网服务器接收到数据包后，将响应数据包发送回NAT设备，并将目标IP地址和目标端口号设置为NAT设备的公网IP地址和之前记录的随机端口号。
  5. NAT设备接收到响应数据包后，根据记录的映射关系将目标IP地址和目标端口号还原成客户端设备的私有IP地址和端口号，并将响应数据包发送回客户端设备。

  NAT设备在转换IP地址时，会根据每个数据包的源IP地址、目标IP地址、源端口号和目标端口号等信息来进行映射。因此，在内网中，不同设备的私有IP地址和端口号不同，NAT设备可以根据这些信息来区分不同设备发送的数据包，并对其进行转换。
  
  当内网中的设备之间进行通信时，数据包的源IP地址和目标IP地址都是内网中的私有IP地址，NAT设备可以根据这些信息来确定数据包的目标设备，并将其传递到相应的设备。在这种情况下，NAT设备不需要对数据包进行IP地址转换。


- TCP 怎么保证发送数据顺序性（数据包乱序问题）？

  在TCP协议中，为了保证发送数据的顺序性，使用了以下几种机制：

  1. 序列号：TCP协议在发送数据时，会给每个数据包分配一个唯一的序列号，用于区分每个数据包。接收方会通过序列号来确定数据包的顺序，以及是否有丢失的数据包。

  2. 确认应答：接收方在收到数据包后，会向发送方发送一个确认应答（ACK），用于告诉发送方已经接收到数据包。发送方在收到ACK后，会认为该数据包已经成功发送，并将下一个数据包发送出去。

  3. 滑动窗口：TCP协议使用滑动窗口机制来控制发送方发送数据的速度。滑动窗口的大小是动态调节的，接收方可以通过发送窗口（Receiver Window）来告诉发送方可以接收多少数据，发送方将根据发送窗口的大小来控制发送数据的速度。

  通过上述机制，TCP协议可以保证发送数据的顺序性。发送方会按照数据的顺序发送数据包，并等待接收方的确认应答。如果接收方没有收到某个数据包，则会通知发送方重新发送该数据包。同时，滑动窗口机制可以帮助发送方控制发送数据的速度，避免发送过快导致数据包丢失或错误。

- TCP的序列号为什么是随机的？能不能固定从1开始？为什么？

  TCP序列号是为了保证数据传输的可靠性而设计的，它的随机性可以提高数据传输的安全性和可靠性。具体原因如下：

  1. 防止数据包重复：TCP序列号可以防止数据包在传输过程中重复发送或被重复接收，从而保证数据传输的可靠性。

  2. 防止数据包被篡改：TCP序列号可以防止数据包被篡改或冒充，从而保证数据传输的安全性。

  3. 防止攻击者利用序列号进行攻击：如果TCP序列号是固定的，攻击者可以通过猜测序列号来执行攻击，例如TCP SYN Flood攻击。

  因此，TCP序列号通常是随机生成的，以提高数据传输的安全性和可靠性。如果TCP序列号从1开始，攻击者可以轻易地猜测下一个序列号，并进行攻击。此外，TCP序列号的随机性可以保证TCP连接的唯一性，避免不同的连接使用相同的序列号，从而导致数据混乱或错误。

- TCP滑动窗口最大值

  TCP滑动窗口的最大值取决于接收方和发送方的实现以及网络状况。TCP滑动窗口的大小是动态调整的，发送方和接收方会根据网络状况和对方的处理能力来动态调整滑动窗口的大小。

  在TCP协议中，发送方和接收方都有一个窗口大小的参数，分别称为发送窗口和接收窗口。发送方的发送窗口表示可以发送的数据量，而接收方的接收窗口表示可以接收的数据量。发送方和接收方会通过TCP报文段中的窗口字段来告知对方它们的窗口大小。

  发送方会根据接收方的接收窗口来调整自己的发送窗口大小，以控制发送数据的速率。如果接收方的接收窗口变小，发送方就会减小自己的发送窗口，以避免发送过多的数据导致数据包丢失。如果接收方的接收窗口变大，发送方就会增大自己的发送窗口，以提高发送数据的速率。

  因此，TCP滑动窗口的最大值取决于网络状况、对方的处理能力以及实现的具体细节。在实际应用中，TCP滑动窗口的最大值一般会根据具体情况进行调整，以达到最优的网络性能。

- 客户端服务端的窗口是怎么设定的，服务端假设能力比较强，窗口会大一些，客户端能力比较弱，窗口会小一些吗

  在TCP协议中，客户端和服务端的窗口大小是由其接收缓冲区大小和拥塞窗口大小共同决定的。接收缓冲区大小是指能够存储接收数据的缓冲区大小，而拥塞窗口大小是指在网络拥塞控制的机制下，能够用于发送数据的窗口大小。因此，客户端和服务端的窗口大小都是动态调整的，根据网络状况和拥塞情况进行自适应调整。

  一般来说，服务端的接收能力比客户端强，因此服务端的接收缓冲区和拥塞窗口大小可能会比客户端大一些。但这并不是绝对的，因为客户端和服务端的实际能力取决于多种因素，如网络带宽、延迟、负载等等。因此，客户端和服务端的窗口大小需要根据具体情况进行调整，以达到最佳的数据传输效率和可靠性。

  需要注意的是，客户端和服务端的窗口大小不仅受到自身能力的限制，还受到网络状况和其他设备的影响。在实际应用中，需要进行网络监测和流量控制，以便及时调整窗口大小，避免网络拥塞和数据丢失。


- UDP怎么实现TCP的拥塞控制？

  UDP是一种无连接的传输协议，它不提供可靠性、流量控制和拥塞控制的机制，因此在网络拥塞的情况下容易出现数据丢失和网络性能下降的问题。相比之下，TCP是一种基于连接、可靠性高、流量控制和拥塞控制都较为完善的传输协议。

  虽然UDP本身并不提供拥塞控制的机制，但是可以通过一些手段来实现类似于TCP的拥塞控制。以下是几种常见的实现方式：

  1. 使用带拥塞控制的UDP协议：一些厂商和组织提供了一些基于UDP的带拥塞控制的协议，例如QUIC、SCTP等。这些协议在UDP的基础上增加了可靠性、流量控制和拥塞控制等机制，可以提供类似于TCP的性能。

  2. 自行实现拥塞控制：应用程序可以自行实现拥塞控制的算法，例如类似于TCP的拥塞窗口算法。应用程序可以根据网络拥塞程度动态地调整发送速率，避免网络拥塞导致数据丢失和网络性能下降的问题。

  3. 使用反馈机制：应用程序可以通过向接收端发送反馈数据包，获取网络拥塞情况。例如，可以通过接收端返回的ACK数据包的延迟时间、重传次数等信息来判断网络拥塞情况，并根据情况调整发送速率。

  需要注意的是，UDP本身并不提供拥塞控制的机制，因此实现类似于TCP的拥塞控制需要应用程序进行处理。同时，实现拥塞控制可能会增加应用程序的复杂性和开发成本，需要根据实际情况进行权衡。

- TIME_WAIT状态会导致什么问题，怎么解决

  TIME_WAIT状态是指TCP连接关闭后，等待一段时间（通常为2倍MSL，即两倍的最长报文段生存时间）才会释放连接。TIME_WAIT状态可以避免网络中残留的数据包影响下一次连接，但同时也会导致以下问题：

  1. 资源浪费：在高并发场景下，TIME_WAIT状态会占用大量的系统资源，导致资源浪费。

  2. 端口耗尽：在短时间内频繁创建和销毁TCP连接时，TIME_WAIT状态会占用大量的端口资源，导致端口耗尽问题。

  为了解决TIME_WAIT状态带来的问题，可以采取以下措施：

  1. 调整TCP参数：可以通过修改操作系统的TCP参数来缩短TIME_WAIT状态的时间，例如修改tcp_fin_timeout参数等。

  2. 优化应用程序：在应用程序中，可以采用连接池等技术来复用TCP连接，减少TCP连接的创建和销毁，从而避免TIME_WAIT状态的产生。

  3. 使用SO_REUSEADDR选项：在TCP连接关闭时，可以使用SO_REUSEADDR选项来重用端口，避免端口耗尽问题。

  4. 使用负载均衡器：在高并发场景下，可以使用负载均衡器来分发请求，从而减少单个服务器上的TCP连接数量，缓解TIME_WAIT状态带来的负面影响。

  需要注意的是，对TCP参数的调整需要根据具体的应用场景和操作系统而定，同时也需要谨慎进行调整，避免引入其他问题。

- 半连接、半打开、半关闭

  半连接、半打开和半关闭都是TCP协议中的概念，具体含义如下：

  1. 半连接（SYN_SENT状态）：指TCP客户端向服务器发出连接请求，但是服务器还没有进行确认的状态。在这种状态下，TCP客户端等待服务器的响应，如果服务器不响应或响应超时，客户端会重试连接请求。

  2. 半打开（SYN_RCVD状态）：指TCP服务器收到客户端的连接请求后，向客户端发送确认消息，但是还没有完成连接的状态。在这种状态下，TCP服务器等待客户端的确认消息，如果客户端没有响应或响应超时，服务器会重新发送确认消息。

  3. 半关闭（FIN_WAIT_1、FIN_WAIT_2状态）：指TCP连接中的一端主动关闭连接，但是另一端还没有进行确认的状态。在这种状态下，主动关闭的一端等待对方的确认消息，如果对方没有响应或响应超时，主动关闭的一端会重新发送关闭请求。

  需要注意的是，半连接、半打开和半关闭都属于TCP协议中的状态，用于描述TCP连接的建立、维护和关闭过程。在实际应用中，这些状态会对TCP连接的性能和可靠性产生一定的影响，因此需要进行合理的配置和优化。

- 如何关闭处于close_wait 状态的TCP连接？

  在网络编程中，当一个连接的一方发送了 FIN 包（结束包）但对方没有响应时，这个连接就会处于 CLOSE_WAIT 状态。如果有大量的 CLOSE_WAIT 连接堆积在服务器上，可能会导致服务器资源浪费和性能下降。

  要关闭这些 CLOSE_WAIT 连接，可以使用以下几种方法：

  1. 重启应用程序或者服务器：重启应用程序或者服务器可以清除所有的 CLOSE_WAIT 连接，但这种方法会中断当前正在进行的连接和会话，可能会导致用户体验下降。

  2. 调整 TCP 超时时间：可以通过调整 TCP 超时时间来减少 CLOSE_WAIT 连接的数量。在 Linux 系统中，可以使用 sysctl 命令来调整 TCP 超时时间。例如，可以使用以下命令将 TCP 超时时间设置为 60 秒：

     ```
     sudo sysctl -w net.ipv4.tcp_fin_timeout=60
     ```

  3. 使用 TCPKILL 工具：TCPKILL 是一个可以强制关闭指定连接的工具。可以使用以下命令安装 TCPKILL 工具：

     ```
     sudo apt-get install dsniff
     ```

     安装完成后，可以使用以下命令关闭指定 IP 地址和端口号的连接：

     ```
     sudo tcpkill host <IP> and port <port>
     ```

     其中，<IP> 表示要关闭的连接的 IP 地址，<port> 表示要关闭的连接的端口号。

  总之，关闭 CLOSE_WAIT 连接可以使用重启应用程序或者服务器、调整 TCP 超时时间、使用 TCPKILL 工具等方法。需要根据具体情况选择合适的方法来解决问题。

- 如何判断两个 ip 是否在同一个子网

  判断两个 IP 是否在同一个子网，可以根据两个 IP 地址和它们对应的子网掩码来进行计算，具体步骤如下：

  1. 将两个 IP 地址和它们对应的子网掩码转换成二进制形式。

  2. 对两个 IP 地址和子网掩码进行逐位与运算，得到网络地址。即将两个 IP 地址中每一位与对应的子网掩码中的每一位进行与运算，得到网络地址。

  3. 判断两个 IP 地址的网络地址是否相同，如果相同则说明它们在同一个子网中。

  例如，假设有两个 IP 地址分别为 192.168.1.100 和 192.168.2.100，它们对应的子网掩码分别为 255.255.255.0 和 255.255.0.0。则进行如下计算：

  - 将两个 IP 地址和子网掩码转换成二进制形式：
    ```c
    192.168.1.100 -> 11000000 10101000 00000001 01100100
    255.255.255.0 -> 11111111 11111111 11111111 00000000
    192.168.2.100 -> 11000000 10101000 00000010 01100100
    255.255.0.0 -> 11111111 11111111 00000000 00000000
    ```

  - 对两个 IP 地址和子网掩码进行逐位与运算，得到网络地址：

    ```c
    192.168.1.100 & 255.255.255.0 -> 11000000 10101000 00000001 00000000
    192.168.2.100 & 255.255.0.0 -> 11000000 10101000 00000000 00000000
    ```

  - 判断两个 IP 地址的网络地址是否相同：

    ```c
    11000000 10101000 00000001 00000000 = 192.168.1.0
    11000000 10101000 00000000 00000000 = 192.168.0.0
    ```

  由此可见，这两个 IP 地址的网络地址不相同，因此它们不在同一个子网中。

  注意，如果两个 IP 地址对应的子网掩码不同，则需要将它们转换成同一个掩码后再进行计算。具体可以使用子网掩码的长度来进行转换。例如，将子网掩码 255.255.255.0 转换成子网掩码长度为 24，将子网掩码 255.255.0.0 转换成子网掩码长度为 16。然后将两个 IP 地址按照相同的子网掩码长度进行逐位与运算，得到它们的网络地址，再进行比较。

- https会不会出现中间人攻击

  HTTPS 协议通过使用 SSL/TLS 加密技术，可以提供一定程度的数据传输安全性，防止数据在传输过程中被窃取、篡改或伪造。但是，HTTPS 协议仍然有可能被中间人攻击。

  中间人攻击是指攻击者通过篡改或仿冒目标服务器的证书，使得客户端与攻击者之间建立起安全连接，从而获取客户端与服务器之间的通信内容。攻击者可以在中间人攻击过程中窃取敏感信息、篡改数据包、劫持用户会话等。

  中间人攻击主要有两种方式：

  1. 篡改证书：攻击者可以通过攻击证书颁发机构、DNS 劫持等方式，获取目标服务器的证书，然后自己生成一个伪造证书，将伪造证书发送给客户端，使客户端认为自己与目标服务器建立了安全连接。攻击者可以在客户端和服务器之间进行数据窃取、篡改等操作。

  2. 仿冒服务器：攻击者可以自己建立一个服务器，将自己的证书伪装成目标服务器的证书，然后将自己的服务器地址伪装成目标服务器的地址，欺骗客户端与自己建立安全连接。攻击者可以在客户端和服务器之间进行数据窃取、篡改等操作。

  为了防止中间人攻击，HTTPS 协议采用了一些安全机制，如数字证书、数字签名、证书链、证书撤销等。数字证书可以证明服务器的身份和公钥，数字签名可以保证证书的完整性和真实性，证书链可以证明证书的信任链，证书撤销可以及时撤回失效的证书。此外，HTTPS 协议还包括了一些安全头部和安全策略，可以进一步提高安全性。

  虽然 HTTPS 协议可以提供一定的安全保障，但是仍然可能被中间人攻击，因此在使用 HTTPS 协议时，应注意确保证书的真实性和完整性，避免使用不安全的网络环境，以及使用其他安全机制和策略来提高安全性。

- IPv4和IPv6的区别

  IPv4和IPv6是两种不同的IP地址格式。IPv4是目前广泛使用的IP地址格式，而IPv6则是一个新的IP地址格式，旨在解决IPv4地址短缺和安全性等问题。以下是它们之间的主要区别：

  1. 地址长度：IPv4地址长度为32位（即4个字节），而IPv6地址长度为128位（即16个字节）。

  2. 地址数量：由于IPv4地址长度的限制，IPv4地址数量有限，只有约43亿个可用的地址。而IPv6地址长度更长，可以提供更多的地址空间，理论上有3.4×10^38个可用的地址，足以支持未来的互联网发展。

  3. 地址表示：IPv4地址通常表示为点分十进制数，如192.168.0.1。而IPv6地址通常表示为八组四位十六进制数，以冒号分隔，如2001:0db8:85a3:0000:0000:8a2e:0370:7334。

  4. 协议支持：IPv4是互联网最早的协议，广泛使用于互联网中的各种应用。而IPv6是IPv4的升级版，支持更多的协议，如IPSec安全协议，可以提供更高的安全性和可靠性。

  5. 网络性能：IPv6可以提供更快的网络速度和更低的延迟，可以提高网络性能和吞吐量。

  总的来说，IPv6相对于IPv4来说是一种更加先进、更加安全、更加可靠和更加灵活的IP地址格式，可以满足未来互联网的需求。但由于IPv6的推广和普及需要时间和成本，目前IPv4仍然是互联网主要的IP地址格式，两种格式仍然需要共存一段时间。

- 子网掩码的作用

  子网掩码是一种用于划分IP地址的技术，它指定了一个IP地址中哪些部分是网络地址，哪些部分是主机地址。子网掩码的作用主要有以下几个方面：

  1. 确定网络地址和主机地址：子网掩码可以将一个IP地址分成两部分，即网络地址和主机地址，从而确定该IP地址所属的网络和主机。

  2. 划分子网：通过修改子网掩码，可以将一个网络划分成多个子网。这样可以更好地管理网络资源，提高网络的性能和安全性。

  3. 控制广播域：子网掩码可以控制广播域的大小，从而减少广播包的数量，提高网络的性能。

  4. 确定有效IP地址范围：子网掩码可以确定一个网络中可用的IP地址范围，从而帮助管理员进行地址分配和管理。

  5. 提高网络安全性：子网掩码可以限制不同网络之间的通信，从而提高网络的安全性。

  需要注意的是，子网掩码的设置必须与网络中所有设备的IP地址一致，否则就会出现通信故障。此外，子网掩码的设置也需要考虑到网络的规模和需求，设置不当会影响网络的性能和安全性。

- 每一次客户端发送一个tcp包，服务端都会刷新定时器吗

  在TCP协议中，每当服务端接收到客户端发送的数据包时，服务端都会回复一个ACK确认报文，告诉客户端已经成功接收到数据包。在回复ACK报文的同时，服务端会重置定时器，以便在一定时间内等待客户端发送下一个数据包。因此，可以说每一次客户端发送TCP包，服务端都会刷新定时器。

  具体来说，在TCP协议中，如果服务端在一定时间内没有收到客户端的数据包，就会认为网络出现了问题，会触发超时重传机制，重新发送之前发送过的数据包。因此，为了避免不必要的超时重传，服务端需要设置合适的定时器超时时间，以便在规定时间内等待客户端的数据包。

  需要注意的是，TCP协议中的定时器超时时间是动态调整的，根据网络状况和拥塞情况进行自适应调整，以达到更好的性能和可靠性。因此，服务端在刷新定时器时，需要根据具体情况进行调整，以保证数据传输的效率和可靠性。

- 如果有很多连接的第三次握手丢包，会发生什么？如何解决这样的问题？

  如果有很多连接的第三次握手丢包，会导致连接无法建立，从而导致客户端无法与服务端通信。

  在TCP协议中，当客户端发送SYN包后，服务端会回复一个SYN+ACK包作为确认，然后客户端再回复一个ACK包，完成三次握手。如果第三次握手的ACK包丢失，服务端会一直等待客户端的回复，而客户端会认为连接已经建立，等待服务端的响应。这样就会导致连接无法建立。

  为了解决这个问题，可以采取以下措施：

  1. 增加重传次数：TCP协议中有一个重传机制，当一个包没有得到确认时，会进行多次重传。可以通过增加重传次数来提高连接建立的成功率。

  2. 减小重传超时时间：TCP协议中的重传时间间隔会逐渐增加，如果逐渐增加的速度过慢，就会导致连接建立的时间过长。可以通过减小重传超时时间，使得重传速度更快，从而提高连接建立的成功率。

  3. 使用TCP Fast Open（TFO）：TFO是一种优化TCP连接建立的机制，它允许在第一次握手时传输数据，从而避免第三次握手的延迟。使用TFO可以有效地提高连接建立的成功率。

  4. 增加服务端的并发处理能力：如果服务端的并发处理能力不足，就会导致连接建立的延迟增加。可以通过增加服务端的处理能力来加快连接建立的速度。

  需要注意的是，解决连接建立的延迟问题需要根据具体情况进行调整，不同的应用场景可能需要采取不同的措施。在实际应用中，需要根据具体情况进行优化，以达到最佳的性能和稳定性。

- 哪些业务适合长连接，哪些适合短链接

  一般来说，长连接适合于需要频繁通信的业务，而短链接适合于单次请求完成即可的业务。

  下面是一些常见的业务场景和对应的连接方式：

  1. 实时通信：长连接。例如聊天室、在线游戏等，需要保持与服务器的连接，实时发送和接收数据。

  2. 长轮询：长连接。例如在线聊天、在线客服等，客户端向服务器发送请求后，服务器会阻塞等待新的消息，直到有新的消息到来或者超时才返回响应。

  3. 文件上传下载：短连接。例如HTTP文件下载，客户端向服务器发送请求，服务器返回文件数据，传输完成即可关闭连接。

  4. Web应用：短连接。例如HTTP网页请求，客户端向服务器发送请求，服务器返回网页内容，传输完成后关闭连接。

  5. 数据库访问：短连接。例如MySQL数据库访问，客户端向服务器发送SQL语句，服务器返回查询结果，传输完成后关闭连接。

  6. 定时任务：长连接或短连接。如果定时任务需要频繁执行，则可以使用长连接，保持与服务器的连接，定时发送请求执行任务。如果定时任务不需要频繁执行，则可以使用短连接，每次执行任务时建立连接，执行完成后关闭连接。

  需要注意的是，连接的建立和断开都需要消耗一定的资源，因此过多的长连接或短连接都会对服务器产生一定的压力。在设计应用时，需要根据具体业务场景和实际情况选择适当的连接方式，以达到最优的性能和资源利用率。

- 如果你访问一个网站很慢，怎么排查和解决

  如果访问一个网站很慢，可以按照以下步骤进行排查和解决：

  1. 检查网络连接：首先需要检查自己的网络连接是否正常。可以通过打开其他网站或者使用ping或traceroute命令测试网络是否正常。

  2. 清除浏览器缓存：浏览器缓存可能会导致网站访问变慢，可以尝试清除浏览器缓存并重新访问网站。

  3. 检查DNS解析：DNS解析也可能是导致网站访问变慢的原因之一。可以使用nslookup或dig命令检查DNS解析是否正常，如果不正常，可以尝试切换到其他DNS服务器。

  4. 检查网站服务器：网站服务器可能出现宕机或者负载过高等问题，可以使用ping或traceroute命令检查网站服务器是否正常，如果不正常，可以联系网站管理员。

  5. 检查网络延迟：网络延迟也可能导致网站访问变慢，可以使用网络诊断工具（如ping或traceroute）检查网络延迟是否过高，如果过高，可以尝试使用VPN或者更换网络环境。

  6. 检查网站内容：网站内容过大或者包含大量的媒体文件可能会导致网站访问变慢，可以使用浏览器的开发者工具检查网站的加载时间和资源大小，如果过大，可以尝试优化网站内容或者使用CDN加速服务。

  7. 使用其他浏览器或设备：如果以上方法都没有解决问题，可以尝试使用其他浏览器或设备访问网站，以确定问题是否与浏览器或设备有关。

  总之，排查和解决网站访问变慢的问题需要综合考虑多方面因素，并且需要有耐心和细心地进行排查和测试。

- TCP客户端与服务端建立了连接，两种情况分别会怎样：1. 服务端进程突然崩溃；2. 服务器突然断电 

  在TCP客户端与服务端建立了连接之后，如果服务端进程突然崩溃或服务器突然断电，会发生以下情况：

  1. 服务端进程突然崩溃：

     如果服务端进程突然崩溃，客户端会收到一个TCP RST（reset）报文段，表示连接被重置了。此时客户端的socket会进入CLOSED状态，连接被关闭。如果客户端在等待服务端的数据时，也会收到一个SIGPIPE信号，表示管道破裂，因为客户端已经关闭了该连接，无法再从服务端读取数据。

  2. 服务器突然断电：

     如果服务器突然断电，客户端会一直等待服务端的响应，直到超时。TCP协议会在一定时间内重试连接，如果重试多次之后仍然无法建立连接，则会返回一个错误码，表示连接失败。如果客户端在等待服务端的数据时，也会一直等待，直到超时，此时客户端的socket会进入CLOSE_WAIT状态，表示客户端已经关闭了连接，但是仍然等待服务端发送FIN报文段，服务端如果在重启后发送FIN报文段，客户端会回复ACK报文段，最终连接被关闭。

  需要注意的是，TCP协议保证了数据传输的可靠性和有序性，但是对于连接的建立和维护，也需要应用程序进行适当的处理，避免连接被异常中断而导致数据丢失或其他问题。

- https怎么保证证书可靠性

  HTTPS（Hypertext Transfer Protocol Secure）是一种基于 SSL/TLS 协议加密传输的 HTTP 协议，通过使用 SSL/TLS 协议进行数据加密和身份验证，从而保证通信过程的安全性。

  在 HTTPS 通信过程中，服务器会使用公开密钥加密技术（Public Key Cryptography）来提供证书，证书包含服务器的公钥和服务器信息，客户端通过验证证书的完整性和真实性来确保通信双方的身份和数据的安全性。证书的可靠性取决于证书的颁发机构（CA，Certificate Authority）的可信度。

  CA 是一家专门颁发数字证书的机构，它通过对服务器的身份、域名等信息进行严格的认证和审核，然后颁发数字证书。数字证书包含了服务器的公钥、域名、颁发者信息等重要信息，同时也包含了颁发者的数字签名，用于验证证书的真实性和完整性。

  当客户端和服务器进行 HTTPS 通信时，客户端会首先向服务器发送一个请求，服务器会将自己的证书发送给客户端。客户端会对证书进行验证，包括：

  1. 验证证书的颁发机构是否可靠，并检查证书是否被吊销（Revoked）或过期（Expired），以确保证书的真实性和完整性。

  2. 验证证书中的域名是否与服务器的域名一致，以确保通信的安全性。

  如果证书验证通过，客户端会使用服务器的公钥加密数据，并将加密后的数据发送给服务器。服务器使用自己的私钥解密数据，并使用客户端的公钥加密响应数据，保证通信的机密性和完整性。

  因此，HTTPS 通过使用数字证书、公开密钥加密技术和证书颁发机构的认证机制等手段，保证了通信过程的安全性和可靠性。

- TTL指的是什么？

  TTL是Time to Live的缩写，指的是IP数据包在网络中可以经过的最大路由跳数。在IP数据包中，TTL是一个8位的字段，它的值表示该数据包可以经过的路由器的最大数量。每经过一个路由器，TTL的值就会减1。当TTL的值减为0时，数据包就会被丢弃，同时发送方也会收到一个“Time Exceeded”错误消息。

  TTL的作用是防止IP数据包在网络中无限循环，或者因为网络故障等原因导致数据包无法到达目的地。通过限制数据包在网络中经过的最大路由跳数，TTL可以保证数据包在一定时间内能够到达目的地，同时也可以防止网络拥塞和资源浪费。

  需要注意的是，TTL的值并不是数据包在网络中实际经过的路由器数量，而是一个预设的最大值。在实际传输中，数据包可能会因为路线变化、网络拥塞等原因而经过更多的路由器，因此，TTL只是一个大致的估计值，而不是精确的数值。

- traceroute的过程

  traceroute是一种网络诊断工具，用于确定数据包从本地主机到目标主机所经过的路由路径和每个路由器的延迟时间。其原理是向目标主机发送一系列的ICMP数据包，并在每次发送时逐渐增加TTL（Time to Live）字段的值。当数据包到达路由器时，TTL的值会递减，当TTL的值减为0时，路由器会将数据包丢弃，并向发送主机发送一个ICMP错误报文，报告数据包无法到达目标主机。traceroute便是利用这个原理，通过逐跳返回的ICMP错误报文，确定数据包所经过的路由器和延迟时间。

  traceroute的具体过程如下：

  1. 发送第一个TTL值为1的ICMP数据包到目标主机，并设置一个时间戳。
  2. 第一个路由器收到ICMP数据包后，在将数据包转发到下一跳路由器之前，将TTL减1。如果TTL的值减为0，则该路由器将数据包丢弃，并向发送主机发送一个ICMP错误报文。
  3. 当发送主机接收到ICMP错误报文后，便可以确定第一个路由器的IP地址，并计算出数据包从发送主机到第一个路由器的延迟时间。
  4. 发送第二个TTL值为2的ICMP数据包，以便确定第二个路由器的IP地址和延迟时间。重复步骤2-3，直到数据包到达目标主机。
  5. 当数据包到达目标主机时，目标主机会发送一个ICMP回应报文，通知发送主机数据包已经到达。发送主机可以根据ICMP回应报文计算出数据包从发送主机到目标主机的延迟时间。

  通过逐跳返回的ICMP错误报文，traceroute可以确定数据包所经过的路由器和延迟时间，并绘制出完整的路由路径。这个过程需要多次发送ICMP数据包，每次发送的TTL值逐渐增加，因此traceroute可能会导致一些路由器产生大量的ICMP错误报文，对网络造成一定的负担。因此，在实际使用中需要注意不要过度使用traceroute，以免影响网络性能。

- HTTP中头部的行数，头部的最大数量，请求头的最大行数。

  HTTP头部的行数没有固定的限制，HTTP协议并没有规定HTTP头部的行数的最大值。通常情况下，HTTP头部的行数不会太多，一般不超过几十行。但是，HTTP头部的行数过多可能会导致网络传输的延迟和带宽浪费。

  HTTP头部的最大数量也没有固定的限制，不同的服务器可以设置不同的HTTP头部的最大数量。在实际应用中，HTTP头部的最大数量取决于服务器的硬件和软件配置以及网络带宽等因素。如果HTTP头部的数量过多，可能会导致服务器的性能下降，从而影响网站的用户体验。

  HTTP请求头的最大行数也没有固定的限制，不同的服务器可以设置不同的HTTP请求头的最大行数。在实际应用中，HTTP请求头的最大行数取决于服务器的硬件和软件配置以及网络带宽等因素。如果HTTP请求头的行数过多，可能会导致服务器的性能下降，从而影响网站的用户体验。

  需要注意的是，如果HTTP头部的行数、最大数量或HTTP请求头的最大行数超过服务器的配置限制，可能会导致HTTP请求失败或被拒绝。因此，在实际应用中，需要根据服务器的配置和业务需求来设置HTTP头部的行数、最大数量和HTTP请求头的最大行数，以保证服务器的性能和稳定性。

- TCP连接3次握手主要协商了什么东西？

  TCP连接的3次握手是指在建立TCP连接时，需要进行3次通信的握手过程，以确保客户端和服务器能够正确地建立连接，并进行数据传输。在这个过程中，主要协商了以下内容：

  1. 双方的初始序列号（Sequence Number）：TCP连接建立后，每个数据包都需要有序列号，以便接收方能够按照正确的顺序组装数据。在握手过程中，客户端和服务器会交换彼此的初始序列号，以确保两端的数据传输按照正确的顺序进行。

  2. 双方的窗口大小（Window Size）：TCP连接建立后，每个数据包都需要包含窗口大小，以指示接收方还能够接收多少数据。在握手过程中，客户端和服务器会交换彼此的窗口大小，以便双方能够控制数据传输的速度和有效性。

  3. 双方的最大报文段长度（Maximum Segment Size）：TCP连接建立后，每个数据包都有最大报文段长度的限制，以确保数据能够正确地传输。在握手过程中，客户端和服务器会交换彼此的最大报文段长度，以便双方能够控制数据传输的大小和有效性。

  4. 通信方式：在握手过程中，客户端和服务器会交换彼此的通信方式，以便双方能够协商使用何种TCP选项，在数据传输过程中进行更好的控制和优化。

  需要注意的是，TCP连接的3次握手主要用于确保客户端和服务器的同步，并建立可靠的连接，以便进行数据传输。在握手过程中，双方并没有进行具体的数据传输，只是进行了一些基本的协商和验证工作。

- TCP的四个定时器

  TCP协议中有四个定时器，它们分别是：

  1. 连接建立时的SYN定时器：当客户端向服务端发送SYN包后，如果一段时间内没有收到服务端的响应，那么客户端就会重新发送SYN包。这个重传的时间就由SYN定时器控制。

  2. 数据传输时的重传定时器：当发送方向接收方发送数据时，如果在一定时间内没有收到接收方的确认信息，那么发送方就会重新发送数据。这个时间由重传定时器控制。

  3. 接收窗口定时器：接收方会在TCP头部中的窗口字段中告诉发送方自己还能接收多少数据，如果这个窗口变小了，那么发送方就需要减慢发送速度，以避免发送的数据被接收方丢弃。接收窗口定时器就会定期检查窗口的大小，以便发送方及时调整发送速度。

  4. 连接结束时的定时器：当一方发送FIN包通知对方要关闭连接时，如果对方没有及时响应，那么发送方就会启动这个定时器。如果定时器超时，发送方就会认为对方已经关闭连接，从而关闭自己的连接。

- TCP基于数据流，UDP基于数据报文，怎么理解这句话？

  TCP和UDP都是计算机网络中的传输层协议，它们之间最主要的区别是TCP是基于数据流（stream-oriented）的协议，而UDP是基于数据报文（datagram-oriented）的协议。

  基于数据流的协议（如TCP）将数据看作一个连续的数据流，不考虑数据的边界。在发送端，数据被划分为一些小的数据块，每个块都被封装在一个TCP报文段中，然后在网络中传输。在接收端，TCP协议会重新组装这些TCP报文段，并且根据TCP序列号（sequence number）将它们按照正确的顺序组成一个完整的数据流。由于TCP是基于数据流的，因此它可以保证数据的可靠性，但是需要建立连接、维护状态等，因此会带来一定的开销和性能损失。

  基于数据报文的协议（如UDP）将数据看作一个个独立的数据报文（datagram），每个数据报文都包含了完整的数据以及一些元数据（如源地址、目标地址、端口号等）。在发送端，数据被划分为一个个独立的数据报文，并直接在网络中传输。在接收端，UDP协议不会重新组装这些数据报文，而是将它们直接交给应用程序处理。由于UDP是基于数据报文的，因此它比TCP更加轻量级，但是可能会丢失数据或者顺序错乱。

  因此，可以理解为TCP是面向连接、可靠的、流式的传输协议，而UDP是无连接、不可靠的、基于数据报文的传输协议。在选择使用哪种协议时，需要根据具体的应用场景和要求进行权衡。

- 数据包发生乱序如何恢复？

  在网络传输中，数据包可能会因为网络拥塞、路由器故障等原因而发生乱序。为了确保数据的完整性和正确性，我们需要对乱序的数据包进行恢复。以下是一些常用的恢复方法：

  1. 使用序号和确认应答机制。发送方在发送数据包时为每个数据包分配一个唯一的序号，接收方在接收到数据包后向发送方发送确认应答，表示已经接收到该数据包。如果接收方接收到的数据包是乱序的，它会暂时缓存这些数据包，并等待后续的数据包。当接收方接收到后续的数据包时，它会按照序号顺序重新组装数据，并向发送方发送确认应答，表示已经接收到所有的数据包。

  2. 使用滑动窗口协议。滑动窗口协议是一种数据传输协议，它使用一个滑动窗口来控制数据的流动。发送方和接收方各自维护一个滑动窗口，其中发送方的滑动窗口用于控制发送的数据包数量和顺序，接收方的滑动窗口用于控制接收的数据包数量和顺序。当接收方接收到乱序的数据包时，它会将这些数据包暂时缓存，并向发送方发送一个重传请求，要求发送方重新发送乱序的数据包。发送方收到重传请求后，会重新发送数据包，直到接收方收到了所有的数据包。

  3. 使用冗余校验码。冗余校验码是一种用于检测和纠正数据传输错误的技术。发送方在发送数据包时计算出一个校验码，并将其附加到数据包中。接收方在接收到数据包后，会计算出一个新的校验码，并将其与发送方附加的校验码进行比较。如果两个校验码不一致，说明数据包发生了错误，接收方会向发送方发送一个重传请求，要求发送方重新发送数据包。

  4. 使用流水线技术。流水线技术是一种将数据流分成多个阶段，并在每个阶段依次处理的技术。在数据传输中，流水线技术可以用于同时传输多个数据包，并在接收方重新组装数据包时按照正确的顺序组装数据。具体来说，发送方将数据流分成多个数据包，并为每个数据包分配一个唯一的序号。接收方在接收到数据包时，会将其缓存起来，并按照序号顺序重新组装数据。如果接收方接收到乱序的数据包，它会将这些数据包暂时缓存，并等待后续的数据包。当接收方接收到后续的数据包时，它会按照序号顺序重新组装数据，并向发送方发送确认应答，表示已经接收到所有的数据包。

  需要注意的是，在实际应用中，不同的恢复方法可能会结合使用，以提高数据传输的可靠性和效率。此外，由于网络传输中存在许多不确定性因素，如网络延迟、丢包等，因此在设计网络应用时，应该考虑到这些因素，并采取合适的措施来保证数据传输的可靠性和效率。

- HTTP如何实现状态化，cookie被禁用了怎么办？

  HTTP是一种无状态协议，即每次请求与响应之间没有状态保持。而状态化是指在多次请求与响应之间保持某种状态，从而实现数据的持久性和数据共享。HTTP通过引入Cookie来实现状态化，即服务器通过在响应中添加Cookie，客户端在之后的请求中携带该Cookie来实现状态的保持。下面介绍Cookie的原理以及在Cookie被禁用的情况下的解决方案：

  1. Cookie的原理

  Cookie是一种保存在客户端的小数据片段，通常包含一个名称、一个值、一个过期时间和一个路径。服务器在响应中添加Cookie时，会在HTTP头部中添加Set-Cookie字段，客户端在之后的请求中会在HTTP头部中添加Cookie字段，将之前保存的Cookie信息发送给服务器。

  服务器利用Cookie来保持状态，例如在用户登录时，将用户的登录信息保存在Cookie中，客户端在之后的请求中携带该Cookie，服务器就可以识别用户身份，从而实现状态保持。

  2. Cookie被禁用的解决方案

  如果Cookie被禁用，就无法通过Cookie来实现状态保持。但是，还有其他的解决方案可以实现状态的保持，例如：

  - URL参数：将状态信息作为URL的参数传递给服务器。例如，将用户ID作为URL参数传递给服务器，服务器就可以根据该参数来识别用户身份。

  - 隐藏表单字段：将状态信息保存在HTML表单的隐藏字段中，客户端在提交表单时，将该字段的值一起提交给服务器。例如，将用户ID保存在一个隐藏字段中，客户端提交表单时，将该字段的值一起提交给服务器。

  - HTTP头部：利用HTTP头部来传递状态信息。例如，在HTTP头部中添加自定义的字段，将状态信息保存在该字段中，客户端在之后的请求中携带该字段，服务器就可以识别用户身份。

  需要注意的是，这些解决方案并非完全替代Cookie，它们都有各自的局限性和安全风险。例如，URL参数可能会被拦截和篡改，隐藏表单字段可能会被恶意脚本修改，HTTP头部字段可能会被伪造。因此，在选择替代方案时，需要综合考虑安全性、可靠性和性能等因素，并根据具体的应用场景进行选择。

  另外，如果Cookie被禁用是由于用户禁用了浏览器的Cookie功能，可以通过向用户提示开启Cookie功能的方式来解决。通常，浏览器在发送HTTP请求时会在HTTP头部中携带一个Cookie字段，如果该字段为空，说明用户禁用了Cookie功能。在这种情况下，可以向用户提示开启Cookie功能，并提供相应的操作指南。

- ip分片与重组，什么时候分片？在哪里重组？依据什么重组？怎么判断重组全部完成？

  IP 分片和重组是因为 IP 数据报的长度超出了网络的 MTU（Maximum Transmission Unit，最大传输单元）限制而引起的。MTU 是指在一个网络中可以传输的最大数据包大小，不同网络的 MTU 可能不同。当一个 IP 数据报的长度超过了 MTU 限制时，它就需要被分成多个片段进行传输，接收端再将这些片段重组成完整的数据报。

  下面是 IP 分片和重组的过程：

  1. 分片：当一个 IP 数据报的长度超过了网络的 MTU 限制时，它就需要被分成多个片段，以便在网络中进行传输。分片的过程由发送端的 IP 层完成。在分片时，IP 层会根据 MTU 的大小将数据报分成多个大小相等的片段，并为每个片段设置相同的标识符和序号，以便在接收端进行重组。此外，第一个片段包含了 IP 头部的所有字段，而后续的片段只包含 IP 头部的部分字段和数据部分。

  2. 传输：分片后的数据报片段会在网络中传输，可能会经过多个路由器和网络。每个路由器会根据 IP 数据报中的目的地址和路由表中的路由信息将数据报片段转发到下一个网络。

  3. 重组：当 IP 数据报的所有片段到达目的主机时，它们会被接收端的 IP 层进行重组。在重组时，IP 层会根据 IP 头部中的标识符和序号将所有片段重新组装成完整的 IP 数据报。IP 层还会验证每个片段的校验和，以确保数据的完整性和正确性。

  4. 传递：重组后的 IP 数据报会被传递给上层协议进行处理，例如 TCP 或 UDP。在传递给上层协议之前，IP 层还会重新计算 IP 头部的校验和，并将其与原始的校验和进行比较，以确保数据的完整性和正确性。

  重组的依据是 IP 头部中的标识符和序号。IP 头部中的标识符是一个16 位的值，用于标识一个 IP 数据报。在进行分片时，所有分片的 IP 头部中的标识符都相同。IP 头部中的序号字段则用于标识每个数据报片段的位置，第一个片段的序号为 0，后续的片段则依次递增。在重组时，接收端会根据 IP 头部中的标识符和序号将所有片段重新组装成完整的 IP 数据报。

  判断重组全部完成的方法是根据 IP 头部中的“分片偏移”字段和“更多分片”（More Fragments）标志位。分片偏移字段表示该片段在原始数据报中的位置，单位是 8 字节。例如，如果一个 IP 数据报被分成了两个片段，第一个片段中的分片偏移为 0，第二个片段中的分片偏移为 5，则表示第一个片段包含了 IP 头部和前 40 个字节的数据，第二个片段包含了后面的数据。更多分片标志位表示是否还有更多的分片需要重组，当该标志位为 0 时表示已经接收到所有的分片，重组完成。因此，当接收端收到的 IP 数据报中的更多分片标志为 0 时，就可以判断重组已经全部完成。

- MSL和TTL的关系？

  MSL（Maximum Segment Lifetime，最大报文生存时间）和 TTL（Time To Live，生存时间）都是 TCP/IP 协议中的参数，用于控制数据包在网络中的生存时间和有效期。它们的作用和含义不同，但是它们之间有一定的关系。

  MSL 是指一个 TCP 报文段在网络中允许存在的最长时间，也就是说，如果一个 TCP 报文段在网络中存在的时间超过了 MSL，那么该报文段会被丢弃。MSL 的值通常为 2 分钟左右，这个值是根据网络状况和性能来确定的。

  TTL 是指一个 IP 数据包在网络中允许经过的最大路由器数量，也就是说，如果一个 IP 数据包在网络中经过的路由器数量超过了 TTL，那么该数据包会被丢弃。TTL 的值通常为 64 或 128，这个值也是根据网络状况和性能来确定的。

  虽然 MSL 和 TTL 的作用不同，但是它们之间有一定的关系。具体来说，当一个 TCP 报文段被封装成 IP 数据包后，它的 TTL 值会被设置为一个初始值，通常为 64 或 128。当该数据包经过一个路由器时，TTL 的值会减少 1。如果 TTL 的值减少到 0，那么该数据包会被路由器丢弃。这个机制可以保证数据包不会一直在网络中循环，从而防止网络拥塞和资源浪费。

  在 TCP 连接的关闭过程中，MSL 的值也会影响到连接的释放。当一方发送 FIN 报文段时，对方会回复 ACK 报文段，并启动一个计时器，该计时器的值为 MSL。如果在该计时器到期之前，对方没有收到该 FIN 报文段的 ACK 报文段，那么该计时器会被重置，并再次启动。如果在两个 MSL 时间内，对方都没有收到该 FIN 报文段的 ACK 报文段，那么该连接会被认为已经关闭，并释放相应的资源。

  因此，虽然 MSL 和 TTL 的作用和含义不同，但是它们在 TCP/IP 协议中都有重要的作用，可以保证数据包在网络中的有效传输和释放。在 TCP 连接的关闭过程中，MSL 的值也会影响到连接的释放。同时，当 TCP 报文段被封装成 IP 数据包时，它的 TTL 值会被设置为一个初始值，这个值会在数据包经过路由器时逐渐减少，从而保证数据包不会一直在网络中循环。

- 发送窗口、拥塞窗口、接收窗口之间的关系？

  发送窗口、拥塞窗口和接收窗口是 TCP 协议中的重要参数，它们之间的关系如下：

  发送窗口（Send Window）：发送窗口是指发送方缓存中可以用于发送数据的空间大小。发送方会根据发送窗口的大小来控制发送数据的速率，从而避免网络拥塞和丢包。发送窗口的大小受到对端接收窗口、拥塞窗口和网络拥塞程度的影响。

  接收窗口（Receive Window）：接收窗口是指接收方缓存中可以用于接收数据的空间大小。接收方会根据接收窗口的大小来控制发送方的发送速率，从而避免数据包的丢失和重传。接收窗口的大小受到发送方的发送窗口和接收方处理能力的影响。

  拥塞窗口（Congestion Window）：拥塞窗口是指发送方为了避免网络拥塞而限制发送速率的窗口大小。拥塞窗口的大小受到网络拥塞程度和发送方的拥塞控制算法（例如 TCP Tahoe、TCP Reno、TCP Cubic 等）的影响。当网络拥塞程度较高时，发送方会逐渐减小拥塞窗口的大小，从而减少发送数据的速率，以避免网络拥塞和丢包。当网络拥塞程度降低时，发送方会逐渐增大拥塞窗口的大小，以提高发送数据的速率。

  











