# 🔥webserver项目

# 一、webserver项目

[qinguoyi/TinyWebServer: Linux下C++轻量级Web服务器 (github.com)](https://github.com/qinguoyi/TinyWebServer)

[white0dew/WebServer: A TinyWebServer implemented inC++11. (github.com)（注释版）](https://github.com/white0dew/WebServer)

[markparticle/WebServer: C++ Linux WebServer服务器 (github.com)(牛客讲解)](https://github.com/markparticle/WebServer)

---

[linyacool/WebServer: A C++ High Performance Web Server (github.com)](https://github.com/linyacool/WebServer)

[linyacool/WebBench: 修改了WebBench的源码，使其可以支持针对HTTP长连接的测试 (github.com)](https://github.com/linyacool/WebBench)

---

[rongweihe/WebServer: C++ High Performance HTTP WebServer (github.com)](https://github.com/rongweihe/WebServer)

[imarvinle/WebServer: A C++ Lightweight Web Server based on Linux epoll (github.com)](https://github.com/imarvinle/WebServer)

[gaojingcome/WebServer: C++ Linux WebServer服务器 (github.com)](https://github.com/gaojingcome/WebServer)

[KyleAndKelly/MyWebServer: Tiny WebServer Based on Reactor Model 基于Reactor模式的高效WebServer (github.com)](https://github.com/KyleAndKelly/MyWebServer)

# 二、项目面经

[Tinywebserver——服务器常问面试题！ - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/368154495)

[TinyWebServer——从0到服务器开发！ - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/364044293)

[C++多线程学习笔记 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/365311035)

[tinywebserver 代码解读 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/475807065)

[c++项目——TinyWebServer - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/474795447)

[Tinywebserver-一个简易的web服务器_aiwuzhi12的博客-CSDN博客](https://blog.csdn.net/aiwuzhi12/article/details/60767763)

[小白视角：一文读懂社长的TinyWebServer](https://huixxi.github.io/2020/06/02/%E5%B0%8F%E7%99%BD%E8%A7%86%E8%A7%92%EF%BC%9A%E4%B8%80%E6%96%87%E8%AF%BB%E6%87%82%E7%A4%BE%E9%95%BF%E7%9A%84TinyWebServer/#more)

[#Web服务器-原始版本 (qq.com)](https://mp.weixin.qq.com/mp/appmsgalbum?action=getalbum&__biz=MzAxNzU2MzcwMw==&scene=1&album_id=1339230165934882817&count=3#wechat_redirect)

[WebServer服务器项目可能会被问到的问题（一）_笔经面经_牛客网 (nowcoder.com)](https://www.nowcoder.com/discuss/934904?source_id=profile_create_nctrack&channel=-1)

[WebServer服务器项目可能会被问到的问题（二）_笔经面经_牛客网 (nowcoder.com)](https://www.nowcoder.com/discuss/939267)

[如何优雅的介绍自己的项目经历_笔经面经_牛客网 (nowcoder.com)](https://www.nowcoder.com/discuss/150755)

## 项目亮点

1. 使用 **线程池 + 非阻塞socket + epoll(ET和LT均实现) + 事件处理(Reactor和模拟Proactor均实现)** 的高并发模型；
2. 使用正则和**状态机**解析HTTP请求报文，支持解析**GET和POST**请求，实现处理静态资源的请求；
3. 利用标准库容器封装char，实现**自动增长**的缓冲区；
4. 基于**小根堆**实现的定时器，关闭超时的非活动连接；
3. 利用**RAII机制**实现了数据库连接池，减少数据库连接建立与关闭的开销，访问服务器数据库实现web端用户**注册、登录**功能，可以请求服务器**图片和视频文件**；
4. 利用单例模式与阻塞队列实现**同步/异步日志系统**，记录服务器运行状态；
5. 经Webbench压力测试可以实现**上万的并发连接**数据交换；
6. 增加logsys,threadpool测试单元 (todo: timer, sqlconnpool, httprequest, httpresponse) 

## 介绍项目

我开发了网络服务器，主要功能是通过HTTP协议与客户端（通常是浏览器（Browser））进行通信，来接收，存储，处理来自客户端的HTTP请求，并对其请求做出HTTP响应，返回给客户端其请求的内容（文件、网页等）或返回一个Error信息。

项目框架：

<img src="https://gcore.jsdelivr.net/gh/gp868/myFigures/img/202204021828181.jpg" alt="005TJ2c7ly1ge0j1atq5hj30g60lm0w4" style="zoom:130%;" />

<img src="https://gcore.jsdelivr.net/gh/gp868/myFigures/img/202204022020814.png" alt="image-20220402202057737" style="zoom:80%;" />

## Reactor和模拟Proactor

- 使用**同步 I/O**（以 epoll_wait 为例）实现的 **Reactor** 模式的工作流程是：

  要求主线程（I/O处理单元）只负责监听文件描述符上是否有事件发生，有的话就立即将该事件通知工作线程（逻辑单元），将 socket 可读可写事件放入请求队列，交给工作线程处理。除此之外，主线程不做任何其他实质性的工作。读写数据，接受新的连接，以及处理客户请求均在工作线程中完成。

  <img src="https://gcore.jsdelivr.net/gh/gp868/myFigures/img/202203302101257.png" alt="image-20220330210124183" style="zoom: 65%;" />

1. 主线程往 epoll 内核事件表中注册 socket 上的读就绪事件。
2. 主线程调用 epoll_wait 等待 socket 上有数据可读。
3. 当 socket 上有数据可读时， epoll_wait 通知主线程。主线程则将 socket 可读事件放入请求队列。
4. 睡眠在请求队列上的某个工作线程被唤醒，它从 socket 读取数据，并处理客户请求，然后往 epoll内核事件表中注册该 socket 上的写就绪事件。
5. 当主线程调用 epoll_wait 等待 socket 可写。
6. 当 socket 可写时，epoll_wait 通知主线程。主线程将 socket 可写事件放入请求队列。
7. 睡眠在请求队列上的某个工作线程被唤醒，它往 socket 上写入服务器处理客户请求的结果。

- 使用**异步I/O**（如aio_read和aio_write）实现**Proactor**

  Proactor 模式将所有 I/O 操作都交给主线程和内核来处理（进行读、写），工作线程仅仅负责业务逻辑。使用异步 I/O 模型（以 aio_read 和 aio_write 为例）实现的 Proactor 模式的工作流程是：

  <img src="https://gcore.jsdelivr.net/gh/gp868/myFigures/img/202203302104527.png" alt="image-20220330210448452" style="zoom:67%;" />

1. 主线程调用 aio_read 函数向内核注册 socket 上的读完成事件，并告诉内核用户读缓冲区的位置，以及读操作完成时如何通知应用程序（这里以信号为例）；
2. 主线程继续处理其他逻辑；
3. 当 socket 上的数据被读入用户缓冲区后，内核将向应用程序发送一个信号，以通知应用程序数据已经可用。
4. 应用程序预先定义好的信号处理函数选择一个工作线程来处理客户请求。工作线程处理完客户请求后，调用 aio_write 函数向内核注册 socket 上的写完成事件，并告诉内核用户写缓冲区的位置，以及写操作完成时如何通知应用程序。
5. 主线程继续处理其他逻辑。
6. 当用户缓冲区的数据被写入 socket 之后，内核将向应用程序发送一个信号，以通知应用程序数据已经发送完毕。
7. 应用程序预先定义好的信号处理函数选择一个工作线程来做善后处理，比如决定是否关闭 socket。
- **模拟 Proactor 模式**
  使用同步 I/O 方式模拟出 Proactor 模式。原理是：主线程执行数据读写操作，读写完成之后，主线程向工作线程通知这一”完成事件“。那么从工作线程的角度来看，它们就直接获得了数据读写的结果，接下来要做的只是对读写的结果进行逻辑处理。

  <img src="https://gcore.jsdelivr.net/gh/gp868/myFigures/img/202204031036562.png" alt="image-20220403103636379" style="zoom:65%;" />

使用同步 I/O 模型（以 epoll_wait为例）模拟出的 Proactor 模式的工作流程如下：

1. 主线程往 epoll 内核事件表中注册 socket 上的读就绪事件。
2. 主线程调用 epoll_wait 等待 socket 上有数据可读。
3. 当 socket 上有数据可读时，epoll_wait 通知主线程。主线程从 socket 循环读取数据，直到没有更多数据可读，然后将读取到的数据封装成一个请求对象并插入请求队列。
4. 睡眠在请求队列上的某个工作线程被唤醒，它获得请求对象并处理客户请求，然后往 epoll 内核事件表中注册 socket 上的写就绪事件。
5. 主线程调用 epoll_wait 等待 socket 可写。
6. 当 socket 可写时，epoll_wait 通知主线程。主线程往 socket 上写入服务器处理客户请求的结果。

- 总结

  `Reactor` 是**⾮阻塞同步⽹络**模式，感知的是**就绪可读写事件**。在每次感知到有事件发⽣（⽐如可读就绪事件）后，就需要应⽤进程主动调⽤ read ⽅法来完成数据的读取，也就是要应⽤进程主动将socket 接收缓存中的数据读到应⽤进程内存中，这个过程是同步的，读取完数据后应⽤进程才能处理数据。

  `Proactor` 是**异步⽹络**模式， 感知的是**已完成的读写事件**。在发起异步读写请求时，需要传⼊数据缓冲区的地址（⽤来存放结果数据）等信息，这样系统内核才可以⾃动帮我们把数据的读写⼯作完成，这⾥的读写⼯作全程由操作系统来做，并不需要像 Reactor 那样还需要应⽤进程主动发起 read/write来读写数据，操作系统完成读写⼯作后，就会通知应⽤进程直接处理数据。

  因此，**Reactor 可以理解为「来了事件操作系统通知应⽤进程，让应⽤进程来处理」**，而 **Proactor 可以理解为「来了事件操作系统来处理，处理完再通知应⽤进程」**。这⾥的「事件」就是有新连接、有数据可读、有数据可写的这些 I/O 事件，这⾥的「处理」包含从驱动读取到内核以及从内核读取到⽤户空间。

  可惜的是，在 Linux 下的异步 I/O 是不完善的，aio 系列函数是由 POSIX 定义的异步操作接⼝，不是真正的操作系统级别⽀持的，⽽是在⽤户空间模拟出来的异步，并且**仅仅⽀持基于本地⽂件的 aio 异步操作，⽹络编程中的 socket 是不⽀持的**，这也使得基于 Linux 的⾼性能⽹络程序都是使⽤ **Reactor** ⽅案。




## 边沿触发`ET`和水平触发`LT`

epoll ⽀持两种事件触发模式，分别是边缘触发（edge-triggered ， ET）和水平触发（level-triggered ，LT）。

- 使⽤边缘触发模式时，当被监控的 Socket 描述符上有可读事件发⽣时，**服务器端只会从 epoll_wait中苏醒⼀次**，即使进程没有调⽤ read 函数从内核读取数据，也依然只苏醒⼀次，因此我们程序要保证⼀次性将内核缓冲区的数据读取完，读取到出现 `EAGAIN`。
- 使⽤水平触发模式时，当被监控的 Socket 上有可读事件发⽣时，**服务器端不断地从 epoll_wait 中苏醒，直到内核缓冲区数据被 read 函数读完才结束**，⽬的是告诉我们有数据需要读取；

如果使⽤**水平触发**模式，当内核通知⽂件描述符可读写时，接下来还可以继续去检测它的状态，看它是否依然可读或可写。所以在收到通知后，没必要⼀次执⾏尽可能多的读写操作。

如果使⽤**边缘触发**模式，I/O 事件发⽣时只会通知⼀次，⽽且我们不知道到底能读写多少数据，所以在收到通知后应尽可能地读写数据，以免错失读写的机会。

因此，我们会**循环**从⽂件描述符读写数据，那么如果⽂件描述符是阻塞的，没有数据可读写时，进程会阻塞在读写函数那⾥，程序就没办法继续往下执⾏。

所以，**边缘触发模式⼀般和非阻塞 I/O 搭配使用**，程序会⼀直执⾏ I/O 操作，直到系统调⽤（如 read 和write ）返回错误，错误类型为 `EAGAIN` 或 `EWOULDBLOCK` 。多路复⽤ API 返回的事件并不⼀定可读写的，如果使⽤阻塞 I/O， 那么在调⽤ read/write 时则会发⽣程序阻塞，因此最好搭配⾮阻塞 I/O，以便应对极少数的特殊情况。

⼀般来说，**边缘触发的效率⽐⽔平触发的效率要⾼**，因为边缘触发可以减少 epoll_wait 的系统调⽤次数，系统调⽤也是有⼀定的开销的的，毕竟也存在上下⽂的切换。

select/poll 只有⽔平触发模式，epoll 默认的触发模式是⽔平触发，但是可以根据应⽤场景设置为边缘触发模式。

## 线程池相关

- 手写线程池

- 半同步半反应堆线程池：

  主线程充当异步线程，负责监听所有socket上的事件。若有新请求到来，主线程接收请求，得到新的连接socket，然后往epoll内核事件表中注册该socket上的读写事件。如果连接socket上有读写事件发生，主线程从socket上接收数据，并将数据封装成请求对象插入到请求队列中。工作线程睡眠在请求队列上，当有任务到来时，通过竞争（如互斥锁）获得任务的接管权。

  使用一个工作队列完全解除了主线程和工作线程的耦合关系：主线程往工作队列中插入任务，工作线程通过竞争来取得任务并执行它。

  [半同步/半反应堆线程池_午饭要阳光的博客-CSDN博客_半同步半反应堆](https://blog.csdn.net/LF_2016/article/details/72794814)

- 线程的同步机制有哪些？

  信号量、条件变量、互斥量等。

- 线程池中的工作线程是一直等待吗？

  是的，等待新任务的唤醒。

- 你的线程池工作线程处理完一个任务后的状态是什么？

  如果请求队列为空，则该线程进入线程池中等待；若不为空，则该线程跟其他线程一起进行任务的竞争。

- 如果同时1000个客户端进行访问请求，线程数不多，怎么能及时响应处理每一个呢？

  该项目是基于I/O多路复用的并发模式。**需要注意的是，不是一个客户连接就对应一个线程**！如果真是如此，淘宝双12服务器早就崩了！当客户连接有事件需要处理的时，epoll会进行事件提醒，而后将对应的任务加入请求队列，等待工作线程竞争执行。**如果速度还是慢，那就只能够增大线程池容量**，或者考虑集群分布式的做法。

- 如果一个客户请求需要占用线程很久的时间，会不会影响接下来的客户请求呢，有什么好的策略呢?

  会，因为线程的数量是固定的，如果一个客户请求长时间占用着线程资源，势必会影响到服务器对外的整体响应速度。解决的策略可以是给每一个线程处理任务设定一个时间阈值，当某一个客户请求时间过长，则将其置于任务请求最后，或断开连接。

## 并发模型相关

- 简单说一下服务器使用的并发模型？

  该项目选用的半同步半反应堆的并发模型。以Proactor模式为例的工作流程即是：主线程充当异步线程，负责监听所有socket上的事件。若有新请求到来，主线程接收之以得到新的连接socket，然后往epoll内核事件表中注册该socket上的读写事件。如果连接socket上有读写事件发生，主线程从socket上接收数据，并将数据封装成请求对象插入到请求队列中。所有工作线程睡眠在请求队列上，当有任务到来时，通过竞争（如互斥锁）获得任务的接管权。

- reactor、proactor、主从reactor模型的区别？

  **Reactor模式**：要求主线程（I/O处理单元）只负责监听文件描述符上是否有事件发生（可读、可写），若有，则立即通知工作线程，将socket可读可写事件放入请求队列，**读写数据、接受新连接及处理客户请求均在工作线程中完成。(需要区别读和写事件)**

  **Proactor模式**：主线程和内核负责处理读写数据、接受新连接等**I/O操作**，**工作线程仅负责业务逻辑（给予相应的返回url）**，如处理客户请求。

  **主从Reactor模式**：核心思想是，主反应堆线程只负责分发Acceptor连接建立，已连接套接字上的I/O事件交给sub-reactor负责分发。其中 sub-reactor的数量，可以根据CPU的核数来灵活设置。

  **主反应堆线程一直在感知连接建立的事件**，如果有连接成功建立，主反应堆线程通过accept方法获取已连接套接字，**接下来会按照一定的算法选取一个从反应堆线程**，并把已连接套接字**加入到选择好的从反应堆线程中。**主反应堆线程唯一的工作，就是调用accept获取已连接套接字，以及将已连接套接字加入到从反应堆线程中。

- 你用了epoll，说一下为什么用epoll，还有其他复用方式吗？区别是什么？

  先说说其他的复用方式吧，比较常用的有三种：select/poll/epoll。本项目之所以采用epoll，参考问题（[Why is epoll faster than select?](https://link.zhihu.com/?target=https%3A//stackoverflow.com/questions/17355593/why-is-epoll-faster-than-select)）

  对于select和poll来说，所有文件描述符都是在用户态被加入其文件描述符集合的，**每次调用都需要将整个集合拷贝到内核态**；epoll则将整个文件描述符集合维护在内核态，每次添加文件描述符的时候都需要**执行一个系统调用**。系统调用的开销是很大的，而且在有很多短期活跃连接的情况下，epoll可能会慢于select和poll由于这些大量的系统调用开销。

  select使用线性表描述文件描述符集合，**文件描述符有上限**；poll使用**链表来描述**；epoll底层通过红黑树来描述，并且维护一个ready list，将事件表中已经就绪的事件添加到这里，在使用epoll_wait调用时，仅观察这个list中有没有数据即可。

  select和poll的最大开销来自内核判断是否有文件描述符就绪这一过程：每次执行select或poll调用时，**它们会采用遍历的方式**，遍历整个文件描述符集合去判断各个文件描述符是否有活动；epoll则不需要去以这种方式检查，当有活动产生时，**会自动触发epoll回调函数通知epoll文件描述符**，然后内核将这些就绪的文件描述符放到之前提到的**ready list中等待epoll_wait调用后被处理**。

  select和poll都只能工作在**相对低效的LT模式下**，而epoll同时支持LT和ET模式。

  综上，**当监测的fd数量较小**，且各个fd都很活跃的情况下，建议使用select和poll；**当监听的fd数量较多**，且单位时间仅部分fd活跃的情况下，使用epoll会明显提升性能。

## HTTP报文解析相关

- **HTTP处理流程**

  HTTP的处理流程分为以下三个步骤：

  - **连接处理：**浏览器端发出http连接请求，主线程创建http对象接收请求并将所有数据读入对应buffer，将该对象插入任务队列，等待工作线程从任务队列中取出一个任务进行处理。
  - **处理报文请求**：工作线程取出任务后，调用进程处理函数process_read()，通过主、从状态机对请求报文进行解析。
  - **返回响应报文：**解析完之后，调用do_request()函数生成响应报文，通过process_write写入buffer，返回给浏览器端。

- 用了状态机啊，为什么要用状态机？

  有限状态机，是一种抽象的理论模型，它能够把有限个变量描述的状态变化过程，以可构造可验证的方式呈现出来。比如，封闭的有向图。有限状态机可以通过if-else, switch-case和函数指针来实现，从软件工程的角度看，主要是为了封装逻辑。有限状态机是一种逻辑单元内部的一种高效编程方法，在服务器编程中，服务器可以根据不同状态或者消息类型进行相应的处理逻辑，使得程序逻辑清晰易懂。

- https协议为什么安全？

  连接建立阶段基于ssl安全验证；数据传输阶段加密，进一步了解可以百度。

- https的ssl连接过程

  ![img](https://gcore.jsdelivr.net/gh/gp868/myFigures/img/202203302111906.jpeg)

- GET和POST的区别

  GET和POST是HTTP协议中的两种发送请求的方法。GET和POST本质上就是TCP链接，并无差别。但是由于HTTP的规定和浏览器/服务器处理数据能力的限制，导致他们在应用过程中体现出一些不同。 

  首先，HTTP对GET和POST参数的传送渠道（url还是requrest body）提出了要求：GET把参数包含在**URL**中，POST通过**消息体**传递参数。GET主要是用来获取新的网页；POST用作向服务器传递用户的表单数据，如用户名、密码、留言等等。

  其次，GET和POST参数大小的限制不同：GET请求在URL中传送的参数是有长度限制的，而POST通过**消息体**传递的参数没有长度限制。

  此外，GET和POST还有一个**重大区别**：GET产生一个TCP数据包，而POST产生两个TCP数据包。

  对于GET请求，浏览器会把请求头和消息体一并发送出去，服务器响应200 ok（返回数据）；而对于POST请求，浏览器先发送请求头，服务器响应100 continue后，浏览器再发送消息体，服务器响应200 ok（返回数据）。

  其他的区别：GET请求参数会被完整保留在浏览器历史记录里，而POST中的参数不会被保留；对参数的数据类型，GET只接受ASCII字符，而POST没有限制。

-------

POST需要两步，时间上消耗的要多一点，看起来GET比POST更有效，因此Yahoo团队有推荐用GET替换POST来优化网站性能。但这是一个坑！跳入需谨慎。为什么？

1. GET与POST都有自己的语义，不能随便混用。

2. 据研究，在网络环境好的情况下，发一次包的时间和发两次包的时间差别基本可以无视。而在网络环境差的情况下，两次包的TCP在验证数据包完整性上，有非常大的优点。

3. 并不是所有浏览器都会在POST中发送两次包，Firefox就只发送一次。

[GET和POST两种基本请求方法的区别 - 在途中# - 博客园 (cnblogs.com)](https://www.cnblogs.com/logsharing/p/8448446.html)

- 短连接和长链接的区别

  长连接与短连接的概念是针对TCP连接的，TCP连接是一个双向通道，可以保持一段时间不关闭。

  - **概念与原理**

  **长连接**是指在完成链路连接建立后，在链路空闲时并不结束这条链路，而是一直维持这条链路的连接，因此安全性较差。

  **长连接**的**优势**是在多次通信中可以省去连接建立和关闭连接的开销，从总体上来看，进行多次数据传输的总耗时更少。**缺点**是需要花费额外的精力来保持这个连接一直是可用的，因为网络抖动、服务器故障等都会导致这个连接不可用，甚至是由于防火墙的原因。所以，一般我们会通过下面这几种方式来做“保活”工作，确保连接在被使用的时候是可用状态：

  1. 利用 TCP 自身的保活（Keepalive）机制来实现，保活机制会定时发送探测报文来识别对方是否可达。一般的默认定时间隔是 2 小时，你可以根据自己的需要在操作系统层面去调整这个间隔，不管是 linux 还是 windows 系统。

  2. 上层应用主动的定时发送一个小数据包作为“心跳”，探测是否能成功送达到另外一端。 保活功能大多数情况下用于服务端探测客户端的场景，一旦识别客户端不可达，则断开连接，缓解服务端压力。

  **短连接**是指每次通信结束后，连接中断，下次通信时重新建立连接。

  **短连接**的**优势**是由于每次使用的连接都是新建的，所以基本上只要能够建立连接，数据就大概率能送达到对方。并且哪怕这次传输出现异常也不用担心影响后续新的数据传输，因为届时又是一个新的连接。**缺点**是每个连接都需要经过三次握手和四次握手的过程，耗时大大增加。

  另外，短连接还有一个**致命缺点**。socket 包含通信协议、目标地址、状态等，在基于 socket 进行开发的时候，这些包含的具体资源主要就是这 5 个：源 IP、源端口、目的 IP、目的端口、协议，有个专业的叫法称之为“五元组”。在一台计算机上只要这五元组的值不重复，那么连接就可以被建立。然而一台计算机**最多只能开启 65535 个端口**，如果现在两个进程之间需要通信，作为服务端的 IP 和端口必然是固定的，因此单个客户端理论上最多只能与服务端同时建立 65535 个 socket 连接。如果除去操作系统和其它进程所占用的端口，实际还会更少。所以，一旦使用不当，在很短的时间内建立了大量连接，端口很容易被占用完。这不但会导致自身无法正常工作，还会影响到同一台计算机上的其它进程。

  - **应用**

  **长连接**多应用于保持通信的场景，例如：消息推送、链路复用等。对于频繁请求资源的客户来说，较适用长连接。

  **短连接**应用于HTTP技术，HTTP在向服务器交互信息时在一段时间内也会保持长连接。

  长连接多用于操作频繁，点对点的通讯，而且连接数不能太多情况。每个TCP连接都需要三次握手，这需要时间，如果每个操作都是先连接，再操作的话那么处理速度会降低很多，所以每个操作完后都不断开，再次处理时直接发送数据包就OK了，不用建立TCP连接。例如：数据库的连接用长连接，如果用短连接频繁的通信会造成socket错误，而且频繁的socket 创建也是对资源的浪费。

  而像WEB网站的http服务一般都用短连接，因为长连接对于服务端来说会耗费一定的资源，而像WEB网站这么频繁的成千上万甚至上亿客户端的连接用短连接会更省一些资源，如果用长连接，而且同时有成千上万的用户，如果每个用户都占用一个连接的话，那可想而知吧。所以并发量大，但每个用户无需频繁操作情况下需用短连接好。

  

  [长连接与短链接的区别_QYHuiiQ的博客-CSDN博客_长连接和短连接](https://blog.csdn.net/QYHuiiQ/article/details/97613489)

  [长连接和短链接的区别_小码哥(^_^)的博客-CSDN博客_长连接和短连接](https://blog.csdn.net/qq9808/article/details/104864776)

  [TCP长连接和短链接的区别及应用场景_haikuotiankongdong的博客-CSDN博客_长连接和短连接的使用场景](https://blog.csdn.net/weixin_41563161/article/details/105529382)


## 数据库登录注册相关

- 登录说一下？

  具体的涉及到**载入数据库表，提取用户名和密码，注册登录流程与页面跳转**。

  - 载入数据库表，结合代码将数据库中的数据载入到服务器中；
  - 提取用户名和密码，结合代码对报文进行解析，提取用户名和密码；
  - 注册登录流程，结合代码对描述服务器进行注册和登录校验的流程；
  - 页面跳转，结合代码对页面跳转机制进行详解

- 你这个保存状态了吗？如果要保存，你会怎么做？（cookie和session）

  可以利用session或者cookie的方式进行状态的保存。

  cookie其实就是服务器给客户分配了一串“身份标识”，比如“123456789happy”这么一串字符串。每次客户发送数据时，都在HTTP报文附带上这个字符串，服务器就知道你是谁了；

  session是保存在服务器端的状态，每当一个客户发送HTTP报文过来的时候，服务器会在自己记录的用户数据中去找，类似于核对名单；

- 登录中的用户名和密码你是load到本地，然后使用map匹配的，如果有10亿数据，即使load到本地后hash，也是很耗时的，你要怎么优化？

  这个问题的关键在于大数据量情况下的用户登录验证怎么进行？将所有的用户信息加载到内存中耗时耗利，对于大数据最遍历的方法就是**进行hash，利用hash建立多级索引的方式来加快用户验证**。具体操作如下：

  首先，将10亿的用户信息，利用大致缩小1000倍的hash算法进行hash，这时就获得了100万的hash数据，每一个hash数据代表着一个**用户信息块（一级）**；

  而后，再分别对这100万的hash数据再进行hash，例如最终剩下1000个**hash数据（二级）**。

  在这种方式下，服务器只需要保存1000个二级hash数据，当用户请求登录的时候，先对用户信息进行一次hash，找到对应信息块（二级），在读取其对应的一级信息块，最终找到对应的用户数据。

- 用的mysql啊，redis了解吗？用过吗？

  [《Redis设计与实现》及源码分析 - 知乎 (zhihu.com)](https://www.zhihu.com/column/c_1358779780431659008)

## 定时器相关

- 为什么要用定时器？

  处理定时任务，或者非活跃连接，节省系统资源。

- 说一下定时器的工作原理

  服务器为各事件分配一个定时器，本项目使用`SIGALRM`信号来实现定时器。首先每一个定时事件都处于一个**升序链表上**，通过`alarm()`函数周期性触发SIGALRM信号，然后信号回调函数利用**管道**通知主循环，主循环接收到信号之后对升序链表上的定时器进行处理，若一定时间内无数据交换则关闭连接。

- 双向链表，删除和添加的时间复杂度说一下？还可以优化吗？

  添加一般情况下都是O(N)，删除只需要O(1)。从双向链表的方式优化不太现实，可以考虑使用最小堆、或者跳表的数据结构，[跳表详见](https://zhuanlan.zhihu.com/p/360087451)。

- 最小堆优化？说一下时间复杂度和工作原理

  最小堆以每个定时器的过期时间进行排序，最小的定时器位于堆顶，当SIGALRM信号触发tick()函数时执行过期定时器清除，如果堆顶的定时器时间过期，则删除，并重新建堆，再判定是否过期，如此循环直到未过期为止。

  插入，O(logN)；

  删除，O(logN)；

## 日志相关

- 说下你的日志系统的运行机制？

  初始化服务器时，利用单例模式初始化日志系统，根据配置文件确认是同步还是异步写入的方式。

- 为什么要异步？和同步的区别是什么？

  同步方式写入日志时会产生比较多的系统调用，若是某条日志信息过大，会阻塞日志系统，造成系统瓶颈。异步方式采用生产者-消费者模型，具有较高的并发能力。

- 现在你要监控一台服务器的状态，输出监控日志，请问如何将该日志分发到不同的机器上？（消息队列）

  为了便于故障排查，或服务器状态分析，看是否需要维护；可以使用**消息队列**进行消息的分发，例如mqtt、rabitmq等等；

## 压测相关

- 服务器并发量测试过吗？怎么测试的？

  测试过，利用webbench，至少满足万余的并发量。

- webbench是什么？介绍一下原理

  是一款轻量级的网址压力测试工具，可以实现高达3万的并发测试。Webbench实现的核心原理是：父进程fork若干个子进程，每个子进程在用户要求时间或默认的时间内对目标web循环发出实际访问请求，父子进程通过管道进行通信，子进程通过管道写端向父进程传递在若干次请求访问完毕后记录到的总信息，父进程通过管道读端读取子进程发来的相关信息，子进程在时间到后结束，父进程在所有子进程退出后统计并给用户显示最后的测试结果，然后退出。

- 测试的时候有没有遇到问题？

  没有。

## 综合能力

- 你的项目解决了哪些其他同类项目没有解决的问题？

  自己造轮子；

- 说一下前端发送请求后，服务器处理的过程，中间涉及哪些协议？

  HTTP协议、TCP、IP协议等，计算机网络的知识。

- 未整理

  这个项目的性能瓶颈在哪里？

  现在的架构没有缓存，每一次数据请求都是对数据库的访问，当用户量大的时候会造成整体性能下降；至于其他的，脱离业务谈性能有点难以找到切入点，不过你可以研究一下该项目使用的技术有什么缺点，这些缺点就是性能缺陷。


- 这个项目如何处理黏包问题和url的编码格式问题？

  每个连接都有缓冲区，按照行来进行解析，不需要进行粘包处理

- 请问有人知道这个webserv最多支持多少个连接啊？加了定时器的双向链表后能提升多少？面试时被问到过

# 三、项目资料查询

## epoll事件

- EPOLLIN：表示对应的文件描述符**可以读**（包括对端SOCKET正常关闭）

- EPOLLOUT：表示对应的文件描述符**可以写**

- EPOLLPRI：表示对应的文件描述符有**紧急的数据可读**

- EPOLLERR：表示对应的文件描述符**发生错误**

- EPOLLHUP：表示对应的文件描述符**被挂断**；

- EPOLLET：将EPOLL设为**边缘触发(Edge Triggered)模式**，这是相对于水平触发(Level Triggered)而言的

- EPOLLONESHOT：只监听一次事件，当监听完这次事件之后，如果还需要继续监听这个socket的话，需要再次把这个socket加入到EPOLL队列里

- EPOLLRDHUP：表示读关闭，对端关闭，不是所有的内核版本都支持；

- `EPOLLRDHUP` 事件

  现象：明明是对方断开请求，系统却报告一个查询失败的错误，但从用户角度来看请求的结果正常返回，没有任何问题。

  在使用 epoll 时，对端正常断开连接（调用 close()），在服务器端会触发一个 epoll 事件。在低于 2.6.17 版本的内核中，这个 epoll 事件一般是 EPOLLIN，即 0x1，代表连接可读。

  连接池检测到某个连接发生 EPOLLIN 事件且没有错误后，会认为有请求到来，将连接交给上层进行处理。这样一来，上层尝试在对端已经 close() 的连接上读取请求，只能读到 EOF，会认为发生异常，报告一个错误。

  因此在使用 2.6.17 之前版本内核的系统中，我们无法依赖封装 epoll 的底层连接库来实现对对端关闭连接事件的检测，只能通过上层读取数据时进行区分处理。

  在使用 2.6.17 之后版本内核的服务器系统中，对端连接断开触发的 epoll 事件会包含 EPOLLIN | EPOLLRDHUP，即 0x2001。有了这个事件，对端断开连接的异常就可以在底层进行处理了，不用再移交到上层。

  [EPOLL 事件之 EPOLLRDHUP_摩力克的博客-CSDN博客_epoll epollrdhup](https://blog.csdn.net/midion9/article/details/49883063)

- `EPOLLONESHOT` 事件

  一个线程读取某个socket上的数据后开始处理数据，在处理过程中该socket上又有新数据可读，此时另一个线程被唤醒读取，此时出现两个线程处理同一个socket的现象。


- 我们期望的是**一个socket连接在任一时刻都只被一个线程处理**，通过epoll_ctl对该文件描述符注册epolloneshot事件，一个线程处理socket时，其他线程将无法处理，**当该线程处理完后，需要通过epoll_ctl重置epolloneshot事件**。

- `EAGAIN` 错误码

  这个错误经常出现在当应用程序进行一些非阻塞(non-blocking)操作(对文件或socket)的时候。

  如：以 O_NONBLOCK的标志打开文件/socket/FIFO，如果连续做read操作而没有数据可读。此时程序不会阻塞起来等待数据准备就绪返回，read函数会返回一个错误EAGAIN，提示你的应用程序现在没有数据可读请稍后再试。

  又例如，当一个系统调用(比如fork)因为没有足够的资源(比如虚拟内存)而执行失败，返回EAGAIN提示其再调用一次(也许下次就能成功)。

## 静态变量

静态成员就是在成员变量和成员函数前加上关键字static，称为静态成员。

  静态成员分为：

  1. 静态成员变量

     所有对象共享同一份数据

     在编译阶段分配内存

     类内声明，类外初始化
  2. 静态成员函数

     所有对象共享同一个函数

     静态成员函数只能访问静态成员变量

  静态成员变量两种访问方式：

1.  通过对象
2.  通过类名

### 静态成员变量

将类成员变量声明为static，则为静态成员变量，与一般的成员变量不同，无论建立多少对象，都只有一个静态成员变量的拷贝，静态成员变量属于一个类，所有对象共享。静态变量在**编译阶段**就分配了空间，对象还没创建时就已经分配了空间，放到全局静态区。

- 类内声明，类外初始化（以免类名访问静态成员访问不到）；

- 无论公有，私有，静态成员都可以在类外定义，但私有成员仍有访问权限；

- 非静态成员类外不能初始化；

- 静态成员数据是共享的；

### 静态成员函数

将类成员函数声明为static，则为静态成员函数。

- 静态成员函数可以直接访问静态成员变量，不能直接访问普通成员变量，但可以通过参数传递的方式访问；

- 普通成员函数可以访问普通成员变量，也可以访问静态成员变量；
- **静态成员函数没有this指针**。非静态成员为对象单独维护，但静态成员函数为共享函数，无法区分是哪个对象，因此不能直接访问普通变量成员，也没有this指针；

## delete 和 delete[] 的区别

delete 释放new分配的单个对象指针指向的内存；

delete[] 释放new分配的[对象数组](user_cancel)指针指向的内存。

如果str代表的是一个用new申请的内存返回的内存空间地址，即所谓的指针，那么：

对于像 int/char/long/int*/struct 等等简单数据类型，由于对象没有析构函数，所以用delete 和delete [] 是一样的，直接通过指针就可以获取实际分配的内存空间，但是如果是C++对象数组就不同了。

delete  str  代表用来释放内存，且只用来释放str指向的内存，容易造成内存泄漏。仅仅释放了str指针指向的全部内存空间，但是只调用了str[0]对象的析构函数，剩下的从str[1]到str[9]这9个用户自行分配的mc_namek对应内存空间将不能释放，从而造成内存泄漏。

delete[ ]  str  用来释放str指向的内存，还逐一调用数组中每个对象的析构函数。调用使用类对象的析构函数释放用户自己分配的内存空间，并且释放了a指针指向的全部内存空间。

- [deleete和delete[]的具体区别_one-77的博客-CSDN博客](https://blog.csdn.net/gaorutao0923/article/details/97537174)

1. delete 基本数据类型数组
   这种情况使用delete和delete[]效果一样，都把数组内存给释放了。
2. delete 自定义数据类型数组
   这种情况下，使用delete可以释放数组内存，但是只调用数组第一个对象的析构函数，而delete[]不仅释放内存，而且调用了每个数组对象的析构函数。

   delete和delete[]的区别就在于是否调用数组中每个数组对象的析构函数。所以还是遵守new和delete，new[]和delete[]配对的原则来使用。

   - [delete和delete[]区别_Dark_Passion的博客-CSDN博客](https://blog.csdn.net/why_up/article/details/6779862?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_title~default-1.topblog&spm=1001.2101.3001.4242.2&utm_relevant_index=4)

## C++引用

引用相当于变量或对象的别名，因此不能再将已有的引用名作为其他变量或对象的名字或别名

引用不是定义一个新的变量或对象，因此内存不会为引用开辟新的空间存储这个引用

注意：

1. 当用引用作为函数的参数时，其效果和用指针作为函数参数的效果相当。当调用函数时，函数中的形参就会被当成实参变量或对象的一个别名来使用，也就是说此时函数中对形参的各种操作实际上是对实参本身进行操作，而非简单的将实参变量或对象的值拷贝给形参。
2. 通常函数调用时，系统采用值传递的方式将实参变量的值传递给函数的形参变量。此时，系统会在内存中开辟空间用来存储形参变量，并将实参变量的值拷贝给形参变量，也就是说形参变量只是实参变量的副本而已；并且如果函数传递的是类的对象，系统还会调用类中的拷贝构造函数来构造形参对象。而使用引用作为函数的形参时，由于此时形参只是要传递给函数的实参变量或对象的别名而非副本，故系统不会耗费时间来在内存中开辟空间来存储形参。因此如果参数传递的数据较大时，建议使用引用作为函数的形参，这样会提高函数的时间效率，并节省内存空间。
3. 使用指针作为函数的形参虽然达到的效果和使用引用一样，但当调用函数时仍需要为形参指针变量在内存中分配空间，而引用则不需要这样，故在C++中推荐使用引用而非指针作为函数的参数。
4. 如果在编程过程中既希望通过让引用作为函数的参数来提高函数的编程效率，又希望保护传递的参数使其在函数中不被改变，则此时应当使用对常量的引用作为函数的参数，即 const 关键字。
5. 数组的引用作为函数的参数：C++的数组类型是带有长度信息的，引用传递时如果指明的是数组则必须指定数组的长度。

## C++ 模板使用

[C++模板详解 - 小天_y - 博客园 (cnblogs.com)](https://www.cnblogs.com/yyxt/p/4256022.html)

[C++：引用的简单理解 - Tom文星 - 博客园 (cnblogs.com)](https://www.cnblogs.com/duwenxing/p/7421100.html)

## \r,\n,\r\n的区别：回车与换行

[\r,\n,\r\n的区别：回车与换行*古老的屋檐下的博客-CSDN博客*\r](https://blog.csdn.net/liewen_/article/details/89673402)

- 回车、换行的区别：

  在Windows中：‘\r’ (回车)：即将光标回到当前行的行首(而不会换到下一行)，之后的输出会把之前的输出覆盖；‘\n’ 换行，换到当前位置的下一位置，而不会回到行首；

  Unix系统里，每行结尾只有“<换行>”，即"\n"；
  Windows系统里面，每行结尾是“<回车><换行>”，即“\r\n”；
  Mac系统里，每行结尾是“<回车>”，即"\r"；

- 也就是：

`Linux`中遇到换行符("\n")会进行回车+换行的操作，回车符（“\r”）反而只会作为控制字符("^M")显示，不发生回车的操作。而 `windows`中要回车符+换行符("\r\n")才会回车+换行，缺少一个控制符或者顺序不对都不能正确的另起一行。

- 一个直接后果是：

Unix/Mac系统下的文件在Windows里打开的话，所有文字会变成一行；Windows里的文件在Unix/Mac下打开的话，在每行的结尾可能会多出一个^M符号。

- 应用：

在解析字符串，或其他格式的文件内容的时候，经常需要判定回车换行”的地方，这个时候就要注意：既要判定"\r\n"又要判定"\n"。

写程序时可能得到一行，将其进行trim掉’\r’,这样能得到所需要的string了。

\0：字符串结束符

## 几个系统调用

### **stat**

stat函数用于取得指定文件的文件属性，并将文件属性存储在结构体stat里，这里仅对其中用到的成员进行介绍。

```
#include <sys/types.h>
#include <sys/stat.h>
#include <unistd.h>

//获取文件属性，存储在statbuf中
int stat(const char *pathname, struct stat *statbuf);

struct stat 
{
   mode_t    st_mode;        /* 文件类型和权限 */
   off_t     st_size;        /* 文件大小，字节数*/
};
```

### **mmap**

用于将一个文件或其他对象映射到内存，提高文件的访问速度。

```
1void* mmap(void* start,size_t length,int prot,int flags,int fd,off_t offset);
2int munmap(void* start,size_t length);
```



- start：映射区的开始地址，设置为0时表示由系统决定映射区的起始地址
- length：映射区的长度
- prot：期望的内存保护标志，不能与文件的打开模式冲突
- PROT_READ 表示页内容可以被读取
- flags：指定映射对象的类型，映射选项和映射页是否可以共享
- MAP_PRIVATE 建立一个写入时拷贝的私有映射，内存区域的写入不会影响到原文件
- fd：有效的文件描述符，一般是由open()函数返回
- off_toffset：被映射对象内容的起点

### **iovec**

定义了一个向量元素，通常这个结构用作一个多元素的数组。

```
struct iovec {
    void      *iov_base;      /* starting address of buffer */
    size_t    iov_len;        /* size of buffer */
};
```

- iov_base指向数据的地址
- iov_len表示数据的长度

### **writev**

writev函数用于在一次函数调用中写多个非连续缓冲区，有时也将这该函数称为聚集写。

```
#include <sys/uio.h>
ssize_t writev(int filedes, const struct iovec *iov, int iovcnt);
```

- filedes表示文件描述符
- iov为前述io向量机制结构体iovec
- iovcnt为结构体的个数

若成功则返回已写的字节数，若出错则返回-1。`writev`以顺序`iov[0]`，`iov[1]`至`iov[iovcnt-1]`从缓冲区中聚集输出数据。`writev`返回输出的字节总数，通常它应等于所有缓冲区长度之和。

**特别注意：** 循环调用writev时，需要重新处理iovec中的指针和长度，该函数不会对这两个成员做任何处理。writev的返回值为已写的字节数，但这个返回值“实用性”并不高，因为参数传入的是iovec数组，计量单位是iovcnt，而不是字节数，我们仍然需要通过遍历iovec来计算新的基址，另外写入数据的“结束点”可能位于一个iovec的中间某个位置，因此需要调整临界iovec的io_base和io_len。

## 优雅关闭链接

优雅关闭是在结束传输的时候调用`shutdown`函数而不是close/closesocket函数

调用close之后，即便仍有数据未发送，或者发送的数据尚未确认收到，对应的fd也会被销毁，也就是说连接直接中断。
调用shutdown，并且设置了参数SO_LINGER>0（该参数代表延时事件）之后，连接只有超过这个事件，或者发送完数据才会中断。
shutdown()不会销毁fd，它只会关闭字节流，但是会给对方发送FIN信号。

```
shutdown(fd, SHUT_RDWR);
struct linger linger;
linger.l_onoff = 1;
linger.l_linger = 1;
setsockopt(fd, SOL_SOCKET, SO_LINGER, (char *) &linger, sizeof(linger));
close(fd);
```
其中linger是延时结构体：
```
struct linger{
	u_short l_onoff ;//开关，零或者非零 
	u_short l_linger;//优雅关闭最长时限 
};
```

| l_onoff | l_linger |                       closesocket行为                        |                   发送队列                   |                           底层行为                           |
| :-----: | :------: | :----------------------------------------------------------: | :------------------------------------------: | :----------------------------------------------------------: |
|   零    |   忽略   |                           立即返回                           |               保持直至发送完成               |             系统接管套接字并保证将数据发送至对端             |
|  非零   |    零    |                           立即返回                           |                   立即放弃                   | 直接发送RST包，自身立即复位，不用经过2MSL状态；对端收到复位错误号 |
|  非零   |   非零   | 阻塞直到l_linger时间超时或数据发送完成 (套接字必须设置为阻塞) | 在超时时间段内保持尝试发送，若超时则立即放弃 |           超时则同第二种情况，若发送完成则皆大欢喜           |

[优雅关闭是什么_Einskai216的博客-CSDN博客_什么是优雅关闭连接](https://blog.csdn.net/Einskai216/article/details/105334644)

[SO_LINGER实现优雅关闭连接 - unique_ptr - 博客园 (cnblogs.com)](https://www.cnblogs.com/developing/p/10888563.html)

## I/O模型

Unix有**五种基本的IO模型**：

- 阻塞式IO（守株待兔）
- 非阻塞式IO（没有就返回，直到有，其实是一种轮询（polling）操作）
- IO复用（select、poll等，使系统阻塞在select或poll调用上，而不是真正的IO系统调用（如recvfrom），等待select返回可读才调用IO系统，其优势就在于可以等待多个描述符就位）
- 信号驱动式IO（sigio，即利用信号处理函数来通知数据已完备且不阻塞主进程）
- 异步IO（posix的aio_系列函数，与信号驱动的区别在于，信号驱动是内核告诉我们何时可以进行IO，而后者是内核通知何时IO操作已完成）

什么是同步I/O，什么是异步I/O呢？

- 同步（阻塞）I/O：**等待IO操作完成，才能继续进行下一步操作**。这种情况称为同步IO。
- 异步（非阻塞）I/O：当代码执行IO操作时，它只发出IO指令，并不等待IO结果，然后就去执行其他代码了。一段时间后，当IO返回结果时（内核已经完成数据拷贝），再通知CPU进行处理。（异步操作的潜台词就是**你先做，我去忙其他的，你好了再叫我**）

## select/poll/epoll比较

[深入理解Socket网络编程与I/O多路复用 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/418293949)

IO复用需要借助select/poll/epoll，本项目之所以采用epoll，参考问题（[Why is epoll faster than select?](https://link.zhihu.com/?target=https%3A//stackoverflow.com/questions/17355593/why-is-epoll-faster-than-select)）

- 对于select和poll来说，所有文件描述符都是在用户态被加入其文件描述符集合的，**每次调用都需要将整个集合拷贝到内核态**；epoll则将整个文件描述符集合维护在内核态，每次添加文件描述符的时候都需要**执行一个系统调用**。系统调用的开销是很大的，而且在有很多短期活跃连接的情况下，epoll可能会慢于select和poll，由于大量的系统调用开销。
- select使用线性表描述文件描述符集合，**文件描述符有上限**；poll使用**链表**来描述；epoll底层通过**红黑树**来描述，并且维护一个ready list，将事件表中已经就绪的事件添加到这里，在使用epoll_wait调用时，仅观察这个list中有没有数据即可。
- select和poll的最大开销来自内核判断是否有文件描述符就绪这一过程：每次执行select或poll调用时，**它们会采用遍历的方式**，遍历整个文件描述符集合去判断各个文件描述符是否有活动；epoll则不需要去以这种方式检查，当有活动产生时，**会自动触发epoll回调函数通知epoll文件描述符**，然后内核将这些就绪的文件描述符放到之前提到的**ready list中等待epoll_wait调用后被处理**。
- select和poll都只能工作在**相对低效的LT模式下**，而epoll同时支持LT和ET模式。
- 综上，**当监测的fd数量较小**，且各个fd都很活跃的情况下，建议使用select和poll；**当监听的fd数量较多**，且单位时间仅部分fd活跃的情况下，使用epoll会明显提升性能。

# 面经

- 服务端的socket接收缓冲区只剩10个字节，但是客户端发过来一个未经过分片的12个字节的报文。之后客户端和服务端分别会发生什么事情？如果服务端的接收窗口变为0会怎么样？

  [Socket缓冲区_summer_west_fish的博客-CSDN博客](https://blog.csdn.net/summer_fish/article/details/121740570)

  - 如果缓冲区满了，执行 send 会发生什么？

  如果 socket 是阻塞的，那么程序会阻塞等待，直到释放出新的缓存空间，就继续把数据拷贝到接收缓冲区，然后返回。如果 socket 是非阻塞的，程序就会立刻返回一个 EAGAIN 错误信息，说明现在缓冲区满了，待会再试一次。

  - 如果接收缓冲区为空，执行 recv 会发生什么？

  如果 socket 是阻塞的，那么程序会阻塞等待，直到接收缓冲区有数据，就会把数据从接收缓冲区拷贝到用户缓冲区，然后返回。如果 socket 是非阻塞的，程序就会立刻返回一个 EAGAIN 错误信息。

  - 如果socket缓冲区还有数据，执行close了，会怎么样？

  有数据没发出去，内核会把发送缓冲区最后一个数据块拿出来，然后置为 FIN。socket 缓冲区是个先进先出的队列，内核会等待TCP层把发送缓冲区数据都发完，最后再执行四次挥手的第一次挥手（FIN包）。

  - 如果接收缓冲区有数据时，执行close了，会怎么样？

  如果接收缓冲区还有数据未读，会先把接收缓冲区的数据清空，然后给对端发一个RST。

  ![image-20230303110153985](https://gcore.jsdelivr.net/gh/gp868/myFigures/img/image-20230303110153985.png)

